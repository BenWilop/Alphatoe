{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphatoe import models, plot, interpretability, game\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_memlab import LineProfiler, MemReporter\n",
    "from showmethetypes import SMTT\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import LogFormatter\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = SMTT(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = interpretability.load_model(\n",
    "    \"../scripts/models/prob all 8 layer control-20230718-185339\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_csv(\"../data/prob all 8 layer control-20230718-185339_stats.csv\")\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sort games by game length [X]\n",
    "- batch inference for games of length [X]\n",
    "- extract activations with hooks [X]\n",
    "- train autoencoder on data reconstruction (anthropic has tips here) [X]\n",
    "- find good metrics + start looking at data (anthropic has tips here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games = game.generate_all_games([game.Board()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_len_dict = {5: [], 6: [], 7: [], 8: [], 9: []}\n",
    "for game in all_games:\n",
    "    games_len_dict[len(game.moves_played)].append(game.moves_played)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for key in games_len_dict.keys():\n",
    "    s += len(games_len_dict[key])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_len_tensors = {}\n",
    "for key in games_len_dict.keys():\n",
    "    games_len_tensors[key] = torch.stack(\n",
    "        [torch.tensor([10] + game) for game in games_len_dict[key]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_len_tensors.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_len_tensors[9].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation hook\n",
    "def neuron_activations(seq):\n",
    "    def hook(module, input, output):\n",
    "        result = output.clone()\n",
    "        module.captured_activations = result\n",
    "\n",
    "    try:\n",
    "        with torch.inference_mode():\n",
    "            handle = model.blocks[0].mlp.hook_post.register_forward_hook(hook)\n",
    "            _ = model(seq)\n",
    "            activations = model.blocks[0].mlp.hook_post.captured_activations\n",
    "            handle.remove()\n",
    "    except Exception as e:\n",
    "        handle.remove()\n",
    "        raise e\n",
    "\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = neuron_activations(games_len_tensors[5])[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.numel() * a.element_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = neuron_activations(games_len_tensors[9])\n",
    "# reporter = MemReporter()\n",
    "# reporter.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = games_len_tensors[9].shape[0]\n",
    "batchy_size = length // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference loop\n",
    "# will there be a difference across game lengths?\n",
    "# Doesn't fit in memory?\n",
    "# 512 neurons * 255168 games * 32 bit floats * 10 seq len = 5.22 gigabytes???\n",
    "\n",
    "all_acts = []\n",
    "for i, key in enumerate(games_len_tensors.keys()):\n",
    "    print(i)\n",
    "    if games_len_tensors[key].shape[0] < batchy_size:\n",
    "        acts = neuron_activations(games_len_tensors[key])\n",
    "        all_acts.append(acts.to(\"cpu\"))\n",
    "    else:\n",
    "        for j in tqdm.trange(\n",
    "            0, games_len_tensors[key].shape[0], batchy_size, desc=f\"Batch {i}\"\n",
    "        ):\n",
    "            acts = neuron_activations(games_len_tensors[key][j : j + batchy_size])\n",
    "            all_acts.append(acts.to(\"cpu\"))\n",
    "    print(acts.device)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter = MemReporter()\n",
    "reporter.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_len_tensors[9].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for act in all_acts:\n",
    "    tt(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 0\n",
    "for act in all_acts:\n",
    "    out += act.shape[0] * act.shape[1]\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data = torch.cat(\n",
    "    [einops.rearrange(acts, \"batch seq dim -> (batch seq) dim\") for acts in all_acts],\n",
    "    dim=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(act_data, \"all_games_act_data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since there's a lot of repeated phrases in the input, we'll have lots of identical activations. Not sure how that'll change things yet though.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt(act_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc = models.SparseAutoEncoder(512, 1024).to(\"cuda\")\n",
    "\n",
    "loss_fn = torch.nn.functional.mse_loss\n",
    "optimizer = torch.optim.Adam(autoenc.parameters(), lr=1e-4, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data = torch.load(\"all_games_act_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt(act_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = loss_fn(torch.zeros(2,2), torch.ones(2,2), reduction=\"none\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 2**15\n",
    "lam = 1e-7\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    for batch in range(0, act_data.shape[0], batch_size):\n",
    "        dat = act_data[batch : batch + batch_size].to(\"cuda\")\n",
    "        \n",
    "        reg, guess = autoenc(dat)\n",
    "        mse_loss = loss_fn(guess, dat)\n",
    "        \n",
    "        sparse_loss = lam * reg\n",
    "        #sparse_loss = 0\n",
    "        loss = mse_loss + sparse_loss\n",
    "        #losses.append(interpretability.numpy(loss))\n",
    "        losses.append([interpretability.numpy(mse_loss), sparse_loss])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        print(losses[-1])\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            last_loss = loss_fn(guess, dat, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_loss.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yscale(\"log\")\n",
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now we've got an autoencoder, what do we do with it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_freqs(num_batches=25, local_encoder=None):\n",
    "    if local_encoder is None:\n",
    "        local_encoder = encoder\n",
    "    act_freq_scores = torch.zeros(\n",
    "        local_encoder.W_in.shape[1], dtype=torch.float32\n",
    "    ).cuda()\n",
    "    total = 0\n",
    "    for i in tqdm.trange(num_batches):\n",
    "        tokens = act_data[torch.randperm(len(act_data))][: 2**14].to(\"cuda\")\n",
    "\n",
    "        hidden = local_encoder.get_act_density(tokens)\n",
    "\n",
    "        act_freq_scores += hidden\n",
    "        total += tokens.shape[0]\n",
    "    act_freq_scores /= total\n",
    "    num_dead = (act_freq_scores == 0).float().mean()\n",
    "    print(\"Num dead\", num_dead)\n",
    "    return act_freq_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = get_freqs(local_encoder=autoenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freqs[112]*act_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = interpretability.numpy(freqs)*act_data.shape[0];\n",
    "# x = interpretability.numpy(freqs)\n",
    "x = x[np.isfinite(x)];\n",
    "fig, ax = plt.subplots();\n",
    "#set figure size\n",
    "fig.set_size_inches(10, 6);\n",
    "ax.hist(x, bins=np.logspace(np.log10(5), np.log10(10000000), 100));\n",
    "ax.set_xscale(\"log\");\n",
    "#x label\n",
    "#ax.xlabel(\"Number of Moves (log 10 scale)\");\n",
    "#y label\n",
    "#ax.ylabel(\"Count of Features(neuron acts)\");\n",
    "#set xtick and labels of ticks\n",
    "tick_positions = [1, 10, 100, 1000, 10000, 100000, 1000000]\n",
    "tick_labels = ['1', '10', '100', '1k', '10k', '100k', '1M']\n",
    "ax.set_xticks(tick_positions);\n",
    "ax.set_xticklabels(tick_labels);\n",
    "#ax.get_xaxis().set_major_formatter(plt.ScalarFormatter());\n",
    "ax.set_xlabel(\"Number of Times Fired Out of 2,361,456\");\n",
    "ax.set_ylabel(\"Count of Features(neuron acts)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoenc, \"sparse_autoencoder_on_activations_02NOV2023.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
