{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import tqdm\n",
    "#functional\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from functools import partial\n",
    "import einops\n",
    "import circuitsvis as cv\n",
    "from src.game import Board, apply_best_moves, get_best_moves"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor, flat=False):\n",
    "    if type(tensor)!=torch.Tensor:\n",
    "        return tensor\n",
    "    if flat:\n",
    "        return tensor.flatten().detach().cpu().numpy()\n",
    "    else:\n",
    "        return tensor.detach().cpu().numpy()\n",
    "\n",
    "def imshow(tensor, xaxis=None, yaxis=None, animation_name='Snapshot', **kwargs):\n",
    "    tensor = torch.squeeze(tensor)\n",
    "    px.imshow(to_numpy(tensor, flat=False),aspect='auto', \n",
    "              labels={'x':xaxis, 'y':yaxis, 'animation_name':animation_name}, \n",
    "              **kwargs).show()\n",
    "# Set default colour scheme\n",
    "imshow = partial(imshow, color_continuous_scale='Blues')\n",
    "# Creates good defaults for showing divergent colour scales (ie with both \n",
    "# positive and negative values, where 0 is white)\n",
    "imshow_div = partial(imshow, color_continuous_scale='RdBu', color_continuous_midpoint=0.0)\n",
    "# Presets a bunch of defaults to imshow to make it suitable for showing heatmaps \n",
    "# of activations with x axis being input 1 and y axis being input 2.\n",
    "inputs_heatmap = partial(imshow, xaxis='Input 1', yaxis='Input 2', color_continuous_scale='RdBu', color_continuous_midpoint=0.0)\n",
    "\n",
    "def line(x, y=None, hover=None, xaxis='', yaxis='', **kwargs):\n",
    "    if type(y)==torch.Tensor:\n",
    "        y = to_numpy(y, flat=True)\n",
    "    if type(x)==torch.Tensor:\n",
    "        x = to_numpy(x, flat=True)\n",
    "    fig = px.line(x, y=y, hover_name=hover, **kwargs)\n",
    "    fig.update_layout(xaxis_title=xaxis, yaxis_title=yaxis)\n",
    "    fig.show()\n",
    "\n",
    "def lines(lines_list, x=None, mode='lines', labels=None, xaxis='', yaxis='', title = '', log_y=False, hover=None, **kwargs):\n",
    "    if type(lines_list)==torch.Tensor:\n",
    "        lines_list = [lines_list[i] for i in range(lines_list.shape[0])]\n",
    "    if x is None:\n",
    "        x=np.arange(len(lines_list[0]))\n",
    "    fig = go.Figure(layout={'title':title})\n",
    "    fig.update_xaxes(title=xaxis)\n",
    "    fig.update_yaxes(title=yaxis)\n",
    "    for c, line in enumerate(lines_list):\n",
    "        if type(line)==torch.Tensor:\n",
    "            line = to_numpy(line)\n",
    "        if labels is not None:\n",
    "            label = labels[c]\n",
    "        else:\n",
    "            label = c\n",
    "        fig.add_trace(go.Scatter(x=x, y=line, mode=mode, name=label, hovertext=hover, **kwargs))\n",
    "    if log_y:\n",
    "        fig.update_layout(yaxis_type=\"log\")\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Config Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = HookedTransformerConfig(\n",
    "    n_layers = 8,\n",
    "    n_heads = 8,\n",
    "    d_model = 128,\n",
    "    d_head = 16,\n",
    "    d_mlp = 512,\n",
    "    act_fn = \"relu\",\n",
    "    normalization_type=None,\n",
    "    d_vocab=11,\n",
    "    d_vocab_out=10,\n",
    "    n_ctx=10,\n",
    "    init_weights=True,\n",
    "    device=\"cuda\",\n",
    "    seed = 1337,\n",
    ")\n",
    "\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-4\n",
    "test_train_split = 0.8\n",
    "epochs = 1000\n",
    "batch_size = 4096\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np_data = np.load('data/moves.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3584, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = [Board()]\n",
    "game_list = apply_best_moves(boards)\n",
    "moves = np.array([[10] + game.moves_played + [9] for game in game_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3584\n",
      "3584\n",
      "[10  0  4  1  2  6  3  5  7  8]\n",
      "[0 4 1 2 6 3 5 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "#load npy file\n",
    "# np_data = np.load('data/moves.npy')\n",
    "data = moves[:, :-1]\n",
    "labels = moves[:, 1:]\n",
    "\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "print(data[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         ...,\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]]])\n",
      "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "encoded_labels = F.one_hot(t.tensor(labels))\n",
    "print(encoded_labels)\n",
    "print(t.sum(encoded_labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "encoded_data = F.one_hot(t.tensor(data))\n",
    "print(encoded_data[1238])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_labels[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data and labels as numpy arrays\n",
    "data = np.array(data)\n",
    "encoded_labels = np.array(encoded_labels)\n",
    "#data and encoded_labels as tensors\n",
    "data = t.from_numpy(data)\n",
    "encoded_labels = t.from_numpy(encoded_labels).to(t.float)\n",
    "total_data = list(zip(data, encoded_labels))\n",
    "split_data = list(t.utils.data.random_split(total_data, [.8, .2]))\n",
    "train_pairs = split_data[0]\n",
    "test_pairs= split_data[1]\n",
    "train_data, train_labels = zip(*train_pairs)\n",
    "test_data, test_labels = zip(*test_pairs)\n",
    "\n",
    "train_data = t.stack(train_data).to(cfg.device)\n",
    "train_labels = t.stack(train_labels).to(cfg.device)\n",
    "test_data = t.stack(test_data).to(cfg.device)\n",
    "test_labels = t.stack(test_labels).to(cfg.device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test train split\n",
    "train_data = data[:int(len(data)*test_train_split)]\n",
    "train_labels = encoded_labels[:int(len(data)*test_train_split)]\n",
    "test_data = data[int(len(data)*test_train_split):]\n",
    "test_labels = encoded_labels[int(len(data)*test_train_split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716\n",
      "716\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits: Tensor, labels: Tensor):\n",
    "    return t.nn.functional.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3133)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten = t.tensor([0,1]).to(t.float)\n",
    "loss_fn(ten, ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  1,  7,  5,  2,  6,  3,  4,  8,  0], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'board' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_best_moves(board)[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'board' is not defined"
     ]
    }
   ],
   "source": [
    "get_best_moves(board)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-222.5590,  -42.9554,  -87.6360,  -67.9028, -129.8622,  205.6978,\n",
       "          -64.0102, -189.5659,  -65.8357,   -8.7005],\n",
       "        [-341.7577,  -15.9937,  -63.9421,  -57.8569, -102.3532,  210.5430,\n",
       "          -46.0593, -181.4177,  -53.4683,  -26.1564],\n",
       "        [-321.7386,    3.7408,  -52.6238,  -34.5443,  -90.2642,  164.2334,\n",
       "          -31.2029, -159.5603,  -31.1296,  -19.8039],\n",
       "        [-312.9674,   26.2824,  -98.7273,  -28.1300,  -63.2898,  165.7475,\n",
       "          -15.8166, -138.5478,  -13.0268,  -28.9097]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(seq))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [10,0,5,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = Board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| X |   | X |\n",
      "|   |   | O |\n",
      "|   |   |   |\n"
     ]
    }
   ],
   "source": [
    "board.make_move(seq[-1])\n",
    "board.draw_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_is_matched(input: list[int], seq: list[int]) -> bool:\n",
    "    return all(seq[i] == input[i] for i in range(len(seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 0, 1, 7, 3, 5, 2, 6, 8],\n",
       " [4, 0, 1, 7, 3, 5, 6, 2, 8],\n",
       " [4, 0, 1, 7, 3, 5, 8, 2, 6],\n",
       " [4, 0, 1, 7, 3, 5, 8, 6, 2],\n",
       " [4, 0, 1, 7, 5, 3, 6, 2, 8],\n",
       " [4, 0, 1, 7, 6, 2, 3, 5, 8],\n",
       " [4, 0, 1, 7, 6, 2, 5, 3, 8],\n",
       " [4, 0, 1, 7, 6, 2, 8, 3, 5],\n",
       " [4, 0, 1, 7, 6, 2, 8, 5, 3],\n",
       " [4, 0, 1, 7, 8, 2, 3, 5, 6],\n",
       " [4, 0, 1, 7, 8, 2, 5, 3, 6],\n",
       " [4, 0, 1, 7, 8, 2, 6, 3, 5],\n",
       " [4, 0, 1, 7, 8, 2, 6, 5, 3],\n",
       " [4, 0, 1, 7, 8, 3, 6, 2, 5],\n",
       " [4, 0, 1, 7, 8, 5, 2, 6, 3],\n",
       " [4, 0, 1, 7, 8, 5, 3, 2, 6],\n",
       " [4, 0, 1, 7, 8, 5, 3, 6, 2],\n",
       " [4, 0, 1, 7, 8, 5, 6, 2, 3],\n",
       " [4, 0, 1, 7, 8, 6, 3, 5, 2],\n",
       " [4, 0, 2, 6, 3, 5, 1, 7, 8],\n",
       " [4, 0, 2, 6, 3, 5, 7, 1, 8],\n",
       " [4, 0, 2, 6, 3, 5, 8, 1, 7],\n",
       " [4, 0, 2, 6, 3, 5, 8, 7, 1],\n",
       " [4, 0, 3, 5, 1, 7, 2, 6, 8],\n",
       " [4, 0, 3, 5, 1, 7, 6, 2, 8],\n",
       " [4, 0, 3, 5, 1, 7, 8, 2, 6],\n",
       " [4, 0, 3, 5, 1, 7, 8, 6, 2],\n",
       " [4, 0, 3, 5, 2, 6, 1, 7, 8],\n",
       " [4, 0, 3, 5, 2, 6, 7, 1, 8],\n",
       " [4, 0, 3, 5, 2, 6, 8, 1, 7],\n",
       " [4, 0, 3, 5, 2, 6, 8, 7, 1],\n",
       " [4, 0, 3, 5, 7, 1, 2, 6, 8],\n",
       " [4, 0, 3, 5, 8, 1, 2, 6, 7],\n",
       " [4, 0, 3, 5, 8, 2, 1, 7, 6],\n",
       " [4, 0, 3, 5, 8, 6, 1, 7, 2],\n",
       " [4, 0, 3, 5, 8, 6, 2, 1, 7],\n",
       " [4, 0, 3, 5, 8, 6, 2, 7, 1],\n",
       " [4, 0, 3, 5, 8, 6, 7, 1, 2],\n",
       " [4, 0, 3, 5, 8, 7, 1, 2, 6],\n",
       " [4, 0, 3, 5, 8, 7, 1, 6, 2],\n",
       " [4, 0, 3, 5, 8, 7, 2, 6, 1],\n",
       " [4, 0, 3, 5, 8, 7, 6, 2, 1],\n",
       " [4, 0, 5, 3, 6, 2, 1, 7, 8],\n",
       " [4, 0, 6, 2, 1, 7, 3, 5, 8],\n",
       " [4, 0, 6, 2, 1, 7, 5, 3, 8],\n",
       " [4, 0, 6, 2, 1, 7, 8, 3, 5],\n",
       " [4, 0, 6, 2, 1, 7, 8, 5, 3],\n",
       " [4, 0, 7, 1, 2, 6, 3, 5, 8],\n",
       " [4, 0, 8, 2, 1, 7, 3, 5, 6],\n",
       " [4, 0, 8, 2, 1, 7, 5, 3, 6],\n",
       " [4, 0, 8, 2, 1, 7, 6, 3, 5],\n",
       " [4, 0, 8, 2, 1, 7, 6, 5, 3],\n",
       " [4, 0, 8, 6, 3, 5, 1, 7, 2],\n",
       " [4, 0, 8, 6, 3, 5, 2, 1, 7],\n",
       " [4, 0, 8, 6, 3, 5, 2, 7, 1],\n",
       " [4, 0, 8, 6, 3, 5, 7, 1, 2],\n",
       " [4, 2, 0, 8, 5, 3, 1, 7, 6],\n",
       " [4, 2, 0, 8, 5, 3, 6, 1, 7],\n",
       " [4, 2, 0, 8, 5, 3, 6, 7, 1],\n",
       " [4, 2, 0, 8, 5, 3, 7, 1, 6],\n",
       " [4, 2, 1, 7, 3, 5, 8, 0, 6],\n",
       " [4, 2, 1, 7, 5, 3, 0, 8, 6],\n",
       " [4, 2, 1, 7, 5, 3, 6, 0, 8],\n",
       " [4, 2, 1, 7, 5, 3, 6, 8, 0],\n",
       " [4, 2, 1, 7, 5, 3, 8, 0, 6],\n",
       " [4, 2, 1, 7, 6, 0, 3, 5, 8],\n",
       " [4, 2, 1, 7, 6, 0, 5, 3, 8],\n",
       " [4, 2, 1, 7, 6, 0, 8, 3, 5],\n",
       " [4, 2, 1, 7, 6, 0, 8, 5, 3],\n",
       " [4, 2, 1, 7, 6, 3, 0, 8, 5],\n",
       " [4, 2, 1, 7, 6, 3, 5, 0, 8],\n",
       " [4, 2, 1, 7, 6, 3, 5, 8, 0],\n",
       " [4, 2, 1, 7, 6, 3, 8, 0, 5],\n",
       " [4, 2, 1, 7, 6, 5, 8, 0, 3],\n",
       " [4, 2, 1, 7, 6, 8, 5, 3, 0],\n",
       " [4, 2, 1, 7, 8, 0, 3, 5, 6],\n",
       " [4, 2, 1, 7, 8, 0, 5, 3, 6],\n",
       " [4, 2, 1, 7, 8, 0, 6, 3, 5],\n",
       " [4, 2, 1, 7, 8, 0, 6, 5, 3],\n",
       " [4, 2, 3, 5, 8, 0, 1, 7, 6],\n",
       " [4, 2, 5, 3, 0, 8, 1, 7, 6],\n",
       " [4, 2, 5, 3, 0, 8, 6, 1, 7],\n",
       " [4, 2, 5, 3, 0, 8, 6, 7, 1],\n",
       " [4, 2, 5, 3, 0, 8, 7, 1, 6],\n",
       " [4, 2, 5, 3, 1, 7, 0, 8, 6],\n",
       " [4, 2, 5, 3, 1, 7, 6, 0, 8],\n",
       " [4, 2, 5, 3, 1, 7, 6, 8, 0],\n",
       " [4, 2, 5, 3, 1, 7, 8, 0, 6],\n",
       " [4, 2, 5, 3, 6, 0, 1, 7, 8],\n",
       " [4, 2, 5, 3, 6, 1, 0, 8, 7],\n",
       " [4, 2, 5, 3, 6, 7, 0, 8, 1],\n",
       " [4, 2, 5, 3, 6, 7, 1, 0, 8],\n",
       " [4, 2, 5, 3, 6, 7, 1, 8, 0],\n",
       " [4, 2, 5, 3, 6, 7, 8, 0, 1],\n",
       " [4, 2, 5, 3, 6, 8, 0, 1, 7],\n",
       " [4, 2, 5, 3, 6, 8, 0, 7, 1],\n",
       " [4, 2, 5, 3, 6, 8, 1, 7, 0],\n",
       " [4, 2, 5, 3, 6, 8, 7, 1, 0],\n",
       " [4, 2, 5, 3, 7, 1, 0, 8, 6],\n",
       " [4, 2, 6, 0, 1, 7, 3, 5, 8],\n",
       " [4, 2, 6, 0, 1, 7, 5, 3, 8],\n",
       " [4, 2, 6, 0, 1, 7, 8, 3, 5],\n",
       " [4, 2, 6, 0, 1, 7, 8, 5, 3],\n",
       " [4, 2, 6, 8, 5, 3, 0, 1, 7],\n",
       " [4, 2, 6, 8, 5, 3, 0, 7, 1],\n",
       " [4, 2, 6, 8, 5, 3, 1, 7, 0],\n",
       " [4, 2, 6, 8, 5, 3, 7, 1, 0],\n",
       " [4, 2, 7, 1, 0, 8, 5, 3, 6],\n",
       " [4, 2, 8, 0, 1, 7, 3, 5, 6],\n",
       " [4, 2, 8, 0, 1, 7, 5, 3, 6],\n",
       " [4, 2, 8, 0, 1, 7, 6, 3, 5],\n",
       " [4, 2, 8, 0, 1, 7, 6, 5, 3],\n",
       " [4, 6, 0, 8, 7, 1, 2, 3, 5],\n",
       " [4, 6, 0, 8, 7, 1, 2, 5, 3],\n",
       " [4, 6, 0, 8, 7, 1, 3, 5, 2],\n",
       " [4, 6, 0, 8, 7, 1, 5, 3, 2],\n",
       " [4, 6, 1, 7, 8, 0, 3, 5, 2],\n",
       " [4, 6, 2, 0, 3, 5, 1, 7, 8],\n",
       " [4, 6, 2, 0, 3, 5, 7, 1, 8],\n",
       " [4, 6, 2, 0, 3, 5, 8, 1, 7],\n",
       " [4, 6, 2, 0, 3, 5, 8, 7, 1],\n",
       " [4, 6, 2, 8, 7, 1, 0, 3, 5],\n",
       " [4, 6, 2, 8, 7, 1, 0, 5, 3],\n",
       " [4, 6, 2, 8, 7, 1, 3, 5, 0],\n",
       " [4, 6, 2, 8, 7, 1, 5, 3, 0],\n",
       " [4, 6, 3, 5, 1, 7, 8, 0, 2],\n",
       " [4, 6, 3, 5, 2, 0, 1, 7, 8],\n",
       " [4, 6, 3, 5, 2, 0, 7, 1, 8],\n",
       " [4, 6, 3, 5, 2, 0, 8, 1, 7],\n",
       " [4, 6, 3, 5, 2, 0, 8, 7, 1],\n",
       " [4, 6, 3, 5, 2, 1, 0, 8, 7],\n",
       " [4, 6, 3, 5, 2, 1, 7, 0, 8],\n",
       " [4, 6, 3, 5, 2, 1, 7, 8, 0],\n",
       " [4, 6, 3, 5, 2, 1, 8, 0, 7],\n",
       " [4, 6, 3, 5, 2, 7, 8, 0, 1],\n",
       " [4, 6, 3, 5, 2, 8, 7, 1, 0],\n",
       " [4, 6, 3, 5, 7, 1, 0, 8, 2],\n",
       " [4, 6, 3, 5, 7, 1, 2, 0, 8],\n",
       " [4, 6, 3, 5, 7, 1, 2, 8, 0],\n",
       " [4, 6, 3, 5, 7, 1, 8, 0, 2],\n",
       " [4, 6, 3, 5, 8, 0, 1, 7, 2],\n",
       " [4, 6, 3, 5, 8, 0, 2, 1, 7],\n",
       " [4, 6, 3, 5, 8, 0, 2, 7, 1],\n",
       " [4, 6, 3, 5, 8, 0, 7, 1, 2],\n",
       " [4, 6, 5, 3, 0, 8, 7, 1, 2],\n",
       " [4, 6, 7, 1, 0, 8, 2, 3, 5],\n",
       " [4, 6, 7, 1, 0, 8, 2, 5, 3],\n",
       " [4, 6, 7, 1, 0, 8, 3, 5, 2],\n",
       " [4, 6, 7, 1, 0, 8, 5, 3, 2],\n",
       " [4, 6, 7, 1, 2, 0, 3, 5, 8],\n",
       " [4, 6, 7, 1, 2, 3, 0, 8, 5],\n",
       " [4, 6, 7, 1, 2, 5, 0, 8, 3],\n",
       " [4, 6, 7, 1, 2, 5, 3, 0, 8],\n",
       " [4, 6, 7, 1, 2, 5, 3, 8, 0],\n",
       " [4, 6, 7, 1, 2, 5, 8, 0, 3],\n",
       " [4, 6, 7, 1, 2, 8, 0, 3, 5],\n",
       " [4, 6, 7, 1, 2, 8, 0, 5, 3],\n",
       " [4, 6, 7, 1, 2, 8, 3, 5, 0],\n",
       " [4, 6, 7, 1, 2, 8, 5, 3, 0],\n",
       " [4, 6, 7, 1, 3, 5, 0, 8, 2],\n",
       " [4, 6, 7, 1, 3, 5, 2, 0, 8],\n",
       " [4, 6, 7, 1, 3, 5, 2, 8, 0],\n",
       " [4, 6, 7, 1, 3, 5, 8, 0, 2],\n",
       " [4, 6, 7, 1, 5, 3, 0, 8, 2],\n",
       " [4, 6, 8, 0, 3, 5, 1, 7, 2],\n",
       " [4, 6, 8, 0, 3, 5, 2, 1, 7],\n",
       " [4, 6, 8, 0, 3, 5, 2, 7, 1],\n",
       " [4, 6, 8, 0, 3, 5, 7, 1, 2],\n",
       " [4, 8, 0, 2, 5, 3, 1, 7, 6],\n",
       " [4, 8, 0, 2, 5, 3, 6, 1, 7],\n",
       " [4, 8, 0, 2, 5, 3, 6, 7, 1],\n",
       " [4, 8, 0, 2, 5, 3, 7, 1, 6],\n",
       " [4, 8, 0, 6, 7, 1, 2, 3, 5],\n",
       " [4, 8, 0, 6, 7, 1, 2, 5, 3],\n",
       " [4, 8, 0, 6, 7, 1, 3, 5, 2],\n",
       " [4, 8, 0, 6, 7, 1, 5, 3, 2],\n",
       " [4, 8, 1, 7, 6, 2, 5, 3, 0],\n",
       " [4, 8, 2, 6, 7, 1, 0, 3, 5],\n",
       " [4, 8, 2, 6, 7, 1, 0, 5, 3],\n",
       " [4, 8, 2, 6, 7, 1, 3, 5, 0],\n",
       " [4, 8, 2, 6, 7, 1, 5, 3, 0],\n",
       " [4, 8, 3, 5, 2, 6, 7, 1, 0],\n",
       " [4, 8, 5, 3, 0, 1, 2, 6, 7],\n",
       " [4, 8, 5, 3, 0, 1, 6, 2, 7],\n",
       " [4, 8, 5, 3, 0, 1, 7, 2, 6],\n",
       " [4, 8, 5, 3, 0, 1, 7, 6, 2],\n",
       " [4, 8, 5, 3, 0, 2, 1, 7, 6],\n",
       " [4, 8, 5, 3, 0, 2, 6, 1, 7],\n",
       " [4, 8, 5, 3, 0, 2, 6, 7, 1],\n",
       " [4, 8, 5, 3, 0, 2, 7, 1, 6],\n",
       " [4, 8, 5, 3, 0, 6, 7, 1, 2],\n",
       " [4, 8, 5, 3, 0, 7, 6, 2, 1],\n",
       " [4, 8, 5, 3, 1, 7, 6, 2, 0],\n",
       " [4, 8, 5, 3, 6, 2, 0, 1, 7],\n",
       " [4, 8, 5, 3, 6, 2, 0, 7, 1],\n",
       " [4, 8, 5, 3, 6, 2, 1, 7, 0],\n",
       " [4, 8, 5, 3, 6, 2, 7, 1, 0],\n",
       " [4, 8, 5, 3, 7, 1, 0, 2, 6],\n",
       " [4, 8, 5, 3, 7, 1, 0, 6, 2],\n",
       " [4, 8, 5, 3, 7, 1, 2, 6, 0],\n",
       " [4, 8, 5, 3, 7, 1, 6, 2, 0],\n",
       " [4, 8, 6, 2, 5, 3, 0, 1, 7],\n",
       " [4, 8, 6, 2, 5, 3, 0, 7, 1],\n",
       " [4, 8, 6, 2, 5, 3, 1, 7, 0],\n",
       " [4, 8, 6, 2, 5, 3, 7, 1, 0],\n",
       " [4, 8, 7, 1, 0, 2, 5, 3, 6],\n",
       " [4, 8, 7, 1, 0, 3, 2, 6, 5],\n",
       " [4, 8, 7, 1, 0, 3, 5, 2, 6],\n",
       " [4, 8, 7, 1, 0, 3, 5, 6, 2],\n",
       " [4, 8, 7, 1, 0, 3, 6, 2, 5],\n",
       " [4, 8, 7, 1, 0, 5, 2, 6, 3],\n",
       " [4, 8, 7, 1, 0, 6, 2, 3, 5],\n",
       " [4, 8, 7, 1, 0, 6, 2, 5, 3],\n",
       " [4, 8, 7, 1, 0, 6, 3, 5, 2],\n",
       " [4, 8, 7, 1, 0, 6, 5, 3, 2],\n",
       " [4, 8, 7, 1, 2, 6, 0, 3, 5],\n",
       " [4, 8, 7, 1, 2, 6, 0, 5, 3],\n",
       " [4, 8, 7, 1, 2, 6, 3, 5, 0],\n",
       " [4, 8, 7, 1, 2, 6, 5, 3, 0],\n",
       " [4, 8, 7, 1, 3, 5, 2, 6, 0],\n",
       " [4, 8, 7, 1, 5, 3, 0, 2, 6],\n",
       " [4, 8, 7, 1, 5, 3, 0, 6, 2],\n",
       " [4, 8, 7, 1, 5, 3, 2, 6, 0],\n",
       " [4, 8, 7, 1, 5, 3, 6, 2, 0]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[seq for seq in seqs if seq_is_matched(seq, [4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 4, 1, 2, 6, 3, 5, 7, 8],\n",
       " [0, 4, 1, 2, 6, 3, 5, 8, 7],\n",
       " [0, 4, 2, 1, 7, 3, 5, 8, 6],\n",
       " [0, 4, 2, 1, 7, 5, 3, 6, 8],\n",
       " [0, 4, 2, 1, 7, 6, 3, 5, 8],\n",
       " [0, 4, 2, 1, 7, 6, 3, 8, 5],\n",
       " [0, 4, 2, 1, 7, 6, 5, 8, 3],\n",
       " [0, 4, 2, 1, 7, 6, 8, 5, 3],\n",
       " [0, 4, 2, 1, 7, 8, 3, 6, 5],\n",
       " [0, 4, 2, 1, 7, 8, 5, 3, 6],\n",
       " [0, 4, 2, 1, 7, 8, 5, 6, 3],\n",
       " [0, 4, 2, 1, 7, 8, 6, 3, 5],\n",
       " [0, 4, 3, 6, 2, 1, 7, 5, 8],\n",
       " [0, 4, 3, 6, 2, 1, 7, 8, 5],\n",
       " [0, 4, 5, 1, 7, 6, 2, 8, 3],\n",
       " [0, 4, 5, 1, 7, 8, 2, 3, 6],\n",
       " [0, 4, 5, 1, 7, 8, 2, 6, 3],\n",
       " [0, 4, 5, 1, 7, 8, 3, 6, 2],\n",
       " [0, 4, 5, 1, 7, 8, 6, 3, 2],\n",
       " [0, 4, 5, 2, 6, 3, 1, 7, 8],\n",
       " [0, 4, 5, 2, 6, 3, 1, 8, 7],\n",
       " [0, 4, 5, 2, 6, 3, 7, 8, 1],\n",
       " [0, 4, 5, 2, 6, 3, 8, 7, 1],\n",
       " [0, 4, 5, 7, 1, 2, 6, 3, 8],\n",
       " [0, 4, 5, 8, 1, 2, 6, 3, 7],\n",
       " [0, 4, 5, 8, 2, 1, 7, 3, 6],\n",
       " [0, 4, 5, 8, 2, 1, 7, 6, 3],\n",
       " [0, 4, 5, 8, 6, 3, 1, 2, 7],\n",
       " [0, 4, 5, 8, 6, 3, 2, 1, 7],\n",
       " [0, 4, 5, 8, 6, 3, 7, 1, 2],\n",
       " [0, 4, 5, 8, 6, 3, 7, 2, 1],\n",
       " [0, 4, 5, 8, 7, 1, 2, 3, 6],\n",
       " [0, 4, 5, 8, 7, 1, 2, 6, 3],\n",
       " [0, 4, 5, 8, 7, 1, 3, 6, 2],\n",
       " [0, 4, 5, 8, 7, 1, 6, 3, 2],\n",
       " [0, 4, 5, 8, 7, 2, 6, 3, 1],\n",
       " [0, 4, 5, 8, 7, 3, 1, 2, 6],\n",
       " [0, 4, 5, 8, 7, 3, 2, 1, 6],\n",
       " [0, 4, 5, 8, 7, 3, 6, 1, 2],\n",
       " [0, 4, 5, 8, 7, 3, 6, 2, 1],\n",
       " [0, 4, 5, 8, 7, 6, 2, 1, 3],\n",
       " [0, 4, 6, 3, 5, 1, 7, 8, 2],\n",
       " [0, 4, 6, 3, 5, 2, 1, 7, 8],\n",
       " [0, 4, 6, 3, 5, 2, 1, 8, 7],\n",
       " [0, 4, 6, 3, 5, 2, 7, 8, 1],\n",
       " [0, 4, 6, 3, 5, 2, 8, 7, 1],\n",
       " [0, 4, 6, 3, 5, 7, 1, 2, 8],\n",
       " [0, 4, 6, 3, 5, 8, 1, 2, 7],\n",
       " [0, 4, 6, 3, 5, 8, 2, 1, 7],\n",
       " [0, 4, 6, 3, 5, 8, 7, 1, 2],\n",
       " [0, 4, 6, 3, 5, 8, 7, 2, 1],\n",
       " [0, 4, 7, 3, 5, 2, 6, 8, 1],\n",
       " [0, 4, 7, 3, 5, 8, 1, 2, 6],\n",
       " [0, 4, 7, 3, 5, 8, 2, 1, 6],\n",
       " [0, 4, 7, 3, 5, 8, 6, 1, 2],\n",
       " [0, 4, 7, 3, 5, 8, 6, 2, 1],\n",
       " [0, 4, 7, 5, 3, 6, 2, 1, 8],\n",
       " [0, 4, 7, 6, 2, 1, 3, 5, 8],\n",
       " [0, 4, 7, 6, 2, 1, 3, 8, 5],\n",
       " [0, 4, 7, 6, 2, 1, 5, 8, 3],\n",
       " [0, 4, 7, 6, 2, 1, 8, 5, 3],\n",
       " [0, 4, 7, 8, 2, 1, 3, 6, 5],\n",
       " [0, 4, 7, 8, 2, 1, 5, 3, 6],\n",
       " [0, 4, 7, 8, 2, 1, 5, 6, 3],\n",
       " [0, 4, 7, 8, 2, 1, 6, 3, 5],\n",
       " [0, 4, 7, 8, 3, 6, 2, 1, 5],\n",
       " [0, 4, 7, 8, 5, 1, 2, 3, 6],\n",
       " [0, 4, 7, 8, 5, 1, 2, 6, 3],\n",
       " [0, 4, 7, 8, 5, 1, 3, 6, 2],\n",
       " [0, 4, 7, 8, 5, 1, 6, 3, 2],\n",
       " [0, 4, 7, 8, 5, 2, 6, 3, 1],\n",
       " [0, 4, 7, 8, 5, 3, 1, 2, 6],\n",
       " [0, 4, 7, 8, 5, 3, 2, 1, 6],\n",
       " [0, 4, 7, 8, 5, 3, 6, 1, 2],\n",
       " [0, 4, 7, 8, 5, 3, 6, 2, 1],\n",
       " [0, 4, 7, 8, 5, 6, 2, 1, 3],\n",
       " [0, 4, 7, 8, 6, 3, 5, 1, 2],\n",
       " [0, 4, 7, 8, 6, 3, 5, 2, 1],\n",
       " [0, 4, 8, 1, 7, 6, 2, 5, 3],\n",
       " [0, 4, 8, 3, 5, 2, 6, 7, 1],\n",
       " [0, 4, 8, 5, 3, 6, 2, 1, 7],\n",
       " [0, 4, 8, 7, 1, 2, 6, 3, 5],\n",
       " [1, 0, 3, 4, 8, 2, 6, 7, 5],\n",
       " [1, 0, 3, 4, 8, 5, 2, 6, 7],\n",
       " [1, 0, 3, 4, 8, 5, 2, 7, 6],\n",
       " [1, 0, 3, 4, 8, 5, 6, 7, 2],\n",
       " [1, 0, 3, 4, 8, 5, 7, 6, 2],\n",
       " [1, 0, 3, 4, 8, 6, 2, 5, 7],\n",
       " [1, 0, 3, 4, 8, 7, 2, 5, 6],\n",
       " [1, 0, 3, 4, 8, 7, 5, 2, 6],\n",
       " [1, 0, 3, 4, 8, 7, 6, 2, 5],\n",
       " [1, 0, 3, 4, 8, 7, 6, 5, 2],\n",
       " [1, 0, 3, 5, 2, 4, 8, 6, 7],\n",
       " [1, 0, 3, 5, 2, 4, 8, 7, 6],\n",
       " [1, 0, 3, 5, 2, 6, 4, 7, 8],\n",
       " [1, 0, 3, 5, 2, 6, 7, 4, 8],\n",
       " [1, 0, 3, 5, 2, 6, 8, 4, 7],\n",
       " [1, 0, 3, 5, 2, 6, 8, 7, 4],\n",
       " [1, 0, 3, 5, 2, 7, 4, 6, 8],\n",
       " [1, 0, 3, 5, 2, 7, 6, 4, 8],\n",
       " [1, 0, 3, 5, 2, 7, 8, 4, 6],\n",
       " [1, 0, 3, 5, 2, 7, 8, 6, 4],\n",
       " [1, 0, 3, 5, 4, 7, 2, 6, 8],\n",
       " [1, 0, 3, 5, 4, 7, 6, 2, 8],\n",
       " [1, 0, 3, 5, 4, 7, 8, 2, 6],\n",
       " [1, 0, 3, 5, 4, 7, 8, 6, 2],\n",
       " [1, 0, 3, 5, 7, 4, 8, 6, 2],\n",
       " [1, 0, 3, 5, 8, 4, 2, 6, 7],\n",
       " [1, 0, 3, 5, 8, 4, 2, 7, 6],\n",
       " [1, 0, 3, 5, 8, 4, 6, 7, 2],\n",
       " [1, 0, 3, 5, 8, 4, 7, 6, 2],\n",
       " [1, 0, 3, 5, 8, 6, 2, 4, 7],\n",
       " [1, 0, 3, 5, 8, 6, 2, 7, 4],\n",
       " [1, 0, 3, 5, 8, 6, 4, 7, 2],\n",
       " [1, 0, 3, 5, 8, 6, 7, 4, 2],\n",
       " [1, 0, 3, 5, 8, 7, 2, 4, 6],\n",
       " [1, 0, 3, 5, 8, 7, 2, 6, 4],\n",
       " [1, 0, 3, 5, 8, 7, 4, 2, 6],\n",
       " [1, 0, 3, 5, 8, 7, 4, 6, 2],\n",
       " [1, 0, 3, 5, 8, 7, 6, 2, 4],\n",
       " [1, 0, 3, 5, 8, 7, 6, 4, 2],\n",
       " [1, 0, 3, 7, 4, 5, 2, 6, 8],\n",
       " [1, 0, 3, 7, 4, 5, 6, 2, 8],\n",
       " [1, 0, 3, 7, 4, 5, 8, 2, 6],\n",
       " [1, 0, 3, 7, 4, 5, 8, 6, 2],\n",
       " [1, 0, 3, 7, 5, 4, 8, 2, 6],\n",
       " [1, 0, 3, 7, 6, 2, 4, 5, 8],\n",
       " [1, 0, 3, 7, 6, 2, 5, 4, 8],\n",
       " [1, 0, 3, 7, 6, 2, 8, 4, 5],\n",
       " [1, 0, 3, 7, 6, 2, 8, 5, 4],\n",
       " [1, 0, 3, 7, 6, 4, 8, 2, 5],\n",
       " [1, 0, 3, 7, 6, 4, 8, 5, 2],\n",
       " [1, 0, 3, 7, 6, 5, 2, 4, 8],\n",
       " [1, 0, 3, 7, 6, 5, 4, 2, 8],\n",
       " [1, 0, 3, 7, 6, 5, 8, 2, 4],\n",
       " [1, 0, 3, 7, 6, 5, 8, 4, 2],\n",
       " [1, 0, 3, 7, 8, 2, 4, 5, 6],\n",
       " [1, 0, 3, 7, 8, 2, 5, 4, 6],\n",
       " [1, 0, 3, 7, 8, 2, 6, 4, 5],\n",
       " [1, 0, 3, 7, 8, 2, 6, 5, 4],\n",
       " [1, 0, 3, 7, 8, 4, 2, 5, 6],\n",
       " [1, 0, 3, 7, 8, 4, 5, 2, 6],\n",
       " [1, 0, 3, 7, 8, 4, 6, 2, 5],\n",
       " [1, 0, 3, 7, 8, 4, 6, 5, 2],\n",
       " [1, 0, 3, 7, 8, 5, 2, 4, 6],\n",
       " [1, 0, 3, 7, 8, 5, 2, 6, 4],\n",
       " [1, 0, 3, 7, 8, 5, 4, 2, 6],\n",
       " [1, 0, 3, 7, 8, 5, 4, 6, 2],\n",
       " [1, 0, 3, 7, 8, 5, 6, 2, 4],\n",
       " [1, 0, 3, 7, 8, 5, 6, 4, 2],\n",
       " [1, 0, 4, 7, 3, 5, 2, 6, 8],\n",
       " [1, 0, 4, 7, 3, 5, 6, 2, 8],\n",
       " [1, 0, 4, 7, 3, 5, 8, 2, 6],\n",
       " [1, 0, 4, 7, 3, 5, 8, 6, 2],\n",
       " [1, 0, 4, 7, 5, 3, 6, 2, 8],\n",
       " [1, 0, 4, 7, 6, 2, 3, 5, 8],\n",
       " [1, 0, 4, 7, 6, 2, 5, 3, 8],\n",
       " [1, 0, 4, 7, 6, 2, 8, 3, 5],\n",
       " [1, 0, 4, 7, 6, 2, 8, 5, 3],\n",
       " [1, 0, 4, 7, 8, 2, 3, 5, 6],\n",
       " [1, 0, 4, 7, 8, 2, 5, 3, 6],\n",
       " [1, 0, 4, 7, 8, 2, 6, 3, 5],\n",
       " [1, 0, 4, 7, 8, 2, 6, 5, 3],\n",
       " [1, 0, 4, 7, 8, 3, 6, 2, 5],\n",
       " [1, 0, 4, 7, 8, 5, 2, 6, 3],\n",
       " [1, 0, 4, 7, 8, 5, 3, 2, 6],\n",
       " [1, 0, 4, 7, 8, 5, 3, 6, 2],\n",
       " [1, 0, 4, 7, 8, 5, 6, 2, 3],\n",
       " [1, 0, 4, 7, 8, 6, 3, 5, 2],\n",
       " [1, 0, 6, 4, 8, 7, 2, 5, 3],\n",
       " [1, 0, 6, 4, 8, 7, 3, 2, 5],\n",
       " [1, 0, 6, 4, 8, 7, 3, 5, 2],\n",
       " [1, 0, 6, 4, 8, 7, 5, 2, 3],\n",
       " [1, 0, 6, 7, 2, 4, 8, 5, 3],\n",
       " [1, 0, 6, 7, 3, 2, 4, 5, 8],\n",
       " [1, 0, 6, 7, 3, 2, 5, 4, 8],\n",
       " [1, 0, 6, 7, 3, 2, 8, 4, 5],\n",
       " [1, 0, 6, 7, 3, 2, 8, 5, 4],\n",
       " [1, 0, 6, 7, 3, 4, 8, 2, 5],\n",
       " [1, 0, 6, 7, 3, 4, 8, 5, 2],\n",
       " [1, 0, 6, 7, 3, 5, 2, 4, 8],\n",
       " [1, 0, 6, 7, 3, 5, 4, 2, 8],\n",
       " [1, 0, 6, 7, 3, 5, 8, 2, 4],\n",
       " [1, 0, 6, 7, 3, 5, 8, 4, 2],\n",
       " [1, 0, 6, 7, 4, 2, 3, 5, 8],\n",
       " [1, 0, 6, 7, 4, 2, 5, 3, 8],\n",
       " [1, 0, 6, 7, 4, 2, 8, 3, 5],\n",
       " [1, 0, 6, 7, 4, 2, 8, 5, 3],\n",
       " [1, 0, 6, 7, 5, 2, 3, 4, 8],\n",
       " [1, 0, 6, 7, 5, 2, 4, 3, 8],\n",
       " [1, 0, 6, 7, 5, 2, 8, 3, 4],\n",
       " [1, 0, 6, 7, 5, 2, 8, 4, 3],\n",
       " [1, 0, 6, 7, 5, 4, 8, 2, 3],\n",
       " [1, 0, 6, 7, 8, 2, 3, 4, 5],\n",
       " [1, 0, 6, 7, 8, 2, 3, 5, 4],\n",
       " [1, 0, 6, 7, 8, 2, 4, 3, 5],\n",
       " [1, 0, 6, 7, 8, 2, 4, 5, 3],\n",
       " [1, 0, 6, 7, 8, 2, 5, 3, 4],\n",
       " [1, 0, 6, 7, 8, 2, 5, 4, 3],\n",
       " [1, 0, 6, 7, 8, 4, 2, 5, 3],\n",
       " [1, 0, 6, 7, 8, 4, 3, 2, 5],\n",
       " [1, 0, 6, 7, 8, 4, 3, 5, 2],\n",
       " [1, 0, 6, 7, 8, 4, 5, 2, 3],\n",
       " [1, 0, 6, 7, 8, 5, 2, 4, 3],\n",
       " [1, 0, 6, 7, 8, 5, 3, 2, 4],\n",
       " [1, 0, 6, 7, 8, 5, 3, 4, 2],\n",
       " [1, 0, 6, 7, 8, 5, 4, 2, 3],\n",
       " [1, 0, 8, 4, 2, 5, 3, 6, 7],\n",
       " [1, 0, 8, 4, 2, 5, 3, 7, 6],\n",
       " [1, 0, 8, 4, 3, 2, 6, 7, 5],\n",
       " [1, 0, 8, 4, 3, 5, 2, 6, 7],\n",
       " [1, 0, 8, 4, 3, 5, 2, 7, 6],\n",
       " [1, 0, 8, 4, 3, 5, 6, 7, 2],\n",
       " [1, 0, 8, 4, 3, 5, 7, 6, 2],\n",
       " [1, 0, 8, 4, 3, 6, 2, 5, 7],\n",
       " [1, 0, 8, 4, 3, 7, 2, 5, 6],\n",
       " [1, 0, 8, 4, 3, 7, 5, 2, 6],\n",
       " [1, 0, 8, 4, 3, 7, 6, 2, 5],\n",
       " [1, 0, 8, 4, 3, 7, 6, 5, 2],\n",
       " [1, 0, 8, 4, 5, 2, 6, 7, 3],\n",
       " [1, 0, 8, 4, 6, 7, 2, 5, 3],\n",
       " [1, 0, 8, 4, 6, 7, 3, 2, 5],\n",
       " [1, 0, 8, 4, 6, 7, 3, 5, 2],\n",
       " [1, 0, 8, 4, 6, 7, 5, 2, 3],\n",
       " [1, 0, 8, 6, 3, 4, 2, 5, 7],\n",
       " [1, 0, 8, 6, 3, 5, 2, 4, 7],\n",
       " [1, 0, 8, 6, 3, 5, 2, 7, 4],\n",
       " [1, 0, 8, 6, 3, 5, 4, 7, 2],\n",
       " [1, 0, 8, 6, 3, 5, 7, 4, 2],\n",
       " [1, 0, 8, 7, 2, 5, 3, 4, 6],\n",
       " [1, 0, 8, 7, 2, 5, 3, 6, 4],\n",
       " [1, 0, 8, 7, 2, 5, 4, 6, 3],\n",
       " [1, 0, 8, 7, 2, 5, 6, 4, 3],\n",
       " [1, 0, 8, 7, 3, 2, 4, 5, 6],\n",
       " [1, 0, 8, 7, 3, 2, 5, 4, 6],\n",
       " [1, 0, 8, 7, 3, 2, 6, 4, 5],\n",
       " [1, 0, 8, 7, 3, 2, 6, 5, 4],\n",
       " [1, 0, 8, 7, 3, 4, 2, 5, 6],\n",
       " [1, 0, 8, 7, 3, 4, 5, 2, 6],\n",
       " [1, 0, 8, 7, 3, 4, 6, 2, 5],\n",
       " [1, 0, 8, 7, 3, 4, 6, 5, 2],\n",
       " [1, 0, 8, 7, 3, 5, 2, 4, 6],\n",
       " [1, 0, 8, 7, 3, 5, 2, 6, 4],\n",
       " [1, 0, 8, 7, 3, 5, 4, 2, 6],\n",
       " [1, 0, 8, 7, 3, 5, 4, 6, 2],\n",
       " [1, 0, 8, 7, 3, 5, 6, 2, 4],\n",
       " [1, 0, 8, 7, 3, 5, 6, 4, 2],\n",
       " [1, 0, 8, 7, 4, 2, 3, 5, 6],\n",
       " [1, 0, 8, 7, 4, 2, 5, 3, 6],\n",
       " [1, 0, 8, 7, 4, 2, 6, 3, 5],\n",
       " [1, 0, 8, 7, 4, 2, 6, 5, 3],\n",
       " [1, 0, 8, 7, 4, 3, 6, 2, 5],\n",
       " [1, 0, 8, 7, 4, 5, 2, 6, 3],\n",
       " [1, 0, 8, 7, 4, 5, 3, 2, 6],\n",
       " [1, 0, 8, 7, 4, 5, 3, 6, 2],\n",
       " [1, 0, 8, 7, 4, 5, 6, 2, 3],\n",
       " [1, 0, 8, 7, 4, 6, 3, 5, 2],\n",
       " [1, 0, 8, 7, 5, 2, 3, 4, 6],\n",
       " [1, 0, 8, 7, 5, 2, 4, 3, 6],\n",
       " [1, 0, 8, 7, 5, 2, 6, 3, 4],\n",
       " [1, 0, 8, 7, 5, 2, 6, 4, 3],\n",
       " [1, 0, 8, 7, 6, 2, 3, 4, 5],\n",
       " [1, 0, 8, 7, 6, 2, 3, 5, 4],\n",
       " [1, 0, 8, 7, 6, 2, 4, 3, 5],\n",
       " [1, 0, 8, 7, 6, 2, 4, 5, 3],\n",
       " [1, 0, 8, 7, 6, 2, 5, 3, 4],\n",
       " [1, 0, 8, 7, 6, 2, 5, 4, 3],\n",
       " [1, 0, 8, 7, 6, 4, 2, 5, 3],\n",
       " [1, 0, 8, 7, 6, 4, 3, 2, 5],\n",
       " [1, 0, 8, 7, 6, 4, 3, 5, 2],\n",
       " [1, 0, 8, 7, 6, 4, 5, 2, 3],\n",
       " [1, 0, 8, 7, 6, 5, 2, 4, 3],\n",
       " [1, 0, 8, 7, 6, 5, 3, 2, 4],\n",
       " [1, 0, 8, 7, 6, 5, 3, 4, 2],\n",
       " [1, 0, 8, 7, 6, 5, 4, 2, 3],\n",
       " [1, 2, 4, 7, 3, 5, 8, 0, 6],\n",
       " [1, 2, 4, 7, 5, 3, 0, 8, 6],\n",
       " [1, 2, 4, 7, 5, 3, 6, 0, 8],\n",
       " [1, 2, 4, 7, 5, 3, 6, 8, 0],\n",
       " [1, 2, 4, 7, 5, 3, 8, 0, 6],\n",
       " [1, 2, 4, 7, 6, 0, 3, 5, 8],\n",
       " [1, 2, 4, 7, 6, 0, 5, 3, 8],\n",
       " [1, 2, 4, 7, 6, 0, 8, 3, 5],\n",
       " [1, 2, 4, 7, 6, 0, 8, 5, 3],\n",
       " [1, 2, 4, 7, 6, 3, 0, 8, 5],\n",
       " [1, 2, 4, 7, 6, 3, 5, 0, 8],\n",
       " [1, 2, 4, 7, 6, 3, 5, 8, 0],\n",
       " [1, 2, 4, 7, 6, 3, 8, 0, 5],\n",
       " [1, 2, 4, 7, 6, 5, 8, 0, 3],\n",
       " [1, 2, 4, 7, 6, 8, 5, 3, 0],\n",
       " [1, 2, 4, 7, 8, 0, 3, 5, 6],\n",
       " [1, 2, 4, 7, 8, 0, 5, 3, 6],\n",
       " [1, 2, 4, 7, 8, 0, 6, 3, 5],\n",
       " [1, 2, 4, 7, 8, 0, 6, 5, 3],\n",
       " [1, 2, 5, 3, 0, 4, 6, 7, 8],\n",
       " [1, 2, 5, 3, 0, 4, 6, 8, 7],\n",
       " [1, 2, 5, 3, 0, 7, 4, 8, 6],\n",
       " [1, 2, 5, 3, 0, 7, 6, 4, 8],\n",
       " [1, 2, 5, 3, 0, 7, 6, 8, 4],\n",
       " [1, 2, 5, 3, 0, 7, 8, 4, 6],\n",
       " [1, 2, 5, 3, 0, 8, 4, 7, 6],\n",
       " [1, 2, 5, 3, 0, 8, 6, 4, 7],\n",
       " [1, 2, 5, 3, 0, 8, 6, 7, 4],\n",
       " [1, 2, 5, 3, 0, 8, 7, 4, 6],\n",
       " [1, 2, 5, 3, 4, 7, 0, 8, 6],\n",
       " [1, 2, 5, 3, 4, 7, 6, 0, 8],\n",
       " [1, 2, 5, 3, 4, 7, 6, 8, 0],\n",
       " [1, 2, 5, 3, 4, 7, 8, 0, 6],\n",
       " [1, 2, 5, 3, 6, 4, 0, 7, 8],\n",
       " [1, 2, 5, 3, 6, 4, 0, 8, 7],\n",
       " [1, 2, 5, 3, 6, 4, 7, 8, 0],\n",
       " [1, 2, 5, 3, 6, 4, 8, 7, 0],\n",
       " [1, 2, 5, 3, 6, 7, 0, 4, 8],\n",
       " [1, 2, 5, 3, 6, 7, 0, 8, 4],\n",
       " [1, 2, 5, 3, 6, 7, 4, 0, 8],\n",
       " [1, 2, 5, 3, 6, 7, 4, 8, 0],\n",
       " [1, 2, 5, 3, 6, 7, 8, 0, 4],\n",
       " [1, 2, 5, 3, 6, 7, 8, 4, 0],\n",
       " [1, 2, 5, 3, 6, 8, 0, 4, 7],\n",
       " [1, 2, 5, 3, 6, 8, 0, 7, 4],\n",
       " [1, 2, 5, 3, 6, 8, 4, 7, 0],\n",
       " [1, 2, 5, 3, 6, 8, 7, 4, 0],\n",
       " [1, 2, 5, 3, 7, 4, 6, 8, 0],\n",
       " [1, 2, 5, 4, 6, 0, 8, 7, 3],\n",
       " [1, 2, 5, 4, 6, 3, 0, 7, 8],\n",
       " [1, 2, 5, 4, 6, 3, 0, 8, 7],\n",
       " [1, 2, 5, 4, 6, 3, 7, 8, 0],\n",
       " [1, 2, 5, 4, 6, 3, 8, 7, 0],\n",
       " [1, 2, 5, 4, 6, 7, 0, 3, 8],\n",
       " [1, 2, 5, 4, 6, 7, 3, 0, 8],\n",
       " [1, 2, 5, 4, 6, 7, 8, 0, 3],\n",
       " [1, 2, 5, 4, 6, 7, 8, 3, 0],\n",
       " [1, 2, 5, 4, 6, 8, 0, 3, 7],\n",
       " [1, 2, 5, 7, 3, 4, 6, 0, 8],\n",
       " [1, 2, 5, 7, 4, 3, 0, 8, 6],\n",
       " [1, 2, 5, 7, 4, 3, 6, 0, 8],\n",
       " [1, 2, 5, 7, 4, 3, 6, 8, 0],\n",
       " [1, 2, 5, 7, 4, 3, 8, 0, 6],\n",
       " [1, 2, 5, 7, 6, 0, 3, 4, 8],\n",
       " [1, 2, 5, 7, 6, 0, 4, 3, 8],\n",
       " [1, 2, 5, 7, 6, 0, 8, 3, 4],\n",
       " [1, 2, 5, 7, 6, 0, 8, 4, 3],\n",
       " [1, 2, 5, 7, 6, 3, 0, 4, 8],\n",
       " [1, 2, 5, 7, 6, 3, 0, 8, 4],\n",
       " [1, 2, 5, 7, 6, 3, 4, 0, 8],\n",
       " [1, 2, 5, 7, 6, 3, 4, 8, 0],\n",
       " [1, 2, 5, 7, 6, 3, 8, 0, 4],\n",
       " [1, 2, 5, 7, 6, 3, 8, 4, 0],\n",
       " [1, 2, 5, 7, 6, 4, 0, 3, 8],\n",
       " [1, 2, 5, 7, 6, 4, 3, 0, 8],\n",
       " [1, 2, 5, 7, 6, 4, 8, 0, 3],\n",
       " [1, 2, 5, 7, 6, 4, 8, 3, 0],\n",
       " [1, 2, 5, 7, 8, 0, 3, 4, 6],\n",
       " [1, 2, 5, 7, 8, 0, 4, 3, 6],\n",
       " [1, 2, 5, 7, 8, 0, 6, 3, 4],\n",
       " [1, 2, 5, 7, 8, 0, 6, 4, 3],\n",
       " [1, 2, 5, 7, 8, 3, 0, 4, 6],\n",
       " [1, 2, 5, 7, 8, 3, 4, 0, 6],\n",
       " [1, 2, 5, 7, 8, 3, 6, 0, 4],\n",
       " [1, 2, 5, 7, 8, 3, 6, 4, 0],\n",
       " [1, 2, 5, 7, 8, 4, 6, 0, 3],\n",
       " [1, 2, 5, 7, 8, 4, 6, 3, 0],\n",
       " [1, 2, 6, 4, 0, 3, 5, 7, 8],\n",
       " [1, 2, 6, 4, 0, 3, 5, 8, 7],\n",
       " [1, 2, 6, 4, 3, 0, 8, 7, 5],\n",
       " [1, 2, 6, 4, 5, 0, 8, 7, 3],\n",
       " [1, 2, 6, 4, 5, 3, 0, 7, 8],\n",
       " [1, 2, 6, 4, 5, 3, 0, 8, 7],\n",
       " [1, 2, 6, 4, 5, 3, 7, 8, 0],\n",
       " [1, 2, 6, 4, 5, 3, 8, 7, 0],\n",
       " [1, 2, 6, 4, 5, 7, 0, 3, 8],\n",
       " [1, 2, 6, 4, 5, 7, 3, 0, 8],\n",
       " [1, 2, 6, 4, 5, 7, 8, 0, 3],\n",
       " [1, 2, 6, 4, 5, 7, 8, 3, 0],\n",
       " [1, 2, 6, 4, 5, 8, 0, 3, 7],\n",
       " [1, 2, 6, 4, 8, 7, 0, 3, 5],\n",
       " [1, 2, 6, 4, 8, 7, 3, 0, 5],\n",
       " [1, 2, 6, 4, 8, 7, 5, 0, 3],\n",
       " [1, 2, 6, 4, 8, 7, 5, 3, 0],\n",
       " [1, 2, 6, 7, 0, 3, 4, 8, 5],\n",
       " [1, 2, 6, 7, 0, 3, 5, 4, 8],\n",
       " [1, 2, 6, 7, 0, 3, 5, 8, 4],\n",
       " [1, 2, 6, 7, 0, 3, 8, 4, 5],\n",
       " [1, 2, 6, 7, 3, 0, 4, 5, 8],\n",
       " [1, 2, 6, 7, 3, 0, 5, 4, 8],\n",
       " [1, 2, 6, 7, 3, 0, 8, 4, 5],\n",
       " [1, 2, 6, 7, 3, 0, 8, 5, 4],\n",
       " [1, 2, 6, 7, 4, 0, 3, 5, 8],\n",
       " [1, 2, 6, 7, 4, 0, 5, 3, 8],\n",
       " [1, 2, 6, 7, 4, 0, 8, 3, 5],\n",
       " [1, 2, 6, 7, 4, 0, 8, 5, 3],\n",
       " [1, 2, 6, 7, 4, 3, 0, 8, 5],\n",
       " [1, 2, 6, 7, 4, 3, 5, 0, 8],\n",
       " [1, 2, 6, 7, 4, 3, 5, 8, 0],\n",
       " [1, 2, 6, 7, 4, 3, 8, 0, 5],\n",
       " [1, 2, 6, 7, 4, 5, 8, 0, 3],\n",
       " [1, 2, 6, 7, 4, 8, 5, 3, 0],\n",
       " [1, 2, 6, 7, 5, 0, 3, 4, 8],\n",
       " [1, 2, 6, 7, 5, 0, 4, 3, 8],\n",
       " [1, 2, 6, 7, 5, 0, 8, 3, 4],\n",
       " [1, 2, 6, 7, 5, 0, 8, 4, 3],\n",
       " [1, 2, 6, 7, 5, 3, 0, 4, 8],\n",
       " [1, 2, 6, 7, 5, 3, 0, 8, 4],\n",
       " [1, 2, 6, 7, 5, 3, 4, 0, 8],\n",
       " [1, 2, 6, 7, 5, 3, 4, 8, 0],\n",
       " [1, 2, 6, 7, 5, 3, 8, 0, 4],\n",
       " [1, 2, 6, 7, 5, 3, 8, 4, 0],\n",
       " [1, 2, 6, 7, 5, 4, 0, 3, 8],\n",
       " [1, 2, 6, 7, 5, 4, 3, 0, 8],\n",
       " [1, 2, 6, 7, 5, 4, 8, 0, 3],\n",
       " [1, 2, 6, 7, 5, 4, 8, 3, 0],\n",
       " [1, 2, 6, 7, 8, 0, 3, 4, 5],\n",
       " [1, 2, 6, 7, 8, 0, 3, 5, 4],\n",
       " [1, 2, 6, 7, 8, 0, 4, 3, 5],\n",
       " [1, 2, 6, 7, 8, 0, 4, 5, 3],\n",
       " [1, 2, 6, 7, 8, 0, 5, 3, 4],\n",
       " [1, 2, 6, 7, 8, 0, 5, 4, 3],\n",
       " [1, 2, 6, 7, 8, 3, 0, 4, 5],\n",
       " [1, 2, 6, 7, 8, 3, 4, 0, 5],\n",
       " [1, 2, 6, 7, 8, 3, 5, 0, 4],\n",
       " [1, 2, 6, 7, 8, 3, 5, 4, 0],\n",
       " [1, 2, 6, 7, 8, 4, 0, 3, 5],\n",
       " [1, 2, 6, 7, 8, 4, 3, 0, 5],\n",
       " [1, 2, 6, 7, 8, 4, 5, 0, 3],\n",
       " [1, 2, 6, 7, 8, 4, 5, 3, 0],\n",
       " [1, 2, 6, 8, 5, 3, 0, 4, 7],\n",
       " [1, 2, 6, 8, 5, 3, 0, 7, 4],\n",
       " [1, 2, 6, 8, 5, 3, 4, 7, 0],\n",
       " [1, 2, 6, 8, 5, 3, 7, 4, 0],\n",
       " [1, 2, 6, 8, 5, 4, 0, 3, 7],\n",
       " [1, 2, 8, 4, 6, 7, 0, 3, 5],\n",
       " [1, 2, 8, 4, 6, 7, 3, 0, 5],\n",
       " [1, 2, 8, 4, 6, 7, 5, 0, 3],\n",
       " [1, 2, 8, 4, 6, 7, 5, 3, 0],\n",
       " [1, 2, 8, 7, 0, 4, 6, 3, 5],\n",
       " [1, 2, 8, 7, 3, 0, 4, 5, 6],\n",
       " [1, 2, 8, 7, 3, 0, 5, 4, 6],\n",
       " [1, 2, 8, 7, 3, 0, 6, 4, 5],\n",
       " [1, 2, 8, 7, 3, 0, 6, 5, 4],\n",
       " [1, 2, 8, 7, 3, 4, 6, 0, 5],\n",
       " [1, 2, 8, 7, 4, 0, 3, 5, 6],\n",
       " [1, 2, 8, 7, 4, 0, 5, 3, 6],\n",
       " [1, 2, 8, 7, 4, 0, 6, 3, 5],\n",
       " [1, 2, 8, 7, 4, 0, 6, 5, 3],\n",
       " [1, 2, 8, 7, 5, 0, 3, 4, 6],\n",
       " [1, 2, 8, 7, 5, 0, 4, 3, 6],\n",
       " [1, 2, 8, 7, 5, 0, 6, 3, 4],\n",
       " [1, 2, 8, 7, 5, 0, 6, 4, 3],\n",
       " [1, 2, 8, 7, 5, 3, 0, 4, 6],\n",
       " [1, 2, 8, 7, 5, 3, 4, 0, 6],\n",
       " [1, 2, 8, 7, 5, 3, 6, 0, 4],\n",
       " [1, 2, 8, 7, 5, 3, 6, 4, 0],\n",
       " [1, 2, 8, 7, 5, 4, 6, 0, 3],\n",
       " [1, 2, 8, 7, 5, 4, 6, 3, 0],\n",
       " [1, 2, 8, 7, 6, 0, 3, 4, 5],\n",
       " [1, 2, 8, 7, 6, 0, 3, 5, 4],\n",
       " [1, 2, 8, 7, 6, 0, 4, 3, 5],\n",
       " [1, 2, 8, 7, 6, 0, 4, 5, 3],\n",
       " [1, 2, 8, 7, 6, 0, 5, 3, 4],\n",
       " [1, 2, 8, 7, 6, 0, 5, 4, 3],\n",
       " [1, 2, 8, 7, 6, 3, 0, 4, 5],\n",
       " [1, 2, 8, 7, 6, 3, 4, 0, 5],\n",
       " [1, 2, 8, 7, 6, 3, 5, 0, 4],\n",
       " [1, 2, 8, 7, 6, 3, 5, 4, 0],\n",
       " [1, 2, 8, 7, 6, 4, 0, 3, 5],\n",
       " [1, 2, 8, 7, 6, 4, 3, 0, 5],\n",
       " [1, 2, 8, 7, 6, 4, 5, 0, 3],\n",
       " [1, 2, 8, 7, 6, 4, 5, 3, 0],\n",
       " [1, 4, 0, 2, 6, 3, 5, 7, 8],\n",
       " [1, 4, 0, 2, 6, 3, 5, 8, 7],\n",
       " [1, 4, 2, 0, 8, 5, 3, 6, 7],\n",
       " [1, 4, 2, 0, 8, 5, 3, 7, 6],\n",
       " [1, 4, 3, 0, 8, 2, 6, 7, 5],\n",
       " [1, 4, 3, 0, 8, 5, 2, 6, 7],\n",
       " [1, 4, 3, 0, 8, 5, 2, 7, 6],\n",
       " [1, 4, 3, 0, 8, 5, 6, 7, 2],\n",
       " [1, 4, 3, 0, 8, 5, 7, 6, 2],\n",
       " [1, 4, 3, 0, 8, 6, 2, 5, 7],\n",
       " [1, 4, 3, 0, 8, 7, 2, 5, 6],\n",
       " [1, 4, 3, 0, 8, 7, 5, 2, 6],\n",
       " [1, 4, 3, 0, 8, 7, 6, 2, 5],\n",
       " [1, 4, 3, 0, 8, 7, 6, 5, 2],\n",
       " [1, 4, 3, 2, 6, 0, 8, 7, 5],\n",
       " [1, 4, 3, 6, 2, 0, 8, 5, 7],\n",
       " [1, 4, 5, 0, 8, 2, 6, 7, 3],\n",
       " [1, 4, 5, 2, 6, 0, 8, 7, 3],\n",
       " [1, 4, 5, 2, 6, 3, 0, 7, 8],\n",
       " [1, 4, 5, 2, 6, 3, 0, 8, 7],\n",
       " [1, 4, 5, 2, 6, 3, 7, 8, 0],\n",
       " [1, 4, 5, 2, 6, 3, 8, 7, 0],\n",
       " [1, 4, 5, 2, 6, 7, 0, 3, 8],\n",
       " [1, 4, 5, 2, 6, 7, 3, 0, 8],\n",
       " [1, 4, 5, 2, 6, 7, 8, 0, 3],\n",
       " [1, 4, 5, 2, 6, 7, 8, 3, 0],\n",
       " [1, 4, 5, 2, 6, 8, 0, 3, 7],\n",
       " [1, 4, 5, 8, 0, 2, 6, 3, 7],\n",
       " [1, 4, 6, 0, 8, 7, 2, 5, 3],\n",
       " [1, 4, 6, 0, 8, 7, 3, 2, 5],\n",
       " [1, 4, 6, 0, 8, 7, 3, 5, 2],\n",
       " [1, 4, 6, 0, 8, 7, 5, 2, 3],\n",
       " [1, 4, 6, 2, 0, 3, 5, 7, 8],\n",
       " [1, 4, 6, 2, 0, 3, 5, 8, 7],\n",
       " [1, 4, 6, 2, 3, 0, 8, 7, 5],\n",
       " [1, 4, 6, 2, 5, 0, 8, 7, 3],\n",
       " [1, 4, 6, 2, 5, 3, 0, 7, 8],\n",
       " [1, 4, 6, 2, 5, 3, 0, 8, 7],\n",
       " [1, 4, 6, 2, 5, 3, 7, 8, 0],\n",
       " [1, 4, 6, 2, 5, 3, 8, 7, 0],\n",
       " [1, 4, 6, 2, 5, 7, 0, 3, 8],\n",
       " [1, 4, 6, 2, 5, 7, 3, 0, 8],\n",
       " [1, 4, 6, 2, 5, 7, 8, 0, 3],\n",
       " [1, 4, 6, 2, 5, 7, 8, 3, 0],\n",
       " [1, 4, 6, 2, 5, 8, 0, 3, 7],\n",
       " [1, 4, 6, 2, 8, 7, 0, 3, 5],\n",
       " [1, 4, 6, 2, 8, 7, 3, 0, 5],\n",
       " [1, 4, 6, 2, 8, 7, 5, 0, 3],\n",
       " [1, 4, 6, 2, 8, 7, 5, 3, 0],\n",
       " [1, 4, 6, 3, 5, 2, 0, 7, 8],\n",
       " [1, 4, 6, 3, 5, 2, 0, 8, 7],\n",
       " [1, 4, 6, 3, 5, 2, 7, 8, 0],\n",
       " [1, 4, 6, 3, 5, 2, 8, 7, 0],\n",
       " [1, 4, 6, 3, 5, 8, 0, 2, 7],\n",
       " [1, 4, 6, 5, 3, 0, 8, 7, 2],\n",
       " [1, 4, 8, 0, 2, 5, 3, 6, 7],\n",
       " [1, 4, 8, 0, 2, 5, 3, 7, 6],\n",
       " [1, 4, 8, 0, 3, 2, 6, 7, 5],\n",
       " [1, 4, 8, 0, 3, 5, 2, 6, 7],\n",
       " [1, 4, 8, 0, 3, 5, 2, 7, 6],\n",
       " [1, 4, 8, 0, 3, 5, 6, 7, 2],\n",
       " [1, 4, 8, 0, 3, 5, 7, 6, 2],\n",
       " [1, 4, 8, 0, 3, 6, 2, 5, 7],\n",
       " [1, 4, 8, 0, 3, 7, 2, 5, 6],\n",
       " [1, 4, 8, 0, 3, 7, 5, 2, 6],\n",
       " [1, 4, 8, 0, 3, 7, 6, 2, 5],\n",
       " [1, 4, 8, 0, 3, 7, 6, 5, 2],\n",
       " [1, 4, 8, 0, 5, 2, 6, 7, 3],\n",
       " [1, 4, 8, 0, 6, 7, 2, 5, 3],\n",
       " [1, 4, 8, 0, 6, 7, 3, 2, 5],\n",
       " [1, 4, 8, 0, 6, 7, 3, 5, 2],\n",
       " [1, 4, 8, 0, 6, 7, 5, 2, 3],\n",
       " [1, 4, 8, 2, 6, 7, 0, 3, 5],\n",
       " [1, 4, 8, 2, 6, 7, 3, 0, 5],\n",
       " [1, 4, 8, 2, 6, 7, 5, 0, 3],\n",
       " [1, 4, 8, 2, 6, 7, 5, 3, 0],\n",
       " [1, 4, 8, 3, 5, 2, 6, 7, 0],\n",
       " [1, 4, 8, 5, 3, 0, 2, 6, 7],\n",
       " [1, 4, 8, 5, 3, 0, 2, 7, 6],\n",
       " [1, 4, 8, 5, 3, 0, 6, 7, 2],\n",
       " [1, 4, 8, 5, 3, 0, 7, 6, 2],\n",
       " [1, 4, 8, 5, 3, 6, 2, 0, 7],\n",
       " [1, 7, 0, 2, 6, 3, 4, 8, 5],\n",
       " [1, 7, 0, 2, 6, 3, 5, 4, 8],\n",
       " [1, 7, 0, 2, 6, 3, 5, 8, 4],\n",
       " [1, 7, 0, 2, 6, 3, 8, 4, 5],\n",
       " [1, 7, 0, 2, 8, 4, 6, 3, 5],\n",
       " [1, 7, 2, 0, 6, 4, 8, 5, 3],\n",
       " [1, 7, 2, 0, 8, 5, 3, 4, 6],\n",
       " [1, 7, 2, 0, 8, 5, 3, 6, 4],\n",
       " [1, 7, 2, 0, 8, 5, 4, 6, 3],\n",
       " [1, 7, 2, 0, 8, 5, 6, 4, 3],\n",
       " [1, 7, 3, 0, 4, 5, 2, 6, 8],\n",
       " [1, 7, 3, 0, 4, 5, 6, 2, 8],\n",
       " [1, 7, 3, 0, 4, 5, 8, 2, 6],\n",
       " [1, 7, 3, 0, 4, 5, 8, 6, 2],\n",
       " [1, 7, 3, 0, 5, 4, 8, 2, 6],\n",
       " [1, 7, 3, 0, 6, 2, 4, 5, 8],\n",
       " [1, 7, 3, 0, 6, 2, 5, 4, 8],\n",
       " [1, 7, 3, 0, 6, 2, 8, 4, 5],\n",
       " [1, 7, 3, 0, 6, 2, 8, 5, 4],\n",
       " [1, 7, 3, 0, 6, 4, 8, 2, 5],\n",
       " [1, 7, 3, 0, 6, 4, 8, 5, 2],\n",
       " [1, 7, 3, 0, 6, 5, 2, 4, 8],\n",
       " [1, 7, 3, 0, 6, 5, 4, 2, 8],\n",
       " [1, 7, 3, 0, 6, 5, 8, 2, 4],\n",
       " [1, 7, 3, 0, 6, 5, 8, 4, 2],\n",
       " [1, 7, 3, 0, 8, 2, 4, 5, 6],\n",
       " [1, 7, 3, 0, 8, 2, 5, 4, 6],\n",
       " [1, 7, 3, 0, 8, 2, 6, 4, 5],\n",
       " [1, 7, 3, 0, 8, 2, 6, 5, 4],\n",
       " [1, 7, 3, 0, 8, 4, 2, 5, 6],\n",
       " [1, 7, 3, 0, 8, 4, 5, 2, 6],\n",
       " [1, 7, 3, 0, 8, 4, 6, 2, 5],\n",
       " [1, 7, 3, 0, 8, 4, 6, 5, 2],\n",
       " [1, 7, 3, 0, 8, 5, 2, 4, 6],\n",
       " [1, 7, 3, 0, 8, 5, 2, 6, 4],\n",
       " [1, 7, 3, 0, 8, 5, 4, 2, 6],\n",
       " [1, 7, 3, 0, 8, 5, 4, 6, 2],\n",
       " [1, 7, 3, 0, 8, 5, 6, 2, 4],\n",
       " [1, 7, 3, 0, 8, 5, 6, 4, 2],\n",
       " [1, 7, 3, 2, 4, 5, 8, 0, 6],\n",
       " [1, 7, 3, 2, 5, 4, 6, 0, 8],\n",
       " [1, 7, 3, 2, 6, 0, 4, 5, 8],\n",
       " [1, 7, 3, 2, 6, 0, 5, 4, 8],\n",
       " [1, 7, 3, 2, 6, 0, 8, 4, 5],\n",
       " [1, 7, 3, 2, 6, 0, 8, 5, 4],\n",
       " [1, 7, 3, 2, 8, 0, 4, 5, 6],\n",
       " [1, 7, 3, 2, 8, 0, 5, 4, 6],\n",
       " [1, 7, 3, 2, 8, 0, 6, 4, 5],\n",
       " [1, 7, 3, 2, 8, 0, 6, 5, 4],\n",
       " [1, 7, 3, 2, 8, 4, 6, 0, 5],\n",
       " [1, 7, 4, 0, 3, 5, 2, 6, 8],\n",
       " [1, 7, 4, 0, 3, 5, 6, 2, 8],\n",
       " [1, 7, 4, 0, 3, 5, 8, 2, 6],\n",
       " [1, 7, 4, 0, 3, 5, 8, 6, 2],\n",
       " [1, 7, 4, 0, 5, 3, 6, 2, 8],\n",
       " [1, 7, 4, 0, 6, 2, 3, 5, 8],\n",
       " [1, 7, 4, 0, 6, 2, 5, 3, 8],\n",
       " [1, 7, 4, 0, 6, 2, 8, 3, 5],\n",
       " [1, 7, 4, 0, 6, 2, 8, 5, 3],\n",
       " [1, 7, 4, 0, 8, 2, 3, 5, 6],\n",
       " [1, 7, 4, 0, 8, 2, 5, 3, 6],\n",
       " [1, 7, 4, 0, 8, 2, 6, 3, 5],\n",
       " [1, 7, 4, 0, 8, 2, 6, 5, 3],\n",
       " [1, 7, 4, 0, 8, 3, 6, 2, 5],\n",
       " [1, 7, 4, 0, 8, 5, 2, 6, 3],\n",
       " [1, 7, 4, 0, 8, 5, 3, 2, 6],\n",
       " [1, 7, 4, 0, 8, 5, 3, 6, 2],\n",
       " [1, 7, 4, 0, 8, 5, 6, 2, 3],\n",
       " [1, 7, 4, 0, 8, 6, 3, 5, 2],\n",
       " [1, 7, 4, 2, 3, 5, 8, 0, 6],\n",
       " [1, 7, 4, 2, 5, 3, 0, 8, 6],\n",
       " [1, 7, 4, 2, 5, 3, 6, 0, 8],\n",
       " [1, 7, 4, 2, 5, 3, 6, 8, 0],\n",
       " [1, 7, 4, 2, 5, 3, 8, 0, 6],\n",
       " [1, 7, 4, 2, 6, 0, 3, 5, 8],\n",
       " [1, 7, 4, 2, 6, 0, 5, 3, 8],\n",
       " [1, 7, 4, 2, 6, 0, 8, 3, 5],\n",
       " [1, 7, 4, 2, 6, 0, 8, 5, 3],\n",
       " [1, 7, 4, 2, 6, 3, 0, 8, 5],\n",
       " [1, 7, 4, 2, 6, 3, 5, 0, 8],\n",
       " [1, 7, 4, 2, 6, 3, 5, 8, 0],\n",
       " [1, 7, 4, 2, 6, 3, 8, 0, 5],\n",
       " [1, 7, 4, 2, 6, 5, 8, 0, 3],\n",
       " [1, 7, 4, 2, 6, 8, 5, 3, 0],\n",
       " [1, 7, 4, 2, 8, 0, 3, 5, 6],\n",
       " [1, 7, 4, 2, 8, 0, 5, 3, 6],\n",
       " [1, 7, 4, 2, 8, 0, 6, 3, 5],\n",
       " [1, 7, 4, 2, 8, 0, 6, 5, 3],\n",
       " [1, 7, 4, 6, 8, 0, 3, 5, 2],\n",
       " [1, 7, 4, 8, 6, 2, 5, 3, 0],\n",
       " [1, 7, 5, 0, 3, 4, 8, 2, 6],\n",
       " [1, 7, 5, 0, 4, 3, 6, 2, 8],\n",
       " [1, 7, 5, 0, 6, 2, 3, 4, 8],\n",
       " [1, 7, 5, 0, 6, 2, 4, 3, 8],\n",
       " [1, 7, 5, 0, 6, 2, 8, 3, 4],\n",
       " [1, 7, 5, 0, 6, 2, 8, 4, 3],\n",
       " [1, 7, 5, 0, 6, 4, 8, 2, 3],\n",
       " [1, 7, 5, 0, 8, 2, 3, 4, 6],\n",
       " [1, 7, 5, 0, 8, 2, 4, 3, 6],\n",
       " [1, 7, 5, 0, 8, 2, 6, 3, 4],\n",
       " [1, 7, 5, 0, 8, 2, 6, 4, 3],\n",
       " [1, 7, 5, 2, 3, 4, 6, 0, 8],\n",
       " [1, 7, 5, 2, 4, 3, 0, 8, 6],\n",
       " [1, 7, 5, 2, 4, 3, 6, 0, 8],\n",
       " [1, 7, 5, 2, 4, 3, 6, 8, 0],\n",
       " [1, 7, 5, 2, 4, 3, 8, 0, 6],\n",
       " [1, 7, 5, 2, 6, 0, 3, 4, 8],\n",
       " [1, 7, 5, 2, 6, 0, 4, 3, 8],\n",
       " [1, 7, 5, 2, 6, 0, 8, 3, 4],\n",
       " [1, 7, 5, 2, 6, 0, 8, 4, 3],\n",
       " [1, 7, 5, 2, 6, 3, 0, 4, 8],\n",
       " [1, 7, 5, 2, 6, 3, 0, 8, 4],\n",
       " [1, 7, 5, 2, 6, 3, 4, 0, 8],\n",
       " [1, 7, 5, 2, 6, 3, 4, 8, 0],\n",
       " [1, 7, 5, 2, 6, 3, 8, 0, 4],\n",
       " [1, 7, 5, 2, 6, 3, 8, 4, 0],\n",
       " [1, 7, 5, 2, 6, 4, 0, 3, 8],\n",
       " [1, 7, 5, 2, 6, 4, 3, 0, 8],\n",
       " [1, 7, 5, 2, 6, 4, 8, 0, 3],\n",
       " [1, 7, 5, 2, 6, 4, 8, 3, 0],\n",
       " [1, 7, 5, 2, 8, 0, 3, 4, 6],\n",
       " [1, 7, 5, 2, 8, 0, 4, 3, 6],\n",
       " [1, 7, 5, 2, 8, 0, 6, 3, 4],\n",
       " [1, 7, 5, 2, 8, 0, 6, 4, 3],\n",
       " [1, 7, 5, 2, 8, 3, 0, 4, 6],\n",
       " [1, 7, 5, 2, 8, 3, 4, 0, 6],\n",
       " [1, 7, 5, 2, 8, 3, 6, 0, 4],\n",
       " [1, 7, 5, 2, 8, 3, 6, 4, 0],\n",
       " [1, 7, 5, 2, 8, 4, 6, 0, 3],\n",
       " [1, 7, 5, 2, 8, 4, 6, 3, 0],\n",
       " [1, 7, 6, 0, 2, 4, 8, 5, 3],\n",
       " [1, 7, 6, 0, 3, 2, 4, 5, 8],\n",
       " [1, 7, 6, 0, 3, 2, 5, 4, 8],\n",
       " [1, 7, 6, 0, 3, 2, 8, 4, 5],\n",
       " [1, 7, 6, 0, 3, 2, 8, 5, 4],\n",
       " [1, 7, 6, 0, 3, 4, 8, 2, 5],\n",
       " [1, 7, 6, 0, 3, 4, 8, 5, 2],\n",
       " [1, 7, 6, 0, 3, 5, 2, 4, 8],\n",
       " [1, 7, 6, 0, 3, 5, 4, 2, 8],\n",
       " [1, 7, 6, 0, 3, 5, 8, 2, 4],\n",
       " [1, 7, 6, 0, 3, 5, 8, 4, 2],\n",
       " [1, 7, 6, 0, 4, 2, 3, 5, 8],\n",
       " [1, 7, 6, 0, 4, 2, 5, 3, 8],\n",
       " [1, 7, 6, 0, 4, 2, 8, 3, 5],\n",
       " [1, 7, 6, 0, 4, 2, 8, 5, 3],\n",
       " [1, 7, 6, 0, 5, 2, 3, 4, 8],\n",
       " [1, 7, 6, 0, 5, 2, 4, 3, 8],\n",
       " [1, 7, 6, 0, 5, 2, 8, 3, 4],\n",
       " [1, 7, 6, 0, 5, 2, 8, 4, 3],\n",
       " [1, 7, 6, 0, 5, 4, 8, 2, 3],\n",
       " [1, 7, 6, 0, 8, 2, 3, 4, 5],\n",
       " [1, 7, 6, 0, 8, 2, 3, 5, 4],\n",
       " [1, 7, 6, 0, 8, 2, 4, 3, 5],\n",
       " [1, 7, 6, 0, 8, 2, 4, 5, 3],\n",
       " [1, 7, 6, 0, 8, 2, 5, 3, 4],\n",
       " [1, 7, 6, 0, 8, 2, 5, 4, 3],\n",
       " [1, 7, 6, 0, 8, 4, 2, 5, 3],\n",
       " [1, 7, 6, 0, 8, 4, 3, 2, 5],\n",
       " [1, 7, 6, 0, 8, 4, 3, 5, 2],\n",
       " [1, 7, 6, 0, 8, 4, 5, 2, 3],\n",
       " [1, 7, 6, 0, 8, 5, 2, 4, 3],\n",
       " [1, 7, 6, 0, 8, 5, 3, 2, 4],\n",
       " [1, 7, 6, 0, 8, 5, 3, 4, 2],\n",
       " [1, 7, 6, 0, 8, 5, 4, 2, 3],\n",
       " [1, 7, 6, 2, 0, 3, 4, 8, 5],\n",
       " [1, 7, 6, 2, 0, 3, 5, 4, 8],\n",
       " [1, 7, 6, 2, 0, 3, 5, 8, 4],\n",
       " [1, 7, 6, 2, 0, 3, 8, 4, 5],\n",
       " [1, 7, 6, 2, 3, 0, 4, 5, 8],\n",
       " [1, 7, 6, 2, 3, 0, 5, 4, 8],\n",
       " [1, 7, 6, 2, 3, 0, 8, 4, 5],\n",
       " [1, 7, 6, 2, 3, 0, 8, 5, 4],\n",
       " [1, 7, 6, 2, 4, 0, 3, 5, 8],\n",
       " [1, 7, 6, 2, 4, 0, 5, 3, 8],\n",
       " [1, 7, 6, 2, 4, 0, 8, 3, 5],\n",
       " [1, 7, 6, 2, 4, 0, 8, 5, 3],\n",
       " [1, 7, 6, 2, 4, 3, 0, 8, 5],\n",
       " [1, 7, 6, 2, 4, 3, 5, 0, 8],\n",
       " [1, 7, 6, 2, 4, 3, 5, 8, 0],\n",
       " [1, 7, 6, 2, 4, 3, 8, 0, 5],\n",
       " [1, 7, 6, 2, 4, 5, 8, 0, 3],\n",
       " [1, 7, 6, 2, 4, 8, 5, 3, 0],\n",
       " [1, 7, 6, 2, 5, 0, 3, 4, 8],\n",
       " [1, 7, 6, 2, 5, 0, 4, 3, 8],\n",
       " [1, 7, 6, 2, 5, 0, 8, 3, 4],\n",
       " [1, 7, 6, 2, 5, 0, 8, 4, 3],\n",
       " [1, 7, 6, 2, 5, 3, 0, 4, 8],\n",
       " [1, 7, 6, 2, 5, 3, 0, 8, 4],\n",
       " [1, 7, 6, 2, 5, 3, 4, 0, 8],\n",
       " [1, 7, 6, 2, 5, 3, 4, 8, 0],\n",
       " [1, 7, 6, 2, 5, 3, 8, 0, 4],\n",
       " [1, 7, 6, 2, 5, 3, 8, 4, 0],\n",
       " [1, 7, 6, 2, 5, 4, 0, 3, 8],\n",
       " [1, 7, 6, 2, 5, 4, 3, 0, 8],\n",
       " [1, 7, 6, 2, 5, 4, 8, 0, 3],\n",
       " [1, 7, 6, 2, 5, 4, 8, 3, 0],\n",
       " [1, 7, 6, 2, 8, 0, 3, 4, 5],\n",
       " [1, 7, 6, 2, 8, 0, 3, 5, 4],\n",
       " [1, 7, 6, 2, 8, 0, 4, 3, 5],\n",
       " [1, 7, 6, 2, 8, 0, 4, 5, 3],\n",
       " [1, 7, 6, 2, 8, 0, 5, 3, 4],\n",
       " [1, 7, 6, 2, 8, 0, 5, 4, 3],\n",
       " [1, 7, 6, 2, 8, 3, 0, 4, 5],\n",
       " [1, 7, 6, 2, 8, 3, 4, 0, 5],\n",
       " [1, 7, 6, 2, 8, 3, 5, 0, 4],\n",
       " [1, 7, 6, 2, 8, 3, 5, 4, 0],\n",
       " [1, 7, 6, 2, 8, 4, 0, 3, 5],\n",
       " [1, 7, 6, 2, 8, 4, 3, 0, 5],\n",
       " [1, 7, 6, 2, 8, 4, 5, 0, 3],\n",
       " [1, 7, 6, 2, 8, 4, 5, 3, 0],\n",
       " [1, 7, 8, 0, 2, 5, 3, 4, 6],\n",
       " [1, 7, 8, 0, 2, 5, 3, 6, 4],\n",
       " [1, 7, 8, 0, 2, 5, 4, 6, 3],\n",
       " [1, 7, 8, 0, 2, 5, 6, 4, 3],\n",
       " [1, 7, 8, 0, 3, 2, 4, 5, 6],\n",
       " [1, 7, 8, 0, 3, 2, 5, 4, 6],\n",
       " [1, 7, 8, 0, 3, 2, 6, 4, 5],\n",
       " [1, 7, 8, 0, 3, 2, 6, 5, 4],\n",
       " [1, 7, 8, 0, 3, 4, 2, 5, 6],\n",
       " [1, 7, 8, 0, 3, 4, 5, 2, 6],\n",
       " [1, 7, 8, 0, 3, 4, 6, 2, 5],\n",
       " [1, 7, 8, 0, 3, 4, 6, 5, 2],\n",
       " [1, 7, 8, 0, 3, 5, 2, 4, 6],\n",
       " [1, 7, 8, 0, 3, 5, 2, 6, 4],\n",
       " [1, 7, 8, 0, 3, 5, 4, 2, 6],\n",
       " [1, 7, 8, 0, 3, 5, 4, 6, 2],\n",
       " [1, 7, 8, 0, 3, 5, 6, 2, 4],\n",
       " [1, 7, 8, 0, 3, 5, 6, 4, 2],\n",
       " [1, 7, 8, 0, 4, 2, 3, 5, 6],\n",
       " [1, 7, 8, 0, 4, 2, 5, 3, 6],\n",
       " [1, 7, 8, 0, 4, 2, 6, 3, 5],\n",
       " [1, 7, 8, 0, 4, 2, 6, 5, 3],\n",
       " [1, 7, 8, 0, 4, 3, 6, 2, 5],\n",
       " [1, 7, 8, 0, 4, 5, 2, 6, 3],\n",
       " [1, 7, 8, 0, 4, 5, 3, 2, 6],\n",
       " [1, 7, 8, 0, 4, 5, 3, 6, 2],\n",
       " [1, 7, 8, 0, 4, 5, 6, 2, 3],\n",
       " [1, 7, 8, 0, 4, 6, 3, 5, 2],\n",
       " [1, 7, 8, 0, 5, 2, 3, 4, 6],\n",
       " [1, 7, 8, 0, 5, 2, 4, 3, 6],\n",
       " [1, 7, 8, 0, 5, 2, 6, 3, 4],\n",
       " [1, 7, 8, 0, 5, 2, 6, 4, 3],\n",
       " [1, 7, 8, 0, 6, 2, 3, 4, 5],\n",
       " [1, 7, 8, 0, 6, 2, 3, 5, 4],\n",
       " [1, 7, 8, 0, 6, 2, 4, 3, 5],\n",
       " [1, 7, 8, 0, 6, 2, 4, 5, 3],\n",
       " [1, 7, 8, 0, 6, 2, 5, 3, 4],\n",
       " [1, 7, 8, 0, 6, 2, 5, 4, 3],\n",
       " [1, 7, 8, 0, 6, 4, 2, 5, 3],\n",
       " [1, 7, 8, 0, 6, 4, 3, 2, 5],\n",
       " [1, 7, 8, 0, 6, 4, 3, 5, 2],\n",
       " [1, 7, 8, 0, 6, 4, 5, 2, 3],\n",
       " [1, 7, 8, 0, 6, 5, 2, 4, 3],\n",
       " [1, 7, 8, 0, 6, 5, 3, 2, 4],\n",
       " [1, 7, 8, 0, 6, 5, 3, 4, 2],\n",
       " [1, 7, 8, 0, 6, 5, 4, 2, 3],\n",
       " [1, 7, 8, 2, 0, 4, 6, 3, 5],\n",
       " [1, 7, 8, 2, 3, 0, 4, 5, 6],\n",
       " [1, 7, 8, 2, 3, 0, 5, 4, 6],\n",
       " [1, 7, 8, 2, 3, 0, 6, 4, 5],\n",
       " [1, 7, 8, 2, 3, 0, 6, 5, 4],\n",
       " [1, 7, 8, 2, 3, 4, 6, 0, 5],\n",
       " [1, 7, 8, 2, 4, 0, 3, 5, 6],\n",
       " [1, 7, 8, 2, 4, 0, 5, 3, 6],\n",
       " [1, 7, 8, 2, 4, 0, 6, 3, 5],\n",
       " [1, 7, 8, 2, 4, 0, 6, 5, 3],\n",
       " [1, 7, 8, 2, 5, 0, 3, 4, 6],\n",
       " [1, 7, 8, 2, 5, 0, 4, 3, 6],\n",
       " [1, 7, 8, 2, 5, 0, 6, 3, 4],\n",
       " [1, 7, 8, 2, 5, 0, 6, 4, 3],\n",
       " [1, 7, 8, 2, 5, 3, 0, 4, 6],\n",
       " [1, 7, 8, 2, 5, 3, 4, 0, 6],\n",
       " [1, 7, 8, 2, 5, 3, 6, 0, 4],\n",
       " [1, 7, 8, 2, 5, 3, 6, 4, 0],\n",
       " [1, 7, 8, 2, 5, 4, 6, 0, 3],\n",
       " [1, 7, 8, 2, 5, 4, 6, 3, 0],\n",
       " [1, 7, 8, 2, 6, 0, 3, 4, 5],\n",
       " [1, 7, 8, 2, 6, 0, 3, 5, 4],\n",
       " [1, 7, 8, 2, 6, 0, 4, 3, 5],\n",
       " [1, 7, 8, 2, 6, 0, 4, 5, 3],\n",
       " [1, 7, 8, 2, 6, 0, 5, 3, 4],\n",
       " [1, 7, 8, 2, 6, 0, 5, 4, 3],\n",
       " [1, 7, 8, 2, 6, 3, 0, 4, 5],\n",
       " [1, 7, 8, 2, 6, 3, 4, 0, 5],\n",
       " [1, 7, 8, 2, 6, 3, 5, 0, 4],\n",
       " [1, 7, 8, 2, 6, 3, 5, 4, 0],\n",
       " [1, 7, 8, 2, 6, 4, 0, 3, 5],\n",
       " [1, 7, 8, 2, 6, 4, 3, 0, 5],\n",
       " [1, 7, 8, 2, 6, 4, 5, 0, 3],\n",
       " [1, 7, 8, 2, 6, 4, 5, 3, 0],\n",
       " [2, 4, 0, 1, 7, 3, 5, 8, 6],\n",
       " [2, 4, 0, 1, 7, 5, 3, 6, 8],\n",
       " [2, 4, 0, 1, 7, 6, 3, 5, 8],\n",
       " [2, 4, 0, 1, 7, 6, 3, 8, 5],\n",
       " [2, 4, 0, 1, 7, 6, 5, 8, 3],\n",
       " [2, 4, 0, 1, 7, 6, 8, 5, 3],\n",
       " [2, 4, 0, 1, 7, 8, 3, 6, 5],\n",
       " [2, 4, 0, 1, 7, 8, 5, 3, 6],\n",
       " [2, 4, 0, 1, 7, 8, 5, 6, 3],\n",
       " [2, 4, 0, 1, 7, 8, 6, 3, 5],\n",
       " [2, 4, 1, 0, 8, 5, 3, 6, 7],\n",
       " [2, 4, 1, 0, 8, 5, 3, 7, 6],\n",
       " [2, 4, 3, 0, 8, 5, 1, 6, 7],\n",
       " [2, 4, 3, 0, 8, 5, 1, 7, 6],\n",
       " [2, 4, 3, 0, 8, 5, 6, 7, 1],\n",
       " [2, 4, 3, 0, 8, 5, 7, 6, 1],\n",
       " [2, 4, 3, 1, 7, 6, 0, 5, 8],\n",
       " [2, 4, 3, 1, 7, 6, 0, 8, 5],\n",
       " [2, 4, 3, 1, 7, 6, 5, 8, 0],\n",
       " [2, 4, 3, 1, 7, 6, 8, 5, 0],\n",
       " [2, 4, 3, 1, 7, 8, 0, 6, 5],\n",
       " [2, 4, 3, 6, 0, 1, 7, 5, 8],\n",
       " [2, 4, 3, 6, 0, 1, 7, 8, 5],\n",
       " [2, 4, 3, 6, 1, 0, 8, 5, 7],\n",
       " [2, 4, 3, 6, 7, 0, 8, 5, 1],\n",
       " [2, 4, 3, 6, 7, 1, 0, 5, 8],\n",
       " [2, 4, 3, 6, 7, 1, 0, 8, 5],\n",
       " [2, 4, 3, 6, 7, 1, 5, 8, 0],\n",
       " [2, 4, 3, 6, 7, 1, 8, 5, 0],\n",
       " [2, 4, 3, 6, 7, 5, 0, 1, 8],\n",
       " [2, 4, 3, 6, 7, 5, 1, 0, 8],\n",
       " [2, 4, 3, 6, 7, 5, 8, 0, 1],\n",
       " [2, 4, 3, 6, 7, 5, 8, 1, 0],\n",
       " [2, 4, 3, 6, 7, 8, 0, 1, 5],\n",
       " [2, 4, 3, 6, 8, 5, 0, 1, 7],\n",
       " [2, 4, 3, 6, 8, 5, 1, 0, 7],\n",
       " [2, 4, 3, 6, 8, 5, 7, 0, 1],\n",
       " [2, 4, 3, 6, 8, 5, 7, 1, 0],\n",
       " [2, 4, 3, 7, 1, 0, 8, 5, 6],\n",
       " [2, 4, 5, 8, 0, 1, 7, 3, 6],\n",
       " [2, 4, 5, 8, 0, 1, 7, 6, 3],\n",
       " [2, 4, 6, 1, 7, 8, 0, 3, 5],\n",
       " [2, 4, 6, 3, 5, 8, 0, 1, 7],\n",
       " [2, 4, 6, 5, 3, 0, 8, 7, 1],\n",
       " [2, 4, 6, 7, 1, 0, 8, 5, 3],\n",
       " [2, 4, 7, 3, 5, 8, 0, 1, 6],\n",
       " [2, 4, 7, 5, 3, 0, 8, 6, 1],\n",
       " [2, 4, 7, 5, 3, 6, 0, 1, 8],\n",
       " [2, 4, 7, 5, 3, 6, 1, 0, 8],\n",
       " [2, 4, 7, 5, 3, 6, 8, 0, 1],\n",
       " [2, 4, 7, 5, 3, 6, 8, 1, 0],\n",
       " [2, 4, 7, 6, 0, 1, 3, 5, 8],\n",
       " [2, 4, 7, 6, 0, 1, 3, 8, 5],\n",
       " [2, 4, 7, 6, 0, 1, 5, 8, 3],\n",
       " [2, 4, 7, 6, 0, 1, 8, 5, 3],\n",
       " [2, 4, 7, 6, 3, 0, 8, 5, 1],\n",
       " [2, 4, 7, 6, 3, 1, 0, 5, 8],\n",
       " [2, 4, 7, 6, 3, 1, 0, 8, 5],\n",
       " [2, 4, 7, 6, 3, 1, 5, 8, 0],\n",
       " [2, 4, 7, 6, 3, 1, 8, 5, 0],\n",
       " [2, 4, 7, 6, 3, 5, 0, 1, 8],\n",
       " [2, 4, 7, 6, 3, 5, 1, 0, 8],\n",
       " [2, 4, 7, 6, 3, 5, 8, 0, 1],\n",
       " [2, 4, 7, 6, 3, 5, 8, 1, 0],\n",
       " [2, 4, 7, 6, 3, 8, 0, 1, 5],\n",
       " [2, 4, 7, 6, 5, 8, 0, 1, 3],\n",
       " [2, 4, 7, 6, 8, 5, 3, 0, 1],\n",
       " [2, 4, 7, 6, 8, 5, 3, 1, 0],\n",
       " [2, 4, 7, 8, 0, 1, 3, 6, 5],\n",
       " [2, 4, 7, 8, 0, 1, 5, 3, 6],\n",
       " [2, 4, 7, 8, 0, 1, 5, 6, 3],\n",
       " [2, 4, 7, 8, 0, 1, 6, 3, 5],\n",
       " [2, 4, 8, 5, 3, 0, 1, 6, 7],\n",
       " [2, 4, 8, 5, 3, 0, 1, 7, 6],\n",
       " [2, 4, 8, 5, 3, 0, 6, 7, 1],\n",
       " [2, 4, 8, 5, 3, 0, 7, 6, 1],\n",
       " [2, 4, 8, 5, 3, 1, 7, 6, 0],\n",
       " [2, 4, 8, 5, 3, 6, 0, 1, 7],\n",
       " [2, 4, 8, 5, 3, 6, 1, 0, 7],\n",
       " [2, 4, 8, 5, 3, 6, 7, 0, 1],\n",
       " [2, 4, 8, 5, 3, 6, 7, 1, 0],\n",
       " [2, 4, 8, 5, 3, 7, 1, 0, 6],\n",
       " [3, 0, 1, 4, 8, 2, 6, 7, 5],\n",
       " [3, 0, 1, 4, 8, 5, 2, 6, 7],\n",
       " [3, 0, 1, 4, 8, 5, 2, 7, 6],\n",
       " [3, 0, 1, 4, 8, 5, 6, 7, 2],\n",
       " [3, 0, 1, 4, 8, 5, 7, 6, 2],\n",
       " [3, 0, 1, 4, 8, 6, 2, 5, 7],\n",
       " [3, 0, 1, 4, 8, 7, 2, 5, 6],\n",
       " [3, 0, 1, 4, 8, 7, 5, 2, 6],\n",
       " [3, 0, 1, 4, 8, 7, 6, 2, 5],\n",
       " [3, 0, 1, 4, 8, 7, 6, 5, 2],\n",
       " [3, 0, 1, 5, 2, 4, 8, 6, 7],\n",
       " [3, 0, 1, 5, 2, 4, 8, 7, 6],\n",
       " [3, 0, 1, 5, 2, 6, 4, 7, 8],\n",
       " [3, 0, 1, 5, 2, 6, 7, 4, 8],\n",
       " [3, 0, 1, 5, 2, 6, 8, 4, 7],\n",
       " [3, 0, 1, 5, 2, 6, 8, 7, 4],\n",
       " [3, 0, 1, 5, 2, 7, 4, 6, 8],\n",
       " [3, 0, 1, 5, 2, 7, 6, 4, 8],\n",
       " [3, 0, 1, 5, 2, 7, 8, 4, 6],\n",
       " [3, 0, 1, 5, 2, 7, 8, 6, 4],\n",
       " [3, 0, 1, 5, 4, 7, 2, 6, 8],\n",
       " [3, 0, 1, 5, 4, 7, 6, 2, 8],\n",
       " [3, 0, 1, 5, 4, 7, 8, 2, 6],\n",
       " [3, 0, 1, 5, 4, 7, 8, 6, 2],\n",
       " [3, 0, 1, 5, 7, 4, 8, 6, 2],\n",
       " [3, 0, 1, 5, 8, 4, 2, 6, 7],\n",
       " [3, 0, 1, 5, 8, 4, 2, 7, 6],\n",
       " [3, 0, 1, 5, 8, 4, 6, 7, 2],\n",
       " [3, 0, 1, 5, 8, 4, 7, 6, 2],\n",
       " [3, 0, 1, 5, 8, 6, 2, 4, 7],\n",
       " [3, 0, 1, 5, 8, 6, 2, 7, 4],\n",
       " [3, 0, 1, 5, 8, 6, 4, 7, 2],\n",
       " [3, 0, 1, 5, 8, 6, 7, 4, 2],\n",
       " [3, 0, 1, 5, 8, 7, 2, 4, 6],\n",
       " [3, 0, 1, 5, 8, 7, 2, 6, 4],\n",
       " [3, 0, 1, 5, 8, 7, 4, 2, 6],\n",
       " [3, 0, 1, 5, 8, 7, 4, 6, 2],\n",
       " [3, 0, 1, 5, 8, 7, 6, 2, 4],\n",
       " [3, 0, 1, 5, 8, 7, 6, 4, 2],\n",
       " [3, 0, 1, 7, 4, 5, 2, 6, 8],\n",
       " [3, 0, 1, 7, 4, 5, 6, 2, 8],\n",
       " [3, 0, 1, 7, 4, 5, 8, 2, 6],\n",
       " [3, 0, 1, 7, 4, 5, 8, 6, 2],\n",
       " [3, 0, 1, 7, 5, 4, 8, 2, 6],\n",
       " [3, 0, 1, 7, 6, 2, 4, 5, 8],\n",
       " [3, 0, 1, 7, 6, 2, 5, 4, 8],\n",
       " [3, 0, 1, 7, 6, 2, 8, 4, 5],\n",
       " [3, 0, 1, 7, 6, 2, 8, 5, 4],\n",
       " [3, 0, 1, 7, 6, 4, 8, 2, 5],\n",
       " [3, 0, 1, 7, 6, 4, 8, 5, 2],\n",
       " [3, 0, 1, 7, 6, 5, 2, 4, 8],\n",
       " [3, 0, 1, 7, 6, 5, 4, 2, 8],\n",
       " [3, 0, 1, 7, 6, 5, 8, 2, 4],\n",
       " [3, 0, 1, 7, 6, 5, 8, 4, 2],\n",
       " [3, 0, 1, 7, 8, 2, 4, 5, 6],\n",
       " [3, 0, 1, 7, 8, 2, 5, 4, 6],\n",
       " [3, 0, 1, 7, 8, 2, 6, 4, 5],\n",
       " [3, 0, 1, 7, 8, 2, 6, 5, 4],\n",
       " [3, 0, 1, 7, 8, 4, 2, 5, 6],\n",
       " [3, 0, 1, 7, 8, 4, 5, 2, 6],\n",
       " [3, 0, 1, 7, 8, 4, 6, 2, 5],\n",
       " [3, 0, 1, 7, 8, 4, 6, 5, 2],\n",
       " [3, 0, 1, 7, 8, 5, 2, 4, 6],\n",
       " [3, 0, 1, 7, 8, 5, 2, 6, 4],\n",
       " [3, 0, 1, 7, 8, 5, 4, 2, 6],\n",
       " [3, 0, 1, 7, 8, 5, 4, 6, 2],\n",
       " [3, 0, 1, 7, 8, 5, 6, 2, 4],\n",
       " [3, 0, 1, 7, 8, 5, 6, 4, 2],\n",
       " [3, 0, 2, 4, 8, 5, 1, 6, 7],\n",
       " [3, 0, 2, 4, 8, 5, 1, 7, 6],\n",
       " [3, 0, 2, 4, 8, 5, 6, 7, 1],\n",
       " [3, 0, 2, 4, 8, 5, 7, 6, 1],\n",
       " [3, 0, 2, 5, 1, 4, 8, 6, 7],\n",
       " [3, 0, 2, 5, 1, 4, 8, 7, 6],\n",
       " [3, 0, 2, 5, 1, 6, 4, 7, 8],\n",
       " [3, 0, 2, 5, 1, 6, 7, 4, 8],\n",
       " [3, 0, 2, 5, 1, 6, 8, 4, 7],\n",
       " [3, 0, 2, 5, 1, 6, 8, 7, 4],\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = [game.moves_played for game in game_list]\n",
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [10,1]\n",
    "output_seq = [1,9]\n",
    "zeros = [0.] * 10\n",
    "first_output = [0.] * 10\n",
    "first_output[1] = 1.\n",
    "second_output = [0.] * 10\n",
    "second_output[9] = 1.\n",
    "output = torch.tensor([first_output, second_output])\n",
    "\n",
    "\n",
    "logit_base = torch.tensor([-10000000000.] * 10)\n",
    "first_logit = torch.clone(logit_base)\n",
    "first_logit[1] = 100000.\n",
    "second_logit = torch.clone(logit_base)\n",
    "second_logit[9] = 100000.\n",
    "logits = torch.stack([first_logit, second_logit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor([[-1.0000e+10,  1.0000e+05, -1.0000e+10, -1.0000e+10, -1.0000e+10,\n",
      "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
      "        [-1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10,\n",
      "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10,  1.0000e+05]])\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n",
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_fn(logits, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [10,1]\n",
    "output_seq = [1,9]\n",
    "zeros = [0] * 10\n",
    "first_output = [0] * 10\n",
    "first_output[1] = 1\n",
    "second_output = [0] * 10\n",
    "second_output[9] = 1\n",
    "output = torch.tensor([first_output, second_output])\n",
    "\n",
    "\n",
    "logit_base = torch.tensor([-np.inf] * 10)\n",
    "first_logit = torch.clone(logit_base)\n",
    "first_logit[1] = np.inf\n",
    "second_logit = torch.clone(logit_base)\n",
    "second_logit[9] = np.inf\n",
    "logits = torch.stack([first_logit, second_logit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  1,  7,  5,  2,  6,  3,  4,  8,  0], device='cuda:0')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n",
      "Epoch 0 | Train Loss: 2.708627700805664 | Test Loss: 2.52840256690979\n",
      "Epoch 1 | Train Loss: 2.5274133682250977 | Test Loss: 2.5168142318725586\n",
      "Epoch 2 | Train Loss: 2.505772590637207 | Test Loss: 2.812495470046997\n",
      "Epoch 3 | Train Loss: 2.831326723098755 | Test Loss: 2.153665781021118\n",
      "Epoch 4 | Train Loss: 2.1369757652282715 | Test Loss: 1.8449795246124268\n",
      "Epoch 5 | Train Loss: 1.855232834815979 | Test Loss: 1.6901593208312988\n",
      "Epoch 6 | Train Loss: 1.7010107040405273 | Test Loss: 1.4590767621994019\n",
      "Epoch 7 | Train Loss: 1.4588277339935303 | Test Loss: 1.3246701955795288\n",
      "Epoch 8 | Train Loss: 1.320685625076294 | Test Loss: 1.19852614402771\n",
      "Epoch 9 | Train Loss: 1.1879924535751343 | Test Loss: 1.0949195623397827\n",
      "Epoch 10 | Train Loss: 1.0802693367004395 | Test Loss: 0.9508247375488281\n",
      "Epoch 11 | Train Loss: 0.9485883116722107 | Test Loss: 0.8471229076385498\n",
      "Epoch 12 | Train Loss: 0.8394076228141785 | Test Loss: 0.7652381658554077\n",
      "Epoch 13 | Train Loss: 0.7598364353179932 | Test Loss: 0.6368617415428162\n",
      "Epoch 14 | Train Loss: 0.636762797832489 | Test Loss: 0.5596321821212769\n",
      "Epoch 15 | Train Loss: 0.5577282905578613 | Test Loss: 0.5286388397216797\n",
      "Epoch 16 | Train Loss: 0.5174071788787842 | Test Loss: 0.46937423944473267\n",
      "Epoch 17 | Train Loss: 0.45985326170921326 | Test Loss: 0.4121308922767639\n",
      "Epoch 18 | Train Loss: 0.4031035006046295 | Test Loss: 0.36824437975883484\n",
      "Epoch 19 | Train Loss: 0.35666629672050476 | Test Loss: 0.31283459067344666\n",
      "Epoch 20 | Train Loss: 0.3098866939544678 | Test Loss: 0.29623791575431824\n",
      "Epoch 21 | Train Loss: 0.29388871788978577 | Test Loss: 0.4665044844150543\n",
      "Epoch 22 | Train Loss: 0.43020129203796387 | Test Loss: 0.34601518511772156\n",
      "Epoch 23 | Train Loss: 0.33832722902297974 | Test Loss: 0.39792534708976746\n",
      "Epoch 24 | Train Loss: 0.38489535450935364 | Test Loss: 0.5155378580093384\n",
      "Epoch 25 | Train Loss: 0.48992919921875 | Test Loss: 0.43898120522499084\n",
      "Epoch 26 | Train Loss: 0.41361430287361145 | Test Loss: 0.37437117099761963\n",
      "Epoch 27 | Train Loss: 0.36163780093193054 | Test Loss: 0.3563831150531769\n",
      "Epoch 28 | Train Loss: 0.3594362139701843 | Test Loss: 0.297419011592865\n",
      "Epoch 29 | Train Loss: 0.297652930021286 | Test Loss: 0.2613367736339569\n",
      "Epoch 30 | Train Loss: 0.2499905526638031 | Test Loss: 0.24884814023971558\n",
      "Epoch 31 | Train Loss: 0.23415127396583557 | Test Loss: 0.2366791069507599\n",
      "Epoch 32 | Train Loss: 0.22368700802326202 | Test Loss: 0.2004190981388092\n",
      "Epoch 33 | Train Loss: 0.1863764375448227 | Test Loss: 0.3962213695049286\n",
      "Epoch 34 | Train Loss: 0.39391183853149414 | Test Loss: 0.2736647129058838\n",
      "Epoch 35 | Train Loss: 0.258053183555603 | Test Loss: 0.2854881286621094\n",
      "Epoch 36 | Train Loss: 0.2697952687740326 | Test Loss: 0.3315742611885071\n",
      "Epoch 37 | Train Loss: 0.31867581605911255 | Test Loss: 0.34460270404815674\n",
      "Epoch 38 | Train Loss: 0.3380987346172333 | Test Loss: 0.32319697737693787\n",
      "Epoch 39 | Train Loss: 0.3237573802471161 | Test Loss: 0.300579696893692\n",
      "Epoch 40 | Train Loss: 0.31021228432655334 | Test Loss: 0.26422667503356934\n",
      "Epoch 41 | Train Loss: 0.27722904086112976 | Test Loss: 0.2279031127691269\n",
      "Epoch 42 | Train Loss: 0.23293541371822357 | Test Loss: 0.19774796068668365\n",
      "Epoch 43 | Train Loss: 0.21432439982891083 | Test Loss: 0.20220167934894562\n",
      "Epoch 44 | Train Loss: 0.2094581425189972 | Test Loss: 0.24798065423965454\n",
      "Epoch 45 | Train Loss: 0.24345289170742035 | Test Loss: 0.24969393014907837\n",
      "Epoch 46 | Train Loss: 0.2389822006225586 | Test Loss: 0.2647579610347748\n",
      "Epoch 47 | Train Loss: 0.25666090846061707 | Test Loss: 0.24622130393981934\n",
      "Epoch 48 | Train Loss: 0.22606506943702698 | Test Loss: 0.2798902690410614\n",
      "Epoch 49 | Train Loss: 0.2658003270626068 | Test Loss: 0.29936107993125916\n",
      "Epoch 50 | Train Loss: 0.2998453974723816 | Test Loss: 0.5249527096748352\n",
      "Epoch 51 | Train Loss: 0.511041522026062 | Test Loss: 0.29693159461021423\n",
      "Epoch 52 | Train Loss: 0.27840563654899597 | Test Loss: 0.2807973623275757\n",
      "Epoch 53 | Train Loss: 0.2803482413291931 | Test Loss: 0.29824668169021606\n",
      "Epoch 54 | Train Loss: 0.301000714302063 | Test Loss: 0.30131101608276367\n",
      "Epoch 55 | Train Loss: 0.3032227158546448 | Test Loss: 0.27803102135658264\n",
      "Epoch 56 | Train Loss: 0.2804151475429535 | Test Loss: 0.24447712302207947\n",
      "Epoch 57 | Train Loss: 0.2519954442977905 | Test Loss: 0.21511310338974\n",
      "Epoch 58 | Train Loss: 0.21339955925941467 | Test Loss: 0.254103422164917\n",
      "Epoch 59 | Train Loss: 0.22492460906505585 | Test Loss: 0.4310261607170105\n",
      "Epoch 60 | Train Loss: 0.40532347559928894 | Test Loss: 0.3986285626888275\n",
      "Epoch 61 | Train Loss: 0.37411758303642273 | Test Loss: 0.4700629711151123\n",
      "Epoch 62 | Train Loss: 0.43058907985687256 | Test Loss: 0.4733460247516632\n",
      "Epoch 63 | Train Loss: 0.451388955116272 | Test Loss: 1.0714726448059082\n",
      "Epoch 64 | Train Loss: 0.9809418320655823 | Test Loss: 0.9219952821731567\n",
      "Epoch 65 | Train Loss: 0.8418194651603699 | Test Loss: 0.7661916613578796\n",
      "Epoch 66 | Train Loss: 0.7685794234275818 | Test Loss: 0.7153646349906921\n",
      "Epoch 67 | Train Loss: 0.7305548787117004 | Test Loss: 0.912673830986023\n",
      "Epoch 68 | Train Loss: 0.8671654462814331 | Test Loss: 0.4696144461631775\n",
      "Epoch 69 | Train Loss: 0.4518052637577057 | Test Loss: 1.030601978302002\n",
      "Epoch 70 | Train Loss: 1.0072654485702515 | Test Loss: 0.3904467225074768\n",
      "Epoch 71 | Train Loss: 0.4068619906902313 | Test Loss: 0.35623887181282043\n",
      "Epoch 72 | Train Loss: 0.3672011196613312 | Test Loss: 0.5473585724830627\n",
      "Epoch 73 | Train Loss: 0.5222359895706177 | Test Loss: 0.5005807280540466\n",
      "Epoch 74 | Train Loss: 0.4658988416194916 | Test Loss: 0.5006409287452698\n",
      "Epoch 75 | Train Loss: 0.48447754979133606 | Test Loss: 0.35280582308769226\n",
      "Epoch 76 | Train Loss: 0.3607349097728729 | Test Loss: 0.3917109966278076\n",
      "Epoch 77 | Train Loss: 0.3970721960067749 | Test Loss: 0.3685329854488373\n",
      "Epoch 78 | Train Loss: 0.3673703372478485 | Test Loss: 0.38620442152023315\n",
      "Epoch 79 | Train Loss: 0.3844812512397766 | Test Loss: 0.5856775045394897\n",
      "Epoch 80 | Train Loss: 0.5384570956230164 | Test Loss: 0.4507777690887451\n",
      "Epoch 81 | Train Loss: 0.40631094574928284 | Test Loss: 0.9432283639907837\n",
      "Epoch 82 | Train Loss: 0.9144976139068604 | Test Loss: 1.1336981058120728\n",
      "Epoch 83 | Train Loss: 1.0839223861694336 | Test Loss: 0.7536897659301758\n",
      "Epoch 84 | Train Loss: 0.7221201062202454 | Test Loss: 0.609811544418335\n",
      "Epoch 85 | Train Loss: 0.5861078500747681 | Test Loss: 0.9911413192749023\n",
      "Epoch 86 | Train Loss: 0.9664468169212341 | Test Loss: 1.244498610496521\n",
      "Epoch 87 | Train Loss: 1.219435691833496 | Test Loss: 0.9186979532241821\n",
      "Epoch 88 | Train Loss: 0.9189733266830444 | Test Loss: 0.7560778260231018\n",
      "Epoch 89 | Train Loss: 0.7685202956199646 | Test Loss: 0.7386487126350403\n",
      "Epoch 90 | Train Loss: 0.746974527835846 | Test Loss: 0.849337100982666\n",
      "Epoch 91 | Train Loss: 0.8768321871757507 | Test Loss: 0.7660388350486755\n",
      "Epoch 92 | Train Loss: 0.7818990349769592 | Test Loss: 0.614345908164978\n",
      "Epoch 93 | Train Loss: 0.6160582900047302 | Test Loss: 0.8860315680503845\n",
      "Epoch 94 | Train Loss: 0.8677313327789307 | Test Loss: 0.8429154753684998\n",
      "Epoch 95 | Train Loss: 0.8474121689796448 | Test Loss: 0.6554733514785767\n",
      "Epoch 96 | Train Loss: 0.6693756580352783 | Test Loss: 0.9721301198005676\n",
      "Epoch 97 | Train Loss: 1.0087308883666992 | Test Loss: 0.9670318365097046\n",
      "Epoch 98 | Train Loss: 1.028181791305542 | Test Loss: 1.0718291997909546\n",
      "Epoch 99 | Train Loss: 1.112541913986206 | Test Loss: 1.2223173379898071\n",
      "Epoch 100 | Train Loss: 1.2623404264450073 | Test Loss: 1.689563512802124\n",
      "Epoch 101 | Train Loss: 1.7115886211395264 | Test Loss: 1.6396865844726562\n",
      "Epoch 102 | Train Loss: 1.650143027305603 | Test Loss: 1.4561604261398315\n",
      "Epoch 103 | Train Loss: 1.451932668685913 | Test Loss: 1.264950156211853\n",
      "Epoch 104 | Train Loss: 1.2949576377868652 | Test Loss: 1.0920250415802002\n",
      "Epoch 105 | Train Loss: 1.0951260328292847 | Test Loss: 1.0152462720870972\n",
      "Epoch 106 | Train Loss: 1.0253652334213257 | Test Loss: 0.8019506335258484\n",
      "Epoch 107 | Train Loss: 0.7958846688270569 | Test Loss: 0.7179147601127625\n",
      "Epoch 108 | Train Loss: 0.7071596384048462 | Test Loss: 0.6720007061958313\n",
      "Epoch 109 | Train Loss: 0.6574439406394958 | Test Loss: 0.6597215533256531\n",
      "Epoch 110 | Train Loss: 0.6545990705490112 | Test Loss: 0.7056214809417725\n",
      "Epoch 111 | Train Loss: 0.6870784759521484 | Test Loss: 0.8289211392402649\n",
      "Epoch 112 | Train Loss: 0.8282192349433899 | Test Loss: 0.7849171161651611\n",
      "Epoch 113 | Train Loss: 0.7719361186027527 | Test Loss: 0.6985640525817871\n",
      "Epoch 114 | Train Loss: 0.6795512437820435 | Test Loss: 0.6873573064804077\n",
      "Epoch 115 | Train Loss: 0.6862256526947021 | Test Loss: 0.5471439957618713\n",
      "Epoch 116 | Train Loss: 0.5457543730735779 | Test Loss: 0.514992892742157\n",
      "Epoch 117 | Train Loss: 0.5043741464614868 | Test Loss: 0.48036372661590576\n",
      "Epoch 118 | Train Loss: 0.47968780994415283 | Test Loss: 0.5419420003890991\n",
      "Epoch 119 | Train Loss: 0.5361818075180054 | Test Loss: 0.53549724817276\n",
      "Epoch 120 | Train Loss: 0.544462263584137 | Test Loss: 0.4398564100265503\n",
      "Epoch 121 | Train Loss: 0.4263915717601776 | Test Loss: 0.5757790803909302\n",
      "Epoch 122 | Train Loss: 0.5689387321472168 | Test Loss: 0.4220210015773773\n",
      "Epoch 123 | Train Loss: 0.4109191298484802 | Test Loss: 0.3454850912094116\n",
      "Epoch 124 | Train Loss: 0.3287239372730255 | Test Loss: 0.37279391288757324\n",
      "Epoch 125 | Train Loss: 0.3618035912513733 | Test Loss: 0.35044386982917786\n",
      "Epoch 126 | Train Loss: 0.3381901979446411 | Test Loss: 0.3033391535282135\n",
      "Epoch 127 | Train Loss: 0.3009330928325653 | Test Loss: 0.28826427459716797\n",
      "Epoch 128 | Train Loss: 0.275299608707428 | Test Loss: 0.22307850420475006\n",
      "Epoch 129 | Train Loss: 0.21781101822853088 | Test Loss: 0.21942025423049927\n",
      "Epoch 130 | Train Loss: 0.2160569578409195 | Test Loss: 0.19852080941200256\n",
      "Epoch 131 | Train Loss: 0.19132636487483978 | Test Loss: 0.19325968623161316\n",
      "Epoch 132 | Train Loss: 0.1777736246585846 | Test Loss: 0.22542472183704376\n",
      "Epoch 133 | Train Loss: 0.2092229127883911 | Test Loss: 0.22564025223255157\n",
      "Epoch 134 | Train Loss: 0.21587233245372772 | Test Loss: 0.19906161725521088\n",
      "Epoch 135 | Train Loss: 0.1938522905111313 | Test Loss: 0.18040262162685394\n",
      "Epoch 136 | Train Loss: 0.18331368267536163 | Test Loss: 0.17135435342788696\n",
      "Epoch 137 | Train Loss: 0.16382059454917908 | Test Loss: 0.16224931180477142\n",
      "Epoch 138 | Train Loss: 0.16454045474529266 | Test Loss: 0.161233052611351\n",
      "Epoch 139 | Train Loss: 0.16876357793807983 | Test Loss: 0.2254430204629898\n",
      "Epoch 140 | Train Loss: 0.2131308764219284 | Test Loss: 0.6082730293273926\n",
      "Epoch 141 | Train Loss: 0.5995402336120605 | Test Loss: 0.33671465516090393\n",
      "Epoch 142 | Train Loss: 0.3146403431892395 | Test Loss: 0.9303365349769592\n",
      "Epoch 143 | Train Loss: 0.941017210483551 | Test Loss: 0.5371014475822449\n",
      "Epoch 144 | Train Loss: 0.5777788758277893 | Test Loss: 0.8197300434112549\n",
      "Epoch 145 | Train Loss: 0.8023239970207214 | Test Loss: 0.5110916495323181\n",
      "Epoch 146 | Train Loss: 0.4929675757884979 | Test Loss: 0.5312796831130981\n",
      "Epoch 147 | Train Loss: 0.5437250137329102 | Test Loss: 0.634679913520813\n",
      "Epoch 148 | Train Loss: 0.6544736623764038 | Test Loss: 0.6009992361068726\n",
      "Epoch 149 | Train Loss: 0.5971968173980713 | Test Loss: 0.6424321532249451\n",
      "Epoch 150 | Train Loss: 0.6320983171463013 | Test Loss: 0.6335029006004333\n",
      "Epoch 151 | Train Loss: 0.6246724128723145 | Test Loss: 1.2496991157531738\n",
      "Epoch 152 | Train Loss: 1.2907012701034546 | Test Loss: 0.8951902389526367\n",
      "Epoch 153 | Train Loss: 0.8774251341819763 | Test Loss: 0.9428121447563171\n",
      "Epoch 154 | Train Loss: 0.9195418357849121 | Test Loss: 0.8323929309844971\n",
      "Epoch 155 | Train Loss: 0.8206253051757812 | Test Loss: 0.7339659333229065\n",
      "Epoch 156 | Train Loss: 0.7119592428207397 | Test Loss: 0.7316029667854309\n",
      "Epoch 157 | Train Loss: 0.7275704741477966 | Test Loss: 0.6301584839820862\n",
      "Epoch 158 | Train Loss: 0.6287611722946167 | Test Loss: 0.6413518190383911\n",
      "Epoch 159 | Train Loss: 0.6267995834350586 | Test Loss: 1.1007544994354248\n",
      "Epoch 160 | Train Loss: 1.0618711709976196 | Test Loss: 0.7463560104370117\n",
      "Epoch 161 | Train Loss: 0.697693407535553 | Test Loss: 0.7756596803665161\n",
      "Epoch 162 | Train Loss: 0.7541399598121643 | Test Loss: 0.8333978652954102\n",
      "Epoch 163 | Train Loss: 0.7928434014320374 | Test Loss: 0.9056029319763184\n",
      "Epoch 164 | Train Loss: 0.8662804365158081 | Test Loss: 0.8118136525154114\n",
      "Epoch 165 | Train Loss: 0.7653018832206726 | Test Loss: 1.9996726512908936\n",
      "Epoch 166 | Train Loss: 1.831073522567749 | Test Loss: 1.8911230564117432\n",
      "Epoch 167 | Train Loss: 1.7543296813964844 | Test Loss: 1.3459930419921875\n",
      "Epoch 168 | Train Loss: 1.2954164743423462 | Test Loss: 1.16306734085083\n",
      "Epoch 169 | Train Loss: 1.1562118530273438 | Test Loss: 1.5742336511611938\n",
      "Epoch 170 | Train Loss: 1.5571027994155884 | Test Loss: 1.4526139497756958\n",
      "Epoch 171 | Train Loss: 1.4315444231033325 | Test Loss: 2.2587335109710693\n",
      "Epoch 172 | Train Loss: 2.2824840545654297 | Test Loss: 3.7787160873413086\n",
      "Epoch 173 | Train Loss: 3.7851858139038086 | Test Loss: 2.791470766067505\n",
      "Epoch 174 | Train Loss: 2.7298672199249268 | Test Loss: 2.769547462463379\n",
      "Epoch 175 | Train Loss: 2.7341361045837402 | Test Loss: 6.348069667816162\n",
      "Epoch 176 | Train Loss: 6.20320987701416 | Test Loss: 5.334617614746094\n",
      "Epoch 177 | Train Loss: 5.259507656097412 | Test Loss: 7.437254905700684\n",
      "Epoch 178 | Train Loss: 7.477093696594238 | Test Loss: 10.314138412475586\n",
      "Epoch 179 | Train Loss: 10.537941932678223 | Test Loss: 7.299478054046631\n",
      "Epoch 180 | Train Loss: 7.249573230743408 | Test Loss: 10.66882610321045\n",
      "Epoch 181 | Train Loss: 10.58381462097168 | Test Loss: 11.426600456237793\n",
      "Epoch 182 | Train Loss: 11.610565185546875 | Test Loss: 5.5032196044921875\n",
      "Epoch 183 | Train Loss: 5.554202079772949 | Test Loss: 3.918156385421753\n",
      "Epoch 184 | Train Loss: 4.025303840637207 | Test Loss: 3.5088188648223877\n",
      "Epoch 185 | Train Loss: 3.5511698722839355 | Test Loss: 4.800567150115967\n",
      "Epoch 186 | Train Loss: 4.872369289398193 | Test Loss: 3.533348798751831\n",
      "Epoch 187 | Train Loss: 3.4726758003234863 | Test Loss: 3.782628297805786\n",
      "Epoch 188 | Train Loss: 3.6990861892700195 | Test Loss: 3.8172380924224854\n",
      "Epoch 189 | Train Loss: 3.654846429824829 | Test Loss: 6.064826011657715\n",
      "Epoch 190 | Train Loss: 5.675210952758789 | Test Loss: 3.378101348876953\n",
      "Epoch 191 | Train Loss: 3.3391973972320557 | Test Loss: 3.874943733215332\n",
      "Epoch 192 | Train Loss: 3.8088624477386475 | Test Loss: 8.904400825500488\n",
      "Epoch 193 | Train Loss: 8.82194709777832 | Test Loss: 11.593823432922363\n",
      "Epoch 194 | Train Loss: 11.541970252990723 | Test Loss: 13.406164169311523\n",
      "Epoch 195 | Train Loss: 13.282842636108398 | Test Loss: 14.986621856689453\n",
      "Epoch 196 | Train Loss: 14.906278610229492 | Test Loss: 12.438372611999512\n",
      "Epoch 197 | Train Loss: 12.228081703186035 | Test Loss: 9.202101707458496\n",
      "Epoch 198 | Train Loss: 9.0130033493042 | Test Loss: 8.227747917175293\n",
      "Epoch 199 | Train Loss: 8.081385612487793 | Test Loss: 17.80449867248535\n",
      "Epoch 200 | Train Loss: 17.449914932250977 | Test Loss: 9.819642066955566\n",
      "Epoch 201 | Train Loss: 9.761554718017578 | Test Loss: 6.90645694732666\n",
      "Epoch 202 | Train Loss: 6.943755149841309 | Test Loss: 16.61911964416504\n",
      "Epoch 203 | Train Loss: 16.86127281188965 | Test Loss: 9.676100730895996\n",
      "Epoch 204 | Train Loss: 9.761019706726074 | Test Loss: 5.886669158935547\n",
      "Epoch 205 | Train Loss: 5.872363090515137 | Test Loss: 6.060904026031494\n",
      "Epoch 206 | Train Loss: 6.0792412757873535 | Test Loss: 5.309098720550537\n",
      "Epoch 207 | Train Loss: 5.288404941558838 | Test Loss: 3.972707986831665\n",
      "Epoch 208 | Train Loss: 4.006660461425781 | Test Loss: 5.5554609298706055\n",
      "Epoch 209 | Train Loss: 5.685641765594482 | Test Loss: 3.4187121391296387\n",
      "Epoch 210 | Train Loss: 3.4813709259033203 | Test Loss: 2.864861011505127\n",
      "Epoch 211 | Train Loss: 2.8984827995300293 | Test Loss: 2.7625582218170166\n",
      "Epoch 212 | Train Loss: 2.7762162685394287 | Test Loss: 2.933176279067993\n",
      "Epoch 213 | Train Loss: 2.9436604976654053 | Test Loss: 2.4661951065063477\n",
      "Epoch 214 | Train Loss: 2.474161386489868 | Test Loss: 2.544154644012451\n",
      "Epoch 215 | Train Loss: 2.5591351985931396 | Test Loss: 2.3965682983398438\n",
      "Epoch 216 | Train Loss: 2.404428005218506 | Test Loss: 2.449510097503662\n",
      "Epoch 217 | Train Loss: 2.437265634536743 | Test Loss: 2.4610953330993652\n",
      "Epoch 218 | Train Loss: 2.445068120956421 | Test Loss: 2.430443286895752\n",
      "Epoch 219 | Train Loss: 2.4442789554595947 | Test Loss: 2.3162426948547363\n",
      "Epoch 220 | Train Loss: 2.334017753601074 | Test Loss: 2.3492820262908936\n",
      "Epoch 221 | Train Loss: 2.3818976879119873 | Test Loss: 2.434234619140625\n",
      "Epoch 222 | Train Loss: 2.474421262741089 | Test Loss: 2.0032496452331543\n",
      "Epoch 223 | Train Loss: 2.012984275817871 | Test Loss: 2.1525092124938965\n",
      "Epoch 224 | Train Loss: 2.152153253555298 | Test Loss: 2.183058261871338\n",
      "Epoch 225 | Train Loss: 2.163862943649292 | Test Loss: 1.8080432415008545\n",
      "Epoch 226 | Train Loss: 1.7716902494430542 | Test Loss: 1.7663068771362305\n",
      "Epoch 227 | Train Loss: 1.747215986251831 | Test Loss: 1.631957769393921\n",
      "Epoch 228 | Train Loss: 1.6236000061035156 | Test Loss: 1.5179482698440552\n",
      "Epoch 229 | Train Loss: 1.5163838863372803 | Test Loss: 1.4425228834152222\n",
      "Epoch 230 | Train Loss: 1.4361783266067505 | Test Loss: 1.4858893156051636\n",
      "Epoch 231 | Train Loss: 1.4836397171020508 | Test Loss: 1.3988988399505615\n",
      "Epoch 232 | Train Loss: 1.3939197063446045 | Test Loss: 1.393739104270935\n",
      "Epoch 233 | Train Loss: 1.3892614841461182 | Test Loss: 1.343336582183838\n",
      "Epoch 234 | Train Loss: 1.3402785062789917 | Test Loss: 1.3301113843917847\n",
      "Epoch 235 | Train Loss: 1.3233113288879395 | Test Loss: 1.3154062032699585\n",
      "Epoch 236 | Train Loss: 1.305195927619934 | Test Loss: 1.2683148384094238\n",
      "Epoch 237 | Train Loss: 1.2606844902038574 | Test Loss: 1.22295081615448\n",
      "Epoch 238 | Train Loss: 1.2182612419128418 | Test Loss: 1.1894716024398804\n",
      "Epoch 239 | Train Loss: 1.1853841543197632 | Test Loss: 1.1737710237503052\n",
      "Epoch 240 | Train Loss: 1.1692023277282715 | Test Loss: 1.1700992584228516\n",
      "Epoch 241 | Train Loss: 1.1640417575836182 | Test Loss: 1.1516225337982178\n",
      "Epoch 242 | Train Loss: 1.1465556621551514 | Test Loss: 1.1181994676589966\n",
      "Epoch 243 | Train Loss: 1.1132831573486328 | Test Loss: 1.096691608428955\n",
      "Epoch 244 | Train Loss: 1.090413212776184 | Test Loss: 1.069384217262268\n",
      "Epoch 245 | Train Loss: 1.0641709566116333 | Test Loss: 1.0443867444992065\n",
      "Epoch 246 | Train Loss: 1.041150689125061 | Test Loss: 1.0288922786712646\n",
      "Epoch 247 | Train Loss: 1.0310680866241455 | Test Loss: 1.0140477418899536\n",
      "Epoch 248 | Train Loss: 1.014622688293457 | Test Loss: 1.0051299333572388\n",
      "Epoch 249 | Train Loss: 1.0023077726364136 | Test Loss: 0.9807331562042236\n",
      "Epoch 250 | Train Loss: 0.979121208190918 | Test Loss: 0.9681663513183594\n",
      "Epoch 251 | Train Loss: 0.9666145443916321 | Test Loss: 0.9516459703445435\n",
      "Epoch 252 | Train Loss: 0.9495042562484741 | Test Loss: 0.9319899082183838\n",
      "Epoch 253 | Train Loss: 0.930655837059021 | Test Loss: 0.9117419123649597\n",
      "Epoch 254 | Train Loss: 0.9114023447036743 | Test Loss: 0.8969576358795166\n",
      "Epoch 255 | Train Loss: 0.8952562212944031 | Test Loss: 0.8833372592926025\n",
      "Epoch 256 | Train Loss: 0.8814972639083862 | Test Loss: 0.8709694743156433\n",
      "Epoch 257 | Train Loss: 0.8684248328208923 | Test Loss: 0.856290340423584\n",
      "Epoch 258 | Train Loss: 0.8522976636886597 | Test Loss: 0.8433206677436829\n",
      "Epoch 259 | Train Loss: 0.835481584072113 | Test Loss: 0.8286962509155273\n",
      "Epoch 260 | Train Loss: 0.819334089756012 | Test Loss: 0.8161896467208862\n",
      "Epoch 261 | Train Loss: 0.8057820200920105 | Test Loss: 0.8005381226539612\n",
      "Epoch 262 | Train Loss: 0.7938797473907471 | Test Loss: 0.7998939752578735\n",
      "Epoch 263 | Train Loss: 0.7999429702758789 | Test Loss: 0.8009993433952332\n",
      "Epoch 264 | Train Loss: 0.8070760369300842 | Test Loss: 0.7821842432022095\n",
      "Epoch 265 | Train Loss: 0.788719654083252 | Test Loss: 0.758470356464386\n",
      "Epoch 266 | Train Loss: 0.7595045566558838 | Test Loss: 0.7475470900535583\n",
      "Epoch 267 | Train Loss: 0.7445893287658691 | Test Loss: 0.7374064922332764\n",
      "Epoch 268 | Train Loss: 0.732887327671051 | Test Loss: 0.725923478603363\n",
      "Epoch 269 | Train Loss: 0.7190712690353394 | Test Loss: 0.7131401896476746\n",
      "Epoch 270 | Train Loss: 0.7056987881660461 | Test Loss: 0.7012587189674377\n",
      "Epoch 271 | Train Loss: 0.6932153105735779 | Test Loss: 0.6944490075111389\n",
      "Epoch 272 | Train Loss: 0.6836872696876526 | Test Loss: 0.6833419799804688\n",
      "Epoch 273 | Train Loss: 0.6718155741691589 | Test Loss: 0.6772788763046265\n",
      "Epoch 274 | Train Loss: 0.6641181707382202 | Test Loss: 0.6652358770370483\n",
      "Epoch 275 | Train Loss: 0.6531205773353577 | Test Loss: 0.6586100459098816\n",
      "Epoch 276 | Train Loss: 0.6455753445625305 | Test Loss: 0.6484425663948059\n",
      "Epoch 277 | Train Loss: 0.6377418637275696 | Test Loss: 0.6379573941230774\n",
      "Epoch 278 | Train Loss: 0.6255217790603638 | Test Loss: 0.6284785270690918\n",
      "Epoch 279 | Train Loss: 0.615075409412384 | Test Loss: 0.6177180409431458\n",
      "Epoch 280 | Train Loss: 0.6041206121444702 | Test Loss: 0.6043797135353088\n",
      "Epoch 281 | Train Loss: 0.5918653607368469 | Test Loss: 0.6016618013381958\n",
      "Epoch 282 | Train Loss: 0.5861088037490845 | Test Loss: 0.5871877074241638\n",
      "Epoch 283 | Train Loss: 0.5759673714637756 | Test Loss: 0.5781410336494446\n",
      "Epoch 284 | Train Loss: 0.5684847831726074 | Test Loss: 0.5745235681533813\n",
      "Epoch 285 | Train Loss: 0.5627930164337158 | Test Loss: 0.5639072060585022\n",
      "Epoch 286 | Train Loss: 0.5517657399177551 | Test Loss: 0.5557163953781128\n",
      "Epoch 287 | Train Loss: 0.5428584218025208 | Test Loss: 0.5496328473091125\n",
      "Epoch 288 | Train Loss: 0.5367546677589417 | Test Loss: 0.5455410480499268\n",
      "Epoch 289 | Train Loss: 0.5290160775184631 | Test Loss: 0.583906352519989\n",
      "Epoch 290 | Train Loss: 0.564918041229248 | Test Loss: 0.603866696357727\n",
      "Epoch 291 | Train Loss: 0.5842041969299316 | Test Loss: 0.5832257270812988\n",
      "Epoch 292 | Train Loss: 0.566307008266449 | Test Loss: 0.5379732847213745\n",
      "Epoch 293 | Train Loss: 0.5255775451660156 | Test Loss: 0.5582044720649719\n",
      "Epoch 294 | Train Loss: 0.5521813631057739 | Test Loss: 0.6225034594535828\n",
      "Epoch 295 | Train Loss: 0.6123144626617432 | Test Loss: 0.6293421387672424\n",
      "Epoch 296 | Train Loss: 0.6221787929534912 | Test Loss: 0.5889025926589966\n",
      "Epoch 297 | Train Loss: 0.5817638635635376 | Test Loss: 0.5575241446495056\n",
      "Epoch 298 | Train Loss: 0.5475091934204102 | Test Loss: 0.5681036710739136\n",
      "Epoch 299 | Train Loss: 0.5536932349205017 | Test Loss: 0.5623164772987366\n",
      "Epoch 300 | Train Loss: 0.5506561398506165 | Test Loss: 0.5405291318893433\n",
      "Epoch 301 | Train Loss: 0.5359751582145691 | Test Loss: 0.5454750657081604\n",
      "Epoch 302 | Train Loss: 0.5425214171409607 | Test Loss: 0.5479937195777893\n",
      "Epoch 303 | Train Loss: 0.5456454753875732 | Test Loss: 0.5411773920059204\n",
      "Epoch 304 | Train Loss: 0.538385808467865 | Test Loss: 0.5204843878746033\n",
      "Epoch 305 | Train Loss: 0.5167838931083679 | Test Loss: 0.5060523748397827\n",
      "Epoch 306 | Train Loss: 0.5006710886955261 | Test Loss: 0.4907955825328827\n",
      "Epoch 307 | Train Loss: 0.48432981967926025 | Test Loss: 0.4813666045665741\n",
      "Epoch 308 | Train Loss: 0.4716270864009857 | Test Loss: 0.46812954545021057\n",
      "Epoch 309 | Train Loss: 0.4586659073829651 | Test Loss: 0.4539090394973755\n",
      "Epoch 310 | Train Loss: 0.44554606080055237 | Test Loss: 0.43978551030158997\n",
      "Epoch 311 | Train Loss: 0.4334661364555359 | Test Loss: 0.4305652976036072\n",
      "Epoch 312 | Train Loss: 0.42489027976989746 | Test Loss: 0.422341912984848\n",
      "Epoch 313 | Train Loss: 0.4176439046859741 | Test Loss: 0.4166601896286011\n",
      "Epoch 314 | Train Loss: 0.4123937785625458 | Test Loss: 0.4078957140445709\n",
      "Epoch 315 | Train Loss: 0.4016759693622589 | Test Loss: 0.3999359905719757\n",
      "Epoch 316 | Train Loss: 0.3918682634830475 | Test Loss: 0.39228105545043945\n",
      "Epoch 317 | Train Loss: 0.3826659321784973 | Test Loss: 0.3825334310531616\n",
      "Epoch 318 | Train Loss: 0.37304794788360596 | Test Loss: 0.3745735287666321\n",
      "Epoch 319 | Train Loss: 0.3643489181995392 | Test Loss: 0.3684018552303314\n",
      "Epoch 320 | Train Loss: 0.35853612422943115 | Test Loss: 0.3630184233188629\n",
      "Epoch 321 | Train Loss: 0.35348087549209595 | Test Loss: 0.35824668407440186\n",
      "Epoch 322 | Train Loss: 0.3489619195461273 | Test Loss: 0.3528982996940613\n",
      "Epoch 323 | Train Loss: 0.34426456689834595 | Test Loss: 0.34558701515197754\n",
      "Epoch 324 | Train Loss: 0.3375731408596039 | Test Loss: 0.3354809880256653\n",
      "Epoch 325 | Train Loss: 0.32694944739341736 | Test Loss: 0.328197717666626\n",
      "Epoch 326 | Train Loss: 0.3196675479412079 | Test Loss: 0.3214889466762543\n",
      "Epoch 327 | Train Loss: 0.3136037588119507 | Test Loss: 0.31443172693252563\n",
      "Epoch 328 | Train Loss: 0.306718647480011 | Test Loss: 0.3093387484550476\n",
      "Epoch 329 | Train Loss: 0.3022717535495758 | Test Loss: 0.3063938021659851\n",
      "Epoch 330 | Train Loss: 0.29887303709983826 | Test Loss: 0.30420440435409546\n",
      "Epoch 331 | Train Loss: 0.29444774985313416 | Test Loss: 0.3021978735923767\n",
      "Epoch 332 | Train Loss: 0.2899143099784851 | Test Loss: 0.29820555448532104\n",
      "Epoch 333 | Train Loss: 0.2856529653072357 | Test Loss: 0.2935432493686676\n",
      "Epoch 334 | Train Loss: 0.28089040517807007 | Test Loss: 0.2870114743709564\n",
      "Epoch 335 | Train Loss: 0.2745005786418915 | Test Loss: 0.28168588876724243\n",
      "Epoch 336 | Train Loss: 0.2698114514350891 | Test Loss: 0.2824363708496094\n",
      "Epoch 337 | Train Loss: 0.2713846266269684 | Test Loss: 0.2808396816253662\n",
      "Epoch 338 | Train Loss: 0.2707290053367615 | Test Loss: 0.2731318175792694\n",
      "Epoch 339 | Train Loss: 0.2601941227912903 | Test Loss: 0.2699168622493744\n",
      "Epoch 340 | Train Loss: 0.2554655075073242 | Test Loss: 0.2683612108230591\n",
      "Epoch 341 | Train Loss: 0.2540654242038727 | Test Loss: 0.26339802145957947\n",
      "Epoch 342 | Train Loss: 0.24892672896385193 | Test Loss: 0.25677770376205444\n",
      "Epoch 343 | Train Loss: 0.24193939566612244 | Test Loss: 0.24901749193668365\n",
      "Epoch 344 | Train Loss: 0.23501355946063995 | Test Loss: 0.2464713156223297\n",
      "Epoch 345 | Train Loss: 0.23407109081745148 | Test Loss: 0.24440276622772217\n",
      "Epoch 346 | Train Loss: 0.23503698408603668 | Test Loss: 0.2395365685224533\n",
      "Epoch 347 | Train Loss: 0.22999092936515808 | Test Loss: 0.2344217300415039\n",
      "Epoch 348 | Train Loss: 0.2245892882347107 | Test Loss: 0.23291069269180298\n",
      "Epoch 349 | Train Loss: 0.22042740881443024 | Test Loss: 0.2309730499982834\n",
      "Epoch 350 | Train Loss: 0.21828605234622955 | Test Loss: 0.22725200653076172\n",
      "Epoch 351 | Train Loss: 0.21564459800720215 | Test Loss: 0.22138068079948425\n",
      "Epoch 352 | Train Loss: 0.21007990837097168 | Test Loss: 0.21726755797863007\n",
      "Epoch 353 | Train Loss: 0.20559516549110413 | Test Loss: 0.21348173916339874\n",
      "Epoch 354 | Train Loss: 0.20248794555664062 | Test Loss: 0.21139058470726013\n",
      "Epoch 355 | Train Loss: 0.20061561465263367 | Test Loss: 0.20793992280960083\n",
      "Epoch 356 | Train Loss: 0.1970546394586563 | Test Loss: 0.20566429197788239\n",
      "Epoch 357 | Train Loss: 0.19239158928394318 | Test Loss: 0.2026604562997818\n",
      "Epoch 358 | Train Loss: 0.19006408751010895 | Test Loss: 0.20119845867156982\n",
      "Epoch 359 | Train Loss: 0.18816570937633514 | Test Loss: 0.19804547727108002\n",
      "Epoch 360 | Train Loss: 0.1847524791955948 | Test Loss: 0.19461938738822937\n",
      "Epoch 361 | Train Loss: 0.18101467192173004 | Test Loss: 0.19080404937267303\n",
      "Epoch 362 | Train Loss: 0.17743465304374695 | Test Loss: 0.18727798759937286\n",
      "Epoch 363 | Train Loss: 0.1745327264070511 | Test Loss: 0.1841914802789688\n",
      "Epoch 364 | Train Loss: 0.172177255153656 | Test Loss: 0.1827174574136734\n",
      "Epoch 365 | Train Loss: 0.1701032519340515 | Test Loss: 0.18307684361934662\n",
      "Epoch 366 | Train Loss: 0.16917932033538818 | Test Loss: 0.1790187656879425\n",
      "Epoch 367 | Train Loss: 0.16611060500144958 | Test Loss: 0.17700470983982086\n",
      "Epoch 368 | Train Loss: 0.16380013525485992 | Test Loss: 0.17514309287071228\n",
      "Epoch 369 | Train Loss: 0.16193746030330658 | Test Loss: 0.1714046150445938\n",
      "Epoch 370 | Train Loss: 0.15799367427825928 | Test Loss: 0.16758474707603455\n",
      "Epoch 371 | Train Loss: 0.1550012230873108 | Test Loss: 0.16556522250175476\n",
      "Epoch 372 | Train Loss: 0.1528942734003067 | Test Loss: 0.16679167747497559\n",
      "Epoch 373 | Train Loss: 0.1522429883480072 | Test Loss: 0.16541361808776855\n",
      "Epoch 374 | Train Loss: 0.15113620460033417 | Test Loss: 0.16148391366004944\n",
      "Epoch 375 | Train Loss: 0.14876241981983185 | Test Loss: 0.15894632041454315\n",
      "Epoch 376 | Train Loss: 0.14639778435230255 | Test Loss: 0.1569090038537979\n",
      "Epoch 377 | Train Loss: 0.1441078633069992 | Test Loss: 0.15557649731636047\n",
      "Epoch 378 | Train Loss: 0.14252863824367523 | Test Loss: 0.15462258458137512\n",
      "Epoch 379 | Train Loss: 0.13999605178833008 | Test Loss: 0.15336300432682037\n",
      "Epoch 380 | Train Loss: 0.1384924352169037 | Test Loss: 0.15228651463985443\n",
      "Epoch 381 | Train Loss: 0.13641393184661865 | Test Loss: 0.1505378782749176\n",
      "Epoch 382 | Train Loss: 0.1341656595468521 | Test Loss: 0.15233078598976135\n",
      "Epoch 383 | Train Loss: 0.1354592740535736 | Test Loss: 0.15116280317306519\n",
      "Epoch 384 | Train Loss: 0.1343117654323578 | Test Loss: 0.14669080078601837\n",
      "Epoch 385 | Train Loss: 0.13279320299625397 | Test Loss: 0.14693327248096466\n",
      "Epoch 386 | Train Loss: 0.13427212834358215 | Test Loss: 0.14512841403484344\n",
      "Epoch 387 | Train Loss: 0.12992021441459656 | Test Loss: 0.14177219569683075\n",
      "Epoch 388 | Train Loss: 0.12605974078178406 | Test Loss: 0.14253826439380646\n",
      "Epoch 389 | Train Loss: 0.12574784457683563 | Test Loss: 0.13873879611492157\n",
      "Epoch 390 | Train Loss: 0.12323468923568726 | Test Loss: 0.13395459949970245\n",
      "Epoch 391 | Train Loss: 0.11889415234327316 | Test Loss: 0.13174481689929962\n",
      "Epoch 392 | Train Loss: 0.11796261370182037 | Test Loss: 0.13013866543769836\n",
      "Epoch 393 | Train Loss: 0.11651849001646042 | Test Loss: 0.12853707373142242\n",
      "Epoch 394 | Train Loss: 0.11434359103441238 | Test Loss: 0.1288609802722931\n",
      "Epoch 395 | Train Loss: 0.1138601154088974 | Test Loss: 0.12873081862926483\n",
      "Epoch 396 | Train Loss: 0.11341296136379242 | Test Loss: 0.12668269872665405\n",
      "Epoch 397 | Train Loss: 0.11299977451562881 | Test Loss: 0.12753763794898987\n",
      "Epoch 398 | Train Loss: 0.11550259590148926 | Test Loss: 0.13132011890411377\n",
      "Epoch 399 | Train Loss: 0.11888434737920761 | Test Loss: 0.1307869851589203\n",
      "Epoch 400 | Train Loss: 0.11849852651357651 | Test Loss: 0.1277206540107727\n",
      "Epoch 401 | Train Loss: 0.11589816212654114 | Test Loss: 0.12393305450677872\n",
      "Epoch 402 | Train Loss: 0.11192899197340012 | Test Loss: 0.12163840979337692\n",
      "Epoch 403 | Train Loss: 0.10958520323038101 | Test Loss: 0.1193540021777153\n",
      "Epoch 404 | Train Loss: 0.10648737102746964 | Test Loss: 0.11649905145168304\n",
      "Epoch 405 | Train Loss: 0.10442459583282471 | Test Loss: 0.11542929708957672\n",
      "Epoch 406 | Train Loss: 0.10288485139608383 | Test Loss: 0.11187336593866348\n",
      "Epoch 407 | Train Loss: 0.09984873980283737 | Test Loss: 0.11098956316709518\n",
      "Epoch 408 | Train Loss: 0.0987694188952446 | Test Loss: 0.10909916460514069\n",
      "Epoch 409 | Train Loss: 0.09648390859365463 | Test Loss: 0.10811552405357361\n",
      "Epoch 410 | Train Loss: 0.09482600539922714 | Test Loss: 0.10731187462806702\n",
      "Epoch 411 | Train Loss: 0.09337430447340012 | Test Loss: 0.1067441776394844\n",
      "Epoch 412 | Train Loss: 0.09253834187984467 | Test Loss: 0.10547065734863281\n",
      "Epoch 413 | Train Loss: 0.0918068215250969 | Test Loss: 0.1042703241109848\n",
      "Epoch 414 | Train Loss: 0.09067396074533463 | Test Loss: 0.10310240834951401\n",
      "Epoch 415 | Train Loss: 0.08901938796043396 | Test Loss: 0.10321932286024094\n",
      "Epoch 416 | Train Loss: 0.08890911936759949 | Test Loss: 0.10270088911056519\n",
      "Epoch 417 | Train Loss: 0.08771829307079315 | Test Loss: 0.10121079534292221\n",
      "Epoch 418 | Train Loss: 0.08589296042919159 | Test Loss: 0.10041884332895279\n",
      "Epoch 419 | Train Loss: 0.08504459261894226 | Test Loss: 0.09852026402950287\n",
      "Epoch 420 | Train Loss: 0.08269380033016205 | Test Loss: 0.0979033038020134\n",
      "Epoch 421 | Train Loss: 0.08169171214103699 | Test Loss: 0.10056353360414505\n",
      "Epoch 422 | Train Loss: 0.08203283697366714 | Test Loss: 0.0959663912653923\n",
      "Epoch 423 | Train Loss: 0.08056497573852539 | Test Loss: 0.09386877715587616\n",
      "Epoch 424 | Train Loss: 0.07806418091058731 | Test Loss: 0.09276352822780609\n",
      "Epoch 425 | Train Loss: 0.07812225073575974 | Test Loss: 0.09293261170387268\n",
      "Epoch 426 | Train Loss: 0.07755132019519806 | Test Loss: 0.09080920368432999\n",
      "Epoch 427 | Train Loss: 0.07475202530622482 | Test Loss: 0.08944962173700333\n",
      "Epoch 428 | Train Loss: 0.07279977202415466 | Test Loss: 0.08843251317739487\n",
      "Epoch 429 | Train Loss: 0.0717097818851471 | Test Loss: 0.08900830149650574\n",
      "Epoch 430 | Train Loss: 0.071999691426754 | Test Loss: 0.08992329984903336\n",
      "Epoch 431 | Train Loss: 0.073618084192276 | Test Loss: 0.08800365775823593\n",
      "Epoch 432 | Train Loss: 0.07081269472837448 | Test Loss: 0.08856531977653503\n",
      "Epoch 433 | Train Loss: 0.0699896514415741 | Test Loss: 0.087549589574337\n",
      "Epoch 434 | Train Loss: 0.06953667104244232 | Test Loss: 0.08658967912197113\n",
      "Epoch 435 | Train Loss: 0.06948786973953247 | Test Loss: 0.08509842306375504\n",
      "Epoch 436 | Train Loss: 0.06816712021827698 | Test Loss: 0.08217865973711014\n",
      "Epoch 437 | Train Loss: 0.06745384633541107 | Test Loss: 0.08142495155334473\n",
      "Epoch 438 | Train Loss: 0.06684069335460663 | Test Loss: 0.0796898677945137\n",
      "Epoch 439 | Train Loss: 0.06548620015382767 | Test Loss: 0.07855784147977829\n",
      "Epoch 440 | Train Loss: 0.06437084823846817 | Test Loss: 0.07752281427383423\n",
      "Epoch 441 | Train Loss: 0.0629560574889183 | Test Loss: 0.07627905905246735\n",
      "Epoch 442 | Train Loss: 0.06215877830982208 | Test Loss: 0.07623901218175888\n",
      "Epoch 443 | Train Loss: 0.06142990663647652 | Test Loss: 0.07552067935466766\n",
      "Epoch 444 | Train Loss: 0.06037510931491852 | Test Loss: 0.0739389955997467\n",
      "Epoch 445 | Train Loss: 0.05935244634747505 | Test Loss: 0.07407253980636597\n",
      "Epoch 446 | Train Loss: 0.06033844128251076 | Test Loss: 0.0746941938996315\n",
      "Epoch 447 | Train Loss: 0.060307323932647705 | Test Loss: 0.07860860228538513\n",
      "Epoch 448 | Train Loss: 0.06526482850313187 | Test Loss: 0.08182387053966522\n",
      "Epoch 449 | Train Loss: 0.06840185821056366 | Test Loss: 0.0738765224814415\n",
      "Epoch 450 | Train Loss: 0.06127750501036644 | Test Loss: 0.07476693391799927\n",
      "Epoch 451 | Train Loss: 0.060904473066329956 | Test Loss: 0.07437841594219208\n",
      "Epoch 452 | Train Loss: 0.06225096061825752 | Test Loss: 0.07358329743146896\n",
      "Epoch 453 | Train Loss: 0.06273715943098068 | Test Loss: 0.07212613523006439\n",
      "Epoch 454 | Train Loss: 0.05991044640541077 | Test Loss: 0.07238218933343887\n",
      "Epoch 455 | Train Loss: 0.06027143821120262 | Test Loss: 0.07507949322462082\n",
      "Epoch 456 | Train Loss: 0.0625397115945816 | Test Loss: 0.07493656128644943\n",
      "Epoch 457 | Train Loss: 0.06282416731119156 | Test Loss: 0.07594868540763855\n",
      "Epoch 458 | Train Loss: 0.0633799284696579 | Test Loss: 0.07288649678230286\n",
      "Epoch 459 | Train Loss: 0.05863555148243904 | Test Loss: 0.08925232291221619\n",
      "Epoch 460 | Train Loss: 0.07498326897621155 | Test Loss: 0.11245647817850113\n",
      "Epoch 461 | Train Loss: 0.09650267660617828 | Test Loss: 0.10147851705551147\n",
      "Epoch 462 | Train Loss: 0.08358538150787354 | Test Loss: 0.10794481635093689\n",
      "Epoch 463 | Train Loss: 0.09349744021892548 | Test Loss: 0.14006945490837097\n",
      "Epoch 464 | Train Loss: 0.12752437591552734 | Test Loss: 0.15529993176460266\n",
      "Epoch 465 | Train Loss: 0.1433044821023941 | Test Loss: 0.13310927152633667\n",
      "Epoch 466 | Train Loss: 0.12255841493606567 | Test Loss: 0.16344016790390015\n",
      "Epoch 467 | Train Loss: 0.1562611311674118 | Test Loss: 0.16539983451366425\n",
      "Epoch 468 | Train Loss: 0.15638329088687897 | Test Loss: 0.15095633268356323\n",
      "Epoch 469 | Train Loss: 0.1489306092262268 | Test Loss: 0.1985652893781662\n",
      "Epoch 470 | Train Loss: 0.20013943314552307 | Test Loss: 0.1701323539018631\n",
      "Epoch 471 | Train Loss: 0.1736077517271042 | Test Loss: 0.14249250292778015\n",
      "Epoch 472 | Train Loss: 0.13939864933490753 | Test Loss: 0.1450202763080597\n",
      "Epoch 473 | Train Loss: 0.13876226544380188 | Test Loss: 0.1514192819595337\n",
      "Epoch 474 | Train Loss: 0.14490766823291779 | Test Loss: 0.15686488151550293\n",
      "Epoch 475 | Train Loss: 0.14614959061145782 | Test Loss: 0.14462873339653015\n",
      "Epoch 476 | Train Loss: 0.13411352038383484 | Test Loss: 0.14001818001270294\n",
      "Epoch 477 | Train Loss: 0.13006015121936798 | Test Loss: 0.13157911598682404\n",
      "Epoch 478 | Train Loss: 0.12180272489786148 | Test Loss: 0.12531253695487976\n",
      "Epoch 479 | Train Loss: 0.1146235540509224 | Test Loss: 0.12020403891801834\n",
      "Epoch 480 | Train Loss: 0.10627396404743195 | Test Loss: 0.10902224481105804\n",
      "Epoch 481 | Train Loss: 0.0992458239197731 | Test Loss: 0.09895963966846466\n",
      "Epoch 482 | Train Loss: 0.09035751223564148 | Test Loss: 0.09086687862873077\n",
      "Epoch 483 | Train Loss: 0.08372747153043747 | Test Loss: 0.09479281306266785\n",
      "Epoch 484 | Train Loss: 0.0849044993519783 | Test Loss: 0.09900542348623276\n",
      "Epoch 485 | Train Loss: 0.09165973961353302 | Test Loss: 0.10064131021499634\n",
      "Epoch 486 | Train Loss: 0.0929407924413681 | Test Loss: 0.09090438485145569\n",
      "Epoch 487 | Train Loss: 0.08409848809242249 | Test Loss: 0.08093036711215973\n",
      "Epoch 488 | Train Loss: 0.07243740558624268 | Test Loss: 0.0796404629945755\n",
      "Epoch 489 | Train Loss: 0.06962756812572479 | Test Loss: 0.07815814763307571\n",
      "Epoch 490 | Train Loss: 0.07023857533931732 | Test Loss: 0.08569861948490143\n",
      "Epoch 491 | Train Loss: 0.07845410704612732 | Test Loss: 0.09156379103660583\n",
      "Epoch 492 | Train Loss: 0.08842693269252777 | Test Loss: 0.09057562053203583\n",
      "Epoch 493 | Train Loss: 0.0874212458729744 | Test Loss: 0.08876921236515045\n",
      "Epoch 494 | Train Loss: 0.08324652910232544 | Test Loss: 0.08219409734010696\n",
      "Epoch 495 | Train Loss: 0.07456183433532715 | Test Loss: 0.07712090015411377\n",
      "Epoch 496 | Train Loss: 0.0686551183462143 | Test Loss: 0.07222723215818405\n",
      "Epoch 497 | Train Loss: 0.06516390293836594 | Test Loss: 0.07064470648765564\n",
      "Epoch 498 | Train Loss: 0.06303836405277252 | Test Loss: 0.07073178142309189\n",
      "Epoch 499 | Train Loss: 0.0629420354962349 | Test Loss: 0.07146663218736649\n",
      "Epoch 500 | Train Loss: 0.061836376786231995 | Test Loss: 0.07076860964298248\n",
      "Epoch 501 | Train Loss: 0.06193998083472252 | Test Loss: 0.07015618681907654\n",
      "Epoch 502 | Train Loss: 0.06265120208263397 | Test Loss: 0.06930600851774216\n",
      "Epoch 503 | Train Loss: 0.060253843665122986 | Test Loss: 0.06578926742076874\n",
      "Epoch 504 | Train Loss: 0.057448066771030426 | Test Loss: 0.063675656914711\n",
      "Epoch 505 | Train Loss: 0.05658038333058357 | Test Loss: 0.062324535101652145\n",
      "Epoch 506 | Train Loss: 0.05448676273226738 | Test Loss: 0.058734990656375885\n",
      "Epoch 507 | Train Loss: 0.05150818079710007 | Test Loss: 0.05791115015745163\n",
      "Epoch 508 | Train Loss: 0.05050751194357872 | Test Loss: 0.056316301226615906\n",
      "Epoch 509 | Train Loss: 0.04965313524007797 | Test Loss: 0.057395659387111664\n",
      "Epoch 510 | Train Loss: 0.04955088719725609 | Test Loss: 0.05607972294092178\n",
      "Epoch 511 | Train Loss: 0.0478033609688282 | Test Loss: 0.05658722668886185\n",
      "Epoch 512 | Train Loss: 0.04667864739894867 | Test Loss: 0.05514442175626755\n",
      "Epoch 513 | Train Loss: 0.04437778517603874 | Test Loss: 0.05239659920334816\n",
      "Epoch 514 | Train Loss: 0.04242680221796036 | Test Loss: 0.05019501969218254\n",
      "Epoch 515 | Train Loss: 0.04080705717206001 | Test Loss: 0.04821707308292389\n",
      "Epoch 516 | Train Loss: 0.03871578723192215 | Test Loss: 0.0465116985142231\n",
      "Epoch 517 | Train Loss: 0.0371454693377018 | Test Loss: 0.0458732545375824\n",
      "Epoch 518 | Train Loss: 0.03606849163770676 | Test Loss: 0.045653749257326126\n",
      "Epoch 519 | Train Loss: 0.03509197384119034 | Test Loss: 0.04527341574430466\n",
      "Epoch 520 | Train Loss: 0.034259166568517685 | Test Loss: 0.04363609477877617\n",
      "Epoch 521 | Train Loss: 0.032666921615600586 | Test Loss: 0.04194701462984085\n",
      "Epoch 522 | Train Loss: 0.03243452310562134 | Test Loss: 0.04201941937208176\n",
      "Epoch 523 | Train Loss: 0.03196815401315689 | Test Loss: 0.04134627804160118\n",
      "Epoch 524 | Train Loss: 0.03089369647204876 | Test Loss: 0.040361370891332626\n",
      "Epoch 525 | Train Loss: 0.029767930507659912 | Test Loss: 0.039374370127916336\n",
      "Epoch 526 | Train Loss: 0.02879408746957779 | Test Loss: 0.03874211013317108\n",
      "Epoch 527 | Train Loss: 0.028160810470581055 | Test Loss: 0.0382925420999527\n",
      "Epoch 528 | Train Loss: 0.027736468240618706 | Test Loss: 0.03770792856812477\n",
      "Epoch 529 | Train Loss: 0.02714812010526657 | Test Loss: 0.03774425759911537\n",
      "Epoch 530 | Train Loss: 0.026826078072190285 | Test Loss: 0.03802569583058357\n",
      "Epoch 531 | Train Loss: 0.027934571728110313 | Test Loss: 0.03808024153113365\n",
      "Epoch 532 | Train Loss: 0.029468392953276634 | Test Loss: 0.04201599210500717\n",
      "Epoch 533 | Train Loss: 0.03193411976099014 | Test Loss: 0.04349924251437187\n",
      "Epoch 534 | Train Loss: 0.033717554062604904 | Test Loss: 0.04233003035187721\n",
      "Epoch 535 | Train Loss: 0.032701704651117325 | Test Loss: 0.040098220109939575\n",
      "Epoch 536 | Train Loss: 0.029777640476822853 | Test Loss: 0.037038322538137436\n",
      "Epoch 537 | Train Loss: 0.02744232304394245 | Test Loss: 0.036288607865571976\n",
      "Epoch 538 | Train Loss: 0.026755541563034058 | Test Loss: 0.03734159842133522\n",
      "Epoch 539 | Train Loss: 0.028377993032336235 | Test Loss: 0.03769148513674736\n",
      "Epoch 540 | Train Loss: 0.028754057362675667 | Test Loss: 0.03931226581335068\n",
      "Epoch 541 | Train Loss: 0.02905776910483837 | Test Loss: 0.037853799760341644\n",
      "Epoch 542 | Train Loss: 0.027938494458794594 | Test Loss: 0.03555477783083916\n",
      "Epoch 543 | Train Loss: 0.025545381009578705 | Test Loss: 0.0347273126244545\n",
      "Epoch 544 | Train Loss: 0.024644002318382263 | Test Loss: 0.03438012674450874\n",
      "Epoch 545 | Train Loss: 0.02425619401037693 | Test Loss: 0.03447626531124115\n",
      "Epoch 546 | Train Loss: 0.024523593485355377 | Test Loss: 0.03470229357481003\n",
      "Epoch 547 | Train Loss: 0.024510791525244713 | Test Loss: 0.03437594696879387\n",
      "Epoch 548 | Train Loss: 0.024264948442578316 | Test Loss: 0.03401331976056099\n",
      "Epoch 549 | Train Loss: 0.023291215300559998 | Test Loss: 0.03208392113447189\n",
      "Epoch 550 | Train Loss: 0.022123968228697777 | Test Loss: 0.03185579553246498\n",
      "Epoch 551 | Train Loss: 0.020899944007396698 | Test Loss: 0.03296003118157387\n",
      "Epoch 552 | Train Loss: 0.020906198769807816 | Test Loss: 0.03188345581293106\n",
      "Epoch 553 | Train Loss: 0.020600806921720505 | Test Loss: 0.030769117176532745\n",
      "Epoch 554 | Train Loss: 0.020642155781388283 | Test Loss: 0.030145321041345596\n",
      "Epoch 555 | Train Loss: 0.021301306784152985 | Test Loss: 0.028965706005692482\n",
      "Epoch 556 | Train Loss: 0.02097983844578266 | Test Loss: 0.027505990117788315\n",
      "Epoch 557 | Train Loss: 0.02019168995320797 | Test Loss: 0.02809194289147854\n",
      "Epoch 558 | Train Loss: 0.0203982125967741 | Test Loss: 0.028533935546875\n",
      "Epoch 559 | Train Loss: 0.020262783393263817 | Test Loss: 0.028038527816534042\n",
      "Epoch 560 | Train Loss: 0.01946980506181717 | Test Loss: 0.026643771678209305\n",
      "Epoch 561 | Train Loss: 0.01861102506518364 | Test Loss: 0.025862691923975945\n",
      "Epoch 562 | Train Loss: 0.018242737278342247 | Test Loss: 0.025463055819272995\n",
      "Epoch 563 | Train Loss: 0.017381032928824425 | Test Loss: 0.025349972769618034\n",
      "Epoch 564 | Train Loss: 0.01774447038769722 | Test Loss: 0.025100022554397583\n",
      "Epoch 565 | Train Loss: 0.017581414431333542 | Test Loss: 0.024711742997169495\n",
      "Epoch 566 | Train Loss: 0.017259400337934494 | Test Loss: 0.029431935399770737\n",
      "Epoch 567 | Train Loss: 0.021767672151327133 | Test Loss: 0.03714297339320183\n",
      "Epoch 568 | Train Loss: 0.029306506738066673 | Test Loss: 0.0419895239174366\n",
      "Epoch 569 | Train Loss: 0.0337708406150341 | Test Loss: 0.03996345028281212\n",
      "Epoch 570 | Train Loss: 0.03224355727434158 | Test Loss: 0.04013350233435631\n",
      "Epoch 571 | Train Loss: 0.029670771211385727 | Test Loss: 0.03346743807196617\n",
      "Epoch 572 | Train Loss: 0.024054203182458878 | Test Loss: 0.034662529826164246\n",
      "Epoch 573 | Train Loss: 0.02450227364897728 | Test Loss: 0.03897394612431526\n",
      "Epoch 574 | Train Loss: 0.029221834614872932 | Test Loss: 0.039485249668359756\n",
      "Epoch 575 | Train Loss: 0.03165207803249359 | Test Loss: 0.03547642007470131\n",
      "Epoch 576 | Train Loss: 0.028262650594115257 | Test Loss: 0.03025556541979313\n",
      "Epoch 577 | Train Loss: 0.0220854002982378 | Test Loss: 0.02755492553114891\n",
      "Epoch 578 | Train Loss: 0.020272770896553993 | Test Loss: 0.02816273644566536\n",
      "Epoch 579 | Train Loss: 0.021159382537007332 | Test Loss: 0.02898850291967392\n",
      "Epoch 580 | Train Loss: 0.022431423887610435 | Test Loss: 0.02914430759847164\n",
      "Epoch 581 | Train Loss: 0.022822661325335503 | Test Loss: 0.028502482920885086\n",
      "Epoch 582 | Train Loss: 0.022030889987945557 | Test Loss: 0.026435358449816704\n",
      "Epoch 583 | Train Loss: 0.020868780091404915 | Test Loss: 0.025890350341796875\n",
      "Epoch 584 | Train Loss: 0.02011597342789173 | Test Loss: 0.024715708568692207\n",
      "Epoch 585 | Train Loss: 0.01902037300169468 | Test Loss: 0.024976037442684174\n",
      "Epoch 586 | Train Loss: 0.018414810299873352 | Test Loss: 0.025432394817471504\n",
      "Epoch 587 | Train Loss: 0.018582656979560852 | Test Loss: 0.026533711701631546\n",
      "Epoch 588 | Train Loss: 0.019291000440716743 | Test Loss: 0.026805927976965904\n",
      "Epoch 589 | Train Loss: 0.018973639234900475 | Test Loss: 0.02542872354388237\n",
      "Epoch 590 | Train Loss: 0.017859864979982376 | Test Loss: 0.02443532459437847\n",
      "Epoch 591 | Train Loss: 0.016724806278944016 | Test Loss: 0.02269778400659561\n",
      "Epoch 592 | Train Loss: 0.01577962189912796 | Test Loss: 0.02228444628417492\n",
      "Epoch 593 | Train Loss: 0.015165943652391434 | Test Loss: 0.02112681418657303\n",
      "Epoch 594 | Train Loss: 0.014705894514918327 | Test Loss: 0.020926402881741524\n",
      "Epoch 595 | Train Loss: 0.014246285893023014 | Test Loss: 0.02085789106786251\n",
      "Epoch 596 | Train Loss: 0.013704141601920128 | Test Loss: 0.020915357396006584\n",
      "Epoch 597 | Train Loss: 0.013212176971137524 | Test Loss: 0.02070779725909233\n",
      "Epoch 598 | Train Loss: 0.01291035208851099 | Test Loss: 0.02053411491215229\n",
      "Epoch 599 | Train Loss: 0.012742397375404835 | Test Loss: 0.020222067832946777\n",
      "Epoch 600 | Train Loss: 0.012495494447648525 | Test Loss: 0.019685478881001472\n",
      "Epoch 601 | Train Loss: 0.012176310643553734 | Test Loss: 0.019244709983468056\n",
      "Epoch 602 | Train Loss: 0.01189171802252531 | Test Loss: 0.018763316795229912\n",
      "Epoch 603 | Train Loss: 0.011563893407583237 | Test Loss: 0.018330756574869156\n",
      "Epoch 604 | Train Loss: 0.011214789003133774 | Test Loss: 0.017983583733439445\n",
      "Epoch 605 | Train Loss: 0.01099342480301857 | Test Loss: 0.017585741356015205\n",
      "Epoch 606 | Train Loss: 0.010792654007673264 | Test Loss: 0.017352040857076645\n",
      "Epoch 607 | Train Loss: 0.010619652457535267 | Test Loss: 0.0170955378562212\n",
      "Epoch 608 | Train Loss: 0.010427208617329597 | Test Loss: 0.016915397718548775\n",
      "Epoch 609 | Train Loss: 0.010250936262309551 | Test Loss: 0.016786042600870132\n",
      "Epoch 610 | Train Loss: 0.010056517086923122 | Test Loss: 0.01671958714723587\n",
      "Epoch 611 | Train Loss: 0.009892296977341175 | Test Loss: 0.01661045476794243\n",
      "Epoch 612 | Train Loss: 0.0096801882609725 | Test Loss: 0.016498835757374763\n",
      "Epoch 613 | Train Loss: 0.009621045552194118 | Test Loss: 0.016234245151281357\n",
      "Epoch 614 | Train Loss: 0.009392195381224155 | Test Loss: 0.016006167978048325\n",
      "Epoch 615 | Train Loss: 0.009264347143471241 | Test Loss: 0.015856485813856125\n",
      "Epoch 616 | Train Loss: 0.00913337804377079 | Test Loss: 0.015773169696331024\n",
      "Epoch 617 | Train Loss: 0.009018227458000183 | Test Loss: 0.015777070075273514\n",
      "Epoch 618 | Train Loss: 0.009023888036608696 | Test Loss: 0.015808384865522385\n",
      "Epoch 619 | Train Loss: 0.008892316371202469 | Test Loss: 0.015689510852098465\n",
      "Epoch 620 | Train Loss: 0.008798733353614807 | Test Loss: 0.015492873266339302\n",
      "Epoch 621 | Train Loss: 0.008926640264689922 | Test Loss: 0.015357890166342258\n",
      "Epoch 622 | Train Loss: 0.008791999891400337 | Test Loss: 0.016183728352189064\n",
      "Epoch 623 | Train Loss: 0.008622813038527966 | Test Loss: 0.015521259047091007\n",
      "Epoch 624 | Train Loss: 0.008684833534061909 | Test Loss: 0.015587154775857925\n",
      "Epoch 625 | Train Loss: 0.008929165080189705 | Test Loss: 0.016156543046236038\n",
      "Epoch 626 | Train Loss: 0.008802135474979877 | Test Loss: 0.02037268690764904\n",
      "Epoch 627 | Train Loss: 0.012446369044482708 | Test Loss: 0.016991479322314262\n",
      "Epoch 628 | Train Loss: 0.010848337784409523 | Test Loss: 0.025469278916716576\n",
      "Epoch 629 | Train Loss: 0.01601238176226616 | Test Loss: 0.03628481924533844\n",
      "Epoch 630 | Train Loss: 0.025951514020562172 | Test Loss: 0.05081574618816376\n",
      "Epoch 631 | Train Loss: 0.039726704359054565 | Test Loss: 0.04113117232918739\n",
      "Epoch 632 | Train Loss: 0.029653703793883324 | Test Loss: 0.04139239713549614\n",
      "Epoch 633 | Train Loss: 0.02875836007297039 | Test Loss: 0.050184205174446106\n",
      "Epoch 634 | Train Loss: 0.04073631018400192 | Test Loss: 0.03684835135936737\n",
      "Epoch 635 | Train Loss: 0.02581937238574028 | Test Loss: 0.05279083177447319\n",
      "Epoch 636 | Train Loss: 0.0376664437353611 | Test Loss: 0.09127295762300491\n",
      "Epoch 637 | Train Loss: 0.07233430445194244 | Test Loss: 0.1055070012807846\n",
      "Epoch 638 | Train Loss: 0.08907390385866165 | Test Loss: 0.08198714256286621\n",
      "Epoch 639 | Train Loss: 0.07007896900177002 | Test Loss: 0.11386104673147202\n",
      "Epoch 640 | Train Loss: 0.0989624634385109 | Test Loss: 0.10936000198125839\n",
      "Epoch 641 | Train Loss: 0.08557570725679398 | Test Loss: 0.08635205030441284\n",
      "Epoch 642 | Train Loss: 0.063186414539814 | Test Loss: 0.11800722777843475\n",
      "Epoch 643 | Train Loss: 0.10878486186265945 | Test Loss: 0.08835498243570328\n",
      "Epoch 644 | Train Loss: 0.07355006784200668 | Test Loss: 0.06387900561094284\n",
      "Epoch 645 | Train Loss: 0.055981189012527466 | Test Loss: 0.06968089193105698\n",
      "Epoch 646 | Train Loss: 0.0630519762635231 | Test Loss: 0.07833652943372726\n",
      "Epoch 647 | Train Loss: 0.07119400799274445 | Test Loss: 0.08072468638420105\n",
      "Epoch 648 | Train Loss: 0.07298561930656433 | Test Loss: 0.06905495375394821\n",
      "Epoch 649 | Train Loss: 0.06652659922838211 | Test Loss: 0.05781112238764763\n",
      "Epoch 650 | Train Loss: 0.05070493370294571 | Test Loss: 0.05746638774871826\n",
      "Epoch 651 | Train Loss: 0.05042547360062599 | Test Loss: 0.05428242310881615\n",
      "Epoch 652 | Train Loss: 0.047579575330019 | Test Loss: 0.04987545683979988\n",
      "Epoch 653 | Train Loss: 0.04388904944062233 | Test Loss: 0.06459968537092209\n",
      "Epoch 654 | Train Loss: 0.05871649459004402 | Test Loss: 0.08235353976488113\n",
      "Epoch 655 | Train Loss: 0.07420945167541504 | Test Loss: 0.07510755956172943\n",
      "Epoch 656 | Train Loss: 0.06780213862657547 | Test Loss: 0.06459829211235046\n",
      "Epoch 657 | Train Loss: 0.05548980087041855 | Test Loss: 0.057339951395988464\n",
      "Epoch 658 | Train Loss: 0.04834030941128731 | Test Loss: 0.051965560764074326\n",
      "Epoch 659 | Train Loss: 0.048573777079582214 | Test Loss: 0.04918685927987099\n",
      "Epoch 660 | Train Loss: 0.04502582550048828 | Test Loss: 0.04814619943499565\n",
      "Epoch 661 | Train Loss: 0.04321730509400368 | Test Loss: 0.04514007270336151\n",
      "Epoch 662 | Train Loss: 0.04149036109447479 | Test Loss: 0.04327964410185814\n",
      "Epoch 663 | Train Loss: 0.03980289772152901 | Test Loss: 0.04237666353583336\n",
      "Epoch 664 | Train Loss: 0.0399489551782608 | Test Loss: 0.04104145988821983\n",
      "Epoch 665 | Train Loss: 0.03789013996720314 | Test Loss: 0.03835953027009964\n",
      "Epoch 666 | Train Loss: 0.035424601286649704 | Test Loss: 0.034657370299100876\n",
      "Epoch 667 | Train Loss: 0.030989021062850952 | Test Loss: 0.031436946243047714\n",
      "Epoch 668 | Train Loss: 0.02683175355195999 | Test Loss: 0.02934073656797409\n",
      "Epoch 669 | Train Loss: 0.024093912914395332 | Test Loss: 0.02769305184483528\n",
      "Epoch 670 | Train Loss: 0.022716043516993523 | Test Loss: 0.028200466185808182\n",
      "Epoch 671 | Train Loss: 0.02196659706532955 | Test Loss: 0.028560513630509377\n",
      "Epoch 672 | Train Loss: 0.02124819904565811 | Test Loss: 0.02881935052573681\n",
      "Epoch 673 | Train Loss: 0.02074461802840233 | Test Loss: 0.02957526594400406\n",
      "Epoch 674 | Train Loss: 0.021211741492152214 | Test Loss: 0.03068019449710846\n",
      "Epoch 675 | Train Loss: 0.02242835983633995 | Test Loss: 0.032232627272605896\n",
      "Epoch 676 | Train Loss: 0.023659801110625267 | Test Loss: 0.028360944241285324\n",
      "Epoch 677 | Train Loss: 0.022202689200639725 | Test Loss: 0.023472974076867104\n",
      "Epoch 678 | Train Loss: 0.016498349606990814 | Test Loss: 0.02222023345530033\n",
      "Epoch 679 | Train Loss: 0.0164716225117445 | Test Loss: 0.022882353514432907\n",
      "Epoch 680 | Train Loss: 0.018000420182943344 | Test Loss: 0.023912405595183372\n",
      "Epoch 681 | Train Loss: 0.01887841522693634 | Test Loss: 0.024659238755702972\n",
      "Epoch 682 | Train Loss: 0.02060999721288681 | Test Loss: 0.024350382387638092\n",
      "Epoch 683 | Train Loss: 0.019757820293307304 | Test Loss: 0.023546965792775154\n",
      "Epoch 684 | Train Loss: 0.019292576238512993 | Test Loss: 0.022979620844125748\n",
      "Epoch 685 | Train Loss: 0.018361328169703484 | Test Loss: 0.021636784076690674\n",
      "Epoch 686 | Train Loss: 0.017813686281442642 | Test Loss: 0.020413821563124657\n",
      "Epoch 687 | Train Loss: 0.016427868977189064 | Test Loss: 0.02048884890973568\n",
      "Epoch 688 | Train Loss: 0.015519187785685062 | Test Loss: 0.017860671505331993\n",
      "Epoch 689 | Train Loss: 0.013531431555747986 | Test Loss: 0.018772028386592865\n",
      "Epoch 690 | Train Loss: 0.013797478750348091 | Test Loss: 0.020949725061655045\n",
      "Epoch 691 | Train Loss: 0.016073010861873627 | Test Loss: 0.02261943556368351\n",
      "Epoch 692 | Train Loss: 0.019222166389226913 | Test Loss: 0.02492722123861313\n",
      "Epoch 693 | Train Loss: 0.021753715351223946 | Test Loss: 0.025015803053975105\n",
      "Epoch 694 | Train Loss: 0.019260557368397713 | Test Loss: 0.024632377550005913\n",
      "Epoch 695 | Train Loss: 0.01845531165599823 | Test Loss: 0.021901894360780716\n",
      "Epoch 696 | Train Loss: 0.016090281307697296 | Test Loss: 0.020378045737743378\n",
      "Epoch 697 | Train Loss: 0.014917389489710331 | Test Loss: 0.01930263824760914\n",
      "Epoch 698 | Train Loss: 0.013655747286975384 | Test Loss: 0.018398722633719444\n",
      "Epoch 699 | Train Loss: 0.013095413334667683 | Test Loss: 0.019102664664387703\n",
      "Epoch 700 | Train Loss: 0.01336414460092783 | Test Loss: 0.019695835188031197\n",
      "Epoch 701 | Train Loss: 0.014039264991879463 | Test Loss: 0.020289944484829903\n",
      "Epoch 702 | Train Loss: 0.014747758395969868 | Test Loss: 0.0204716045409441\n",
      "Epoch 703 | Train Loss: 0.014958235435187817 | Test Loss: 0.019901232793927193\n",
      "Epoch 704 | Train Loss: 0.014383465982973576 | Test Loss: 0.01976233534514904\n",
      "Epoch 705 | Train Loss: 0.013997803442180157 | Test Loss: 0.019816169515252113\n",
      "Epoch 706 | Train Loss: 0.014407106675207615 | Test Loss: 0.01893579587340355\n",
      "Epoch 707 | Train Loss: 0.014401919208467007 | Test Loss: 0.017682021483778954\n",
      "Epoch 708 | Train Loss: 0.013118965551257133 | Test Loss: 0.01629638671875\n",
      "Epoch 709 | Train Loss: 0.012086693197488785 | Test Loss: 0.017644574865698814\n",
      "Epoch 710 | Train Loss: 0.01201824564486742 | Test Loss: 0.015278921462595463\n",
      "Epoch 711 | Train Loss: 0.010416441597044468 | Test Loss: 0.015416350215673447\n",
      "Epoch 712 | Train Loss: 0.009921821765601635 | Test Loss: 0.016325965523719788\n",
      "Epoch 713 | Train Loss: 0.010058612562716007 | Test Loss: 0.018897850066423416\n",
      "Epoch 714 | Train Loss: 0.012292434461414814 | Test Loss: 0.018817836418747902\n",
      "Epoch 715 | Train Loss: 0.012804863043129444 | Test Loss: 0.019378172233700752\n",
      "Epoch 716 | Train Loss: 0.012079291045665741 | Test Loss: 0.017954399809241295\n",
      "Epoch 717 | Train Loss: 0.011592086404561996 | Test Loss: 0.015948954969644547\n",
      "Epoch 718 | Train Loss: 0.010053110308945179 | Test Loss: 0.015033068135380745\n",
      "Epoch 719 | Train Loss: 0.009182515554130077 | Test Loss: 0.013571465387940407\n",
      "Epoch 720 | Train Loss: 0.008538518100976944 | Test Loss: 0.013473463244736195\n",
      "Epoch 721 | Train Loss: 0.00822586938738823 | Test Loss: 0.012868800200521946\n",
      "Epoch 722 | Train Loss: 0.008237493224442005 | Test Loss: 0.012096741236746311\n",
      "Epoch 723 | Train Loss: 0.008001116104424 | Test Loss: 0.011543122120201588\n",
      "Epoch 724 | Train Loss: 0.007947378791868687 | Test Loss: 0.011185736395418644\n",
      "Epoch 725 | Train Loss: 0.007777039427310228 | Test Loss: 0.01087900623679161\n",
      "Epoch 726 | Train Loss: 0.007472440600395203 | Test Loss: 0.010455125942826271\n",
      "Epoch 727 | Train Loss: 0.007332421373575926 | Test Loss: 0.010002890601754189\n",
      "Epoch 728 | Train Loss: 0.006963413208723068 | Test Loss: 0.009916704148054123\n",
      "Epoch 729 | Train Loss: 0.0068050711415708065 | Test Loss: 0.009881451725959778\n",
      "Epoch 730 | Train Loss: 0.006640630774199963 | Test Loss: 0.009911011904478073\n",
      "Epoch 731 | Train Loss: 0.006441333796828985 | Test Loss: 0.009948493912816048\n",
      "Epoch 732 | Train Loss: 0.006275190506130457 | Test Loss: 0.010067330673336983\n",
      "Epoch 733 | Train Loss: 0.006104641128331423 | Test Loss: 0.010016919113695621\n",
      "Epoch 734 | Train Loss: 0.005928030703216791 | Test Loss: 0.01000071968883276\n",
      "Epoch 735 | Train Loss: 0.005797508172690868 | Test Loss: 0.010033594444394112\n",
      "Epoch 736 | Train Loss: 0.005625185556709766 | Test Loss: 0.009919955395162106\n",
      "Epoch 737 | Train Loss: 0.0054754046723246574 | Test Loss: 0.009763750247657299\n",
      "Epoch 738 | Train Loss: 0.005322703626006842 | Test Loss: 0.00958163756877184\n",
      "Epoch 739 | Train Loss: 0.005182231310755014 | Test Loss: 0.00932658463716507\n",
      "Epoch 740 | Train Loss: 0.005063701421022415 | Test Loss: 0.009108339436352253\n",
      "Epoch 741 | Train Loss: 0.004946606699377298 | Test Loss: 0.008904797025024891\n",
      "Epoch 742 | Train Loss: 0.004846097901463509 | Test Loss: 0.008707634173333645\n",
      "Epoch 743 | Train Loss: 0.004756178706884384 | Test Loss: 0.008580041117966175\n",
      "Epoch 744 | Train Loss: 0.004655107390135527 | Test Loss: 0.008448830805718899\n",
      "Epoch 745 | Train Loss: 0.004561072215437889 | Test Loss: 0.008324873633682728\n",
      "Epoch 746 | Train Loss: 0.004478535149246454 | Test Loss: 0.008214961737394333\n",
      "Epoch 747 | Train Loss: 0.004401445854455233 | Test Loss: 0.008125309832394123\n",
      "Epoch 748 | Train Loss: 0.00433344254270196 | Test Loss: 0.008054632693529129\n",
      "Epoch 749 | Train Loss: 0.004261369816958904 | Test Loss: 0.007978630252182484\n",
      "Epoch 750 | Train Loss: 0.004189795348793268 | Test Loss: 0.007905881851911545\n",
      "Epoch 751 | Train Loss: 0.004123091232031584 | Test Loss: 0.007849497720599174\n",
      "Epoch 752 | Train Loss: 0.004055142868310213 | Test Loss: 0.00781225087121129\n",
      "Epoch 753 | Train Loss: 0.003993357066065073 | Test Loss: 0.007772176992148161\n",
      "Epoch 754 | Train Loss: 0.0039393045008182526 | Test Loss: 0.007743383292108774\n",
      "Epoch 755 | Train Loss: 0.0038876088801771402 | Test Loss: 0.007712964434176683\n",
      "Epoch 756 | Train Loss: 0.0038384690415114164 | Test Loss: 0.007677354849874973\n",
      "Epoch 757 | Train Loss: 0.0037901282776147127 | Test Loss: 0.007631056010723114\n",
      "Epoch 758 | Train Loss: 0.0037392033264040947 | Test Loss: 0.0075834463350474834\n",
      "Epoch 759 | Train Loss: 0.0036913047078996897 | Test Loss: 0.007524334359914064\n",
      "Epoch 760 | Train Loss: 0.0036468813195824623 | Test Loss: 0.007422121241688728\n",
      "Epoch 761 | Train Loss: 0.003595939837396145 | Test Loss: 0.007331020198762417\n",
      "Epoch 762 | Train Loss: 0.0035560273099690676 | Test Loss: 0.007183856330811977\n",
      "Epoch 763 | Train Loss: 0.003512647235766053 | Test Loss: 0.007130854297429323\n",
      "Epoch 764 | Train Loss: 0.003473263932392001 | Test Loss: 0.00708603672683239\n",
      "Epoch 765 | Train Loss: 0.0034344324376434088 | Test Loss: 0.007105742581188679\n",
      "Epoch 766 | Train Loss: 0.0033963106106966734 | Test Loss: 0.0070955390110611916\n",
      "Epoch 767 | Train Loss: 0.003363193478435278 | Test Loss: 0.007067802827805281\n",
      "Epoch 768 | Train Loss: 0.0033209151588380337 | Test Loss: 0.007053731940686703\n",
      "Epoch 769 | Train Loss: 0.003281327895820141 | Test Loss: 0.007053048349916935\n",
      "Epoch 770 | Train Loss: 0.0032437166664749384 | Test Loss: 0.007048540282994509\n",
      "Epoch 771 | Train Loss: 0.0032086523715406656 | Test Loss: 0.007043796591460705\n",
      "Epoch 772 | Train Loss: 0.0031763913575559855 | Test Loss: 0.007038054522126913\n",
      "Epoch 773 | Train Loss: 0.0031456281431019306 | Test Loss: 0.007030196022242308\n",
      "Epoch 774 | Train Loss: 0.0031161245424300432 | Test Loss: 0.007020552176982164\n",
      "Epoch 775 | Train Loss: 0.0030872279312461615 | Test Loss: 0.007007532753050327\n",
      "Epoch 776 | Train Loss: 0.0030584975611418486 | Test Loss: 0.006990144494920969\n",
      "Epoch 777 | Train Loss: 0.003029988380149007 | Test Loss: 0.006969112437218428\n",
      "Epoch 778 | Train Loss: 0.003001590957865119 | Test Loss: 0.006944761611521244\n",
      "Epoch 779 | Train Loss: 0.002973719732835889 | Test Loss: 0.006922170985490084\n",
      "Epoch 780 | Train Loss: 0.002946296473965049 | Test Loss: 0.006900920998305082\n",
      "Epoch 781 | Train Loss: 0.002920447615906596 | Test Loss: 0.006870259065181017\n",
      "Epoch 782 | Train Loss: 0.0028941945638507605 | Test Loss: 0.0068382336758077145\n",
      "Epoch 783 | Train Loss: 0.002868480049073696 | Test Loss: 0.006803048774600029\n",
      "Epoch 784 | Train Loss: 0.002844050293788314 | Test Loss: 0.006772840395569801\n",
      "Epoch 785 | Train Loss: 0.002820011228322983 | Test Loss: 0.00675065815448761\n",
      "Epoch 786 | Train Loss: 0.0027943155728280544 | Test Loss: 0.006737746298313141\n",
      "Epoch 787 | Train Loss: 0.0027683358639478683 | Test Loss: 0.006719901226460934\n",
      "Epoch 788 | Train Loss: 0.002746072132140398 | Test Loss: 0.0066984957084059715\n",
      "Epoch 789 | Train Loss: 0.0027237709145992994 | Test Loss: 0.006670164410024881\n",
      "Epoch 790 | Train Loss: 0.002702354220673442 | Test Loss: 0.006643414497375488\n",
      "Epoch 791 | Train Loss: 0.0026813840959221125 | Test Loss: 0.0066247908398509026\n",
      "Epoch 792 | Train Loss: 0.002660727594047785 | Test Loss: 0.006605150178074837\n",
      "Epoch 793 | Train Loss: 0.0026407423429191113 | Test Loss: 0.0065816547721624374\n",
      "Epoch 794 | Train Loss: 0.0026206925977021456 | Test Loss: 0.006554811727255583\n",
      "Epoch 795 | Train Loss: 0.00260067917406559 | Test Loss: 0.006527860648930073\n",
      "Epoch 796 | Train Loss: 0.002581040607765317 | Test Loss: 0.00650183716788888\n",
      "Epoch 797 | Train Loss: 0.0025617461651563644 | Test Loss: 0.006478165742009878\n",
      "Epoch 798 | Train Loss: 0.0025430989917367697 | Test Loss: 0.00645878491923213\n",
      "Epoch 799 | Train Loss: 0.0025261680129915476 | Test Loss: 0.006446719169616699\n",
      "Epoch 800 | Train Loss: 0.0025078821927309036 | Test Loss: 0.006437815260142088\n",
      "Epoch 801 | Train Loss: 0.0024897640105336905 | Test Loss: 0.006427667569369078\n",
      "Epoch 802 | Train Loss: 0.002472072606906295 | Test Loss: 0.0064156074076890945\n",
      "Epoch 803 | Train Loss: 0.0024546056520193815 | Test Loss: 0.006401961203664541\n",
      "Epoch 804 | Train Loss: 0.0024370644241571426 | Test Loss: 0.006386150605976582\n",
      "Epoch 805 | Train Loss: 0.0024198219180107117 | Test Loss: 0.006365273147821426\n",
      "Epoch 806 | Train Loss: 0.0024017018731683493 | Test Loss: 0.006344333756715059\n",
      "Epoch 807 | Train Loss: 0.002385262632742524 | Test Loss: 0.006325075402855873\n",
      "Epoch 808 | Train Loss: 0.002368992893025279 | Test Loss: 0.0063055697828531265\n",
      "Epoch 809 | Train Loss: 0.002352879149839282 | Test Loss: 0.00628643250092864\n",
      "Epoch 810 | Train Loss: 0.002337599638849497 | Test Loss: 0.006272476632148027\n",
      "Epoch 811 | Train Loss: 0.0023219243157655 | Test Loss: 0.006256747059524059\n",
      "Epoch 812 | Train Loss: 0.0023069926537573338 | Test Loss: 0.0062370747327804565\n",
      "Epoch 813 | Train Loss: 0.002291977172717452 | Test Loss: 0.0062179770320653915\n",
      "Epoch 814 | Train Loss: 0.002277268096804619 | Test Loss: 0.006202498450875282\n",
      "Epoch 815 | Train Loss: 0.002262842608615756 | Test Loss: 0.006191830150783062\n",
      "Epoch 816 | Train Loss: 0.002248438773676753 | Test Loss: 0.006185680627822876\n",
      "Epoch 817 | Train Loss: 0.002234105486422777 | Test Loss: 0.00617951899766922\n",
      "Epoch 818 | Train Loss: 0.0022204588167369366 | Test Loss: 0.0061670150607824326\n",
      "Epoch 819 | Train Loss: 0.002206775126978755 | Test Loss: 0.0061506833881139755\n",
      "Epoch 820 | Train Loss: 0.0021929258946329355 | Test Loss: 0.006130345165729523\n",
      "Epoch 821 | Train Loss: 0.0021794820204377174 | Test Loss: 0.00611396599560976\n",
      "Epoch 822 | Train Loss: 0.0021661976352334023 | Test Loss: 0.006102153565734625\n",
      "Epoch 823 | Train Loss: 0.0021530583035200834 | Test Loss: 0.006089314352720976\n",
      "Epoch 824 | Train Loss: 0.0021399296820163727 | Test Loss: 0.006077536381781101\n",
      "Epoch 825 | Train Loss: 0.0021271537989377975 | Test Loss: 0.006066142115741968\n",
      "Epoch 826 | Train Loss: 0.0021144566126167774 | Test Loss: 0.006053443066775799\n",
      "Epoch 827 | Train Loss: 0.0021018823608756065 | Test Loss: 0.006038553547114134\n",
      "Epoch 828 | Train Loss: 0.002089448506012559 | Test Loss: 0.006026207935065031\n",
      "Epoch 829 | Train Loss: 0.0020771995186805725 | Test Loss: 0.0060163261368870735\n",
      "Epoch 830 | Train Loss: 0.0020650881342589855 | Test Loss: 0.006007264833897352\n",
      "Epoch 831 | Train Loss: 0.0020530507899820805 | Test Loss: 0.005997099447995424\n",
      "Epoch 832 | Train Loss: 0.0020410490687936544 | Test Loss: 0.005984586197882891\n",
      "Epoch 833 | Train Loss: 0.002029203111305833 | Test Loss: 0.005975548643618822\n",
      "Epoch 834 | Train Loss: 0.0020172453951090574 | Test Loss: 0.005960176698863506\n",
      "Epoch 835 | Train Loss: 0.0020055968780070543 | Test Loss: 0.005945958197116852\n",
      "Epoch 836 | Train Loss: 0.0019944580271840096 | Test Loss: 0.005935083609074354\n",
      "Epoch 837 | Train Loss: 0.001983926398679614 | Test Loss: 0.00592825235798955\n",
      "Epoch 838 | Train Loss: 0.0019728918559849262 | Test Loss: 0.005923157092183828\n",
      "Epoch 839 | Train Loss: 0.001962039154022932 | Test Loss: 0.0059115225449204445\n",
      "Epoch 840 | Train Loss: 0.001951119164004922 | Test Loss: 0.005900281015783548\n",
      "Epoch 841 | Train Loss: 0.0019403620390221477 | Test Loss: 0.005890163127332926\n",
      "Epoch 842 | Train Loss: 0.0019296917598694563 | Test Loss: 0.005881048738956451\n",
      "Epoch 843 | Train Loss: 0.0019191610626876354 | Test Loss: 0.00587152224034071\n",
      "Epoch 844 | Train Loss: 0.0019087757682427764 | Test Loss: 0.005862443707883358\n",
      "Epoch 845 | Train Loss: 0.0018985039787366986 | Test Loss: 0.00585410138592124\n",
      "Epoch 846 | Train Loss: 0.0018883602460846305 | Test Loss: 0.005846101325005293\n",
      "Epoch 847 | Train Loss: 0.001878336537629366 | Test Loss: 0.00583862978965044\n",
      "Epoch 848 | Train Loss: 0.0018683987436816096 | Test Loss: 0.005830441601574421\n",
      "Epoch 849 | Train Loss: 0.0018588127568364143 | Test Loss: 0.005828805733472109\n",
      "Epoch 850 | Train Loss: 0.0018495788099244237 | Test Loss: 0.005813355091959238\n",
      "Epoch 851 | Train Loss: 0.0018405058654025197 | Test Loss: 0.0057961721904575825\n",
      "Epoch 852 | Train Loss: 0.0018316019559279084 | Test Loss: 0.005792752839624882\n",
      "Epoch 853 | Train Loss: 0.0018217500764876604 | Test Loss: 0.0057912059128284454\n",
      "Epoch 854 | Train Loss: 0.001812610775232315 | Test Loss: 0.0057876743376255035\n",
      "Epoch 855 | Train Loss: 0.0018033502856269479 | Test Loss: 0.005786677356809378\n",
      "Epoch 856 | Train Loss: 0.001794283976778388 | Test Loss: 0.005785906687378883\n",
      "Epoch 857 | Train Loss: 0.001785283093340695 | Test Loss: 0.005783966742455959\n",
      "Epoch 858 | Train Loss: 0.001776394434273243 | Test Loss: 0.005780715495347977\n",
      "Epoch 859 | Train Loss: 0.001767562236636877 | Test Loss: 0.005776180885732174\n",
      "Epoch 860 | Train Loss: 0.0017586700851097703 | Test Loss: 0.005773084703832865\n",
      "Epoch 861 | Train Loss: 0.0017493092454969883 | Test Loss: 0.005764954257756472\n",
      "Epoch 862 | Train Loss: 0.001740473904646933 | Test Loss: 0.005751501303166151\n",
      "Epoch 863 | Train Loss: 0.0017316080629825592 | Test Loss: 0.005739782936871052\n",
      "Epoch 864 | Train Loss: 0.0017231375677511096 | Test Loss: 0.005731094628572464\n",
      "Epoch 865 | Train Loss: 0.0017148414626717567 | Test Loss: 0.0057245767675340176\n",
      "Epoch 866 | Train Loss: 0.0017066103173419833 | Test Loss: 0.005718373693525791\n",
      "Epoch 867 | Train Loss: 0.0016984294634312391 | Test Loss: 0.005712731275707483\n",
      "Epoch 868 | Train Loss: 0.0016903044888749719 | Test Loss: 0.005707416217774153\n",
      "Epoch 869 | Train Loss: 0.0016822128091007471 | Test Loss: 0.005700776353478432\n",
      "Epoch 870 | Train Loss: 0.0016739702550694346 | Test Loss: 0.0056933751329779625\n",
      "Epoch 871 | Train Loss: 0.001665633637458086 | Test Loss: 0.005688083358108997\n",
      "Epoch 872 | Train Loss: 0.0016579491784796119 | Test Loss: 0.005670582875609398\n",
      "Epoch 873 | Train Loss: 0.00164987298194319 | Test Loss: 0.0056537846103310585\n",
      "Epoch 874 | Train Loss: 0.0016423191409558058 | Test Loss: 0.00564220966771245\n",
      "Epoch 875 | Train Loss: 0.0016348737990483642 | Test Loss: 0.005638513248413801\n",
      "Epoch 876 | Train Loss: 0.0016272872453555465 | Test Loss: 0.005638351663947105\n",
      "Epoch 877 | Train Loss: 0.0016197219956666231 | Test Loss: 0.005638442002236843\n",
      "Epoch 878 | Train Loss: 0.0016123118111863732 | Test Loss: 0.005636132322251797\n",
      "Epoch 879 | Train Loss: 0.0016049426048994064 | Test Loss: 0.005630659405142069\n",
      "Epoch 880 | Train Loss: 0.0015975680435076356 | Test Loss: 0.005622682627290487\n",
      "Epoch 881 | Train Loss: 0.0015902420273050666 | Test Loss: 0.005614211782813072\n",
      "Epoch 882 | Train Loss: 0.0015830936608836055 | Test Loss: 0.0056063649244606495\n",
      "Epoch 883 | Train Loss: 0.0015758934896439314 | Test Loss: 0.005599388852715492\n",
      "Epoch 884 | Train Loss: 0.0015687907580286264 | Test Loss: 0.005592586472630501\n",
      "Epoch 885 | Train Loss: 0.0015617306344211102 | Test Loss: 0.005584820173680782\n",
      "Epoch 886 | Train Loss: 0.0015546734211966395 | Test Loss: 0.005575588438659906\n",
      "Epoch 887 | Train Loss: 0.0015476667322218418 | Test Loss: 0.005566907115280628\n",
      "Epoch 888 | Train Loss: 0.0015407404862344265 | Test Loss: 0.005559335928410292\n",
      "Epoch 889 | Train Loss: 0.0015338860685005784 | Test Loss: 0.005551348906010389\n",
      "Epoch 890 | Train Loss: 0.0015271868323907256 | Test Loss: 0.005543240811675787\n",
      "Epoch 891 | Train Loss: 0.0015205402160063386 | Test Loss: 0.005537201184779406\n",
      "Epoch 892 | Train Loss: 0.001513930968940258 | Test Loss: 0.005531925708055496\n",
      "Epoch 893 | Train Loss: 0.0015074060065671802 | Test Loss: 0.005524851381778717\n",
      "Epoch 894 | Train Loss: 0.0015008782502263784 | Test Loss: 0.005516869015991688\n",
      "Epoch 895 | Train Loss: 0.0014943677233532071 | Test Loss: 0.005509873852133751\n",
      "Epoch 896 | Train Loss: 0.0014880017843097448 | Test Loss: 0.005506202112883329\n",
      "Epoch 897 | Train Loss: 0.001481605926528573 | Test Loss: 0.005501047242432833\n",
      "Epoch 898 | Train Loss: 0.0014753361465409398 | Test Loss: 0.00549382995814085\n",
      "Epoch 899 | Train Loss: 0.0014690060634166002 | Test Loss: 0.0054870047606527805\n",
      "Epoch 900 | Train Loss: 0.0014628639910370111 | Test Loss: 0.00548130227252841\n",
      "Epoch 901 | Train Loss: 0.0014567205216735601 | Test Loss: 0.005475696641951799\n",
      "Epoch 902 | Train Loss: 0.0014505175640806556 | Test Loss: 0.005468825809657574\n",
      "Epoch 903 | Train Loss: 0.0014444495318457484 | Test Loss: 0.0054596345871686935\n",
      "Epoch 904 | Train Loss: 0.0014383950037881732 | Test Loss: 0.005448597017675638\n",
      "Epoch 905 | Train Loss: 0.001432316843420267 | Test Loss: 0.005439348053187132\n",
      "Epoch 906 | Train Loss: 0.0014263655757531524 | Test Loss: 0.0054350183345377445\n",
      "Epoch 907 | Train Loss: 0.001420429558493197 | Test Loss: 0.005435482133179903\n",
      "Epoch 908 | Train Loss: 0.001414471073076129 | Test Loss: 0.005433609709143639\n",
      "Epoch 909 | Train Loss: 0.0014086742885410786 | Test Loss: 0.0054279048927128315\n",
      "Epoch 910 | Train Loss: 0.0014028939185664058 | Test Loss: 0.005421231500804424\n",
      "Epoch 911 | Train Loss: 0.0013971554581075907 | Test Loss: 0.00541563518345356\n",
      "Epoch 912 | Train Loss: 0.0013914918527007103 | Test Loss: 0.00541106378659606\n",
      "Epoch 913 | Train Loss: 0.0013858468737453222 | Test Loss: 0.0054069929756224155\n",
      "Epoch 914 | Train Loss: 0.0013802185421809554 | Test Loss: 0.00540265953168273\n",
      "Epoch 915 | Train Loss: 0.001374647836200893 | Test Loss: 0.005398044362664223\n",
      "Epoch 916 | Train Loss: 0.0013691402273252606 | Test Loss: 0.005393281579017639\n",
      "Epoch 917 | Train Loss: 0.0013636478688567877 | Test Loss: 0.0053884428925812244\n",
      "Epoch 918 | Train Loss: 0.0013582127867266536 | Test Loss: 0.0053835115395486355\n",
      "Epoch 919 | Train Loss: 0.0013528176350519061 | Test Loss: 0.0053787799552083015\n",
      "Epoch 920 | Train Loss: 0.0013474398292601109 | Test Loss: 0.005374581087380648\n",
      "Epoch 921 | Train Loss: 0.0013421124313026667 | Test Loss: 0.005370216444134712\n",
      "Epoch 922 | Train Loss: 0.001336810877546668 | Test Loss: 0.005364861339330673\n",
      "Epoch 923 | Train Loss: 0.0013315175892785192 | Test Loss: 0.00535873556509614\n",
      "Epoch 924 | Train Loss: 0.0013262731954455376 | Test Loss: 0.0053527746349573135\n",
      "Epoch 925 | Train Loss: 0.0013210437027737498 | Test Loss: 0.005347767379134893\n",
      "Epoch 926 | Train Loss: 0.0013158043147996068 | Test Loss: 0.00534428795799613\n",
      "Epoch 927 | Train Loss: 0.0013106242986395955 | Test Loss: 0.00534088397398591\n",
      "Epoch 928 | Train Loss: 0.001305514364503324 | Test Loss: 0.005335584748536348\n",
      "Epoch 929 | Train Loss: 0.0013004252687096596 | Test Loss: 0.0053301723673939705\n",
      "Epoch 930 | Train Loss: 0.0012953990371897817 | Test Loss: 0.005326973740011454\n",
      "Epoch 931 | Train Loss: 0.0012903815368190408 | Test Loss: 0.005323896184563637\n",
      "Epoch 932 | Train Loss: 0.0012854257365688682 | Test Loss: 0.005319289397448301\n",
      "Epoch 933 | Train Loss: 0.0012804929865524173 | Test Loss: 0.005315097980201244\n",
      "Epoch 934 | Train Loss: 0.0012756009818986058 | Test Loss: 0.005311757791787386\n",
      "Epoch 935 | Train Loss: 0.0012707203859463334 | Test Loss: 0.0053086415864527225\n",
      "Epoch 936 | Train Loss: 0.001265874132514 | Test Loss: 0.005304657854139805\n",
      "Epoch 937 | Train Loss: 0.0012610668782144785 | Test Loss: 0.005300298798829317\n",
      "Epoch 938 | Train Loss: 0.0012562911724671721 | Test Loss: 0.005296210292726755\n",
      "Epoch 939 | Train Loss: 0.0012515486450865865 | Test Loss: 0.005291832610964775\n",
      "Epoch 940 | Train Loss: 0.0012468440691009164 | Test Loss: 0.005286556668579578\n",
      "Epoch 941 | Train Loss: 0.0012421640567481518 | Test Loss: 0.00528113916516304\n",
      "Epoch 942 | Train Loss: 0.001237530610524118 | Test Loss: 0.0052767181769013405\n",
      "Epoch 943 | Train Loss: 0.0012329258024692535 | Test Loss: 0.005272596143186092\n",
      "Epoch 944 | Train Loss: 0.0012283462565392256 | Test Loss: 0.005267790053039789\n",
      "Epoch 945 | Train Loss: 0.0012237923219799995 | Test Loss: 0.0052625094540417194\n",
      "Epoch 946 | Train Loss: 0.0012192713329568505 | Test Loss: 0.005257392767816782\n",
      "Epoch 947 | Train Loss: 0.001214773626998067 | Test Loss: 0.005252900533378124\n",
      "Epoch 948 | Train Loss: 0.0012103074695914984 | Test Loss: 0.005248307716101408\n",
      "Epoch 949 | Train Loss: 0.0012058778665959835 | Test Loss: 0.005243796855211258\n",
      "Epoch 950 | Train Loss: 0.0012014691019430757 | Test Loss: 0.005239309277385473\n",
      "Epoch 951 | Train Loss: 0.0011970801278948784 | Test Loss: 0.0052350303158164024\n",
      "Epoch 952 | Train Loss: 0.0011927307350561023 | Test Loss: 0.00523044029250741\n",
      "Epoch 953 | Train Loss: 0.0011883925180882215 | Test Loss: 0.005225552711635828\n",
      "Epoch 954 | Train Loss: 0.0011840894585475326 | Test Loss: 0.005221041385084391\n",
      "Epoch 955 | Train Loss: 0.001179808285087347 | Test Loss: 0.005216603633016348\n",
      "Epoch 956 | Train Loss: 0.001175552955828607 | Test Loss: 0.005212236195802689\n",
      "Epoch 957 | Train Loss: 0.0011713184649124742 | Test Loss: 0.0052078948356211185\n",
      "Epoch 958 | Train Loss: 0.0011671001557260752 | Test Loss: 0.005204066634178162\n",
      "Epoch 959 | Train Loss: 0.0011629172367975116 | Test Loss: 0.005200505722314119\n",
      "Epoch 960 | Train Loss: 0.001158745726570487 | Test Loss: 0.00519682327285409\n",
      "Epoch 961 | Train Loss: 0.0011546050664037466 | Test Loss: 0.005192646756768227\n",
      "Epoch 962 | Train Loss: 0.0011504816357046366 | Test Loss: 0.005188250448554754\n",
      "Epoch 963 | Train Loss: 0.0011463818373158574 | Test Loss: 0.005184041801840067\n",
      "Epoch 964 | Train Loss: 0.0011423053219914436 | Test Loss: 0.005179674830287695\n",
      "Epoch 965 | Train Loss: 0.001138248830102384 | Test Loss: 0.0051751877181231976\n",
      "Epoch 966 | Train Loss: 0.0011342004872858524 | Test Loss: 0.005170714575797319\n",
      "Epoch 967 | Train Loss: 0.0011301659978926182 | Test Loss: 0.005166845396161079\n",
      "Epoch 968 | Train Loss: 0.001126165734604001 | Test Loss: 0.005164098460227251\n",
      "Epoch 969 | Train Loss: 0.0011222184402868152 | Test Loss: 0.005161868873983622\n",
      "Epoch 970 | Train Loss: 0.0011182880261912942 | Test Loss: 0.005158931482583284\n",
      "Epoch 971 | Train Loss: 0.0011143744923174381 | Test Loss: 0.005156985018402338\n",
      "Epoch 972 | Train Loss: 0.0011104749282822013 | Test Loss: 0.005154802463948727\n",
      "Epoch 973 | Train Loss: 0.0011066007427871227 | Test Loss: 0.0051514757797122\n",
      "Epoch 974 | Train Loss: 0.001102736801840365 | Test Loss: 0.005147409625351429\n",
      "Epoch 975 | Train Loss: 0.0010989148868247867 | Test Loss: 0.005144909955561161\n",
      "Epoch 976 | Train Loss: 0.0010950993746519089 | Test Loss: 0.005140926688909531\n",
      "Epoch 977 | Train Loss: 0.0010912847938016057 | Test Loss: 0.005136206280440092\n",
      "Epoch 978 | Train Loss: 0.0010874951258301735 | Test Loss: 0.005133428145200014\n",
      "Epoch 979 | Train Loss: 0.0010836994042620063 | Test Loss: 0.005130518693476915\n",
      "Epoch 980 | Train Loss: 0.0010799490846693516 | Test Loss: 0.005126886535435915\n",
      "Epoch 981 | Train Loss: 0.001076230313628912 | Test Loss: 0.005123972427099943\n",
      "Epoch 982 | Train Loss: 0.0010725375032052398 | Test Loss: 0.005121052265167236\n",
      "Epoch 983 | Train Loss: 0.0010688870679587126 | Test Loss: 0.005118279717862606\n",
      "Epoch 984 | Train Loss: 0.001065254444256425 | Test Loss: 0.005116509273648262\n",
      "Epoch 985 | Train Loss: 0.0010616387007758021 | Test Loss: 0.005115210544317961\n",
      "Epoch 986 | Train Loss: 0.0010580358793959022 | Test Loss: 0.005113278515636921\n",
      "Epoch 987 | Train Loss: 0.0010544541291892529 | Test Loss: 0.005111526697874069\n",
      "Epoch 988 | Train Loss: 0.0010508913546800613 | Test Loss: 0.005110003985464573\n",
      "Epoch 989 | Train Loss: 0.0010473366128280759 | Test Loss: 0.0051090773195028305\n",
      "Epoch 990 | Train Loss: 0.0010438065510243177 | Test Loss: 0.005109432153403759\n",
      "Epoch 991 | Train Loss: 0.0010402844054624438 | Test Loss: 0.005110790953040123\n",
      "Epoch 992 | Train Loss: 0.0010367811191827059 | Test Loss: 0.0051128980703651905\n",
      "Epoch 993 | Train Loss: 0.001033294596709311 | Test Loss: 0.00511577632278204\n",
      "Epoch 994 | Train Loss: 0.001029827049933374 | Test Loss: 0.005118280183523893\n",
      "Epoch 995 | Train Loss: 0.0010263771982863545 | Test Loss: 0.0051195695996284485\n",
      "Epoch 996 | Train Loss: 0.0010229357285425067 | Test Loss: 0.005121845286339521\n",
      "Epoch 997 | Train Loss: 0.0010195086942985654 | Test Loss: 0.005125225055962801\n",
      "Epoch 998 | Train Loss: 0.0010161051759496331 | Test Loss: 0.0051282974891364574\n",
      "Epoch 999 | Train Loss: 0.0010127201676368713 | Test Loss: 0.005133415572345257\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "# ALPHATOE\n",
    "model = HookedTransformer(cfg).to(cfg.device)\n",
    "optimizer = t.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# for epoch in tqdm.tqdm(range(epochs)):\n",
    "for epoch in range(epochs):\n",
    "    for batch in range(0, len(train_data), batch_size):\n",
    "        train_logits = model(train_data[batch:batch+batch_size])\n",
    "        train_loss = loss_fn(train_logits, train_labels[batch:batch+batch_size])\n",
    "\n",
    "        train_loss.backward()\n",
    "\n",
    "        train_losses.append(train_loss.item())\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with t.inference_mode():\n",
    "            test_logits = model(test_data)\n",
    "            test_loss = loss_fn(test_logits, test_labels)\n",
    "            test_losses.append(test_loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch} | Train Loss: {train_loss.item()} | Test Loss: {test_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "0",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "y": [
          2.52840256690979,
          2.5168142318725586,
          2.812495470046997,
          2.153665781021118,
          1.8449795246124268,
          1.6901593208312988,
          1.4590767621994019,
          1.3246701955795288,
          1.19852614402771,
          1.0949195623397827,
          0.9508247375488281,
          0.8471229076385498,
          0.7652381658554077,
          0.6368617415428162,
          0.5596321821212769,
          0.5286388397216797,
          0.46937423944473267,
          0.4121308922767639,
          0.36824437975883484,
          0.31283459067344666,
          0.29623791575431824,
          0.4665044844150543,
          0.34601518511772156,
          0.39792534708976746,
          0.5155378580093384,
          0.43898120522499084,
          0.37437117099761963,
          0.3563831150531769,
          0.297419011592865,
          0.2613367736339569,
          0.24884814023971558,
          0.2366791069507599,
          0.2004190981388092,
          0.3962213695049286,
          0.2736647129058838,
          0.2854881286621094,
          0.3315742611885071,
          0.34460270404815674,
          0.32319697737693787,
          0.300579696893692,
          0.26422667503356934,
          0.2279031127691269,
          0.19774796068668365,
          0.20220167934894562,
          0.24798065423965454,
          0.24969393014907837,
          0.2647579610347748,
          0.24622130393981934,
          0.2798902690410614,
          0.29936107993125916,
          0.5249527096748352,
          0.29693159461021423,
          0.2807973623275757,
          0.29824668169021606,
          0.30131101608276367,
          0.27803102135658264,
          0.24447712302207947,
          0.21511310338974,
          0.254103422164917,
          0.4310261607170105,
          0.3986285626888275,
          0.4700629711151123,
          0.4733460247516632,
          1.0714726448059082,
          0.9219952821731567,
          0.7661916613578796,
          0.7153646349906921,
          0.912673830986023,
          0.4696144461631775,
          1.030601978302002,
          0.3904467225074768,
          0.35623887181282043,
          0.5473585724830627,
          0.5005807280540466,
          0.5006409287452698,
          0.35280582308769226,
          0.3917109966278076,
          0.3685329854488373,
          0.38620442152023315,
          0.5856775045394897,
          0.4507777690887451,
          0.9432283639907837,
          1.1336981058120728,
          0.7536897659301758,
          0.609811544418335,
          0.9911413192749023,
          1.244498610496521,
          0.9186979532241821,
          0.7560778260231018,
          0.7386487126350403,
          0.849337100982666,
          0.7660388350486755,
          0.614345908164978,
          0.8860315680503845,
          0.8429154753684998,
          0.6554733514785767,
          0.9721301198005676,
          0.9670318365097046,
          1.0718291997909546,
          1.2223173379898071,
          1.689563512802124,
          1.6396865844726562,
          1.4561604261398315,
          1.264950156211853,
          1.0920250415802002,
          1.0152462720870972,
          0.8019506335258484,
          0.7179147601127625,
          0.6720007061958313,
          0.6597215533256531,
          0.7056214809417725,
          0.8289211392402649,
          0.7849171161651611,
          0.6985640525817871,
          0.6873573064804077,
          0.5471439957618713,
          0.514992892742157,
          0.48036372661590576,
          0.5419420003890991,
          0.53549724817276,
          0.4398564100265503,
          0.5757790803909302,
          0.4220210015773773,
          0.3454850912094116,
          0.37279391288757324,
          0.35044386982917786,
          0.3033391535282135,
          0.28826427459716797,
          0.22307850420475006,
          0.21942025423049927,
          0.19852080941200256,
          0.19325968623161316,
          0.22542472183704376,
          0.22564025223255157,
          0.19906161725521088,
          0.18040262162685394,
          0.17135435342788696,
          0.16224931180477142,
          0.161233052611351,
          0.2254430204629898,
          0.6082730293273926,
          0.33671465516090393,
          0.9303365349769592,
          0.5371014475822449,
          0.8197300434112549,
          0.5110916495323181,
          0.5312796831130981,
          0.634679913520813,
          0.6009992361068726,
          0.6424321532249451,
          0.6335029006004333,
          1.2496991157531738,
          0.8951902389526367,
          0.9428121447563171,
          0.8323929309844971,
          0.7339659333229065,
          0.7316029667854309,
          0.6301584839820862,
          0.6413518190383911,
          1.1007544994354248,
          0.7463560104370117,
          0.7756596803665161,
          0.8333978652954102,
          0.9056029319763184,
          0.8118136525154114,
          1.9996726512908936,
          1.8911230564117432,
          1.3459930419921875,
          1.16306734085083,
          1.5742336511611938,
          1.4526139497756958,
          2.2587335109710693,
          3.7787160873413086,
          2.791470766067505,
          2.769547462463379,
          6.348069667816162,
          5.334617614746094,
          7.437254905700684,
          10.314138412475586,
          7.299478054046631,
          10.66882610321045,
          11.426600456237793,
          5.5032196044921875,
          3.918156385421753,
          3.5088188648223877,
          4.800567150115967,
          3.533348798751831,
          3.782628297805786,
          3.8172380924224854,
          6.064826011657715,
          3.378101348876953,
          3.874943733215332,
          8.904400825500488,
          11.593823432922363,
          13.406164169311523,
          14.986621856689453,
          12.438372611999512,
          9.202101707458496,
          8.227747917175293,
          17.80449867248535,
          9.819642066955566,
          6.90645694732666,
          16.61911964416504,
          9.676100730895996,
          5.886669158935547,
          6.060904026031494,
          5.309098720550537,
          3.972707986831665,
          5.5554609298706055,
          3.4187121391296387,
          2.864861011505127,
          2.7625582218170166,
          2.933176279067993,
          2.4661951065063477,
          2.544154644012451,
          2.3965682983398438,
          2.449510097503662,
          2.4610953330993652,
          2.430443286895752,
          2.3162426948547363,
          2.3492820262908936,
          2.434234619140625,
          2.0032496452331543,
          2.1525092124938965,
          2.183058261871338,
          1.8080432415008545,
          1.7663068771362305,
          1.631957769393921,
          1.5179482698440552,
          1.4425228834152222,
          1.4858893156051636,
          1.3988988399505615,
          1.393739104270935,
          1.343336582183838,
          1.3301113843917847,
          1.3154062032699585,
          1.2683148384094238,
          1.22295081615448,
          1.1894716024398804,
          1.1737710237503052,
          1.1700992584228516,
          1.1516225337982178,
          1.1181994676589966,
          1.096691608428955,
          1.069384217262268,
          1.0443867444992065,
          1.0288922786712646,
          1.0140477418899536,
          1.0051299333572388,
          0.9807331562042236,
          0.9681663513183594,
          0.9516459703445435,
          0.9319899082183838,
          0.9117419123649597,
          0.8969576358795166,
          0.8833372592926025,
          0.8709694743156433,
          0.856290340423584,
          0.8433206677436829,
          0.8286962509155273,
          0.8161896467208862,
          0.8005381226539612,
          0.7998939752578735,
          0.8009993433952332,
          0.7821842432022095,
          0.758470356464386,
          0.7475470900535583,
          0.7374064922332764,
          0.725923478603363,
          0.7131401896476746,
          0.7012587189674377,
          0.6944490075111389,
          0.6833419799804688,
          0.6772788763046265,
          0.6652358770370483,
          0.6586100459098816,
          0.6484425663948059,
          0.6379573941230774,
          0.6284785270690918,
          0.6177180409431458,
          0.6043797135353088,
          0.6016618013381958,
          0.5871877074241638,
          0.5781410336494446,
          0.5745235681533813,
          0.5639072060585022,
          0.5557163953781128,
          0.5496328473091125,
          0.5455410480499268,
          0.583906352519989,
          0.603866696357727,
          0.5832257270812988,
          0.5379732847213745,
          0.5582044720649719,
          0.6225034594535828,
          0.6293421387672424,
          0.5889025926589966,
          0.5575241446495056,
          0.5681036710739136,
          0.5623164772987366,
          0.5405291318893433,
          0.5454750657081604,
          0.5479937195777893,
          0.5411773920059204,
          0.5204843878746033,
          0.5060523748397827,
          0.4907955825328827,
          0.4813666045665741,
          0.46812954545021057,
          0.4539090394973755,
          0.43978551030158997,
          0.4305652976036072,
          0.422341912984848,
          0.4166601896286011,
          0.4078957140445709,
          0.3999359905719757,
          0.39228105545043945,
          0.3825334310531616,
          0.3745735287666321,
          0.3684018552303314,
          0.3630184233188629,
          0.35824668407440186,
          0.3528982996940613,
          0.34558701515197754,
          0.3354809880256653,
          0.328197717666626,
          0.3214889466762543,
          0.31443172693252563,
          0.3093387484550476,
          0.3063938021659851,
          0.30420440435409546,
          0.3021978735923767,
          0.29820555448532104,
          0.2935432493686676,
          0.2870114743709564,
          0.28168588876724243,
          0.2824363708496094,
          0.2808396816253662,
          0.2731318175792694,
          0.2699168622493744,
          0.2683612108230591,
          0.26339802145957947,
          0.25677770376205444,
          0.24901749193668365,
          0.2464713156223297,
          0.24440276622772217,
          0.2395365685224533,
          0.2344217300415039,
          0.23291069269180298,
          0.2309730499982834,
          0.22725200653076172,
          0.22138068079948425,
          0.21726755797863007,
          0.21348173916339874,
          0.21139058470726013,
          0.20793992280960083,
          0.20566429197788239,
          0.2026604562997818,
          0.20119845867156982,
          0.19804547727108002,
          0.19461938738822937,
          0.19080404937267303,
          0.18727798759937286,
          0.1841914802789688,
          0.1827174574136734,
          0.18307684361934662,
          0.1790187656879425,
          0.17700470983982086,
          0.17514309287071228,
          0.1714046150445938,
          0.16758474707603455,
          0.16556522250175476,
          0.16679167747497559,
          0.16541361808776855,
          0.16148391366004944,
          0.15894632041454315,
          0.1569090038537979,
          0.15557649731636047,
          0.15462258458137512,
          0.15336300432682037,
          0.15228651463985443,
          0.1505378782749176,
          0.15233078598976135,
          0.15116280317306519,
          0.14669080078601837,
          0.14693327248096466,
          0.14512841403484344,
          0.14177219569683075,
          0.14253826439380646,
          0.13873879611492157,
          0.13395459949970245,
          0.13174481689929962,
          0.13013866543769836,
          0.12853707373142242,
          0.1288609802722931,
          0.12873081862926483,
          0.12668269872665405,
          0.12753763794898987,
          0.13132011890411377,
          0.1307869851589203,
          0.1277206540107727,
          0.12393305450677872,
          0.12163840979337692,
          0.1193540021777153,
          0.11649905145168304,
          0.11542929708957672,
          0.11187336593866348,
          0.11098956316709518,
          0.10909916460514069,
          0.10811552405357361,
          0.10731187462806702,
          0.1067441776394844,
          0.10547065734863281,
          0.1042703241109848,
          0.10310240834951401,
          0.10321932286024094,
          0.10270088911056519,
          0.10121079534292221,
          0.10041884332895279,
          0.09852026402950287,
          0.0979033038020134,
          0.10056353360414505,
          0.0959663912653923,
          0.09386877715587616,
          0.09276352822780609,
          0.09293261170387268,
          0.09080920368432999,
          0.08944962173700333,
          0.08843251317739487,
          0.08900830149650574,
          0.08992329984903336,
          0.08800365775823593,
          0.08856531977653503,
          0.087549589574337,
          0.08658967912197113,
          0.08509842306375504,
          0.08217865973711014,
          0.08142495155334473,
          0.0796898677945137,
          0.07855784147977829,
          0.07752281427383423,
          0.07627905905246735,
          0.07623901218175888,
          0.07552067935466766,
          0.0739389955997467,
          0.07407253980636597,
          0.0746941938996315,
          0.07860860228538513,
          0.08182387053966522,
          0.0738765224814415,
          0.07476693391799927,
          0.07437841594219208,
          0.07358329743146896,
          0.07212613523006439,
          0.07238218933343887,
          0.07507949322462082,
          0.07493656128644943,
          0.07594868540763855,
          0.07288649678230286,
          0.08925232291221619,
          0.11245647817850113,
          0.10147851705551147,
          0.10794481635093689,
          0.14006945490837097,
          0.15529993176460266,
          0.13310927152633667,
          0.16344016790390015,
          0.16539983451366425,
          0.15095633268356323,
          0.1985652893781662,
          0.1701323539018631,
          0.14249250292778015,
          0.1450202763080597,
          0.1514192819595337,
          0.15686488151550293,
          0.14462873339653015,
          0.14001818001270294,
          0.13157911598682404,
          0.12531253695487976,
          0.12020403891801834,
          0.10902224481105804,
          0.09895963966846466,
          0.09086687862873077,
          0.09479281306266785,
          0.09900542348623276,
          0.10064131021499634,
          0.09090438485145569,
          0.08093036711215973,
          0.0796404629945755,
          0.07815814763307571,
          0.08569861948490143,
          0.09156379103660583,
          0.09057562053203583,
          0.08876921236515045,
          0.08219409734010696,
          0.07712090015411377,
          0.07222723215818405,
          0.07064470648765564,
          0.07073178142309189,
          0.07146663218736649,
          0.07076860964298248,
          0.07015618681907654,
          0.06930600851774216,
          0.06578926742076874,
          0.063675656914711,
          0.062324535101652145,
          0.058734990656375885,
          0.05791115015745163,
          0.056316301226615906,
          0.057395659387111664,
          0.05607972294092178,
          0.05658722668886185,
          0.05514442175626755,
          0.05239659920334816,
          0.05019501969218254,
          0.04821707308292389,
          0.0465116985142231,
          0.0458732545375824,
          0.045653749257326126,
          0.04527341574430466,
          0.04363609477877617,
          0.04194701462984085,
          0.04201941937208176,
          0.04134627804160118,
          0.040361370891332626,
          0.039374370127916336,
          0.03874211013317108,
          0.0382925420999527,
          0.03770792856812477,
          0.03774425759911537,
          0.03802569583058357,
          0.03808024153113365,
          0.04201599210500717,
          0.04349924251437187,
          0.04233003035187721,
          0.040098220109939575,
          0.037038322538137436,
          0.036288607865571976,
          0.03734159842133522,
          0.03769148513674736,
          0.03931226581335068,
          0.037853799760341644,
          0.03555477783083916,
          0.0347273126244545,
          0.03438012674450874,
          0.03447626531124115,
          0.03470229357481003,
          0.03437594696879387,
          0.03401331976056099,
          0.03208392113447189,
          0.03185579553246498,
          0.03296003118157387,
          0.03188345581293106,
          0.030769117176532745,
          0.030145321041345596,
          0.028965706005692482,
          0.027505990117788315,
          0.02809194289147854,
          0.028533935546875,
          0.028038527816534042,
          0.026643771678209305,
          0.025862691923975945,
          0.025463055819272995,
          0.025349972769618034,
          0.025100022554397583,
          0.024711742997169495,
          0.029431935399770737,
          0.03714297339320183,
          0.0419895239174366,
          0.03996345028281212,
          0.04013350233435631,
          0.03346743807196617,
          0.034662529826164246,
          0.03897394612431526,
          0.039485249668359756,
          0.03547642007470131,
          0.03025556541979313,
          0.02755492553114891,
          0.02816273644566536,
          0.02898850291967392,
          0.02914430759847164,
          0.028502482920885086,
          0.026435358449816704,
          0.025890350341796875,
          0.024715708568692207,
          0.024976037442684174,
          0.025432394817471504,
          0.026533711701631546,
          0.026805927976965904,
          0.02542872354388237,
          0.02443532459437847,
          0.02269778400659561,
          0.02228444628417492,
          0.02112681418657303,
          0.020926402881741524,
          0.02085789106786251,
          0.020915357396006584,
          0.02070779725909233,
          0.02053411491215229,
          0.020222067832946777,
          0.019685478881001472,
          0.019244709983468056,
          0.018763316795229912,
          0.018330756574869156,
          0.017983583733439445,
          0.017585741356015205,
          0.017352040857076645,
          0.0170955378562212,
          0.016915397718548775,
          0.016786042600870132,
          0.01671958714723587,
          0.01661045476794243,
          0.016498835757374763,
          0.016234245151281357,
          0.016006167978048325,
          0.015856485813856125,
          0.015773169696331024,
          0.015777070075273514,
          0.015808384865522385,
          0.015689510852098465,
          0.015492873266339302,
          0.015357890166342258,
          0.016183728352189064,
          0.015521259047091007,
          0.015587154775857925,
          0.016156543046236038,
          0.02037268690764904,
          0.016991479322314262,
          0.025469278916716576,
          0.03628481924533844,
          0.05081574618816376,
          0.04113117232918739,
          0.04139239713549614,
          0.050184205174446106,
          0.03684835135936737,
          0.05279083177447319,
          0.09127295762300491,
          0.1055070012807846,
          0.08198714256286621,
          0.11386104673147202,
          0.10936000198125839,
          0.08635205030441284,
          0.11800722777843475,
          0.08835498243570328,
          0.06387900561094284,
          0.06968089193105698,
          0.07833652943372726,
          0.08072468638420105,
          0.06905495375394821,
          0.05781112238764763,
          0.05746638774871826,
          0.05428242310881615,
          0.04987545683979988,
          0.06459968537092209,
          0.08235353976488113,
          0.07510755956172943,
          0.06459829211235046,
          0.057339951395988464,
          0.051965560764074326,
          0.04918685927987099,
          0.04814619943499565,
          0.04514007270336151,
          0.04327964410185814,
          0.04237666353583336,
          0.04104145988821983,
          0.03835953027009964,
          0.034657370299100876,
          0.031436946243047714,
          0.02934073656797409,
          0.02769305184483528,
          0.028200466185808182,
          0.028560513630509377,
          0.02881935052573681,
          0.02957526594400406,
          0.03068019449710846,
          0.032232627272605896,
          0.028360944241285324,
          0.023472974076867104,
          0.02222023345530033,
          0.022882353514432907,
          0.023912405595183372,
          0.024659238755702972,
          0.024350382387638092,
          0.023546965792775154,
          0.022979620844125748,
          0.021636784076690674,
          0.020413821563124657,
          0.02048884890973568,
          0.017860671505331993,
          0.018772028386592865,
          0.020949725061655045,
          0.02261943556368351,
          0.02492722123861313,
          0.025015803053975105,
          0.024632377550005913,
          0.021901894360780716,
          0.020378045737743378,
          0.01930263824760914,
          0.018398722633719444,
          0.019102664664387703,
          0.019695835188031197,
          0.020289944484829903,
          0.0204716045409441,
          0.019901232793927193,
          0.01976233534514904,
          0.019816169515252113,
          0.01893579587340355,
          0.017682021483778954,
          0.01629638671875,
          0.017644574865698814,
          0.015278921462595463,
          0.015416350215673447,
          0.016325965523719788,
          0.018897850066423416,
          0.018817836418747902,
          0.019378172233700752,
          0.017954399809241295,
          0.015948954969644547,
          0.015033068135380745,
          0.013571465387940407,
          0.013473463244736195,
          0.012868800200521946,
          0.012096741236746311,
          0.011543122120201588,
          0.011185736395418644,
          0.01087900623679161,
          0.010455125942826271,
          0.010002890601754189,
          0.009916704148054123,
          0.009881451725959778,
          0.009911011904478073,
          0.009948493912816048,
          0.010067330673336983,
          0.010016919113695621,
          0.01000071968883276,
          0.010033594444394112,
          0.009919955395162106,
          0.009763750247657299,
          0.00958163756877184,
          0.00932658463716507,
          0.009108339436352253,
          0.008904797025024891,
          0.008707634173333645,
          0.008580041117966175,
          0.008448830805718899,
          0.008324873633682728,
          0.008214961737394333,
          0.008125309832394123,
          0.008054632693529129,
          0.007978630252182484,
          0.007905881851911545,
          0.007849497720599174,
          0.00781225087121129,
          0.007772176992148161,
          0.007743383292108774,
          0.007712964434176683,
          0.007677354849874973,
          0.007631056010723114,
          0.0075834463350474834,
          0.007524334359914064,
          0.007422121241688728,
          0.007331020198762417,
          0.007183856330811977,
          0.007130854297429323,
          0.00708603672683239,
          0.007105742581188679,
          0.0070955390110611916,
          0.007067802827805281,
          0.007053731940686703,
          0.007053048349916935,
          0.007048540282994509,
          0.007043796591460705,
          0.007038054522126913,
          0.007030196022242308,
          0.007020552176982164,
          0.007007532753050327,
          0.006990144494920969,
          0.006969112437218428,
          0.006944761611521244,
          0.006922170985490084,
          0.006900920998305082,
          0.006870259065181017,
          0.0068382336758077145,
          0.006803048774600029,
          0.006772840395569801,
          0.00675065815448761,
          0.006737746298313141,
          0.006719901226460934,
          0.0066984957084059715,
          0.006670164410024881,
          0.006643414497375488,
          0.0066247908398509026,
          0.006605150178074837,
          0.0065816547721624374,
          0.006554811727255583,
          0.006527860648930073,
          0.00650183716788888,
          0.006478165742009878,
          0.00645878491923213,
          0.006446719169616699,
          0.006437815260142088,
          0.006427667569369078,
          0.0064156074076890945,
          0.006401961203664541,
          0.006386150605976582,
          0.006365273147821426,
          0.006344333756715059,
          0.006325075402855873,
          0.0063055697828531265,
          0.00628643250092864,
          0.006272476632148027,
          0.006256747059524059,
          0.0062370747327804565,
          0.0062179770320653915,
          0.006202498450875282,
          0.006191830150783062,
          0.006185680627822876,
          0.00617951899766922,
          0.0061670150607824326,
          0.0061506833881139755,
          0.006130345165729523,
          0.00611396599560976,
          0.006102153565734625,
          0.006089314352720976,
          0.006077536381781101,
          0.006066142115741968,
          0.006053443066775799,
          0.006038553547114134,
          0.006026207935065031,
          0.0060163261368870735,
          0.006007264833897352,
          0.005997099447995424,
          0.005984586197882891,
          0.005975548643618822,
          0.005960176698863506,
          0.005945958197116852,
          0.005935083609074354,
          0.00592825235798955,
          0.005923157092183828,
          0.0059115225449204445,
          0.005900281015783548,
          0.005890163127332926,
          0.005881048738956451,
          0.00587152224034071,
          0.005862443707883358,
          0.00585410138592124,
          0.005846101325005293,
          0.00583862978965044,
          0.005830441601574421,
          0.005828805733472109,
          0.005813355091959238,
          0.0057961721904575825,
          0.005792752839624882,
          0.0057912059128284454,
          0.0057876743376255035,
          0.005786677356809378,
          0.005785906687378883,
          0.005783966742455959,
          0.005780715495347977,
          0.005776180885732174,
          0.005773084703832865,
          0.005764954257756472,
          0.005751501303166151,
          0.005739782936871052,
          0.005731094628572464,
          0.0057245767675340176,
          0.005718373693525791,
          0.005712731275707483,
          0.005707416217774153,
          0.005700776353478432,
          0.0056933751329779625,
          0.005688083358108997,
          0.005670582875609398,
          0.0056537846103310585,
          0.00564220966771245,
          0.005638513248413801,
          0.005638351663947105,
          0.005638442002236843,
          0.005636132322251797,
          0.005630659405142069,
          0.005622682627290487,
          0.005614211782813072,
          0.0056063649244606495,
          0.005599388852715492,
          0.005592586472630501,
          0.005584820173680782,
          0.005575588438659906,
          0.005566907115280628,
          0.005559335928410292,
          0.005551348906010389,
          0.005543240811675787,
          0.005537201184779406,
          0.005531925708055496,
          0.005524851381778717,
          0.005516869015991688,
          0.005509873852133751,
          0.005506202112883329,
          0.005501047242432833,
          0.00549382995814085,
          0.0054870047606527805,
          0.00548130227252841,
          0.005475696641951799,
          0.005468825809657574,
          0.0054596345871686935,
          0.005448597017675638,
          0.005439348053187132,
          0.0054350183345377445,
          0.005435482133179903,
          0.005433609709143639,
          0.0054279048927128315,
          0.005421231500804424,
          0.00541563518345356,
          0.00541106378659606,
          0.0054069929756224155,
          0.00540265953168273,
          0.005398044362664223,
          0.005393281579017639,
          0.0053884428925812244,
          0.0053835115395486355,
          0.0053787799552083015,
          0.005374581087380648,
          0.005370216444134712,
          0.005364861339330673,
          0.00535873556509614,
          0.0053527746349573135,
          0.005347767379134893,
          0.00534428795799613,
          0.00534088397398591,
          0.005335584748536348,
          0.0053301723673939705,
          0.005326973740011454,
          0.005323896184563637,
          0.005319289397448301,
          0.005315097980201244,
          0.005311757791787386,
          0.0053086415864527225,
          0.005304657854139805,
          0.005300298798829317,
          0.005296210292726755,
          0.005291832610964775,
          0.005286556668579578,
          0.00528113916516304,
          0.0052767181769013405,
          0.005272596143186092,
          0.005267790053039789,
          0.0052625094540417194,
          0.005257392767816782,
          0.005252900533378124,
          0.005248307716101408,
          0.005243796855211258,
          0.005239309277385473,
          0.0052350303158164024,
          0.00523044029250741,
          0.005225552711635828,
          0.005221041385084391,
          0.005216603633016348,
          0.005212236195802689,
          0.0052078948356211185,
          0.005204066634178162,
          0.005200505722314119,
          0.00519682327285409,
          0.005192646756768227,
          0.005188250448554754,
          0.005184041801840067,
          0.005179674830287695,
          0.0051751877181231976,
          0.005170714575797319,
          0.005166845396161079,
          0.005164098460227251,
          0.005161868873983622,
          0.005158931482583284,
          0.005156985018402338,
          0.005154802463948727,
          0.0051514757797122,
          0.005147409625351429,
          0.005144909955561161,
          0.005140926688909531,
          0.005136206280440092,
          0.005133428145200014,
          0.005130518693476915,
          0.005126886535435915,
          0.005123972427099943,
          0.005121052265167236,
          0.005118279717862606,
          0.005116509273648262,
          0.005115210544317961,
          0.005113278515636921,
          0.005111526697874069,
          0.005110003985464573,
          0.0051090773195028305,
          0.005109432153403759,
          0.005110790953040123,
          0.0051128980703651905,
          0.00511577632278204,
          0.005118280183523893,
          0.0051195695996284485,
          0.005121845286339521,
          0.005125225055962801,
          0.0051282974891364574,
          0.005133415572345257
         ]
        },
        {
         "mode": "lines",
         "name": "1",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "y": [
          2.708627700805664,
          2.5274133682250977,
          2.505772590637207,
          2.831326723098755,
          2.1369757652282715,
          1.855232834815979,
          1.7010107040405273,
          1.4588277339935303,
          1.320685625076294,
          1.1879924535751343,
          1.0802693367004395,
          0.9485883116722107,
          0.8394076228141785,
          0.7598364353179932,
          0.636762797832489,
          0.5577282905578613,
          0.5174071788787842,
          0.45985326170921326,
          0.4031035006046295,
          0.35666629672050476,
          0.3098866939544678,
          0.29388871788978577,
          0.43020129203796387,
          0.33832722902297974,
          0.38489535450935364,
          0.48992919921875,
          0.41361430287361145,
          0.36163780093193054,
          0.3594362139701843,
          0.297652930021286,
          0.2499905526638031,
          0.23415127396583557,
          0.22368700802326202,
          0.1863764375448227,
          0.39391183853149414,
          0.258053183555603,
          0.2697952687740326,
          0.31867581605911255,
          0.3380987346172333,
          0.3237573802471161,
          0.31021228432655334,
          0.27722904086112976,
          0.23293541371822357,
          0.21432439982891083,
          0.2094581425189972,
          0.24345289170742035,
          0.2389822006225586,
          0.25666090846061707,
          0.22606506943702698,
          0.2658003270626068,
          0.2998453974723816,
          0.511041522026062,
          0.27840563654899597,
          0.2803482413291931,
          0.301000714302063,
          0.3032227158546448,
          0.2804151475429535,
          0.2519954442977905,
          0.21339955925941467,
          0.22492460906505585,
          0.40532347559928894,
          0.37411758303642273,
          0.43058907985687256,
          0.451388955116272,
          0.9809418320655823,
          0.8418194651603699,
          0.7685794234275818,
          0.7305548787117004,
          0.8671654462814331,
          0.4518052637577057,
          1.0072654485702515,
          0.4068619906902313,
          0.3672011196613312,
          0.5222359895706177,
          0.4658988416194916,
          0.48447754979133606,
          0.3607349097728729,
          0.3970721960067749,
          0.3673703372478485,
          0.3844812512397766,
          0.5384570956230164,
          0.40631094574928284,
          0.9144976139068604,
          1.0839223861694336,
          0.7221201062202454,
          0.5861078500747681,
          0.9664468169212341,
          1.219435691833496,
          0.9189733266830444,
          0.7685202956199646,
          0.746974527835846,
          0.8768321871757507,
          0.7818990349769592,
          0.6160582900047302,
          0.8677313327789307,
          0.8474121689796448,
          0.6693756580352783,
          1.0087308883666992,
          1.028181791305542,
          1.112541913986206,
          1.2623404264450073,
          1.7115886211395264,
          1.650143027305603,
          1.451932668685913,
          1.2949576377868652,
          1.0951260328292847,
          1.0253652334213257,
          0.7958846688270569,
          0.7071596384048462,
          0.6574439406394958,
          0.6545990705490112,
          0.6870784759521484,
          0.8282192349433899,
          0.7719361186027527,
          0.6795512437820435,
          0.6862256526947021,
          0.5457543730735779,
          0.5043741464614868,
          0.47968780994415283,
          0.5361818075180054,
          0.544462263584137,
          0.4263915717601776,
          0.5689387321472168,
          0.4109191298484802,
          0.3287239372730255,
          0.3618035912513733,
          0.3381901979446411,
          0.3009330928325653,
          0.275299608707428,
          0.21781101822853088,
          0.2160569578409195,
          0.19132636487483978,
          0.1777736246585846,
          0.2092229127883911,
          0.21587233245372772,
          0.1938522905111313,
          0.18331368267536163,
          0.16382059454917908,
          0.16454045474529266,
          0.16876357793807983,
          0.2131308764219284,
          0.5995402336120605,
          0.3146403431892395,
          0.941017210483551,
          0.5777788758277893,
          0.8023239970207214,
          0.4929675757884979,
          0.5437250137329102,
          0.6544736623764038,
          0.5971968173980713,
          0.6320983171463013,
          0.6246724128723145,
          1.2907012701034546,
          0.8774251341819763,
          0.9195418357849121,
          0.8206253051757812,
          0.7119592428207397,
          0.7275704741477966,
          0.6287611722946167,
          0.6267995834350586,
          1.0618711709976196,
          0.697693407535553,
          0.7541399598121643,
          0.7928434014320374,
          0.8662804365158081,
          0.7653018832206726,
          1.831073522567749,
          1.7543296813964844,
          1.2954164743423462,
          1.1562118530273438,
          1.5571027994155884,
          1.4315444231033325,
          2.2824840545654297,
          3.7851858139038086,
          2.7298672199249268,
          2.7341361045837402,
          6.20320987701416,
          5.259507656097412,
          7.477093696594238,
          10.537941932678223,
          7.249573230743408,
          10.58381462097168,
          11.610565185546875,
          5.554202079772949,
          4.025303840637207,
          3.5511698722839355,
          4.872369289398193,
          3.4726758003234863,
          3.6990861892700195,
          3.654846429824829,
          5.675210952758789,
          3.3391973972320557,
          3.8088624477386475,
          8.82194709777832,
          11.541970252990723,
          13.282842636108398,
          14.906278610229492,
          12.228081703186035,
          9.0130033493042,
          8.081385612487793,
          17.449914932250977,
          9.761554718017578,
          6.943755149841309,
          16.86127281188965,
          9.761019706726074,
          5.872363090515137,
          6.0792412757873535,
          5.288404941558838,
          4.006660461425781,
          5.685641765594482,
          3.4813709259033203,
          2.8984827995300293,
          2.7762162685394287,
          2.9436604976654053,
          2.474161386489868,
          2.5591351985931396,
          2.404428005218506,
          2.437265634536743,
          2.445068120956421,
          2.4442789554595947,
          2.334017753601074,
          2.3818976879119873,
          2.474421262741089,
          2.012984275817871,
          2.152153253555298,
          2.163862943649292,
          1.7716902494430542,
          1.747215986251831,
          1.6236000061035156,
          1.5163838863372803,
          1.4361783266067505,
          1.4836397171020508,
          1.3939197063446045,
          1.3892614841461182,
          1.3402785062789917,
          1.3233113288879395,
          1.305195927619934,
          1.2606844902038574,
          1.2182612419128418,
          1.1853841543197632,
          1.1692023277282715,
          1.1640417575836182,
          1.1465556621551514,
          1.1132831573486328,
          1.090413212776184,
          1.0641709566116333,
          1.041150689125061,
          1.0310680866241455,
          1.014622688293457,
          1.0023077726364136,
          0.979121208190918,
          0.9666145443916321,
          0.9495042562484741,
          0.930655837059021,
          0.9114023447036743,
          0.8952562212944031,
          0.8814972639083862,
          0.8684248328208923,
          0.8522976636886597,
          0.835481584072113,
          0.819334089756012,
          0.8057820200920105,
          0.7938797473907471,
          0.7999429702758789,
          0.8070760369300842,
          0.788719654083252,
          0.7595045566558838,
          0.7445893287658691,
          0.732887327671051,
          0.7190712690353394,
          0.7056987881660461,
          0.6932153105735779,
          0.6836872696876526,
          0.6718155741691589,
          0.6641181707382202,
          0.6531205773353577,
          0.6455753445625305,
          0.6377418637275696,
          0.6255217790603638,
          0.615075409412384,
          0.6041206121444702,
          0.5918653607368469,
          0.5861088037490845,
          0.5759673714637756,
          0.5684847831726074,
          0.5627930164337158,
          0.5517657399177551,
          0.5428584218025208,
          0.5367546677589417,
          0.5290160775184631,
          0.564918041229248,
          0.5842041969299316,
          0.566307008266449,
          0.5255775451660156,
          0.5521813631057739,
          0.6123144626617432,
          0.6221787929534912,
          0.5817638635635376,
          0.5475091934204102,
          0.5536932349205017,
          0.5506561398506165,
          0.5359751582145691,
          0.5425214171409607,
          0.5456454753875732,
          0.538385808467865,
          0.5167838931083679,
          0.5006710886955261,
          0.48432981967926025,
          0.4716270864009857,
          0.4586659073829651,
          0.44554606080055237,
          0.4334661364555359,
          0.42489027976989746,
          0.4176439046859741,
          0.4123937785625458,
          0.4016759693622589,
          0.3918682634830475,
          0.3826659321784973,
          0.37304794788360596,
          0.3643489181995392,
          0.35853612422943115,
          0.35348087549209595,
          0.3489619195461273,
          0.34426456689834595,
          0.3375731408596039,
          0.32694944739341736,
          0.3196675479412079,
          0.3136037588119507,
          0.306718647480011,
          0.3022717535495758,
          0.29887303709983826,
          0.29444774985313416,
          0.2899143099784851,
          0.2856529653072357,
          0.28089040517807007,
          0.2745005786418915,
          0.2698114514350891,
          0.2713846266269684,
          0.2707290053367615,
          0.2601941227912903,
          0.2554655075073242,
          0.2540654242038727,
          0.24892672896385193,
          0.24193939566612244,
          0.23501355946063995,
          0.23407109081745148,
          0.23503698408603668,
          0.22999092936515808,
          0.2245892882347107,
          0.22042740881443024,
          0.21828605234622955,
          0.21564459800720215,
          0.21007990837097168,
          0.20559516549110413,
          0.20248794555664062,
          0.20061561465263367,
          0.1970546394586563,
          0.19239158928394318,
          0.19006408751010895,
          0.18816570937633514,
          0.1847524791955948,
          0.18101467192173004,
          0.17743465304374695,
          0.1745327264070511,
          0.172177255153656,
          0.1701032519340515,
          0.16917932033538818,
          0.16611060500144958,
          0.16380013525485992,
          0.16193746030330658,
          0.15799367427825928,
          0.1550012230873108,
          0.1528942734003067,
          0.1522429883480072,
          0.15113620460033417,
          0.14876241981983185,
          0.14639778435230255,
          0.1441078633069992,
          0.14252863824367523,
          0.13999605178833008,
          0.1384924352169037,
          0.13641393184661865,
          0.1341656595468521,
          0.1354592740535736,
          0.1343117654323578,
          0.13279320299625397,
          0.13427212834358215,
          0.12992021441459656,
          0.12605974078178406,
          0.12574784457683563,
          0.12323468923568726,
          0.11889415234327316,
          0.11796261370182037,
          0.11651849001646042,
          0.11434359103441238,
          0.1138601154088974,
          0.11341296136379242,
          0.11299977451562881,
          0.11550259590148926,
          0.11888434737920761,
          0.11849852651357651,
          0.11589816212654114,
          0.11192899197340012,
          0.10958520323038101,
          0.10648737102746964,
          0.10442459583282471,
          0.10288485139608383,
          0.09984873980283737,
          0.0987694188952446,
          0.09648390859365463,
          0.09482600539922714,
          0.09337430447340012,
          0.09253834187984467,
          0.0918068215250969,
          0.09067396074533463,
          0.08901938796043396,
          0.08890911936759949,
          0.08771829307079315,
          0.08589296042919159,
          0.08504459261894226,
          0.08269380033016205,
          0.08169171214103699,
          0.08203283697366714,
          0.08056497573852539,
          0.07806418091058731,
          0.07812225073575974,
          0.07755132019519806,
          0.07475202530622482,
          0.07279977202415466,
          0.0717097818851471,
          0.071999691426754,
          0.073618084192276,
          0.07081269472837448,
          0.0699896514415741,
          0.06953667104244232,
          0.06948786973953247,
          0.06816712021827698,
          0.06745384633541107,
          0.06684069335460663,
          0.06548620015382767,
          0.06437084823846817,
          0.0629560574889183,
          0.06215877830982208,
          0.06142990663647652,
          0.06037510931491852,
          0.05935244634747505,
          0.06033844128251076,
          0.060307323932647705,
          0.06526482850313187,
          0.06840185821056366,
          0.06127750501036644,
          0.060904473066329956,
          0.06225096061825752,
          0.06273715943098068,
          0.05991044640541077,
          0.06027143821120262,
          0.0625397115945816,
          0.06282416731119156,
          0.0633799284696579,
          0.05863555148243904,
          0.07498326897621155,
          0.09650267660617828,
          0.08358538150787354,
          0.09349744021892548,
          0.12752437591552734,
          0.1433044821023941,
          0.12255841493606567,
          0.1562611311674118,
          0.15638329088687897,
          0.1489306092262268,
          0.20013943314552307,
          0.1736077517271042,
          0.13939864933490753,
          0.13876226544380188,
          0.14490766823291779,
          0.14614959061145782,
          0.13411352038383484,
          0.13006015121936798,
          0.12180272489786148,
          0.1146235540509224,
          0.10627396404743195,
          0.0992458239197731,
          0.09035751223564148,
          0.08372747153043747,
          0.0849044993519783,
          0.09165973961353302,
          0.0929407924413681,
          0.08409848809242249,
          0.07243740558624268,
          0.06962756812572479,
          0.07023857533931732,
          0.07845410704612732,
          0.08842693269252777,
          0.0874212458729744,
          0.08324652910232544,
          0.07456183433532715,
          0.0686551183462143,
          0.06516390293836594,
          0.06303836405277252,
          0.0629420354962349,
          0.061836376786231995,
          0.06193998083472252,
          0.06265120208263397,
          0.060253843665122986,
          0.057448066771030426,
          0.05658038333058357,
          0.05448676273226738,
          0.05150818079710007,
          0.05050751194357872,
          0.04965313524007797,
          0.04955088719725609,
          0.0478033609688282,
          0.04667864739894867,
          0.04437778517603874,
          0.04242680221796036,
          0.04080705717206001,
          0.03871578723192215,
          0.0371454693377018,
          0.03606849163770676,
          0.03509197384119034,
          0.034259166568517685,
          0.032666921615600586,
          0.03243452310562134,
          0.03196815401315689,
          0.03089369647204876,
          0.029767930507659912,
          0.02879408746957779,
          0.028160810470581055,
          0.027736468240618706,
          0.02714812010526657,
          0.026826078072190285,
          0.027934571728110313,
          0.029468392953276634,
          0.03193411976099014,
          0.033717554062604904,
          0.032701704651117325,
          0.029777640476822853,
          0.02744232304394245,
          0.026755541563034058,
          0.028377993032336235,
          0.028754057362675667,
          0.02905776910483837,
          0.027938494458794594,
          0.025545381009578705,
          0.024644002318382263,
          0.02425619401037693,
          0.024523593485355377,
          0.024510791525244713,
          0.024264948442578316,
          0.023291215300559998,
          0.022123968228697777,
          0.020899944007396698,
          0.020906198769807816,
          0.020600806921720505,
          0.020642155781388283,
          0.021301306784152985,
          0.02097983844578266,
          0.02019168995320797,
          0.0203982125967741,
          0.020262783393263817,
          0.01946980506181717,
          0.01861102506518364,
          0.018242737278342247,
          0.017381032928824425,
          0.01774447038769722,
          0.017581414431333542,
          0.017259400337934494,
          0.021767672151327133,
          0.029306506738066673,
          0.0337708406150341,
          0.03224355727434158,
          0.029670771211385727,
          0.024054203182458878,
          0.02450227364897728,
          0.029221834614872932,
          0.03165207803249359,
          0.028262650594115257,
          0.0220854002982378,
          0.020272770896553993,
          0.021159382537007332,
          0.022431423887610435,
          0.022822661325335503,
          0.022030889987945557,
          0.020868780091404915,
          0.02011597342789173,
          0.01902037300169468,
          0.018414810299873352,
          0.018582656979560852,
          0.019291000440716743,
          0.018973639234900475,
          0.017859864979982376,
          0.016724806278944016,
          0.01577962189912796,
          0.015165943652391434,
          0.014705894514918327,
          0.014246285893023014,
          0.013704141601920128,
          0.013212176971137524,
          0.01291035208851099,
          0.012742397375404835,
          0.012495494447648525,
          0.012176310643553734,
          0.01189171802252531,
          0.011563893407583237,
          0.011214789003133774,
          0.01099342480301857,
          0.010792654007673264,
          0.010619652457535267,
          0.010427208617329597,
          0.010250936262309551,
          0.010056517086923122,
          0.009892296977341175,
          0.0096801882609725,
          0.009621045552194118,
          0.009392195381224155,
          0.009264347143471241,
          0.00913337804377079,
          0.009018227458000183,
          0.009023888036608696,
          0.008892316371202469,
          0.008798733353614807,
          0.008926640264689922,
          0.008791999891400337,
          0.008622813038527966,
          0.008684833534061909,
          0.008929165080189705,
          0.008802135474979877,
          0.012446369044482708,
          0.010848337784409523,
          0.01601238176226616,
          0.025951514020562172,
          0.039726704359054565,
          0.029653703793883324,
          0.02875836007297039,
          0.04073631018400192,
          0.02581937238574028,
          0.0376664437353611,
          0.07233430445194244,
          0.08907390385866165,
          0.07007896900177002,
          0.0989624634385109,
          0.08557570725679398,
          0.063186414539814,
          0.10878486186265945,
          0.07355006784200668,
          0.055981189012527466,
          0.0630519762635231,
          0.07119400799274445,
          0.07298561930656433,
          0.06652659922838211,
          0.05070493370294571,
          0.05042547360062599,
          0.047579575330019,
          0.04388904944062233,
          0.05871649459004402,
          0.07420945167541504,
          0.06780213862657547,
          0.05548980087041855,
          0.04834030941128731,
          0.048573777079582214,
          0.04502582550048828,
          0.04321730509400368,
          0.04149036109447479,
          0.03980289772152901,
          0.0399489551782608,
          0.03789013996720314,
          0.035424601286649704,
          0.030989021062850952,
          0.02683175355195999,
          0.024093912914395332,
          0.022716043516993523,
          0.02196659706532955,
          0.02124819904565811,
          0.02074461802840233,
          0.021211741492152214,
          0.02242835983633995,
          0.023659801110625267,
          0.022202689200639725,
          0.016498349606990814,
          0.0164716225117445,
          0.018000420182943344,
          0.01887841522693634,
          0.02060999721288681,
          0.019757820293307304,
          0.019292576238512993,
          0.018361328169703484,
          0.017813686281442642,
          0.016427868977189064,
          0.015519187785685062,
          0.013531431555747986,
          0.013797478750348091,
          0.016073010861873627,
          0.019222166389226913,
          0.021753715351223946,
          0.019260557368397713,
          0.01845531165599823,
          0.016090281307697296,
          0.014917389489710331,
          0.013655747286975384,
          0.013095413334667683,
          0.01336414460092783,
          0.014039264991879463,
          0.014747758395969868,
          0.014958235435187817,
          0.014383465982973576,
          0.013997803442180157,
          0.014407106675207615,
          0.014401919208467007,
          0.013118965551257133,
          0.012086693197488785,
          0.01201824564486742,
          0.010416441597044468,
          0.009921821765601635,
          0.010058612562716007,
          0.012292434461414814,
          0.012804863043129444,
          0.012079291045665741,
          0.011592086404561996,
          0.010053110308945179,
          0.009182515554130077,
          0.008538518100976944,
          0.00822586938738823,
          0.008237493224442005,
          0.008001116104424,
          0.007947378791868687,
          0.007777039427310228,
          0.007472440600395203,
          0.007332421373575926,
          0.006963413208723068,
          0.0068050711415708065,
          0.006640630774199963,
          0.006441333796828985,
          0.006275190506130457,
          0.006104641128331423,
          0.005928030703216791,
          0.005797508172690868,
          0.005625185556709766,
          0.0054754046723246574,
          0.005322703626006842,
          0.005182231310755014,
          0.005063701421022415,
          0.004946606699377298,
          0.004846097901463509,
          0.004756178706884384,
          0.004655107390135527,
          0.004561072215437889,
          0.004478535149246454,
          0.004401445854455233,
          0.00433344254270196,
          0.004261369816958904,
          0.004189795348793268,
          0.004123091232031584,
          0.004055142868310213,
          0.003993357066065073,
          0.0039393045008182526,
          0.0038876088801771402,
          0.0038384690415114164,
          0.0037901282776147127,
          0.0037392033264040947,
          0.0036913047078996897,
          0.0036468813195824623,
          0.003595939837396145,
          0.0035560273099690676,
          0.003512647235766053,
          0.003473263932392001,
          0.0034344324376434088,
          0.0033963106106966734,
          0.003363193478435278,
          0.0033209151588380337,
          0.003281327895820141,
          0.0032437166664749384,
          0.0032086523715406656,
          0.0031763913575559855,
          0.0031456281431019306,
          0.0031161245424300432,
          0.0030872279312461615,
          0.0030584975611418486,
          0.003029988380149007,
          0.003001590957865119,
          0.002973719732835889,
          0.002946296473965049,
          0.002920447615906596,
          0.0028941945638507605,
          0.002868480049073696,
          0.002844050293788314,
          0.002820011228322983,
          0.0027943155728280544,
          0.0027683358639478683,
          0.002746072132140398,
          0.0027237709145992994,
          0.002702354220673442,
          0.0026813840959221125,
          0.002660727594047785,
          0.0026407423429191113,
          0.0026206925977021456,
          0.00260067917406559,
          0.002581040607765317,
          0.0025617461651563644,
          0.0025430989917367697,
          0.0025261680129915476,
          0.0025078821927309036,
          0.0024897640105336905,
          0.002472072606906295,
          0.0024546056520193815,
          0.0024370644241571426,
          0.0024198219180107117,
          0.0024017018731683493,
          0.002385262632742524,
          0.002368992893025279,
          0.002352879149839282,
          0.002337599638849497,
          0.0023219243157655,
          0.0023069926537573338,
          0.002291977172717452,
          0.002277268096804619,
          0.002262842608615756,
          0.002248438773676753,
          0.002234105486422777,
          0.0022204588167369366,
          0.002206775126978755,
          0.0021929258946329355,
          0.0021794820204377174,
          0.0021661976352334023,
          0.0021530583035200834,
          0.0021399296820163727,
          0.0021271537989377975,
          0.0021144566126167774,
          0.0021018823608756065,
          0.002089448506012559,
          0.0020771995186805725,
          0.0020650881342589855,
          0.0020530507899820805,
          0.0020410490687936544,
          0.002029203111305833,
          0.0020172453951090574,
          0.0020055968780070543,
          0.0019944580271840096,
          0.001983926398679614,
          0.0019728918559849262,
          0.001962039154022932,
          0.001951119164004922,
          0.0019403620390221477,
          0.0019296917598694563,
          0.0019191610626876354,
          0.0019087757682427764,
          0.0018985039787366986,
          0.0018883602460846305,
          0.001878336537629366,
          0.0018683987436816096,
          0.0018588127568364143,
          0.0018495788099244237,
          0.0018405058654025197,
          0.0018316019559279084,
          0.0018217500764876604,
          0.001812610775232315,
          0.0018033502856269479,
          0.001794283976778388,
          0.001785283093340695,
          0.001776394434273243,
          0.001767562236636877,
          0.0017586700851097703,
          0.0017493092454969883,
          0.001740473904646933,
          0.0017316080629825592,
          0.0017231375677511096,
          0.0017148414626717567,
          0.0017066103173419833,
          0.0016984294634312391,
          0.0016903044888749719,
          0.0016822128091007471,
          0.0016739702550694346,
          0.001665633637458086,
          0.0016579491784796119,
          0.00164987298194319,
          0.0016423191409558058,
          0.0016348737990483642,
          0.0016272872453555465,
          0.0016197219956666231,
          0.0016123118111863732,
          0.0016049426048994064,
          0.0015975680435076356,
          0.0015902420273050666,
          0.0015830936608836055,
          0.0015758934896439314,
          0.0015687907580286264,
          0.0015617306344211102,
          0.0015546734211966395,
          0.0015476667322218418,
          0.0015407404862344265,
          0.0015338860685005784,
          0.0015271868323907256,
          0.0015205402160063386,
          0.001513930968940258,
          0.0015074060065671802,
          0.0015008782502263784,
          0.0014943677233532071,
          0.0014880017843097448,
          0.001481605926528573,
          0.0014753361465409398,
          0.0014690060634166002,
          0.0014628639910370111,
          0.0014567205216735601,
          0.0014505175640806556,
          0.0014444495318457484,
          0.0014383950037881732,
          0.001432316843420267,
          0.0014263655757531524,
          0.001420429558493197,
          0.001414471073076129,
          0.0014086742885410786,
          0.0014028939185664058,
          0.0013971554581075907,
          0.0013914918527007103,
          0.0013858468737453222,
          0.0013802185421809554,
          0.001374647836200893,
          0.0013691402273252606,
          0.0013636478688567877,
          0.0013582127867266536,
          0.0013528176350519061,
          0.0013474398292601109,
          0.0013421124313026667,
          0.001336810877546668,
          0.0013315175892785192,
          0.0013262731954455376,
          0.0013210437027737498,
          0.0013158043147996068,
          0.0013106242986395955,
          0.001305514364503324,
          0.0013004252687096596,
          0.0012953990371897817,
          0.0012903815368190408,
          0.0012854257365688682,
          0.0012804929865524173,
          0.0012756009818986058,
          0.0012707203859463334,
          0.001265874132514,
          0.0012610668782144785,
          0.0012562911724671721,
          0.0012515486450865865,
          0.0012468440691009164,
          0.0012421640567481518,
          0.001237530610524118,
          0.0012329258024692535,
          0.0012283462565392256,
          0.0012237923219799995,
          0.0012192713329568505,
          0.001214773626998067,
          0.0012103074695914984,
          0.0012058778665959835,
          0.0012014691019430757,
          0.0011970801278948784,
          0.0011927307350561023,
          0.0011883925180882215,
          0.0011840894585475326,
          0.001179808285087347,
          0.001175552955828607,
          0.0011713184649124742,
          0.0011671001557260752,
          0.0011629172367975116,
          0.001158745726570487,
          0.0011546050664037466,
          0.0011504816357046366,
          0.0011463818373158574,
          0.0011423053219914436,
          0.001138248830102384,
          0.0011342004872858524,
          0.0011301659978926182,
          0.001126165734604001,
          0.0011222184402868152,
          0.0011182880261912942,
          0.0011143744923174381,
          0.0011104749282822013,
          0.0011066007427871227,
          0.001102736801840365,
          0.0010989148868247867,
          0.0010950993746519089,
          0.0010912847938016057,
          0.0010874951258301735,
          0.0010836994042620063,
          0.0010799490846693516,
          0.001076230313628912,
          0.0010725375032052398,
          0.0010688870679587126,
          0.001065254444256425,
          0.0010616387007758021,
          0.0010580358793959022,
          0.0010544541291892529,
          0.0010508913546800613,
          0.0010473366128280759,
          0.0010438065510243177,
          0.0010402844054624438,
          0.0010367811191827059,
          0.001033294596709311,
          0.001029827049933374,
          0.0010263771982863545,
          0.0010229357285425067,
          0.0010195086942985654,
          0.0010161051759496331,
          0.0010127201676368713
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": ""
        },
        "xaxis": {
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "title": {
          "text": ""
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lines([test_losses, train_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = t.tensor([10] * 10).to(cfg.device)\n",
    "out = model(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-68.5691, -53.3248, -33.7109,  28.4673, -47.1521,  49.8403,  20.7787,\n",
       "          18.6870, -19.6562,  14.9037]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899
         ],
         "xaxis": "x",
         "y": [
          2.2703514099121094,
          2.2395405769348145,
          2.2085189819335938,
          2.1764636039733887,
          2.142791748046875,
          2.10731840133667,
          2.0705783367156982,
          2.0336356163024902,
          1.9981554746627808,
          1.965922474861145,
          1.937679648399353,
          1.9128265380859375,
          1.8900750875473022,
          1.8686412572860718,
          1.8483537435531616,
          1.8294475078582764,
          1.812081217765808,
          1.7959147691726685,
          1.7800649404525757,
          1.7634681463241577,
          1.7454668283462524,
          1.7260545492172241,
          1.7056715488433838,
          1.6847436428070068,
          1.6626578569412231,
          1.63853919506073,
          1.61211359500885,
          1.583520531654358,
          1.5527479648590088,
          1.519374966621399,
          1.4836188554763794,
          1.4458200931549072,
          1.406359076499939,
          1.364904522895813,
          1.3204925060272217,
          1.2731270790100098,
          1.22353994846344,
          1.1708508729934692,
          1.1150083541870117,
          1.0571264028549194,
          0.9966414570808411,
          0.9336987137794495,
          0.8701422810554504,
          0.8066260814666748,
          0.7441383600234985,
          0.6831145286560059,
          0.6247608065605164,
          0.5698306560516357,
          0.5179246664047241,
          0.46841806173324585,
          0.4207397699356079,
          0.3750752806663513,
          0.33206844329833984,
          0.291416198015213,
          0.25355300307273865,
          0.21901148557662964,
          0.18773473799228668,
          0.15960176289081573,
          0.13492557406425476,
          0.11380327492952347,
          0.09573955833911896,
          0.08052349090576172,
          0.06809712946414948,
          0.05818776786327362,
          0.04973116144537926,
          0.04219410941004753,
          0.035934869199991226,
          0.031008217483758926,
          0.027041928842663765,
          0.023780616000294685,
          0.02103719301521778,
          0.01870683953166008,
          0.016702858731150627,
          0.014957020059227943,
          0.01343599148094654,
          0.012132631614804268,
          0.011043697595596313,
          0.010113473050296307,
          0.00927244033664465,
          0.008504824712872505,
          0.007827955298125744,
          0.007231445051729679,
          0.00669760862365365,
          0.006213771644979715,
          0.005779371131211519,
          0.0053921290673315525,
          0.00504921842366457,
          0.004745654296129942,
          0.004474232438951731,
          0.004229612648487091,
          0.004006821196526289,
          0.003802781691774726,
          0.0036154550034552813,
          0.003442961722612381,
          0.0032842967193573713,
          0.0031389787327498198,
          0.003006163751706481,
          0.0028854282572865486,
          0.002775507280603051,
          0.0026750783436000347,
          0.0025827172212302685,
          0.002497381065040827,
          0.0024180614855140448,
          0.00234392611309886,
          0.0022742105647921562,
          0.0022089567501097918,
          0.0021481411531567574,
          0.002091736299917102,
          0.002039363607764244,
          0.0019905806984752417,
          0.0019450061954557896,
          0.0019021208863705397,
          0.00186159648001194,
          0.0018231758149340749,
          0.0017866413109004498,
          0.0017519420944154263,
          0.0017189469654113054,
          0.001687486656010151,
          0.001657444634474814,
          0.0016287794569507241,
          0.0016013813437893987,
          0.0015751435421407223,
          0.001549951615743339,
          0.0015257014892995358,
          0.0015023474115878344,
          0.0014798303600400686,
          0.001458054524846375,
          0.0014369753189384937,
          0.001416612882167101,
          0.0013969428837299347,
          0.0013779043219983578,
          0.0013594356132671237,
          0.0013415053253993392,
          0.0013240998378023505,
          0.0013071896973997355,
          0.001290717045776546,
          0.0012746559223160148,
          0.001258987351320684,
          0.0012436764081940055,
          0.0012287106364965439,
          0.0012140895705670118,
          0.0011997767724096775,
          0.0011858086800202727,
          0.0011721622431650758,
          0.0011588024208322167,
          0.0011457238579168916,
          0.0011329231783747673,
          0.0011203923495486379,
          0.001108107273466885,
          0.0010960428044199944,
          0.0010841808980330825,
          0.0010725517058745027,
          0.0010611464967951179,
          0.0010499432682991028,
          0.0010389399249106646,
          0.0010281448485329747,
          0.0010175458155572414,
          0.0010071264114230871,
          0.0009968697559088469,
          0.000986766186542809,
          0.000976838287897408,
          0.0009670790750533342,
          0.0009574713767506182,
          0.0009480128646828234,
          0.0009387098252773285,
          0.0009295524214394391,
          0.0009205344831570983,
          0.000911643379367888,
          0.0009028696804307401,
          0.0008942388813011348,
          0.0008857441716827452,
          0.0008773694862611592,
          0.0008691144757904112,
          0.000860988802742213,
          0.0008529868791811168,
          0.000845093687530607,
          0.000837305560708046,
          0.0008296119049191475,
          0.000822033325675875,
          0.0008145676692947745,
          0.00080720434198156,
          0.0007999375811778009,
          0.0007927807746455073,
          0.000785722688306123,
          0.000778756570070982,
          0.0007718782871961594,
          0.0007650773040950298,
          0.000758373353164643,
          0.0007517627673223615,
          0.0007452411227859557,
          0.0007388003286905587,
          0.0007324504549615085,
          0.000726187601685524,
          0.0007200014661066234,
          0.0007138896617107093,
          0.0007078427588567138,
          0.0007018781616352499,
          0.0006959927850402892,
          0.0006901820888742805,
          0.0006844415329396725,
          0.0006787788588553667,
          0.0006731878966093063,
          0.0006676629418507218,
          0.0006621999200433493,
          0.0006567931268364191,
          0.0006514590932056308,
          0.0006461917073465884,
          0.0006409883499145508,
          0.0006358455284498632,
          0.000630769704002887,
          0.0006257587228901684,
          0.000620804843492806,
          0.000615903118159622,
          0.0006110514514148235,
          0.0006062620086595416,
          0.0006015316466800869,
          0.0005968562327325344,
          0.0005922324489802122,
          0.0005876714130863547,
          0.0005831631715409458,
          0.0005787057452835143,
          0.0005742929060943425,
          0.000569922907743603,
          0.0005656053544953465,
          0.0005613414687104523,
          0.000557125371415168,
          0.0005529549089260399,
          0.000548834097571671,
          0.0005447638686746359,
          0.0005407357239164412,
          0.0005367479170672596,
          0.0005327966646291316,
          0.0005288926186040044,
          0.0005250347894616425,
          0.0005212196265347302,
          0.0005174422403797507,
          0.0005137121770530939,
          0.0005100247217342257,
          0.0005063759163022041,
          0.0005027607548981905,
          0.0004991774912923574,
          0.0004956367774866521,
          0.0004921347717754543,
          0.0004886719980277121,
          0.0004852437705267221,
          0.00048185570631176233,
          0.0004785051860380918,
          0.0004751876404043287,
          0.00047190109035000205,
          0.000468641024781391,
          0.00046541940537281334,
          0.00046223122626543045,
          0.0004590777098201215,
          0.0004559553926810622,
          0.00045286849490366876,
          0.0004498138732742518,
          0.0004467903927434236,
          0.0004437931929714978,
          0.0004408188397064805,
          0.000437877926742658,
          0.0004349696100689471,
          0.00043208911665715277,
          0.00042923673754557967,
          0.0004264171584509313,
          0.00042362604290246964,
          0.0004208609461784363,
          0.00041811863775365055,
          0.0004153990594204515,
          0.0004127078573219478,
          0.000410045322496444,
          0.00040740828262642026,
          0.0004047964175697416,
          0.00040221205563284457,
          0.00039965510950423777,
          0.0003971206024289131,
          0.0003946075157728046,
          0.0003921138704754412,
          0.000389645661925897,
          0.0003872033266816288,
          0.00038478177157230675,
          0.00038238507113419473,
          0.00038001281791366637,
          0.0003776629746425897,
          0.0003753348719328642,
          0.00037302623968571424,
          0.0003707318683154881,
          0.0003684640978462994,
          0.0003662157978396863,
          0.00036398976226337254,
          0.00036178308073431253,
          0.0003595988964661956,
          0.00035743621992878616,
          0.0003552911221049726,
          0.0003531624097377062,
          0.0003510491515044123,
          0.00034895632416009903,
          0.00034688482992351055,
          0.00034483091440051794,
          0.00034279562532901764,
          0.000340779748512432,
          0.0003387836623005569,
          0.0003368027973920107,
          0.00033483767765574157,
          0.0003328874008730054,
          0.0003309535386506468,
          0.0003290392633061856,
          0.0003271415189374238,
          0.0003252580645494163,
          0.00032339521567337215,
          0.00032155014923773706,
          0.0003197167534381151,
          0.0003178993647452444,
          0.00031609315192326903,
          0.00031430349918082356,
          0.0003125302609987557,
          0.0003107719530817121,
          0.00030902816797606647,
          0.0003073005354963243,
          0.0003055886772926897,
          0.0003038910508621484,
          0.000302202592138201,
          0.0003005281905643642,
          0.000298868166282773,
          0.0002972227812279016,
          0.0002955911331810057,
          0.00029397165053524077,
          0.0002923674474004656,
          0.00029077869839966297,
          0.0002892013581003994,
          0.00028763432055711746,
          0.0002860776148736477,
          0.00028453487902879715,
          0.0002830049197655171,
          0.0002814882027450949,
          0.00027998225414194167,
          0.0002784915850497782,
          0.0002770129940472543,
          0.0002755463938228786,
          0.00027408829191699624,
          0.00027263900847174227,
          0.0002712029963731766,
          0.00026977804373018444,
          0.00026836697361432016,
          0.000266965595073998,
          0.00026557472301647067,
          0.00026419784990139306,
          0.00026282991166226566,
          0.00026147073367610574,
          0.000260121509199962,
          0.0002587822964414954,
          0.0002574539103079587,
          0.00025613655452616513,
          0.00025482839555479586,
          0.0002535332168918103,
          0.0002522474096622318,
          0.0002509711775928736,
          0.0002497025125194341,
          0.00024844237486831844,
          0.00024719134671613574,
          0.00024595099966973066,
          0.00024472008226439357,
          0.00024349801242351532,
          0.00024228819529525936,
          0.00024108534853439778,
          0.00023989318287931383,
          0.00023870653240010142,
          0.00023752832203172147,
          0.00023635885736439377,
          0.00023519707610830665,
          0.00023404670355375856,
          0.00023290314129553735,
          0.00023176969261839986,
          0.0002306456008227542,
          0.00022952807194087654,
          0.0002284167130710557,
          0.00022731312492396683,
          0.00022621717653237283,
          0.0002251297264592722,
          0.0002240507019450888,
          0.000222981019760482,
          0.00022191782773006707,
          0.00022086358512751758,
          0.00021981667669024318,
          0.000218775006942451,
          0.00021774003107566386,
          0.00021671106514986604,
          0.00021569266391452402,
          0.00021468033082783222,
          0.00021367458975873888,
          0.0002126771432813257,
          0.0002116867690347135,
          0.0002107047475874424,
          0.00020972710626665503,
          0.00020875393238384277,
          0.00020778887846972793,
          0.0002068315225187689,
          0.00020588030747603625,
          0.00020493488409556448,
          0.00020399958884809166,
          0.00020306839724071324,
          0.00020214510732330382,
          0.00020122523710597306,
          0.00020031226449646056,
          0.0001994050689972937,
          0.00019850354874506593,
          0.00019761022122111171,
          0.00019672133203130215,
          0.00019584133406169713,
          0.00019496624008752406,
          0.00019409632659517229,
          0.00019323098240420222,
          0.00019237142987549305,
          0.00019151595188304782,
          0.00019066780805587769,
          0.0001898268674267456,
          0.00018898963753599674,
          0.00018816010560840368,
          0.00018733479373622686,
          0.0001865155209088698,
          0.00018570059910416603,
          0.00018488845671527088,
          0.0001840836921473965,
          0.0001832839334383607,
          0.0001824907521950081,
          0.00018170078692492098,
          0.0001809180248528719,
          0.00018014013767242432,
          0.00017936722724698484,
          0.00017859786748886108,
          0.00017783221846912056,
          0.00017707253573462367,
          0.000176317582372576,
          0.0001755676930770278,
          0.00017482374096289277,
          0.0001740831066854298,
          0.0001733500830596313,
          0.0001726202026475221,
          0.00017189189384225756,
          0.0001711696822894737,
          0.00017045212734956294,
          0.00016973901074379683,
          0.0001690309145487845,
          0.00016832680557854474,
          0.0001676274259807542,
          0.00016693337238393724,
          0.0001662420982029289,
          0.00016555600450374186,
          0.00016487273387610912,
          0.00016419304301962256,
          0.00016351933300029486,
          0.00016285052697639912,
          0.00016218343807850033,
          0.00016152230091392994,
          0.0001608665188541636,
          0.0001602129195816815,
          0.00015956370043568313,
          0.00015891641669441015,
          0.0001582736149430275,
          0.00015763497503940016,
          0.00015700106450822204,
          0.00015636993339285254,
          0.00015574412827845663,
          0.00015512316895183176,
          0.00015450383943971246,
          0.0001538883661851287,
          0.00015327564324252307,
          0.0001526666892459616,
          0.0001520612568128854,
          0.0001514599280199036,
          0.0001508630666648969,
          0.0001502690720371902,
          0.00014967971947044134,
          0.00014909377205185592,
          0.00014851041487418115,
          0.0001479279453633353,
          0.00014735069999005646,
          0.00014677834406029433,
          0.00014620661386288702,
          0.0001456402096664533,
          0.00014507726882584393,
          0.00014451798051595688,
          0.0001439620100427419,
          0.0001434069126844406,
          0.0001428549294359982,
          0.00014230776287149638,
          0.00014176327385939658,
          0.00014122112770564854,
          0.00014068307064007968,
          0.00014014898624736816,
          0.00013961701188236475,
          0.0001390880352118984,
          0.00013856159057468176,
          0.00013803664478473365,
          0.00013751622464042157,
          0.00013699947157874703,
          0.0001364853815175593,
          0.00013597344513982534,
          0.00013546491391025484,
          0.00013495991879608482,
          0.00013445767399389297,
          0.00013395535643212497,
          0.00013345840852707624,
          0.00013296173710841686,
          0.0001324689801549539,
          0.0001319803559454158,
          0.00013149381265975535,
          0.00013101020886097103,
          0.00013052980648353696,
          0.0001300506992265582,
          0.00012957466242369264,
          0.00012910037185065448,
          0.0001286291517317295,
          0.00012816049274988472,
          0.00012769544264301658,
          0.00012723154213745147,
          0.0001267706393264234,
          0.00012631391291506588,
          0.00012585839431267232,
          0.00012540401075966656,
          0.00012495268310885876,
          0.00012450305803213269,
          0.00012405644520185888,
          0.00012361217522993684,
          0.00012317078653723001,
          0.0001227331958943978,
          0.000122297162306495,
          0.00012186289677629247,
          0.00012143031199229881,
          0.00012100039020879194,
          0.00012057104322593659,
          0.00012014565436402336,
          0.00011972244101343676,
          0.00011930118489544839,
          0.00011888358858413994,
          0.00011846734560094774,
          0.00011805156827904284,
          0.00011763966176658869,
          0.00011722950875991955,
          0.00011682001786539331,
          0.00011641505261650309,
          0.00011601150617934763,
          0.0001156078651547432,
          0.00011520938278408721,
          0.00011481294495752081,
          0.00011441731476224959,
          0.00011402335803722963,
          0.00011363098019501194,
          0.00011324074876029044,
          0.00011285315849818289,
          0.00011246812937315553,
          0.00011208317300770432,
          0.00011170162906637415,
          0.0001113230682676658,
          0.00011094583169324324,
          0.00011056895891670138,
          0.0001101940797525458,
          0.00010982179082930088,
          0.00010945076792268082,
          0.00010908194235526025,
          0.00010871562699321657,
          0.00010835030116140842,
          0.00010798784933285788,
          0.00010762727470137179,
          0.00010726747859735042,
          0.00010690993804018945,
          0.0001065531323547475,
          0.00010619939712341875,
          0.00010584726260276511,
          0.00010549685976002365,
          0.000105148101283703,
          0.00010480011405888945,
          0.00010445644147694111,
          0.00010411145922262222,
          0.00010376901627751067,
          0.00010342831956222653,
          0.00010308927448932081,
          0.0001027525941026397,
          0.00010241592826787382,
          0.00010208332241745666,
          0.00010175068018725142,
          0.00010142206883756444,
          0.0001010914784274064,
          0.0001007636237773113,
          0.00010043707879958674,
          0.00010011216363636777,
          0.00009978978778235614,
          0.0000994682777673006,
          0.00009914778638631105,
          0.00009882986341835931,
          0.00009851455979514867,
          0.00009819842671277002,
          0.00009788454917725176,
          0.00009757113002706319,
          0.00009726065763970837,
          0.00009695099288364872,
          0.0000966433944995515,
          0.00009633646550355479,
          0.00009603229409549385,
          0.0000957283700699918,
          0.00009542668703943491,
          0.00009512484393781051,
          0.00009482490713708103,
          0.00009452673111809418,
          0.00009423040319234133,
          0.00009393509390065446,
          0.00009364181460114196,
          0.00009334916830994189,
          0.00009305899584433064,
          0.0000927686269278638,
          0.00009247891284758225,
          0.00009219249477609992,
          0.00009190665878122672,
          0.00009162179776467383,
          0.00009133891580859199,
          0.00009105657954933122,
          0.00009077702998183668,
          0.00009049779328051955,
          0.00009021856385516003,
          0.00008994252129923552,
          0.00008966594032244757,
          0.00008939144754549488,
          0.00008911819895729423,
          0.00008884574344847351,
          0.00008857509237714112,
          0.00008830673323245719,
          0.00008803904347587377,
          0.00008777180482866243,
          0.00008750568667892367,
          0.00008724067447474226,
          0.00008697700104676187,
          0.0000867146736709401,
          0.00008645302295917645,
          0.000086194348114077,
          0.00008593669190304354,
          0.00008567737677367404,
          0.00008542118303012103,
          0.00008516534580849111,
          0.00008491146581945941,
          0.00008465755672659725,
          0.00008440639066975564,
          0.00008415467164013535,
          0.0000839052299852483,
          0.0000836564286146313,
          0.00008340929343830794,
          0.00008316228922922164,
          0.00008291725680464879,
          0.0000826726682134904,
          0.00008242733747465536,
          0.00008218600851250812,
          0.00008194510155590251,
          0.00008170521323336288,
          0.0000814660670584999,
          0.0000812283469713293,
          0.00008099075785139576,
          0.00008075494406512007,
          0.00008051852637436241,
          0.00008028510637814179,
          0.00008005173003766686,
          0.00007981985254446045,
          0.00007958876813063398,
          0.00007935972098493949,
          0.0000791306301834993,
          0.0000789026526035741,
          0.00007867461681598797,
          0.00007844873471185565,
          0.00007822277984814718,
          0.00007799967715982348,
          0.0000777757159085013,
          0.00007755433034617454,
          0.00007733221718808636,
          0.00007711263606324792,
          0.00007689172343816608,
          0.00007667347381357104,
          0.00007645547884749249,
          0.00007623796409461647,
          0.00007602317782584578,
          0.00007580833334941417,
          0.00007559406367363408,
          0.00007538139470852911,
          0.0000751689076423645,
          0.00007495813770219684,
          0.0000747469239286147,
          0.00007453673606505617,
          0.00007432940765284002,
          0.00007412122067762539,
          0.00007391339750029147,
          0.00007370692765107378,
          0.00007350283703999594,
          0.00007329812069656327,
          0.00007309435022762045,
          0.00007289140921784565,
          0.00007268793706316501,
          0.00007248748443089426,
          0.00007228793401736766,
          0.00007208852184703574,
          0.00007188934250734746,
          0.00007169215678004548,
          0.00007149457087507471,
          0.00007129891309887171,
          0.00007110235310392454,
          0.00007090784492902458,
          0.00007071351137710735,
          0.00007052087312331423,
          0.00007032808935036883,
          0.00007013633876340464,
          0.00006994667637627572,
          0.00006975589349167421,
          0.00006956636207178235,
          0.0000693779657012783,
          0.0000691903114784509,
          0.00006900267180753872,
          0.00006881551234982908,
          0.00006863150338176638,
          0.00006844630115665495,
          0.00006826176831964403,
          0.00006807931640651077,
          0.00006789638428017497,
          0.00006771401240257546,
          0.00006753300840500742,
          0.00006735307397320867,
          0.0000671722082188353,
          0.00006699362711515278,
          0.00006681502418359742,
          0.00006663887324975803,
          0.00006646040128543973,
          0.00006628474511671811,
          0.00006611046410398558,
          0.00006593309808522463,
          0.00006575923907803372,
          0.00006558666791534051,
          0.00006541279435623437,
          0.00006524119817186147,
          0.00006506993668153882,
          0.00006490003579529002,
          0.00006472897075582296,
          0.00006455900438595563,
          0.00006438972195610404,
          0.00006422298611141741,
          0.0000640547732473351,
          0.00006388621841324493,
          0.00006372118514264002,
          0.00006355615187203512,
          0.00006338992534438148,
          0.00006322610715869814,
          0.00006306219438556582,
          0.00006289935845416039,
          0.00006273452891036868,
          0.00006257386121433228,
          0.00006241184019017965,
          0.00006225262768566608,
          0.00006209143612068146,
          0.00006193338049342856,
          0.0000617737096035853,
          0.000061615755839739,
          0.00006145717634353787,
          0.0000613012962276116,
          0.00006114276038715616,
          0.0000609880116826389,
          0.000060832542658317834,
          0.00006067817594157532,
          0.00006052486423868686,
          0.00006037066486896947,
          0.00006021603985573165,
          0.000060064725403208286,
          0.00005991220677969977,
          0.00005976149986963719,
          0.00005961009082966484,
          0.00005946042438154109,
          0.000059311481891199946,
          0.00005916235750191845,
          0.00005901376425754279,
          0.000058864236052613705,
          0.00005871767643839121,
          0.00005857040741830133,
          0.00005842433893121779,
          0.00005827758286613971,
          0.00005813304233015515,
          0.00005798911661258899,
          0.00005784438326372765,
          0.000057700050092535093,
          0.000057557681429898366,
          0.000057415007177041844,
          0.00005727259485865943,
          0.00005713083010050468,
          0.00005698936729459092,
          0.00005685014548362233,
          0.00005670926839229651,
          0.0000565696791454684,
          0.00005643088661599904,
          0.00005629241422866471,
          0.0000561540546186734,
          0.000056016349844867364,
          0.00005587952182395384,
          0.000055742275435477495,
          0.0000556067461729981,
          0.000055471416999353096,
          0.00005533589865081012,
          0.00005520130071090534,
          0.00005506748129846528,
          0.00005493345815921202,
          0.00005480086474562995,
          0.00005466671791509725,
          0.000054535645176656544,
          0.00005440476525109261,
          0.00005427300129667856,
          0.0000541422632522881,
          0.00005401071030064486,
          0.000053881762141827494,
          0.000053751191444462165,
          0.000053623287385562435,
          0.00005349344064597972,
          0.00005336624235496856,
          0.000053238611144479364,
          0.000053111041779629886,
          0.00005298515679896809,
          0.00005285854422254488,
          0.000052732459153048694,
          0.00005260774923954159,
          0.00005248177330940962,
          0.000052356688684085384,
          0.00005223318294156343,
          0.000052109982789261267,
          0.000051985945901833475,
          0.000051864171837223694,
          0.00005174168472876772,
          0.00005161904118722305,
          0.00005149667413206771,
          0.000051376267947489396,
          0.000051255196012789384,
          0.000051135706598870456,
          0.00005101603164803237,
          0.000050896447646664456,
          0.000050776889111148193,
          0.00005065797449788079,
          0.000050540165830170736,
          0.00005042129851062782,
          0.00005030533793615177,
          0.00005018713272875175,
          0.00005006990613765083,
          0.00004995435301680118,
          0.00004983928010915406,
          0.000049723614210961387,
          0.000049607919208938256,
          0.00004949361755279824,
          0.000049379017582396045,
          0.00004926435212837532,
          0.00004915124372928403,
          0.00004903860462945886,
          0.000048925492592388764,
          0.00004881285349256359,
          0.000048700003389967605,
          0.00004859014370595105,
          0.0000484778756799642,
          0.000048365298425778747,
          0.00004825624273507856,
          0.00004814544445252977,
          0.00004803640331374481,
          0.00004792683830601163,
          0.00004781710231327452,
          0.00004770937084686011,
          0.00004760175943374634,
          0.00004749251820612699,
          0.00004738548523164354,
          0.000047277691919589415,
          0.00004717012416222133,
          0.00004706411709776148,
          0.00004695865209214389,
          0.000046852510422468185,
          0.00004674650699598715,
          0.00004664259176934138,
          0.00004653623545891605,
          0.00004643200009013526,
          0.00004632792479242198,
          0.00004622337291948497,
          0.00004612081102095544,
          0.00004601804539561272,
          0.00004591475226334296,
          0.000045811910240445286,
          0.000045709151891060174,
          0.00004560881279758178,
          0.000045507018512580544,
          0.00004540707959677093,
          0.000045304757804842666,
          0.00004520450602285564,
          0.00004510373037192039,
          0.00004500426075537689,
          0.00004490549326874316,
          0.00004480564166442491,
          0.00004470654312171973,
          0.000044608521420741454,
          0.00004451032873475924,
          0.00004441173223312944,
          0.00004431409979588352,
          0.00004421750418259762,
          0.00004411974805407226,
          0.000044024262024322525,
          0.00004392766277305782,
          0.0000438314164057374,
          0.000043735602957895026,
          0.00004364071719464846
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line(test_losses, log_y=True)\n",
    "# plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899
         ],
         "xaxis": "x",
         "y": [
          2.301990032196045,
          2.271068572998047,
          2.23994779586792,
          2.2092206478118896,
          2.176811695098877,
          2.1434266567230225,
          2.1076362133026123,
          2.070155382156372,
          2.0340754985809326,
          1.9980801343917847,
          1.9673292636871338,
          1.9375600814819336,
          1.9140328168869019,
          1.890297293663025,
          1.8703263998031616,
          1.8486641645431519,
          1.8285305500030518,
          1.813177466392517,
          1.7977007627487183,
          1.7850780487060547,
          1.7640475034713745,
          1.7470600605010986,
          1.7282990217208862,
          1.707759141921997,
          1.684143304824829,
          1.6615384817123413,
          1.6412895917892456,
          1.615416407585144,
          1.589840292930603,
          1.5554484128952026,
          1.5207288265228271,
          1.4847495555877686,
          1.447853684425354,
          1.4046601057052612,
          1.3644217252731323,
          1.321488857269287,
          1.273688554763794,
          1.2271744012832642,
          1.1740831136703491,
          1.1145362854003906,
          1.055804967880249,
          0.998585045337677,
          0.9344625473022461,
          0.8709927797317505,
          0.8093199729919434,
          0.745267391204834,
          0.6857129335403442,
          0.6265265345573425,
          0.5715181231498718,
          0.517713725566864,
          0.468394011259079,
          0.42351245880126953,
          0.37480154633522034,
          0.33606210350990295,
          0.291221559047699,
          0.2551015317440033,
          0.22010841965675354,
          0.18895862996578217,
          0.1602020114660263,
          0.13458159565925598,
          0.11567258834838867,
          0.0959727093577385,
          0.08155813813209534,
          0.06833237409591675,
          0.05873221904039383,
          0.04990093410015106,
          0.04259960353374481,
          0.036075372248888016,
          0.031222213059663773,
          0.02733251266181469,
          0.023842643946409225,
          0.021040376275777817,
          0.018808340653777122,
          0.016962168738245964,
          0.014978194609284401,
          0.013585934415459633,
          0.012280702590942383,
          0.011148259043693542,
          0.010222080163657665,
          0.009298953227698803,
          0.008500603027641773,
          0.007950401864945889,
          0.007358204107731581,
          0.006756930146366358,
          0.006286424584686756,
          0.005878004245460033,
          0.005444241221994162,
          0.005101026501506567,
          0.004754047840833664,
          0.004473147448152304,
          0.0042833187617361546,
          0.004071654286235571,
          0.0038156979717314243,
          0.0036514431703835726,
          0.0034920405596494675,
          0.0033131130039691925,
          0.0031851574312895536,
          0.003001949517056346,
          0.0028868354856967926,
          0.002803441369906068,
          0.0027193098794668913,
          0.0025895119179040194,
          0.002522281603887677,
          0.0024464253801852465,
          0.002365282503888011,
          0.0023117659147828817,
          0.0022096955217421055,
          0.0021499854046851397,
          0.0021094840485602617,
          0.002068719593808055,
          0.001994180493056774,
          0.001963801681995392,
          0.0019234666833654046,
          0.0018742409301921725,
          0.001853539957664907,
          0.0017879009246826172,
          0.0017546433955430984,
          0.0017314881552010775,
          0.0017078530509024858,
          0.0016591619933024049,
          0.0016421641921624541,
          0.0016184309497475624,
          0.001583910547196865,
          0.001575800939463079,
          0.0015281018568202853,
          0.0015064658364281058,
          0.0014901889953762293,
          0.001474240212701261,
          0.0014386108377948403,
          0.0014276693109422922,
          0.0014114391524344683,
          0.0013845361536368728,
          0.0013822632608935237,
          0.0013434424763545394,
          0.001328883576206863,
          0.0013156587956473231,
          0.001303959870710969,
          0.0012757342774420977,
          0.0012688622809946537,
          0.0012565639335662127,
          0.0012337457155808806,
          0.0012346971780061722,
          0.00120096979662776,
          0.0011905819410458207,
          0.0011792590375989676,
          0.0011705746874213219,
          0.0011463674018159509,
          0.0011415740009397268,
          0.001132023986428976,
          0.001112615573219955,
          0.0011146877659484744,
          0.001085318741388619,
          0.0010770575609058142,
          0.0010671202326193452,
          0.001060417271219194,
          0.0010392090771347284,
          0.0010360372252762318,
          0.0010282632429152727,
          0.0010110483272001147,
          0.0010136757045984268,
          0.000987728824838996,
          0.0009809726616367698,
          0.0009720977395772934,
          0.0009667680715210736,
          0.0009480101871304214,
          0.0009458890999667346,
          0.0009394578519277275,
          0.0009238924249075353,
          0.0009269340080209076,
          0.0009037085110321641,
          0.0008980572456493974,
          0.0008900508400984108,
          0.0008857574430294335,
          0.0008689725073054433,
          0.0008675504359416664,
          0.0008621698361821473,
          0.0008480476099066436,
          0.0008513244101777673,
          0.0008304223301820457,
          0.00082563137402758,
          0.0008183288737200201,
          0.0008147937478497624,
          0.0007997145876288414,
          0.0007988822762854397,
          0.0007942959782667458,
          0.000781369861215353,
          0.0007847623201087117,
          0.0007658340036869049,
          0.0007617971277795732,
          0.000755111628677696,
          0.0007521556690335274,
          0.000738547823857516,
          0.0007381337927654386,
          0.0007342075114138424,
          0.0007223595748655498,
          0.0007257675752043724,
          0.0007085629622451961,
          0.0007051440188661218,
          0.0006990195834077895,
          0.0006965243956074119,
          0.0006841927533969283,
          0.000684079306665808,
          0.0006807096651755273,
          0.0006698283250443637,
          0.0006731941248290241,
          0.000657488708384335,
          0.0006545586511492729,
          0.0006489493534900248,
          0.0006468213396146894,
          0.000635601463727653,
          0.0006357257370837033,
          0.0006328379386104643,
          0.0006228075362741947,
          0.0006261146045289934,
          0.0006117022130638361,
          0.000609199982136488,
          0.0006040645530447364,
          0.0006022504530847073,
          0.0005919968243688345,
          0.0005923061980865896,
          0.0005898429080843925,
          0.0005805619293823838,
          0.0005838011275045574,
          0.0005705235525965691,
          0.0005683886120095849,
          0.0005636804853565991,
          0.000562127330340445,
          0.0005527297034859657,
          0.0005531699862331152,
          0.0005510695627890527,
          0.0005424552364274859,
          0.0005456233047880232,
          0.0005333537119440734,
          0.0005315309972502291,
          0.000527199765201658,
          0.0005258712917566299,
          0.0005172318196855485,
          0.0005177754792384803,
          0.0005159850115887821,
          0.0005079704569652677,
          0.000511059770360589,
          0.0004996950156055391,
          0.0004981373785994947,
          0.000494147592689842,
          0.0004930117866024375,
          0.0004850531986448914,
          0.0004856671148445457,
          0.00048414740012958646,
          0.0004766701895277947,
          0.0004796783032361418,
          0.00046912222751416266,
          0.0004677890974562615,
          0.00046411162475124,
          0.00046313609345816076,
          0.00045578545541502535,
          0.0004564494302030653,
          0.00045515852980315685,
          0.00044817267917096615,
          0.00045109959319233894,
          0.00044126613647677004,
          0.0004401266050990671,
          0.00043673402979038656,
          0.00043589179404079914,
          0.0004290817305445671,
          0.0004297848790884018,
          0.0004286973853595555,
          0.0004221529816277325,
          0.00042499788105487823,
          0.0004158135561738163,
          0.00041483977111056447,
          0.0004117040953133255,
          0.000410973938414827,
          0.00040465276106260717,
          0.00040537910535931587,
          0.00040447135688737035,
          0.00039832876063883305,
          0.0004010929842479527,
          0.0003924966440536082,
          0.00039166491478681564,
          0.0003887642815243453,
          0.00038812780985608697,
          0.0003822518337983638,
          0.0003829921188298613,
          0.0003822420258074999,
          0.00037646389682777226,
          0.0003791486378759146,
          0.000371084752259776,
          0.0003703770926222205,
          0.0003676869091577828,
          0.0003671359736472368,
          0.00036165924393571913,
          0.00036240750341676176,
          0.00036179713788442314,
          0.0003563494828995317,
          0.0003589499683585018,
          0.00035137261147610843,
          0.0003507730725686997,
          0.0003482690663076937,
          0.0003477955178823322,
          0.00034268127637915313,
          0.0003434311074670404,
          0.00034294271608814597,
          0.00033779931254684925,
          0.0003403176961001009,
          0.0003331846965011209,
          0.000332680472638458,
          0.0003303417470306158,
          0.000329941714880988,
          0.0003251537855248898,
          0.0003259000077378005,
          0.00032551976619288325,
          0.0003206559631507844,
          0.0003230949805583805,
          0.00031636565108783543,
          0.00031594614847563207,
          0.00031375783146359026,
          0.00031342310830950737,
          0.00030893218354322016,
          0.0003096718282904476,
          0.00030937898554839194,
          0.0003047810459975153,
          0.00030713420710526407,
          0.0003007777559105307,
          0.00030043229344300926,
          0.0002983839367516339,
          0.0002981042198371142,
          0.00029388206894509494,
          0.00029461688245646656,
          0.0002944006701000035,
          0.00029004650423303246,
          0.0002923195715993643,
          0.00028630546876229346,
          0.000286028312984854,
          0.00028410652885213494,
          0.0002838734944816679,
          0.0002798969217110425,
          0.0002806284464895725,
          0.0002804772520903498,
          0.0002763477386906743,
          0.00027854222571477294,
          0.00027284384123049676,
          0.0002726298407651484,
          0.00027082403539679945,
          0.0002706336963456124,
          0.00026688427897170186,
          0.00026760660693980753,
          0.0002675143477972597,
          0.00026358963805250823,
          0.00026571014313958585,
          0.0002603039611130953,
          0.0002601470332592726,
          0.00025844815536402166,
          0.00025829518563114107,
          0.00025474984431639314,
          0.0002554673992563039,
          0.00025542356888763607,
          0.0002516921085771173,
          0.0002537420659791678,
          0.00024860582198016346,
          0.00024849988403730094,
          0.00024689818383194506,
          0.0002467793528921902,
          0.00024342343385796994,
          0.00024413126811850816,
          0.0002441310789436102,
          0.00024057865084614605,
          0.00024255788594018668,
          0.00023767542734276503,
          0.00023761378542985767,
          0.00023610061907675117,
          0.00023601397697348148,
          0.00023283051268663257,
          0.0002335268072783947,
          0.0002335682074772194,
          0.00023018075444269925,
          0.00023209214850794524,
          0.00022744557645637542,
          0.00022742045985069126,
          0.0002259925240650773,
          0.00022593094035983086,
          0.000222908376599662,
          0.00022359447029884905,
          0.00022366979101207107,
          0.00022043616627343,
          0.00022228500165510923,
          0.00021785787248518318,
          0.00021786575962323695,
          0.00021651785937137902,
          0.00021647852554451674,
          0.0002136028342647478,
          0.00021427958563435823,
          0.00021438280236907303,
          0.00021129508968442678,
          0.00021308135183062404,
          0.00020885842968709767,
          0.00020889700681436807,
          0.00020762217172887176,
          0.00020760312327183783,
          0.00020486643188633025,
          0.00020553162903524935,
          0.00020566035527735949,
          0.00020270806271582842,
          0.00020443453104235232,
          0.00020040613890159875,
          0.00020046760619152337,
          0.0001992624020203948,
          0.00019926088862121105,
          0.0001966545096365735,
          0.0001973066246137023,
          0.00019745994359254837,
          0.00019463167700450867,
          0.00019630312453955412,
          0.00019245412840973586,
          0.00019253518257755786,
          0.00019139597134198993,
          0.00019141126540489495,
          0.00018892389198299497,
          0.00018956430722028017,
          0.00018973635451402515,
          0.00018702638044487685,
          0.00018864368030335754,
          0.000184961871127598,
          0.00018506291962694377,
          0.0001839831384131685,
          0.00018401276611257344,
          0.00018163624918088317,
          0.00018226401880383492,
          0.0001824552018661052,
          0.0001798549055820331,
          0.00018141807231586426,
          0.0001778965670382604,
          0.00017801379726734012,
          0.00017698899318929762,
          0.00017703097546473145,
          0.00017475987260695547,
          0.0001753754186211154,
          0.00017558271065354347,
          0.00017308622773271054,
          0.00017459677474107593,
          0.00017122688586823642,
          0.00017135788220912218,
          0.00017038661462720484,
          0.0001704374299151823,
          0.0001682633883319795,
          0.00016886909725144506,
          0.00016908835095819086,
          0.00016668780881445855,
          0.0001681517605902627,
          0.00016492295253556222,
          0.0001650651392992586,
          0.00016414219862781465,
          0.00016420264728367329,
          0.00016212051559705287,
          0.00016271538333967328,
          0.0001629468606552109,
          0.00016063857765402645,
          0.00016205667634494603,
          0.0001589602034073323,
          0.00015911283844616264,
          0.0001582356489961967,
          0.0001583019911777228,
          0.0001563067053211853,
          0.0001568914158269763,
          0.0001571332395542413,
          0.0001549104053992778,
          0.00015628435357939452,
          0.00015331286704167724,
          0.00015347350563388318,
          0.00015263927343767136,
          0.00015271086886059493,
          0.00015079951845109463,
          0.0001513726165285334,
          0.00015162226918619126,
          0.0001494823954999447,
          0.0001508150016888976,
          0.0001479599013691768,
          0.00014812688459642231,
          0.00014733619173057377,
          0.0001474116725148633,
          0.0001455760357202962,
          0.00014613995153922588,
          0.00014639760775025934,
          0.000144334597280249,
          0.00014562490105163306,
          0.00014288185047917068,
          0.0001430543779861182,
          0.00014230083615984768,
          0.00014238145377021283,
          0.00014061776164453477,
          0.00014117239334154874,
          0.0001414365106029436,
          0.0001394440623698756,
          0.00014069740427657962,
          0.00013805933122057468,
          0.000138235351187177,
          0.00013751850929111242,
          0.0001376036088913679,
          0.00013590687012765557,
          0.0001364522468065843,
          0.00013672148634213954,
          0.00013479792687576264,
          0.00013601405953522772,
          0.00013347754429560155,
          0.00013365519407670945,
          0.00013297161785885692,
          0.0001330589147983119,
          0.0001314260734943673,
          0.0001319626608164981,
          0.00013223545101936907,
          0.0001303771568927914,
          0.0001315593544859439,
          0.000129115825984627,
          0.00012929728836752474,
          0.0001286463375436142,
          0.00012873606465291232,
          0.00012716064520645887,
          0.00012768949090968817,
          0.00012796740338671952,
          0.00012617082393262535,
          0.00012731879542116076,
          0.000124965314171277,
          0.00012514674745034426,
          0.00012452545342966914,
          0.00012461686856113374,
          0.00012309869634918869,
          0.00012361937842797488,
          0.00012389985204208642,
          0.00012216343020554632,
          0.00012327880540397018,
          0.0001210101690958254,
          0.00012119189341319725,
          0.00012059907021466643,
          0.00012069315562257543,
          0.00011922812700504437,
          0.00011973911750828847,
          0.00012002227595075965,
          0.00011833906319225207,
          0.00011942535638809204,
          0.00011723684292519465,
          0.00011741912749130279,
          0.00011685430217767134,
          0.00011694955173879862,
          0.0001155335339717567,
          0.00011603676102822646,
          0.00011632197856670246,
          0.00011469283344922587,
          0.0001157494043582119,
          0.00011363637167960405,
          0.00011382007505744696,
          0.00011327788524795324,
          0.0001133746700361371,
          0.0001120075976359658,
          0.0001125007911468856,
          0.00011278777674306184,
          0.00011121023271698505,
          0.0001122385510825552,
          0.00011019755766028538,
          0.00011038122465834022,
          0.00010986238339683041,
          0.00010995881166309118,
          0.00010863868374144658,
          0.00010912407014984637,
          0.00010940999345621094,
          0.00010788103099912405,
          0.00010888336692005396,
          0.00010691144416341558,
          0.00010709406342357397,
          0.00010659772669896483,
          0.0001066961485776119,
          0.00010542001109570265,
          0.00010589690646156669,
          0.00010618211672408506,
          0.00010469984408700839,
          0.00010567633580649272,
          0.0001037681577145122,
          0.00010395183926448226,
          0.00010347592615289614,
          0.00010357455175835639,
          0.00010233847569907084,
          0.00010280816786689684,
          0.00010309489880455658,
          0.00010165637650061399,
          0.00010260617273161188,
          0.00010076124453917146,
          0.00010094331082655117,
          0.00010048670083051547,
          0.0001005862868623808,
          0.00009938951552612707,
          0.00009985054202843457,
          0.00010013727296609432,
          0.00009873984527075663,
          0.00009966702054953203,
          0.00009787989984033629,
          0.00009806102752918378,
          0.00009762388799572363,
          0.00009772311750566587,
          0.00009656447218731046,
          0.00009701723320176825,
          0.0000973042770056054,
          0.00009594548464519903,
          0.00009685056284070015,
          0.00009511932148598135,
          0.0000952991031226702,
          0.0000948795277508907,
          0.00009497906285105273,
          0.00009385561861563474,
          0.00009430235513718799,
          0.0000945873252931051,
          0.0000932676630327478,
          0.0000941497492021881,
          0.00009247234993381426,
          0.00009265122207580134,
          0.00009224807581631467,
          0.00009234821482095867,
          0.00009125890210270882,
          0.00009169741679215804,
          0.00009198264160659164,
          0.00009069905354408547,
          0.00009155816223938018,
          0.00008993388473754749,
          0.0000901096427696757,
          0.00008972325304057449,
          0.00008982264262158424,
          0.000088765453256201,
          0.00008919710671762004,
          0.00008948146569309756,
          0.00008823328244034201,
          0.00008907149458536878,
          0.00008749649714445695,
          0.00008767056715441868,
          0.00008729867840884253,
          0.00008739794429857284,
          0.00008637202699901536,
          0.00008679823076818138,
          0.00008708085806574672,
          0.00008586419426137581,
          0.00008668270311318338,
          0.00008515497029293329,
          0.00008532760693924502,
          0.00008497003000229597,
          0.00008506996528012678,
          0.00008407289715250954,
          0.0000844916285132058,
          0.00008477184746880084,
          0.00008358899503946304,
          0.00008438771328656003,
          0.00008290573896374553,
          0.00008307619282277301,
          0.0000827311523607932,
          0.00008282998169306666,
          0.00008186345075955614,
          0.00008227559010265395,
          0.00008255357533926144,
          0.00008140203863149509,
          0.00008218085713451728,
          0.00008074261131696403,
          0.00008090945630101487,
          0.00008057924424065277,
          0.00008067831367952749,
          0.00007973733590915799,
          0.00008014315244508907,
          0.00008042050467338413,
          0.0000792976570664905,
          0.00008005924610188231,
          0.00007866100349929184,
          0.00007882807403802872,
          0.00007850825932109728,
          0.00007860839104978368,
          0.00007769309013383463,
          0.00007809328963048756,
          0.00007836746226530522,
          0.00007727299089310691,
          0.00007801698666298762,
          0.00007665866723982617,
          0.00007682364230277017,
          0.00007651581836398691,
          0.0000766144585213624,
          0.00007572530739707872,
          0.00007611827459186316,
          0.00007639094110345468,
          0.00007532360177719966,
          0.00007605203427374363,
          0.00007473136065527797,
          0.00007489421841455624,
          0.00007459901098627597,
          0.00007469661068171263,
          0.00007383071351796389,
          0.00007421689224429429,
          0.00007448897667927667,
          0.00007344682671828195,
          0.00007415891013806686,
          0.00007287473272299394,
          0.00007303550228243694,
          0.00007274961535586044,
          0.00007284804451046512,
          0.00007200597610790282,
          0.0000723857301636599,
          0.00007265424210345373,
          0.00007163833652157336,
          0.00007233552605612203,
          0.0000710843742126599,
          0.00007124624971766025,
          0.00007096906483639032,
          0.00007106604607542977,
          0.00007024521619314328,
          0.00007062072836561128,
          0.00007088622805895284,
          0.0000698945441399701,
          0.00007057568291202188,
          0.00006935915007488802,
          0.00006951892282813787,
          0.00006925214984221384,
          0.00006934661359991878,
          0.00006854895036667585,
          0.00006891774683026597,
          0.0000691800523782149,
          0.00006821381248300895,
          0.00006887941708555445,
          0.00006769465107936412,
          0.00006785267032682896,
          0.00006759525422239676,
          0.00006768861203454435,
          0.00006691108137601987,
          0.0000672740425216034,
          0.00006753613706678152,
          0.00006659032078459859,
          0.00006724255945300683,
          0.00006608951662201434,
          0.00006624406523769721,
          0.00006599527841899544,
          0.00006608924741158262,
          0.00006533063424285501,
          0.00006568824028363451,
          0.00006594687147298828,
          0.00006502569158328697,
          0.00006566262163687497,
          0.00006453745299950242,
          0.00006469259096775204,
          0.000064452899096068,
          0.0000645443651592359,
          0.0000638034543953836,
          0.00006415706593543291,
          0.00006441424193326384,
          0.0000635113101452589,
          0.00006413574010366574,
          0.00006304005364654586,
          0.00006319398380583152,
          0.00006295914499787614,
          0.00006305065471678972,
          0.00006232900341274217,
          0.00006267743447097018,
          0.00006293020851444453,
          0.00006205063255038112,
          0.00006266161653911695,
          0.00006159243639558554,
          0.00006174383452162147,
          0.00006152060814201832,
          0.00006160731572890654,
          0.000060904480051249266,
          0.00006124709034338593,
          0.000061498794821091,
          0.00006063778346288018,
          0.00006123663479229435,
          0.00006019217107677832,
          0.000060344140365486965,
          0.000060125708841951564,
          0.00006021382432663813,
          0.0000595268102188129,
          0.000059864858485525474,
          0.000060114263760624453,
          0.000059271755162626505,
          0.000059858051827177405,
          0.000058838904806179926,
          0.00005898890594835393,
          0.00005877863077330403,
          0.00005886489088879898,
          0.000058194105804432184,
          0.000058528130466584116,
          0.00005877532021258958,
          0.00005795078686787747,
          0.00005852470712852664,
          0.000057531229685992,
          0.000057680044847074896,
          0.000057475710491416976,
          0.00005756008977186866,
          0.00005690605757990852,
          0.00005723576759919524,
          0.00005747838440584019,
          0.000056671906349947676,
          0.00005723509821109474,
          0.00005626518031931482,
          0.000056412332924082875,
          0.000056214277719845995,
          0.00005629828592645936,
          0.00005565887113334611,
          0.00005598340794676915,
          0.00005622449316433631,
          0.00005543442603084259,
          0.00005598719508270733,
          0.000055039996368577704,
          0.00005518439138540998,
          0.00005499413964571431,
          0.00005507491368916817,
          0.000054452371841762215,
          0.000054772128351032734,
          0.00005500989573192783,
          0.00005423790935310535,
          0.00005477888771565631,
          0.00005385379699873738,
          0.00005399627843871713,
          0.000053811760153621435,
          0.000053891355491941795,
          0.000053282052249414846,
          0.000053598032536683604,
          0.00005383332245401107,
          0.0000530778088432271,
          0.00005360872091841884,
          0.000052702973334817216,
          0.000052846404287265614,
          0.000052666349802166224,
          0.00005274572686175816,
          0.000052149513066979125,
          0.00005246133150649257,
          0.000052693369070766494,
          0.000051953607908217236,
          0.00005247439185041003,
          0.00005158861677045934,
          0.00005172856253921054,
          0.00005155688995728269,
          0.00005163446985534392,
          0.00005105164018459618,
          0.00005135930405231193,
          0.00005158887506695464,
          0.000050863975047832355,
          0.000051374907343415543,
          0.00005050955951446667,
          0.00005064783545094542,
          0.000050481397920520976,
          0.00005055640576756559,
          0.00004998631993657909,
          0.000050290487706661224,
          0.00005051810512668453,
          0.0000498075460200198,
          0.00005030847023590468,
          0.00004946239278069697,
          0.00004959994839737192,
          0.00004943623207509518,
          0.00004951289156451821,
          0.00004895469101029448,
          0.00004925378743791953,
          0.000049478327127872035,
          0.0000487815668748226,
          0.000049275255150860175,
          0.00004844596332986839,
          0.00004858102693106048,
          0.000048424219130538404,
          0.000048499197873752564,
          0.000047953602916095406,
          0.000048247802624246106,
          0.00004846909359912388,
          0.00004778803850058466,
          0.00004827157317777164,
          0.000047460209316341206,
          0.00004759611329063773,
          0.00004744193938677199,
          0.00004751505912281573,
          0.00004698144766734913,
          0.00004727340638055466,
          0.00004749152503791265,
          0.00004682282451540232,
          0.00004729807915282436,
          0.000046502846089424565,
          0.00004663770232582465,
          0.00004648849062505178,
          0.00004656014425563626,
          0.00004603829074767418,
          0.000046326244046213105,
          0.000046541401388822123,
          0.00004588545925798826,
          0.00004635014192899689,
          0.00004557508509606123,
          0.00004570792953018099,
          0.00004556403655442409,
          0.000045633543777512386,
          0.0000451212799816858,
          0.00004540538429864682,
          0.000045619421143783256,
          0.000044976233766647056,
          0.000045432938350131735,
          0.00004467231337912381,
          0.000044805212382925674,
          0.00004466392783797346,
          0.00004473371882340871,
          0.00004423230348038487,
          0.00004451301720109768,
          0.000044723052269546315,
          0.00004409309622133151,
          0.0000445414443674963,
          0.00004379630263429135,
          0.0000439273972006049
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line(train_losses, log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Must provide a tokenizer if passing a string to the model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model([\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:259\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Input is either a batch of tokens ([batch, pos]) or a text string, a string is automatically tokenized to a batch of a single element. The prepend_bos flag only applies when inputting a text string.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[1;32m    249\u001b[0m \u001b[39mreturn_type Optional[str]: The type of output to return. Can be one of: None (return nothing, don't calculate logits), 'logits' (return logits), 'loss' (return cross-entropy loss), 'both' (return logits and loss)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mNote that loss is the standard \"predict the next token\" cross-entropy loss for GPT-2 style language models - if you want a custom loss function, the recommended behaviour is returning the logits and then applying your custom loss function.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39minput\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39minput\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m    257\u001b[0m     \u001b[39m# If text, convert to tokens (batch_size=1)\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[39massert\u001b[39;00m (\n\u001b[0;32m--> 259\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mMust provide a tokenizer if passing a string to the model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m     \u001b[39m# This is only intended to support passing in a single string\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_tokens(\u001b[39minput\u001b[39m, prepend_bos\u001b[39m=\u001b[39mprepend_bos)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Must provide a tokenizer if passing a string to the model"
     ]
    }
   ],
   "source": [
    "model([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           0.04035932,
           0.029771073,
           -0.079525284,
           -0.07045816,
           0.0065640667,
           -0.051558655,
           0.13125227,
           -0.050364554,
           0.041092288,
           0.12192161,
           -0.110844955,
           -0.043121476,
           -0.007882758,
           0.059765283,
           -0.13408084,
           0.19040377,
           0.11259651,
           -0.0535696,
           0.015645344,
           0.1250925,
           -0.1912154,
           0.07725189,
           0.1613439,
           0.11950842,
           -0.022205483,
           -0.19095875,
           -0.0011097513,
           -0.035015263,
           0.06270127,
           -0.086312845,
           0.18440898,
           0.2287768,
           -0.03026636,
           0.020426994,
           0.1423712,
           0.010953128,
           0.091900416,
           0.0725415,
           -0.10935162,
           -0.038411397,
           -0.03639492,
           -0.040714446,
           0.05679053,
           -0.17807752,
           -0.12870769,
           0.12336261,
           -0.12209892,
           -0.06966297,
           0.20463257,
           -0.060276493,
           0.18591124,
           -0.09026923,
           -0.061819077,
           0.22671603,
           0.2882163,
           -0.17294598,
           0.17324777,
           -0.15289728,
           0.040829286,
           -0.0704618,
           0.08270246,
           0.1433517,
           0.18575166,
           -0.09204035,
           -0.059671715,
           0.083811216,
           -0.02460198,
           -0.03347507,
           -0.06412723,
           0.08578056,
           -0.059936643,
           -0.16090801,
           0.22262797,
           -0.02616868,
           0.0802318,
           0.08422481,
           -0.1474909,
           0.10960183,
           0.018499877,
           -0.007111309,
           0.25180176,
           -0.10654485,
           0.040309228,
           0.0064431685,
           -0.1265317,
           -0.14316776,
           0.10663606,
           0.028643621,
           0.057494473,
           -0.022716552,
           0.083422974,
           -0.09757332,
           -0.0815014,
           -0.06312173,
           -0.14378928,
           -0.11575544,
           -0.15332954,
           -0.16301842,
           0.00049413246,
           -0.0057529574,
           0.07724298,
           -0.09429253,
           -0.07662827,
           0.0685546,
           -0.09286829,
           0.042021327,
           0.051810827,
           0.16904901,
           0.008364196,
           0.26926264,
           -0.124230094,
           -0.21966955,
           -0.026307615,
           -0.008908639,
           0.13963078,
           -0.2088564,
           -0.02223574,
           0.030594213,
           -0.20513587,
           0.06787207,
           0.17130716,
           0.01534965,
           0.08286861,
           -0.03891293,
           -0.112555,
           0.0819529,
           -0.051276077,
           -0.19009742
          ],
          [
           -0.23355646,
           0.19199763,
           0.17809612,
           -0.040530168,
           0.19230643,
           0.16813324,
           0.04853789,
           -0.17449045,
           -0.002780209,
           0.013793087,
           0.13699707,
           0.0757027,
           0.091417566,
           -0.06820377,
           0.14041942,
           0.13777144,
           0.23200858,
           0.1520176,
           -0.17057031,
           -0.081867635,
           0.084153555,
           -0.04167982,
           -0.105157174,
           0.1770451,
           -0.10334025,
           -0.014101562,
           0.17065452,
           -0.052063394,
           -0.12851201,
           -0.06336769,
           0.20685336,
           -0.027565919,
           -0.1147138,
           -0.064569324,
           0.024703527,
           0.24363667,
           -0.28668126,
           0.07628202,
           -0.05963618,
           -0.066302836,
           0.019334577,
           0.24436484,
           -0.03265386,
           0.017098643,
           -0.17512326,
           0.06310371,
           -0.22616899,
           -0.19912234,
           -0.07570129,
           -0.11495473,
           0.025886439,
           0.0064548184,
           0.09622079,
           0.14202817,
           -0.21804644,
           0.07392898,
           0.07502623,
           0.16246809,
           0.08907685,
           -0.1419149,
           -0.08169228,
           0.19170016,
           0.045033626,
           0.15846303,
           0.08508395,
           -0.07695082,
           0.21226819,
           0.079035826,
           0.15604219,
           -0.04917347,
           -0.044491164,
           0.026564658,
           -0.00017557232,
           -0.19061996,
           0.14197206,
           0.0024120342,
           -0.0989258,
           -0.10990998,
           0.00023395353,
           0.06765052,
           0.015246185,
           -0.114333875,
           -0.015217221,
           -0.054447573,
           0.024202729,
           0.114125796,
           0.14122061,
           0.023378182,
           0.11463316,
           0.14416066,
           -0.017057313,
           -0.007308364,
           -0.05576322,
           0.06361964,
           -0.08431767,
           -0.024310037,
           -0.10446728,
           0.007065474,
           0.09330964,
           0.026948621,
           -0.042780418,
           0.12209373,
           0.032311633,
           0.014189596,
           0.12092737,
           -0.17665745,
           0.121302046,
           -0.21618246,
           -0.043044694,
           -0.054973662,
           -0.062828965,
           -0.024495855,
           0.15093309,
           -0.029860131,
           -0.057773814,
           -0.10540944,
           0.0456305,
           -0.08192823,
           -0.053109586,
           -0.14604144,
           -0.076976396,
           -0.048852354,
           -0.04021635,
           -0.17225756,
           0.088330746,
           -0.20826447,
           -0.07268109,
           0.15509988
          ],
          [
           0.123936705,
           -0.14651202,
           -0.13929696,
           0.21733965,
           0.04466528,
           0.032986347,
           0.14956246,
           -0.039496083,
           -0.2191877,
           -0.014240711,
           -0.13646618,
           -0.03887527,
           -0.15942986,
           0.0066174986,
           -0.08477276,
           -0.17094134,
           0.009452958,
           0.1332132,
           -0.09860195,
           0.033923145,
           0.13656753,
           0.008862829,
           -0.14568126,
           0.121037684,
           -0.11870613,
           -0.17432815,
           -0.27810544,
           -0.2965135,
           0.06562662,
           -0.058492027,
           -0.053566694,
           -0.27084628,
           0.07659307,
           0.056094248,
           -0.11351083,
           0.10227841,
           -0.057638258,
           -0.036003858,
           -0.18679136,
           -0.10132174,
           -0.0016828753,
           -0.13979587,
           0.04341199,
           0.12087468,
           0.092047535,
           -0.16869074,
           0.023339422,
           0.06176125,
           0.053760998,
           -0.19607557,
           -0.08551397,
           0.06759404,
           0.13202547,
           0.04757189,
           0.15190987,
           -0.15583885,
           -0.16052008,
           0.17619525,
           -0.15061367,
           0.083680905,
           -0.16001473,
           0.10975966,
           -0.12411436,
           0.15859582,
           0.18293779,
           0.0542399,
           -0.046250667,
           0.2761922,
           0.0005946784,
           0.07704489,
           0.034059383,
           -0.07931163,
           -0.16066071,
           0.032655254,
           0.029898284,
           -0.17173457,
           0.054889943,
           0.04648394,
           0.016773624,
           -0.0046259505,
           -0.043190826,
           -0.13495046,
           0.11678403,
           0.09107427,
           -0.10237034,
           -0.021588806,
           -0.240893,
           0.01484084,
           -0.035223324,
           -0.06533237,
           0.053277873,
           -0.16217697,
           0.08830675,
           -0.1146702,
           0.10710325,
           -0.09547927,
           -0.057875086,
           0.15189618,
           0.08711202,
           -0.0336797,
           -0.23659326,
           0.0029262556,
           -0.1591377,
           0.12435409,
           -0.08434553,
           0.17046148,
           -0.05025883,
           0.031110879,
           0.19509207,
           0.103396066,
           -0.17601693,
           0.124704465,
           -0.051854257,
           -0.21172886,
           0.053311016,
           0.13098027,
           -0.13829012,
           0.048150074,
           -0.07612386,
           -0.08519379,
           0.04513948,
           0.043318454,
           -0.030216912,
           -0.12061877,
           0.15759227,
           0.10687873,
           -0.03953655,
           0.015305962
          ],
          [
           0.026662542,
           -0.016442083,
           0.075357355,
           -0.10743816,
           0.12533508,
           0.18835369,
           0.020386146,
           0.03646957,
           -0.02240418,
           -0.12232472,
           0.100579135,
           -0.116329275,
           0.19907722,
           -0.2204219,
           0.097011894,
           -0.041346665,
           -0.060033873,
           0.063437596,
           -0.1458796,
           -0.07597349,
           -0.06887778,
           -0.11423962,
           -0.04329683,
           -0.15141757,
           0.12381046,
           -0.11209513,
           -0.18283994,
           0.10222307,
           -0.067091994,
           -0.0714593,
           0.051295172,
           0.045458734,
           0.014978394,
           0.14329638,
           -0.23270398,
           -0.14086767,
           0.09305007,
           0.30910134,
           -0.34284014,
           -0.13339566,
           0.063567385,
           -0.13070762,
           -0.032312788,
           -0.025542838,
           0.1172268,
           -0.12147809,
           0.10903813,
           0.13067856,
           -0.19203699,
           0.13732271,
           0.021404147,
           -0.24040376,
           -0.120175555,
           0.22267643,
           0.1690126,
           -0.17780991,
           0.21294679,
           -0.015410082,
           -0.023075318,
           -0.016519526,
           0.19336924,
           0.011317213,
           0.0016412173,
           0.08380015,
           0.08385969,
           -0.050993443,
           0.13515489,
           -0.1075547,
           -0.17955364,
           -0.07713377,
           -0.06716094,
           0.028594002,
           -0.18934913,
           -0.011572085,
           -0.019409114,
           -0.09605767,
           -0.09415077,
           -0.031791992,
           0.041254483,
           0.09373557,
           -0.034297217,
           -0.19848746,
           -0.22846122,
           -0.13278997,
           0.035092063,
           0.101215765,
           -0.07883207,
           0.0356263,
           -0.016315056,
           -0.008255776,
           -0.014543618,
           -0.14499468,
           0.15938987,
           -0.15437143,
           0.18981513,
           0.061289538,
           0.1037944,
           -0.015031704,
           -0.14034182,
           0.051490262,
           0.13818063,
           -0.013346264,
           -0.008546902,
           -0.05320051,
           0.09105729,
           -0.04600974,
           0.012639496,
           -0.115118496,
           0.015714541,
           -0.016248126,
           -0.060955614,
           0.06731257,
           -0.026652884,
           0.086382605,
           0.0650741,
           -0.20669912,
           0.2177385,
           -0.07070919,
           0.039713234,
           0.09060349,
           -0.029058017,
           -0.019041548,
           0.118636005,
           -0.003386647,
           0.18028668,
           -0.021687375,
           0.037455346,
           -0.05806005
          ],
          [
           -0.118118696,
           0.17601289,
           -0.047040533,
           -0.018669166,
           0.194254,
           -0.05078302,
           -0.1939607,
           0.00054657203,
           0.07805247,
           0.14693162,
           -0.22514415,
           -0.17553857,
           -0.060080275,
           -0.21280466,
           -0.07184071,
           -0.1257282,
           0.11874959,
           -0.16792947,
           -0.0026701798,
           -0.17023563,
           0.20949171,
           -0.080277,
           -0.02863167,
           -0.09393588,
           0.17899267,
           -0.08497357,
           -0.17449388,
           -0.05593947,
           -0.0077071064,
           0.16261554,
           0.07166474,
           0.03606372,
           0.043594528,
           0.03558222,
           0.0065833484,
           0.08298276,
           0.069766104,
           -0.018854272,
           0.051706374,
           0.19175021,
           -0.073214926,
           -0.07790919,
           0.07322638,
           0.0780554,
           -0.18814224,
           -0.058044024,
           0.043104485,
           0.102442876,
           0.047731377,
           0.08424302,
           0.073095694,
           0.03399025,
           -0.03373372,
           -0.003975253,
           -0.15437447,
           0.17753531,
           0.12641318,
           0.09279505,
           -0.036770966,
           -0.0072716787,
           -0.08717299,
           0.11887895,
           0.057571474,
           -0.06528482,
           -0.05231056,
           -0.008861495,
           -0.111565895,
           0.03987319,
           0.07318854,
           -0.25373375,
           0.1108978,
           0.1464126,
           -0.07759753,
           -0.12383547,
           -0.11286403,
           0.09723036,
           0.05007154,
           -0.13977648,
           0.09495917,
           -0.03249091,
           -0.07427544,
           0.024425097,
           0.08239316,
           0.20274045,
           -0.22034895,
           -0.1984288,
           -0.10946367,
           0.072830096,
           0.14863618,
           0.106270224,
           0.010857021,
           0.123815276,
           -0.19970548,
           0.10803427,
           0.053083908,
           -0.057638675,
           0.12966582,
           -0.23064709,
           0.063951075,
           -0.13473397,
           0.043858983,
           -0.09421753,
           0.23868696,
           -0.13240314,
           0.27606025,
           0.15054186,
           0.00041169603,
           -0.0064813113,
           0.08019017,
           -0.067134775,
           -0.23837338,
           -0.039422136,
           -0.024982667,
           0.0062515787,
           0.071453065,
           0.013229501,
           -0.016182495,
           0.2756634,
           -0.1754568,
           -0.06832187,
           -0.07280649,
           -0.1868665,
           -0.04184,
           0.089448445,
           -0.14958586,
           0.11730694,
           0.1020776,
           0.06394516
          ],
          [
           -0.11694165,
           0.017538985,
           0.15915288,
           -0.066529825,
           -0.0883872,
           0.022126373,
           -0.21237887,
           0.096144795,
           -0.0042218273,
           -0.27941477,
           -0.16018376,
           -0.07903301,
           -0.05802427,
           -0.050276272,
           0.089888655,
           0.07477846,
           -0.01605637,
           -0.2018622,
           0.17625129,
           0.18596213,
           0.031184234,
           -0.12290174,
           -0.14386143,
           0.074009955,
           -0.05949748,
           0.3357862,
           -0.0009542804,
           0.045471832,
           -0.176762,
           0.0524384,
           -0.11439372,
           0.08206302,
           -0.10312307,
           -0.118157946,
           0.022293149,
           0.083576776,
           -0.025262484,
           -0.1512379,
           0.10175175,
           -0.13693562,
           -0.17037666,
           -0.2200582,
           0.11485734,
           -0.074857205,
           0.13623796,
           -0.051319107,
           -0.016404748,
           -0.14628188,
           0.09230454,
           0.015788278,
           0.03890036,
           -0.16091734,
           0.076787345,
           -0.037671518,
           -0.18236545,
           0.13300148,
           0.062887385,
           0.0050906097,
           -0.0685441,
           0.024226522,
           0.039988153,
           -0.21350911,
           -0.14318411,
           -0.074548095,
           0.08501286,
           0.08853285,
           0.027816389,
           -0.12796736,
           0.020410167,
           -0.049812946,
           0.10760672,
           0.16267113,
           0.17639247,
           -0.0518755,
           0.1747323,
           -0.048224594,
           0.10348169,
           0.04488324,
           -0.20296545,
           -0.19428101,
           0.02257601,
           -0.15433174,
           -0.14458859,
           0.13768466,
           0.07455549,
           0.11423538,
           0.12939948,
           0.049330655,
           0.2198246,
           -0.19136792,
           -0.19512823,
           0.051436204,
           0.07025455,
           0.04913486,
           -0.050394952,
           0.04715927,
           -0.030752715,
           0.15692031,
           0.089972414,
           0.07153479,
           -0.11317301,
           -0.16075106,
           -0.04989604,
           -0.0010930029,
           -0.0211406,
           0.16605662,
           -0.03169356,
           -0.03405064,
           -0.10170521,
           -0.04605527,
           -0.2533857,
           0.028892186,
           -0.11631074,
           0.017622441,
           0.20009324,
           -0.0041399454,
           -0.09699936,
           -0.08047014,
           0.041251104,
           -0.08789679,
           -0.0038002464,
           0.07562178,
           0.08916414,
           -0.1783373,
           -0.090715565,
           0.064771384,
           -0.14538747,
           -0.012178358
          ],
          [
           0.021855038,
           0.13091521,
           0.010487399,
           -0.096136056,
           -0.040123224,
           -0.1644556,
           0.010501688,
           0.14435203,
           0.12873301,
           0.02890947,
           0.06345015,
           0.10410978,
           -0.23587582,
           0.03267421,
           0.09138061,
           0.09315418,
           0.08863629,
           -0.18128936,
           0.07917208,
           0.0087717585,
           0.009337167,
           0.10608395,
           0.126188,
           -0.08497579,
           -0.01875365,
           -0.13366571,
           0.11277825,
           -0.14599527,
           -0.17852144,
           0.21266367,
           -0.07574783,
           -0.007438466,
           -0.10868791,
           0.104284495,
           -0.18986142,
           0.003115486,
           -0.07845419,
           -0.14835383,
           -0.102821365,
           0.23317547,
           -0.124992654,
           -0.14730962,
           0.1574121,
           -0.019364916,
           -0.21375528,
           0.06062781,
           -0.03951754,
           -0.16714947,
           -0.060040012,
           0.1991762,
           -0.12850292,
           0.20234399,
           -0.10494125,
           0.00551293,
           0.15513699,
           -0.015876228,
           -0.0925104,
           0.07672764,
           0.15315677,
           0.060079638,
           -0.0018273136,
           -0.06408877,
           -0.036527492,
           -0.08781139,
           0.17124744,
           0.115002744,
           0.16162592,
           0.19217509,
           0.021036591,
           0.14458881,
           -0.07532977,
           0.17733368,
           -0.095643274,
           0.2194859,
           -0.06386242,
           0.14669661,
           -0.0720736,
           0.04392664,
           0.14917143,
           0.021209624,
           -0.08974223,
           -0.20410402,
           0.16916136,
           -0.1586997,
           0.16597638,
           0.09664388,
           0.033956945,
           0.1683228,
           -0.17023715,
           -0.0872561,
           0.022559058,
           -0.16696723,
           -0.21249777,
           0.017262781,
           -0.041225187,
           -0.12440415,
           0.07559211,
           0.081782885,
           0.10245034,
           0.14145271,
           -0.012098325,
           0.12672235,
           -0.08999727,
           -0.0918319,
           -0.08714917,
           -0.096262306,
           -0.10492615,
           -0.035759993,
           0.108053535,
           0.06835634,
           0.22698122,
           0.11459253,
           0.033783816,
           0.16728233,
           -0.06208351,
           -0.19922197,
           0.0013874037,
           -0.0571631,
           0.24972554,
           0.057222504,
           -0.14556086,
           -0.08525409,
           -0.22278294,
           0.03922637,
           0.034107335,
           -0.26633814,
           0.13675961,
           -0.05861561
          ],
          [
           0.062058035,
           -0.1674679,
           -0.0109997215,
           0.0291225,
           -0.07716963,
           0.06149928,
           -0.15882824,
           -0.01492317,
           -0.061899815,
           -0.09765624,
           -0.015788177,
           -0.12077139,
           0.03173699,
           -0.014459113,
           -0.12851365,
           -0.10619124,
           0.09839858,
           -0.08543104,
           0.09851733,
           0.011755194,
           -0.0113843065,
           0.16537113,
           -0.08438531,
           -0.09831719,
           -0.20393024,
           0.011812434,
           0.07397205,
           0.014723576,
           0.13152592,
           0.109675884,
           0.18655173,
           -0.18910259,
           0.12308479,
           0.083081976,
           0.09495377,
           -0.090509355,
           -0.09682751,
           0.07951899,
           0.21263155,
           0.14676382,
           0.19137517,
           0.14666812,
           -0.04049383,
           -0.06189192,
           -0.01495088,
           0.1759345,
           0.21645088,
           0.1495917,
           -0.058613162,
           -0.1114549,
           0.049110822,
           -0.010662804,
           -0.009031248,
           0.00827007,
           -0.0001782191,
           0.16384096,
           -0.08075261,
           0.011543901,
           0.1266488,
           0.018167863,
           0.001672775,
           0.13160463,
           0.23443101,
           0.23881577,
           0.014943736,
           -0.037152734,
           0.036731746,
           0.20466048,
           -0.10162577,
           0.085938245,
           -0.22816892,
           0.00625119,
           -0.08338389,
           0.0868461,
           -0.13286729,
           0.078104615,
           -0.07295756,
           0.14627162,
           0.037220147,
           0.020614052,
           0.19559468,
           0.08642202,
           -0.09986193,
           0.12369768,
           0.022779727,
           -0.07473396,
           0.15687668,
           -0.21154946,
           -0.09770638,
           -0.16120528,
           -0.07929698,
           0.113099866,
           -0.0040414436,
           -0.088979915,
           0.009528717,
           0.1552343,
           0.043653756,
           0.05299158,
           -0.026263244,
           0.12127628,
           0.022658348,
           0.21899436,
           0.19225438,
           -0.17587984,
           0.05393294,
           -0.16732946,
           -0.0139041385,
           0.059688017,
           -0.18956913,
           -0.09309297,
           0.03445843,
           -0.008363509,
           0.12007426,
           0.06207151,
           0.003405539,
           0.12776522,
           -0.0907491,
           -0.055624314,
           -0.12592487,
           0.080186896,
           -0.22947988,
           0.09755055,
           -0.057045076,
           -0.042750645,
           -0.07194078,
           0.10707843,
           -0.08482167,
           0.20960586
          ],
          [
           0.10558463,
           -0.046579506,
           -0.047351558,
           -0.07590731,
           -0.026148334,
           -0.05496934,
           -0.050849866,
           -0.20839117,
           -0.13801964,
           -0.038324106,
           0.048602656,
           0.041131537,
           -0.07026914,
           0.080795564,
           -0.07659923,
           -0.19493306,
           -0.22903505,
           0.05083834,
           -0.11959668,
           -0.05725078,
           0.15814002,
           -0.18643026,
           0.037130285,
           -0.020435896,
           0.21454778,
           0.09012772,
           0.07241005,
           -0.12239338,
           -0.11902597,
           0.071579464,
           -0.13884412,
           0.1721632,
           -0.035667673,
           0.096551314,
           0.0006474002,
           -0.009718365,
           0.15474899,
           0.031485233,
           0.11867668,
           0.02702239,
           0.014973688,
           0.113012634,
           -0.1631264,
           0.1077116,
           0.01762821,
           -0.024034237,
           0.022157524,
           -0.22784325,
           0.099607766,
           0.08621047,
           -0.04977268,
           0.16209853,
           0.14160582,
           -0.054110188,
           -0.12299731,
           -0.19243239,
           -0.017934041,
           -0.11194,
           0.057234418,
           -0.118337415,
           -0.056876183,
           -0.098018125,
           0.09304579,
           -0.11910624,
           -0.20938613,
           -0.18807189,
           -0.15136494,
           -0.05269251,
           0.21113174,
           0.073737636,
           0.078074306,
           0.19326742,
           -0.11599508,
           -0.15362652,
           -0.023841195,
           0.043600768,
           -0.22475614,
           -0.1718347,
           0.12502488,
           0.17356186,
           0.035306662,
           -0.0051160385,
           -0.22283766,
           0.11524312,
           0.1065319,
           -0.13057402,
           -0.09393086,
           -0.20275787,
           0.085883,
           -0.031497844,
           0.19008093,
           0.024569027,
           0.098914966,
           0.083800435,
           -0.08348168,
           -0.027624646,
           -0.028598145,
           0.06488348,
           -0.09233019,
           -0.16354986,
           0.09574741,
           0.20466983,
           -0.0461572,
           0.20311825,
           0.010493405,
           -0.107058704,
           -0.047074668,
           0.07472382,
           -0.06787043,
           0.031513624,
           0.17965655,
           0.23722813,
           -0.14782044,
           0.052517932,
           -0.07872101,
           0.047553577,
           -0.10944605,
           0.16803108,
           0.030577894,
           0.14964828,
           0.17207378,
           0.015172395,
           0.08046673,
           -0.16679598,
           0.052905336,
           -0.14233458,
           -0.25643003,
           0.017768336
          ],
          [
           -0.017713575,
           -0.027992602,
           -0.0651033,
           0.018021245,
           -0.0053361254,
           0.029427398,
           0.04057442,
           -0.074166566,
           0.05503801,
           0.14465474,
           0.117198795,
           0.04684535,
           -0.03719795,
           -0.0020485497,
           0.07403202,
           -0.101072475,
           0.016593877,
           -0.08508446,
           -0.013681056,
           -0.044716854,
           -0.014557661,
           0.16989115,
           0.055064037,
           0.009685718,
           -0.09123871,
           0.08366725,
           0.101321414,
           -0.12890556,
           -0.06322434,
           0.052210685,
           -0.03282919,
           -0.015310259,
           0.05450666,
           0.044239886,
           -0.016320614,
           0.07610529,
           -0.0033760977,
           0.008654808,
           -0.13882157,
           0.05377263,
           0.06821047,
           -0.044386804,
           -0.008719987,
           0.11956468,
           -0.007879025,
           -0.0013276624,
           0.0062902267,
           -0.044035167,
           -0.015886292,
           -0.017329939,
           -0.010806945,
           0.04325447,
           0.067215286,
           0.05262164,
           0.025537858,
           -0.03780093,
           0.04356892,
           0.009934953,
           0.113685615,
           -0.08660653,
           0.076710664,
           -0.080553114,
           0.0035521141,
           -0.07913527,
           0.074857116,
           -0.027014602,
           -0.031666897,
           0.00058431324,
           0.105251685,
           -0.07759035,
           -0.00268145,
           0.107759364,
           0.0149215525,
           0.09259795,
           -0.045590177,
           0.025197018,
           0.06353375,
           0.044963107,
           -0.029646304,
           -0.0025956258,
           -0.037730392,
           -0.09629863,
           0.023116099,
           -0.07073974,
           -0.063782506,
           -0.12419602,
           -0.048788596,
           0.047636114,
           0.01761872,
           0.07324348,
           -0.049899302,
           -0.010913979,
           -0.06824405,
           0.028715773,
           -0.050036896,
           -0.016448379,
           -0.019658037,
           -0.029038029,
           -0.09010996,
           -0.030251341,
           -0.14256383,
           0.05924153,
           0.0822343,
           -0.044175617,
           -0.12392146,
           0.16219802,
           -0.07393562,
           -0.035393994,
           0.021676335,
           0.10032905,
           -0.073303565,
           -0.049086437,
           0.00854257,
           0.07129522,
           0.15486883,
           0.03977054,
           -0.006329615,
           -0.12042276,
           -0.071109325,
           0.14202829,
           0.019931924,
           0.026921554,
           -0.07937199,
           -0.013007121,
           -0.0394012,
           -0.019776387,
           0.0048855585,
           0.020963846
          ],
          [
           -0.052084267,
           -0.09531737,
           -0.08831296,
           0.13306631,
           0.012958113,
           0.089737296,
           -0.05930928,
           -0.010601584,
           0.06166943,
           -0.01570762,
           -0.051318385,
           0.06279375,
           -0.10568667,
           -0.10566502,
           -0.018653195,
           0.06586324,
           0.023091527,
           -0.080839805,
           -0.00016533214,
           -0.030871239,
           -0.15064232,
           -0.12714913,
           -0.07284571,
           -0.07469848,
           -0.05780452,
           -0.05342751,
           -0.0696248,
           0.14196607,
           -0.046264295,
           -0.002452143,
           -0.04662601,
           0.049740437,
           0.0025318014,
           0.12504107,
           -0.021335287,
           0.027950905,
           -0.03920802,
           0.043053813,
           0.026371898,
           -0.16056038,
           -0.011730937,
           -0.022466553,
           -0.079086825,
           -0.057122793,
           -0.04116,
           -0.044795547,
           0.01874458,
           0.0033283613,
           -0.03626527,
           -0.022944251,
           0.026091617,
           -0.026873203,
           -0.062337328,
           0.0132892635,
           0.062415175,
           0.03943687,
           0.002199657,
           0.036558956,
           0.011324841,
           -0.07610898,
           -0.11013635,
           -0.017360045,
           0.071768016,
           0.030518757,
           -0.05266594,
           0.016831014,
           -0.045568123,
           -0.15246335,
           -0.06414629,
           0.000904397,
           -0.06566615,
           -0.14496541,
           0.061283868,
           0.105286025,
           0.01863342,
           0.044013534,
           0.009161544,
           -0.06322777,
           0.0028772405,
           -0.09259255,
           -0.10124736,
           -0.02550029,
           0.10404634,
           0.0024588136,
           0.024946876,
           -0.16772147,
           -0.057246037,
           0.13796754,
           0.07136999,
           0.22404344,
           0.117735475,
           0.10087395,
           0.037275545,
           0.05309929,
           0.042097583,
           -0.06182693,
           -0.17549738,
           -0.097554274,
           0.015701048,
           0.16897857,
           -0.1546829,
           0.022852914,
           0.02328171,
           0.10985962,
           -0.019513994,
           -0.05647103,
           0.08538093,
           0.13070004,
           0.09267439,
           -0.03813519,
           0.107727006,
           0.10605332,
           -0.012734579,
           -0.019344803,
           0.06892647,
           0.033357885,
           -0.1541841,
           0.0041907355,
           0.04464089,
           0.18624224,
           0.06738617,
           -0.044256225,
           -0.07858271,
           -0.07733402,
           0.0252006,
           -0.013922876,
           0.103778616,
           0.13224307
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(model.embed.W_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding shape is torch.Size([11, 128]), so our vectors of length 128\n"
     ]
    }
   ],
   "source": [
    "# Take the dot product of all the embedding vectors\n",
    "emb = model.embed.W_E\n",
    "vec_count = emb.shape[0]\n",
    "vec_dim = emb.shape[1]\n",
    "print(f\"The embedding shape is {emb.shape}, so our vectors of length {emb.shape[1]}\")\n",
    "\n",
    "dot_products = einops.einsum(emb, emb, \"v2 embs, v1 emb -> v1 v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 11])\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           0.18764171,
           0.26676604,
           -0.8671944,
           -0.41341057,
           -0.082614675,
           -0.76576304,
           0.2362136,
           0.7582703,
           -0.41233948,
           0.08171892,
           -0.1719785
          ],
          [
           0.26676604,
           0.37925532,
           -1.2328709,
           -0.58773655,
           -0.11745144,
           -1.0886682,
           0.3358196,
           1.078016,
           -0.5862138,
           0.11617797,
           -0.244498
          ],
          [
           -0.8671944,
           -1.2328709,
           4.007777,
           1.910595,
           0.38180733,
           3.5390074,
           -1.0916716,
           -3.5043795,
           1.905645,
           -0.3776676,
           0.7948062
          ],
          [
           -0.41341057,
           -0.58773655,
           1.910595,
           0.91082245,
           0.18201591,
           1.6871223,
           -0.5204237,
           -1.6706144,
           0.90846264,
           -0.1800424,
           0.3789015
          ],
          [
           -0.082614675,
           -0.11745144,
           0.38180733,
           0.18201591,
           0.03637349,
           0.33714923,
           -0.103999846,
           -0.33385035,
           0.18154433,
           -0.03597911,
           0.07571849
          ],
          [
           -0.76576304,
           -1.0886682,
           3.5390074,
           1.6871223,
           0.33714923,
           3.1250675,
           -0.9639842,
           -3.0944898,
           1.6827512,
           -0.3334937,
           0.7018417
          ],
          [
           0.2362136,
           0.3358196,
           -1.0916716,
           -0.5204237,
           -0.103999846,
           -0.9639842,
           0.29735854,
           0.95455194,
           -0.51907533,
           0.10287222,
           -0.2164959
          ],
          [
           0.7582703,
           1.078016,
           -3.5043795,
           -1.6706144,
           -0.33385035,
           -3.0944898,
           0.95455194,
           3.0642114,
           -1.6662861,
           0.3302306,
           -0.6949744
          ],
          [
           -0.41233948,
           -0.5862138,
           1.905645,
           0.90846264,
           0.18154433,
           1.6827512,
           -0.51907533,
           -1.6662861,
           0.906109,
           -0.17957594,
           0.37791982
          ],
          [
           0.08171892,
           0.11617797,
           -0.3776676,
           -0.1800424,
           -0.03597911,
           -0.3334937,
           0.10287222,
           0.3302306,
           -0.17957594,
           0.035589006,
           -0.07489751
          ],
          [
           -0.1719785,
           -0.244498,
           0.7948062,
           0.3789015,
           0.07571849,
           0.7018417,
           -0.2164959,
           -0.6949744,
           0.37791982,
           -0.07489751,
           0.15762275
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0,
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dot_products.shape)\n",
    "imshow_div(dot_products)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What would your hypothesis around the attention head activations be based on seeing this?\n",
    "+ Jack - My poorly informed guess is that tokens with low dot products and/or low norms won't have any strong attentional interaction\n",
    "+ Omar - I think that corner moves [0, 2, 6, 8] will have similar attention patterns\n",
    "+ Ari - I think same as Omar, plus center attends to everything, middle edges have attention symmetry too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [0,1,2,3,4,6,5,8,7]\n",
    "# tokens = ([10] * 5) + [1,2,5,8,7]\n",
    "str_tokens = [str(token) for token in tokens]\n",
    "logits, cache = model.run_with_cache(torch.tensor(tokens).to('cuda'), remove_batch_dim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformer_lens.ActivationCache.ActivationCache'>\n",
      "torch.Size([1, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "print(type(cache))\n",
    "attention_pattern = cache[\"pattern\", 0, \"attn\"]\n",
    "print(attention_pattern.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-e942b606-a036\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-e942b606-a036\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"6\", \"5\", \"8\", \"7\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6631145477294922, 0.3368854522705078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4720534086227417, 0.27894243597984314, 0.24900418519973755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3325713574886322, 0.23309840261936188, 0.22492331266403198, 0.20940691232681274, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2159705013036728, 0.2026263028383255, 0.20975400507450104, 0.2046312391757965, 0.16701795160770416, 0.0, 0.0, 0.0, 0.0], [0.13652291893959045, 0.19666898250579834, 0.20794183015823364, 0.1832628697156906, 0.158939391374588, 0.11666394025087357, 0.0, 0.0, 0.0], [0.10253291577100754, 0.19329938292503357, 0.18019956350326538, 0.16887909173965454, 0.14179188013076782, 0.1123313158750534, 0.10096587985754013, 0.0, 0.0], [0.06971113383769989, 0.1964653730392456, 0.1764858365058899, 0.15546110272407532, 0.13496220111846924, 0.1039423942565918, 0.09184408187866211, 0.07112786918878555, 0.0], [0.0409705713391304, 0.21523472666740417, 0.1756005883216858, 0.1515682339668274, 0.13157404959201813, 0.1056189090013504, 0.08250948786735535, 0.06733623147010803, 0.029587190598249435]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f43f8083970>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.attention.attention_patterns(tokens=str_tokens, attention=attention_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
