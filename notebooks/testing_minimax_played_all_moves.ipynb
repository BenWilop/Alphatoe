{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from alphatoe import evals, data, game, train\n",
    "import torch\n",
    "from torch.nn.functional import cross_entropy\n",
    "from tqdm import tqdm\n",
    "from transformer_lens import HookedTransformerConfig, HookedTransformer\n",
    "import json\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "from typing import Callable, Any\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating all possible games...\n",
      "Generated 255168 games\n",
      "Generated array of moves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255168/255168 [01:18<00:00, 3264.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([255168, 10, 10])\n",
      "Generated all data and minimax labels\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels, test_data, test_labels = data.gen_data('minimax all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([204134, 10])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = HookedTransformerConfig(\n",
    "    n_layers = 1,\n",
    "    n_heads = 4,\n",
    "    d_model = 16,\n",
    "    d_head = 4,\n",
    "    d_mlp = 64,\n",
    "    act_fn = \"relu\",\n",
    "    #normalization_type=None,\n",
    "    normalization_type='LN',\n",
    "    d_vocab=11,\n",
    "    d_vocab_out=10,\n",
    "    n_ctx=10,\n",
    "    init_weights=True,\n",
    "    device=\"cuda\",\n",
    "    seed = 1337,\n",
    ")\n",
    "\n",
    "lr = 1e-5\n",
    "weight_decay = 1e-4\n",
    "test_train_split = 0.7\n",
    "epochs = 10_000\n",
    "batch_size = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer(cfg).to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = cross_entropy\n",
    "optimizer =  torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (40960) to match target batch_size (0).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/obayyub/p/Tic-Tac-Transformer/notebooks/testing_minimax_played_all_moves.ipynb Cell 6\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/obayyub/p/Tic-Tac-Transformer/notebooks/testing_minimax_played_all_moves.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m rearranged_train_logits \u001b[39m=\u001b[39m einops\u001b[39m.\u001b[39mrearrange(model(train_logits), \u001b[39m\"\u001b[39m\u001b[39mbatch seq_len one_hots -> (batch seq_len) one_hots\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/obayyub/p/Tic-Tac-Transformer/notebooks/testing_minimax_played_all_moves.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m rearranged_train_labels \u001b[39m=\u001b[39m einops\u001b[39m.\u001b[39mrearrange(train_labels, \u001b[39m\"\u001b[39m\u001b[39mbatch seq_len one_hots -> (batch seq_len) one_hots\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/obayyub/p/Tic-Tac-Transformer/notebooks/testing_minimax_played_all_moves.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m train_loss \u001b[39m=\u001b[39m loss_fn(rearranged_train_logits,rearranged_train_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/obayyub/p/Tic-Tac-Transformer/notebooks/testing_minimax_played_all_moves.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m train_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/obayyub/p/Tic-Tac-Transformer/notebooks/testing_minimax_played_all_moves.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m train_losses\u001b[39m.\u001b[39mappend(train_loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3013\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3014\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (40960) to match target batch_size (0)."
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "# for epoch in tqdm.tqdm(range(epochs)):\n",
    "for epoch in range(epochs):\n",
    "    for batch in range(0, len(train_data), batch_size):\n",
    "        train_logits = train_data[batch:batch+batch_size]\n",
    "        train_labels = train_labels[batch:batch+batch_size]\n",
    "        rearranged_train_logits = einops.rearrange(model(train_logits), \"batch seq_len one_hots -> (batch seq_len) one_hots\")\n",
    "        rearranged_train_labels = einops.rearrange(train_labels, \"batch seq_len one_hots -> (batch seq_len) one_hots\")\n",
    "        train_loss = loss_fn(rearranged_train_logits,rearranged_train_labels)\n",
    "\n",
    "        train_loss.backward()\n",
    "\n",
    "        train_losses.append(train_loss.item())\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            test_logits = model(test_data)\n",
    "\n",
    "            rearranged_test_logits = einops.rearrange(test_logits, \"batch seq_len one_hots -> (batch seq_len) one_hots\")\n",
    "            rearranged_test_labels = einops.rearrange(test_labels, \"batch seq_len one_hots -> (batch seq_len) one_hots\")\n",
    "\n",
    "            test_loss = loss_fn(rearranged_test_logits, rearranged_test_labels)\n",
    "            test_losses.append(test_loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch} | Train Loss: {train_loss.item()} | Test Loss: {test_loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
