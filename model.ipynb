{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import tqdm\n",
    "#functional\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from functools import partial\n",
    "import einops\n",
    "import circuitsvis as cv\n",
    "from src.game import Board, apply_best_moves, get_best_moves, generate_all_games"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor, flat=False):\n",
    "    if type(tensor)!=torch.Tensor:\n",
    "        return tensor\n",
    "    if flat:\n",
    "        return tensor.flatten().detach().cpu().numpy()\n",
    "    else:\n",
    "        return tensor.detach().cpu().numpy()\n",
    "\n",
    "def imshow(tensor, xaxis=None, yaxis=None, animation_name='Snapshot', **kwargs):\n",
    "    tensor = torch.squeeze(tensor)\n",
    "    px.imshow(to_numpy(tensor, flat=False),aspect='auto', \n",
    "              labels={'x':xaxis, 'y':yaxis, 'animation_name':animation_name}, \n",
    "              **kwargs).show()\n",
    "# Set default colour scheme\n",
    "imshow = partial(imshow, color_continuous_scale='Blues')\n",
    "# Creates good defaults for showing divergent colour scales (ie with both \n",
    "# positive and negative values, where 0 is white)\n",
    "imshow_div = partial(imshow, color_continuous_scale='RdBu', color_continuous_midpoint=0.0)\n",
    "# Presets a bunch of defaults to imshow to make it suitable for showing heatmaps \n",
    "# of activations with x axis being input 1 and y axis being input 2.\n",
    "inputs_heatmap = partial(imshow, xaxis='Input 1', yaxis='Input 2', color_continuous_scale='RdBu', color_continuous_midpoint=0.0)\n",
    "\n",
    "def line(x, y=None, hover=None, xaxis='', yaxis='', **kwargs):\n",
    "    if type(y)==torch.Tensor:\n",
    "        y = to_numpy(y, flat=True)\n",
    "    if type(x)==torch.Tensor:\n",
    "        x = to_numpy(x, flat=True)\n",
    "    fig = px.line(x, y=y, hover_name=hover, **kwargs)\n",
    "    fig.update_layout(xaxis_title=xaxis, yaxis_title=yaxis)\n",
    "    fig.show()\n",
    "\n",
    "def lines(lines_list, x=None, mode='lines', labels=None, xaxis='', yaxis='', title = '', log_y=False, hover=None, **kwargs):\n",
    "    if type(lines_list)==torch.Tensor:\n",
    "        lines_list = [lines_list[i] for i in range(lines_list.shape[0])]\n",
    "    if x is None:\n",
    "        x=np.arange(len(lines_list[0]))\n",
    "    fig = go.Figure(layout={'title':title})\n",
    "    fig.update_xaxes(title=xaxis)\n",
    "    fig.update_yaxes(title=yaxis)\n",
    "    for c, line in enumerate(lines_list):\n",
    "        if type(line)==torch.Tensor:\n",
    "            line = to_numpy(line)\n",
    "        if labels is not None:\n",
    "            label = labels[c]\n",
    "        else:\n",
    "            label = c\n",
    "        fig.add_trace(go.Scatter(x=x, y=line, mode=mode, name=label, hovertext=hover, **kwargs))\n",
    "    if log_y:\n",
    "        fig.update_layout(yaxis_type=\"log\")\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Config Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = HookedTransformerConfig(\n",
    "    n_layers = 8,\n",
    "    n_heads = 8,\n",
    "    d_model = 128,\n",
    "    d_head = 16,\n",
    "    d_mlp = 512,\n",
    "    act_fn = \"relu\",\n",
    "    normalization_type=None,\n",
    "    d_vocab=11,\n",
    "    d_vocab_out=10,\n",
    "    n_ctx=10,\n",
    "    init_weights=True,\n",
    "    device=\"cuda\",\n",
    "    seed = 0,\n",
    ")\n",
    "\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-4\n",
    "test_train_split = 0.8\n",
    "epochs = 10\n",
    "batch_size = 8192\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we're on the 1th loop!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not a valid move nerd!!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m boards \u001b[39m=\u001b[39m [Board()]\n\u001b[0;32m----> 2\u001b[0m game_list \u001b[39m=\u001b[39m apply_best_moves(boards)\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:127\u001b[0m, in \u001b[0;36mapply_best_moves\u001b[0;34m(boards)\u001b[0m\n\u001b[1;32m    125\u001b[0m new_boards: \u001b[39mlist\u001b[39m[Board] \u001b[39m=\u001b[39m []\n\u001b[1;32m    126\u001b[0m \u001b[39mfor\u001b[39;00m board \u001b[39min\u001b[39;00m boards:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m get_best_moves(board):\n\u001b[1;32m    128\u001b[0m         _board \u001b[39m=\u001b[39m deepcopy(board)\n\u001b[1;32m    129\u001b[0m         new_boards\u001b[39m.\u001b[39mappend(_board\u001b[39m.\u001b[39mmake_move(move))\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:110\u001b[0m, in \u001b[0;36mget_best_moves\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[1;32m    109\u001b[0m     board\u001b[39m.\u001b[39mmake_move(move)\n\u001b[0;32m--> 110\u001b[0m     score \u001b[39m=\u001b[39m minimax(board)\n\u001b[1;32m    111\u001b[0m     board\u001b[39m.\u001b[39mundo()\n\u001b[1;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m board\u001b[39m.\u001b[39mis_maximizer \u001b[39m&\u001b[39m (score \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m bestScore):\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:173\u001b[0m, in \u001b[0;36mminimax\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[1;32m    172\u001b[0m     board\u001b[39m.\u001b[39mmake_move(move)\n\u001b[0;32m--> 173\u001b[0m     scores\u001b[39m.\u001b[39mappend(minimax(board))\n\u001b[1;32m    174\u001b[0m     board\u001b[39m.\u001b[39mundo()\n\u001b[1;32m    176\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(scores) \u001b[39mif\u001b[39;00m board\u001b[39m.\u001b[39mis_maximizer \u001b[39melse\u001b[39;00m \u001b[39mmin\u001b[39m(scores)\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:173\u001b[0m, in \u001b[0;36mminimax\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[1;32m    172\u001b[0m     board\u001b[39m.\u001b[39mmake_move(move)\n\u001b[0;32m--> 173\u001b[0m     scores\u001b[39m.\u001b[39mappend(minimax(board))\n\u001b[1;32m    174\u001b[0m     board\u001b[39m.\u001b[39mundo()\n\u001b[1;32m    176\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(scores) \u001b[39mif\u001b[39;00m board\u001b[39m.\u001b[39mis_maximizer \u001b[39melse\u001b[39;00m \u001b[39mmin\u001b[39m(scores)\n",
      "    \u001b[0;31m[... skipping similar frames: minimax at line 173 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:173\u001b[0m, in \u001b[0;36mminimax\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[1;32m    172\u001b[0m     board\u001b[39m.\u001b[39mmake_move(move)\n\u001b[0;32m--> 173\u001b[0m     scores\u001b[39m.\u001b[39mappend(minimax(board))\n\u001b[1;32m    174\u001b[0m     board\u001b[39m.\u001b[39mundo()\n\u001b[1;32m    176\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(scores) \u001b[39mif\u001b[39;00m board\u001b[39m.\u001b[39mis_maximizer \u001b[39melse\u001b[39;00m \u001b[39mmin\u001b[39m(scores)\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:172\u001b[0m, in \u001b[0;36mminimax\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    170\u001b[0m scores: \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m]\u001b[39m=\u001b[39m []\n\u001b[1;32m    171\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[0;32m--> 172\u001b[0m     board\u001b[39m.\u001b[39;49mmake_move(move)\n\u001b[1;32m    173\u001b[0m     scores\u001b[39m.\u001b[39mappend(minimax(board))\n\u001b[1;32m    174\u001b[0m     board\u001b[39m.\u001b[39mundo()\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:42\u001b[0m, in \u001b[0;36mBoard.make_move\u001b[0;34m(self, move)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_move\u001b[39m(\u001b[39mself\u001b[39m, move: \u001b[39mint\u001b[39m):\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m move \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[0;32m---> 42\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot a valid move nerd!!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid[move] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mturn\n\u001b[1;32m     44\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmoves_played\u001b[39m.\u001b[39mappend(move)\n",
      "\u001b[0;31mValueError\u001b[0m: Not a valid move nerd!!"
     ]
    }
   ],
   "source": [
    "boards = [Board()]\n",
    "game_list = apply_best_moves(boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we're on the 1th loop!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not a valid move nerd!!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m boards \u001b[39m=\u001b[39m [Board()]\n\u001b[0;32m----> 2\u001b[0m game_list \u001b[39m=\u001b[39m apply_best_moves(boards)\n\u001b[1;32m      3\u001b[0m moves \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m10\u001b[39m] \u001b[39m+\u001b[39m game\u001b[39m.\u001b[39mmoves_played \u001b[39m+\u001b[39m [\u001b[39m9\u001b[39m] \u001b[39mfor\u001b[39;00m game \u001b[39min\u001b[39;00m game_list])\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:127\u001b[0m, in \u001b[0;36mapply_best_moves\u001b[0;34m(boards)\u001b[0m\n\u001b[1;32m    125\u001b[0m new_boards: \u001b[39mlist\u001b[39m[Board] \u001b[39m=\u001b[39m []\n\u001b[1;32m    126\u001b[0m \u001b[39mfor\u001b[39;00m board \u001b[39min\u001b[39;00m boards:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m get_best_moves(board):\n\u001b[1;32m    128\u001b[0m         _board \u001b[39m=\u001b[39m deepcopy(board)\n\u001b[1;32m    129\u001b[0m         new_boards\u001b[39m.\u001b[39mappend(_board\u001b[39m.\u001b[39mmake_move(move))\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:110\u001b[0m, in \u001b[0;36mget_best_moves\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[1;32m    109\u001b[0m     board\u001b[39m.\u001b[39mmake_move(move)\n\u001b[0;32m--> 110\u001b[0m     score \u001b[39m=\u001b[39m minimax(board)\n\u001b[1;32m    111\u001b[0m     board\u001b[39m.\u001b[39mundo()\n\u001b[1;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m board\u001b[39m.\u001b[39mis_maximizer \u001b[39m&\u001b[39m (score \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m bestScore):\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:173\u001b[0m, in \u001b[0;36mminimax\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[1;32m    172\u001b[0m     board\u001b[39m.\u001b[39mmake_move(move)\n\u001b[0;32m--> 173\u001b[0m     scores\u001b[39m.\u001b[39mappend(minimax(board))\n\u001b[1;32m    174\u001b[0m     board\u001b[39m.\u001b[39mundo()\n\u001b[1;32m    176\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(scores) \u001b[39mif\u001b[39;00m board\u001b[39m.\u001b[39mis_maximizer \u001b[39melse\u001b[39;00m \u001b[39mmin\u001b[39m(scores)\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:173\u001b[0m, in \u001b[0;36mminimax\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[1;32m    172\u001b[0m     board\u001b[39m.\u001b[39mmake_move(move)\n\u001b[0;32m--> 173\u001b[0m     scores\u001b[39m.\u001b[39mappend(minimax(board))\n\u001b[1;32m    174\u001b[0m     board\u001b[39m.\u001b[39mundo()\n\u001b[1;32m    176\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(scores) \u001b[39mif\u001b[39;00m board\u001b[39m.\u001b[39mis_maximizer \u001b[39melse\u001b[39;00m \u001b[39mmin\u001b[39m(scores)\n",
      "    \u001b[0;31m[... skipping similar frames: minimax at line 173 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:173\u001b[0m, in \u001b[0;36mminimax\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[1;32m    172\u001b[0m     board\u001b[39m.\u001b[39mmake_move(move)\n\u001b[0;32m--> 173\u001b[0m     scores\u001b[39m.\u001b[39mappend(minimax(board))\n\u001b[1;32m    174\u001b[0m     board\u001b[39m.\u001b[39mundo()\n\u001b[1;32m    176\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(scores) \u001b[39mif\u001b[39;00m board\u001b[39m.\u001b[39mis_maximizer \u001b[39melse\u001b[39;00m \u001b[39mmin\u001b[39m(scores)\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:172\u001b[0m, in \u001b[0;36mminimax\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    170\u001b[0m scores: \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m]\u001b[39m=\u001b[39m []\n\u001b[1;32m    171\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[0;32m--> 172\u001b[0m     board\u001b[39m.\u001b[39;49mmake_move(move)\n\u001b[1;32m    173\u001b[0m     scores\u001b[39m.\u001b[39mappend(minimax(board))\n\u001b[1;32m    174\u001b[0m     board\u001b[39m.\u001b[39mundo()\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:42\u001b[0m, in \u001b[0;36mBoard.make_move\u001b[0;34m(self, move)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_move\u001b[39m(\u001b[39mself\u001b[39m, move: \u001b[39mint\u001b[39m):\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m move \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[0;32m---> 42\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot a valid move nerd!!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid[move] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mturn\n\u001b[1;32m     44\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmoves_played\u001b[39m.\u001b[39mappend(move)\n",
      "\u001b[0;31mValueError\u001b[0m: Not a valid move nerd!!"
     ]
    }
   ],
   "source": [
    "boards = [Board()]\n",
    "game_list = apply_best_moves(boards)\n",
    "moves = np.array([[10] + game.moves_played + [9] for game in game_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = [Board()]\n",
    "game_list = generate_all_games(boards)\n",
    "moves = np.array([[10] + game.moves_played + ([9] * (cfg.n_ctx - len(game.moves_played))) for game in game_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  0  1  3  2  6  9  9  9  9  9]\n"
     ]
    }
   ],
   "source": [
    "print(moves[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we're on the 1th loop!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not a valid move nerd!!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m boards \u001b[39m=\u001b[39m [Board()]\n\u001b[0;32m----> 2\u001b[0m game_list \u001b[39m=\u001b[39m apply_best_moves(boards)\n\u001b[1;32m      3\u001b[0m moves \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([game\u001b[39m.\u001b[39mmoves_played \u001b[39m+\u001b[39m [\u001b[39m9\u001b[39m] \u001b[39mfor\u001b[39;00m game \u001b[39min\u001b[39;00m game_list])\n\u001b[1;32m      4\u001b[0m data \u001b[39m=\u001b[39m moves\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:108\u001b[0m, in \u001b[0;36mapply_best_moves\u001b[0;34m(boards)\u001b[0m\n\u001b[1;32m    106\u001b[0m new_boards \u001b[39m=\u001b[39m []\n\u001b[1;32m    107\u001b[0m \u001b[39mfor\u001b[39;00m board \u001b[39min\u001b[39;00m boards:\n\u001b[0;32m--> 108\u001b[0m     \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m get_best_moves(board):\n\u001b[1;32m    109\u001b[0m         _board \u001b[39m=\u001b[39m deepcopy(board)\n\u001b[1;32m    110\u001b[0m         new_boards\u001b[39m.\u001b[39mappend(_board\u001b[39m.\u001b[39mmake_move(move))\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:132\u001b[0m, in \u001b[0;36mget_best_moves\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[1;32m    131\u001b[0m     board\u001b[39m.\u001b[39mmake_move(move)\n\u001b[0;32m--> 132\u001b[0m     score \u001b[39m=\u001b[39m minimax(board)\n\u001b[1;32m    133\u001b[0m     board\u001b[39m.\u001b[39mundo()\n\u001b[1;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m board\u001b[39m.\u001b[39mis_maximizer \u001b[39m&\u001b[39m (score \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m bestScore):\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:175\u001b[0m, in \u001b[0;36mminimax\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[1;32m    174\u001b[0m     board\u001b[39m.\u001b[39mmake_move(move)\n\u001b[0;32m--> 175\u001b[0m     scores\u001b[39m.\u001b[39mappend(minimax(board))\n\u001b[1;32m    176\u001b[0m     board\u001b[39m.\u001b[39mundo()\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(scores) \u001b[39mif\u001b[39;00m board\u001b[39m.\u001b[39mis_maximizer \u001b[39melse\u001b[39;00m \u001b[39mmin\u001b[39m(scores)\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:175\u001b[0m, in \u001b[0;36mminimax\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[1;32m    174\u001b[0m     board\u001b[39m.\u001b[39mmake_move(move)\n\u001b[0;32m--> 175\u001b[0m     scores\u001b[39m.\u001b[39mappend(minimax(board))\n\u001b[1;32m    176\u001b[0m     board\u001b[39m.\u001b[39mundo()\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(scores) \u001b[39mif\u001b[39;00m board\u001b[39m.\u001b[39mis_maximizer \u001b[39melse\u001b[39;00m \u001b[39mmin\u001b[39m(scores)\n",
      "    \u001b[0;31m[... skipping similar frames: minimax at line 175 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:175\u001b[0m, in \u001b[0;36mminimax\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[1;32m    174\u001b[0m     board\u001b[39m.\u001b[39mmake_move(move)\n\u001b[0;32m--> 175\u001b[0m     scores\u001b[39m.\u001b[39mappend(minimax(board))\n\u001b[1;32m    176\u001b[0m     board\u001b[39m.\u001b[39mundo()\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(scores) \u001b[39mif\u001b[39;00m board\u001b[39m.\u001b[39mis_maximizer \u001b[39melse\u001b[39;00m \u001b[39mmin\u001b[39m(scores)\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:174\u001b[0m, in \u001b[0;36mminimax\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    172\u001b[0m scores \u001b[39m=\u001b[39m []\n\u001b[1;32m    173\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m board\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[0;32m--> 174\u001b[0m     board\u001b[39m.\u001b[39;49mmake_move(move)\n\u001b[1;32m    175\u001b[0m     scores\u001b[39m.\u001b[39mappend(minimax(board))\n\u001b[1;32m    176\u001b[0m     board\u001b[39m.\u001b[39mundo()\n",
      "File \u001b[0;32m~/Code/Tic-Tac-Transformer/src/game.py:43\u001b[0m, in \u001b[0;36mBoard.make_move\u001b[0;34m(self, move)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_move\u001b[39m(\u001b[39mself\u001b[39m, move: \u001b[39mint\u001b[39m):\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m move \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_possible_moves():\n\u001b[0;32m---> 43\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot a valid move nerd!!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid[move] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mturn\n\u001b[1;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmoves_played\u001b[39m.\u001b[39mappend(move)\n",
      "\u001b[0;31mValueError\u001b[0m: Not a valid move nerd!!"
     ]
    }
   ],
   "source": [
    "boards = [Board()]\n",
    "game_list = apply_best_moves(boards)\n",
    "moves = np.array([game.moves_played + [9] for game in game_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = [Board()]\n",
    "game_list = generate_all_games(boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255168"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(game_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255168\n",
      "255168\n",
      "[10  0  1  3  2  6  9  9  9  9]\n",
      "[0 1 3 2 6 9 9 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "#load npy file\n",
    "# np_data = np.load('data/moves.npy')\n",
    "data = moves[:, :-1]\n",
    "labels = moves[:, 1:]\n",
    "\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "print(data[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 11,
=======
   "execution_count": 8,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = F.one_hot(t.tensor(labels))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 12,
=======
   "execution_count": 9,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "encoded_data = F.one_hot(t.tensor(data))\n",
    "print(encoded_data[1238])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 13,
=======
   "execution_count": 10,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 13,
=======
     "execution_count": 10,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_labels[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 14,
=======
   "execution_count": 11,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "#data and labels as numpy arrays\n",
    "data = np.array(data)\n",
    "encoded_labels = np.array(encoded_labels)\n",
    "#data and encoded_labels as tensors\n",
    "data = t.from_numpy(data)\n",
    "encoded_labels = t.from_numpy(encoded_labels).to(t.float)\n",
    "total_data = list(zip(data, encoded_labels))\n",
    "num_samples = len(total_data)\n",
    "train_size = int(test_train_split * num_samples)\n",
    "test_size = num_samples - train_size\n",
    "split_data = list(t.utils.data.random_split(total_data, [train_size, test_size]))\n",
    "train_pairs = split_data[0]\n",
    "test_pairs= split_data[1]\n",
    "train_data, train_labels = zip(*train_pairs)\n",
    "test_data, test_labels = zip(*test_pairs)\n",
    "\n",
    "train_data = t.stack(train_data).to(cfg.device)\n",
    "train_labels = t.stack(train_labels).to(cfg.device)\n",
    "test_data = t.stack(test_data).to(cfg.device)\n",
    "test_labels = t.stack(test_labels).to(cfg.device)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test train split\n",
    "train_data = data[:int(len(data)*test_train_split)]\n",
    "train_labels = encoded_labels[:int(len(data)*test_train_split)]\n",
    "test_data = data[int(len(data)*test_train_split):]\n",
    "test_labels = encoded_labels[int(len(data)*test_train_split):]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 15,
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716\n",
      "716\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits: Tensor, labels: Tensor):\n",
    "    return t.nn.functional.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 20,
=======
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3133)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten = t.tensor([0,1]).to(t.float)\n",
    "loss_fn(ten, ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  1,  7,  5,  2,  6,  3,  4,  8,  0], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'board' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_best_moves(board)[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'board' is not defined"
     ]
    }
   ],
   "source": [
    "get_best_moves(board)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-222.5590,  -42.9554,  -87.6360,  -67.9028, -129.8622,  205.6978,\n",
       "          -64.0102, -189.5659,  -65.8357,   -8.7005],\n",
       "        [-341.7577,  -15.9937,  -63.9421,  -57.8569, -102.3532,  210.5430,\n",
       "          -46.0593, -181.4177,  -53.4683,  -26.1564],\n",
       "        [-321.7386,    3.7408,  -52.6238,  -34.5443,  -90.2642,  164.2334,\n",
       "          -31.2029, -159.5603,  -31.1296,  -19.8039],\n",
       "        [-312.9674,   26.2824,  -98.7273,  -28.1300,  -63.2898,  165.7475,\n",
       "          -15.8166, -138.5478,  -13.0268,  -28.9097]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(seq))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [10,0,5,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = Board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| X |   | X |\n",
      "|   |   | O |\n",
      "|   |   |   |\n"
     ]
    }
   ],
   "source": [
    "board.make_move(seq[-1])\n",
    "board.draw_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_is_matched(input: list[int], seq: list[int]) -> bool:\n",
    "    return all(seq[i] == input[i] for i in range(len(seq)))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 21,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/obayyub/p/Tic-Tac-Transformer/model.ipynb Cell 26\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/obayyub/p/Tic-Tac-Transformer/model.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m [seq \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m seqs \u001b[39mif\u001b[39;00m seq_is_matched(seq, [\u001b[39m4\u001b[39m])]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seqs' is not defined"
     ]
    }
   ],
   "source": [
    "[seq for seq in seqs if seq_is_matched(seq, [4])]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 16,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 4, 1, 2, 6, 3, 5, 7, 8],\n",
       " [0, 4, 1, 2, 6, 3, 5, 8, 7],\n",
       " [0, 4, 2, 1, 7, 3, 5, 8, 6],\n",
       " [0, 4, 2, 1, 7, 5, 3, 6, 8],\n",
       " [0, 4, 2, 1, 7, 6, 3, 5, 8],\n",
       " [0, 4, 2, 1, 7, 6, 3, 8, 5],\n",
       " [0, 4, 2, 1, 7, 6, 5, 8, 3],\n",
       " [0, 4, 2, 1, 7, 6, 8, 5, 3],\n",
       " [0, 4, 2, 1, 7, 8, 3, 6, 5],\n",
       " [0, 4, 2, 1, 7, 8, 5, 3, 6],\n",
       " [0, 4, 2, 1, 7, 8, 5, 6, 3],\n",
       " [0, 4, 2, 1, 7, 8, 6, 3, 5],\n",
       " [0, 4, 3, 6, 2, 1, 7, 5, 8],\n",
       " [0, 4, 3, 6, 2, 1, 7, 8, 5],\n",
       " [0, 4, 5, 1, 7, 6, 2, 8, 3],\n",
       " [0, 4, 5, 1, 7, 8, 2, 3, 6],\n",
       " [0, 4, 5, 1, 7, 8, 2, 6, 3],\n",
       " [0, 4, 5, 1, 7, 8, 3, 6, 2],\n",
       " [0, 4, 5, 1, 7, 8, 6, 3, 2],\n",
       " [0, 4, 5, 2, 6, 3, 1, 7, 8],\n",
       " [0, 4, 5, 2, 6, 3, 1, 8, 7],\n",
       " [0, 4, 5, 2, 6, 3, 7, 8, 1],\n",
       " [0, 4, 5, 2, 6, 3, 8, 7, 1],\n",
       " [0, 4, 5, 7, 1, 2, 6, 3, 8],\n",
       " [0, 4, 5, 8, 1, 2, 6, 3, 7],\n",
       " [0, 4, 5, 8, 2, 1, 7, 3, 6],\n",
       " [0, 4, 5, 8, 2, 1, 7, 6, 3],\n",
       " [0, 4, 5, 8, 6, 3, 1, 2, 7],\n",
       " [0, 4, 5, 8, 6, 3, 2, 1, 7],\n",
       " [0, 4, 5, 8, 6, 3, 7, 1, 2],\n",
       " [0, 4, 5, 8, 6, 3, 7, 2, 1],\n",
       " [0, 4, 5, 8, 7, 1, 2, 3, 6],\n",
       " [0, 4, 5, 8, 7, 1, 2, 6, 3],\n",
       " [0, 4, 5, 8, 7, 1, 3, 6, 2],\n",
       " [0, 4, 5, 8, 7, 1, 6, 3, 2],\n",
       " [0, 4, 5, 8, 7, 2, 6, 3, 1],\n",
       " [0, 4, 5, 8, 7, 3, 1, 2, 6],\n",
       " [0, 4, 5, 8, 7, 3, 2, 1, 6],\n",
       " [0, 4, 5, 8, 7, 3, 6, 1, 2],\n",
       " [0, 4, 5, 8, 7, 3, 6, 2, 1],\n",
       " [0, 4, 5, 8, 7, 6, 2, 1, 3],\n",
       " [0, 4, 6, 3, 5, 1, 7, 8, 2],\n",
       " [0, 4, 6, 3, 5, 2, 1, 7, 8],\n",
       " [0, 4, 6, 3, 5, 2, 1, 8, 7],\n",
       " [0, 4, 6, 3, 5, 2, 7, 8, 1],\n",
       " [0, 4, 6, 3, 5, 2, 8, 7, 1],\n",
       " [0, 4, 6, 3, 5, 7, 1, 2, 8],\n",
       " [0, 4, 6, 3, 5, 8, 1, 2, 7],\n",
       " [0, 4, 6, 3, 5, 8, 2, 1, 7],\n",
       " [0, 4, 6, 3, 5, 8, 7, 1, 2],\n",
       " [0, 4, 6, 3, 5, 8, 7, 2, 1],\n",
       " [0, 4, 7, 3, 5, 2, 6, 8, 1],\n",
       " [0, 4, 7, 3, 5, 8, 1, 2, 6],\n",
       " [0, 4, 7, 3, 5, 8, 2, 1, 6],\n",
       " [0, 4, 7, 3, 5, 8, 6, 1, 2],\n",
       " [0, 4, 7, 3, 5, 8, 6, 2, 1],\n",
       " [0, 4, 7, 5, 3, 6, 2, 1, 8],\n",
       " [0, 4, 7, 6, 2, 1, 3, 5, 8],\n",
       " [0, 4, 7, 6, 2, 1, 3, 8, 5],\n",
       " [0, 4, 7, 6, 2, 1, 5, 8, 3],\n",
       " [0, 4, 7, 6, 2, 1, 8, 5, 3],\n",
       " [0, 4, 7, 8, 2, 1, 3, 6, 5],\n",
       " [0, 4, 7, 8, 2, 1, 5, 3, 6],\n",
       " [0, 4, 7, 8, 2, 1, 5, 6, 3],\n",
       " [0, 4, 7, 8, 2, 1, 6, 3, 5],\n",
       " [0, 4, 7, 8, 3, 6, 2, 1, 5],\n",
       " [0, 4, 7, 8, 5, 1, 2, 3, 6],\n",
       " [0, 4, 7, 8, 5, 1, 2, 6, 3],\n",
       " [0, 4, 7, 8, 5, 1, 3, 6, 2],\n",
       " [0, 4, 7, 8, 5, 1, 6, 3, 2],\n",
       " [0, 4, 7, 8, 5, 2, 6, 3, 1],\n",
       " [0, 4, 7, 8, 5, 3, 1, 2, 6],\n",
       " [0, 4, 7, 8, 5, 3, 2, 1, 6],\n",
       " [0, 4, 7, 8, 5, 3, 6, 1, 2],\n",
       " [0, 4, 7, 8, 5, 3, 6, 2, 1],\n",
       " [0, 4, 7, 8, 5, 6, 2, 1, 3],\n",
       " [0, 4, 7, 8, 6, 3, 5, 1, 2],\n",
       " [0, 4, 7, 8, 6, 3, 5, 2, 1],\n",
       " [0, 4, 8, 1, 7, 6, 2, 5, 3],\n",
       " [0, 4, 8, 3, 5, 2, 6, 7, 1],\n",
       " [0, 4, 8, 5, 3, 6, 2, 1, 7],\n",
       " [0, 4, 8, 7, 1, 2, 6, 3, 5],\n",
       " [1, 0, 3, 4, 8, 2, 6, 7, 5],\n",
       " [1, 0, 3, 4, 8, 5, 2, 6, 7],\n",
       " [1, 0, 3, 4, 8, 5, 2, 7, 6],\n",
       " [1, 0, 3, 4, 8, 5, 6, 7, 2],\n",
       " [1, 0, 3, 4, 8, 5, 7, 6, 2],\n",
       " [1, 0, 3, 4, 8, 6, 2, 5, 7],\n",
       " [1, 0, 3, 4, 8, 7, 2, 5, 6],\n",
       " [1, 0, 3, 4, 8, 7, 5, 2, 6],\n",
       " [1, 0, 3, 4, 8, 7, 6, 2, 5],\n",
       " [1, 0, 3, 4, 8, 7, 6, 5, 2],\n",
       " [1, 0, 3, 5, 2, 4, 8, 6, 7],\n",
       " [1, 0, 3, 5, 2, 4, 8, 7, 6],\n",
       " [1, 0, 3, 5, 2, 6, 4, 7, 8],\n",
       " [1, 0, 3, 5, 2, 6, 7, 4, 8],\n",
       " [1, 0, 3, 5, 2, 6, 8, 4, 7],\n",
       " [1, 0, 3, 5, 2, 6, 8, 7, 4],\n",
       " [1, 0, 3, 5, 2, 7, 4, 6, 8],\n",
       " [1, 0, 3, 5, 2, 7, 6, 4, 8],\n",
       " [1, 0, 3, 5, 2, 7, 8, 4, 6],\n",
       " [1, 0, 3, 5, 2, 7, 8, 6, 4],\n",
       " [1, 0, 3, 5, 4, 7, 2, 6, 8],\n",
       " [1, 0, 3, 5, 4, 7, 6, 2, 8],\n",
       " [1, 0, 3, 5, 4, 7, 8, 2, 6],\n",
       " [1, 0, 3, 5, 4, 7, 8, 6, 2],\n",
       " [1, 0, 3, 5, 7, 4, 8, 6, 2],\n",
       " [1, 0, 3, 5, 8, 4, 2, 6, 7],\n",
       " [1, 0, 3, 5, 8, 4, 2, 7, 6],\n",
       " [1, 0, 3, 5, 8, 4, 6, 7, 2],\n",
       " [1, 0, 3, 5, 8, 4, 7, 6, 2],\n",
       " [1, 0, 3, 5, 8, 6, 2, 4, 7],\n",
       " [1, 0, 3, 5, 8, 6, 2, 7, 4],\n",
       " [1, 0, 3, 5, 8, 6, 4, 7, 2],\n",
       " [1, 0, 3, 5, 8, 6, 7, 4, 2],\n",
       " [1, 0, 3, 5, 8, 7, 2, 4, 6],\n",
       " [1, 0, 3, 5, 8, 7, 2, 6, 4],\n",
       " [1, 0, 3, 5, 8, 7, 4, 2, 6],\n",
       " [1, 0, 3, 5, 8, 7, 4, 6, 2],\n",
       " [1, 0, 3, 5, 8, 7, 6, 2, 4],\n",
       " [1, 0, 3, 5, 8, 7, 6, 4, 2],\n",
       " [1, 0, 3, 7, 4, 5, 2, 6, 8],\n",
       " [1, 0, 3, 7, 4, 5, 6, 2, 8],\n",
       " [1, 0, 3, 7, 4, 5, 8, 2, 6],\n",
       " [1, 0, 3, 7, 4, 5, 8, 6, 2],\n",
       " [1, 0, 3, 7, 5, 4, 8, 2, 6],\n",
       " [1, 0, 3, 7, 6, 2, 4, 5, 8],\n",
       " [1, 0, 3, 7, 6, 2, 5, 4, 8],\n",
       " [1, 0, 3, 7, 6, 2, 8, 4, 5],\n",
       " [1, 0, 3, 7, 6, 2, 8, 5, 4],\n",
       " [1, 0, 3, 7, 6, 4, 8, 2, 5],\n",
       " [1, 0, 3, 7, 6, 4, 8, 5, 2],\n",
       " [1, 0, 3, 7, 6, 5, 2, 4, 8],\n",
       " [1, 0, 3, 7, 6, 5, 4, 2, 8],\n",
       " [1, 0, 3, 7, 6, 5, 8, 2, 4],\n",
       " [1, 0, 3, 7, 6, 5, 8, 4, 2],\n",
       " [1, 0, 3, 7, 8, 2, 4, 5, 6],\n",
       " [1, 0, 3, 7, 8, 2, 5, 4, 6],\n",
       " [1, 0, 3, 7, 8, 2, 6, 4, 5],\n",
       " [1, 0, 3, 7, 8, 2, 6, 5, 4],\n",
       " [1, 0, 3, 7, 8, 4, 2, 5, 6],\n",
       " [1, 0, 3, 7, 8, 4, 5, 2, 6],\n",
       " [1, 0, 3, 7, 8, 4, 6, 2, 5],\n",
       " [1, 0, 3, 7, 8, 4, 6, 5, 2],\n",
       " [1, 0, 3, 7, 8, 5, 2, 4, 6],\n",
       " [1, 0, 3, 7, 8, 5, 2, 6, 4],\n",
       " [1, 0, 3, 7, 8, 5, 4, 2, 6],\n",
       " [1, 0, 3, 7, 8, 5, 4, 6, 2],\n",
       " [1, 0, 3, 7, 8, 5, 6, 2, 4],\n",
       " [1, 0, 3, 7, 8, 5, 6, 4, 2],\n",
       " [1, 0, 4, 7, 3, 5, 2, 6, 8],\n",
       " [1, 0, 4, 7, 3, 5, 6, 2, 8],\n",
       " [1, 0, 4, 7, 3, 5, 8, 2, 6],\n",
       " [1, 0, 4, 7, 3, 5, 8, 6, 2],\n",
       " [1, 0, 4, 7, 5, 3, 6, 2, 8],\n",
       " [1, 0, 4, 7, 6, 2, 3, 5, 8],\n",
       " [1, 0, 4, 7, 6, 2, 5, 3, 8],\n",
       " [1, 0, 4, 7, 6, 2, 8, 3, 5],\n",
       " [1, 0, 4, 7, 6, 2, 8, 5, 3],\n",
       " [1, 0, 4, 7, 8, 2, 3, 5, 6],\n",
       " [1, 0, 4, 7, 8, 2, 5, 3, 6],\n",
       " [1, 0, 4, 7, 8, 2, 6, 3, 5],\n",
       " [1, 0, 4, 7, 8, 2, 6, 5, 3],\n",
       " [1, 0, 4, 7, 8, 3, 6, 2, 5],\n",
       " [1, 0, 4, 7, 8, 5, 2, 6, 3],\n",
       " [1, 0, 4, 7, 8, 5, 3, 2, 6],\n",
       " [1, 0, 4, 7, 8, 5, 3, 6, 2],\n",
       " [1, 0, 4, 7, 8, 5, 6, 2, 3],\n",
       " [1, 0, 4, 7, 8, 6, 3, 5, 2],\n",
       " [1, 0, 6, 4, 8, 7, 2, 5, 3],\n",
       " [1, 0, 6, 4, 8, 7, 3, 2, 5],\n",
       " [1, 0, 6, 4, 8, 7, 3, 5, 2],\n",
       " [1, 0, 6, 4, 8, 7, 5, 2, 3],\n",
       " [1, 0, 6, 7, 2, 4, 8, 5, 3],\n",
       " [1, 0, 6, 7, 3, 2, 4, 5, 8],\n",
       " [1, 0, 6, 7, 3, 2, 5, 4, 8],\n",
       " [1, 0, 6, 7, 3, 2, 8, 4, 5],\n",
       " [1, 0, 6, 7, 3, 2, 8, 5, 4],\n",
       " [1, 0, 6, 7, 3, 4, 8, 2, 5],\n",
       " [1, 0, 6, 7, 3, 4, 8, 5, 2],\n",
       " [1, 0, 6, 7, 3, 5, 2, 4, 8],\n",
       " [1, 0, 6, 7, 3, 5, 4, 2, 8],\n",
       " [1, 0, 6, 7, 3, 5, 8, 2, 4],\n",
       " [1, 0, 6, 7, 3, 5, 8, 4, 2],\n",
       " [1, 0, 6, 7, 4, 2, 3, 5, 8],\n",
       " [1, 0, 6, 7, 4, 2, 5, 3, 8],\n",
       " [1, 0, 6, 7, 4, 2, 8, 3, 5],\n",
       " [1, 0, 6, 7, 4, 2, 8, 5, 3],\n",
       " [1, 0, 6, 7, 5, 2, 3, 4, 8],\n",
       " [1, 0, 6, 7, 5, 2, 4, 3, 8],\n",
       " [1, 0, 6, 7, 5, 2, 8, 3, 4],\n",
       " [1, 0, 6, 7, 5, 2, 8, 4, 3],\n",
       " [1, 0, 6, 7, 5, 4, 8, 2, 3],\n",
       " [1, 0, 6, 7, 8, 2, 3, 4, 5],\n",
       " [1, 0, 6, 7, 8, 2, 3, 5, 4],\n",
       " [1, 0, 6, 7, 8, 2, 4, 3, 5],\n",
       " [1, 0, 6, 7, 8, 2, 4, 5, 3],\n",
       " [1, 0, 6, 7, 8, 2, 5, 3, 4],\n",
       " [1, 0, 6, 7, 8, 2, 5, 4, 3],\n",
       " [1, 0, 6, 7, 8, 4, 2, 5, 3],\n",
       " [1, 0, 6, 7, 8, 4, 3, 2, 5],\n",
       " [1, 0, 6, 7, 8, 4, 3, 5, 2],\n",
       " [1, 0, 6, 7, 8, 4, 5, 2, 3],\n",
       " [1, 0, 6, 7, 8, 5, 2, 4, 3],\n",
       " [1, 0, 6, 7, 8, 5, 3, 2, 4],\n",
       " [1, 0, 6, 7, 8, 5, 3, 4, 2],\n",
       " [1, 0, 6, 7, 8, 5, 4, 2, 3],\n",
       " [1, 0, 8, 4, 2, 5, 3, 6, 7],\n",
       " [1, 0, 8, 4, 2, 5, 3, 7, 6],\n",
       " [1, 0, 8, 4, 3, 2, 6, 7, 5],\n",
       " [1, 0, 8, 4, 3, 5, 2, 6, 7],\n",
       " [1, 0, 8, 4, 3, 5, 2, 7, 6],\n",
       " [1, 0, 8, 4, 3, 5, 6, 7, 2],\n",
       " [1, 0, 8, 4, 3, 5, 7, 6, 2],\n",
       " [1, 0, 8, 4, 3, 6, 2, 5, 7],\n",
       " [1, 0, 8, 4, 3, 7, 2, 5, 6],\n",
       " [1, 0, 8, 4, 3, 7, 5, 2, 6],\n",
       " [1, 0, 8, 4, 3, 7, 6, 2, 5],\n",
       " [1, 0, 8, 4, 3, 7, 6, 5, 2],\n",
       " [1, 0, 8, 4, 5, 2, 6, 7, 3],\n",
       " [1, 0, 8, 4, 6, 7, 2, 5, 3],\n",
       " [1, 0, 8, 4, 6, 7, 3, 2, 5],\n",
       " [1, 0, 8, 4, 6, 7, 3, 5, 2],\n",
       " [1, 0, 8, 4, 6, 7, 5, 2, 3],\n",
       " [1, 0, 8, 6, 3, 4, 2, 5, 7],\n",
       " [1, 0, 8, 6, 3, 5, 2, 4, 7],\n",
       " [1, 0, 8, 6, 3, 5, 2, 7, 4],\n",
       " [1, 0, 8, 6, 3, 5, 4, 7, 2],\n",
       " [1, 0, 8, 6, 3, 5, 7, 4, 2],\n",
       " [1, 0, 8, 7, 2, 5, 3, 4, 6],\n",
       " [1, 0, 8, 7, 2, 5, 3, 6, 4],\n",
       " [1, 0, 8, 7, 2, 5, 4, 6, 3],\n",
       " [1, 0, 8, 7, 2, 5, 6, 4, 3],\n",
       " [1, 0, 8, 7, 3, 2, 4, 5, 6],\n",
       " [1, 0, 8, 7, 3, 2, 5, 4, 6],\n",
       " [1, 0, 8, 7, 3, 2, 6, 4, 5],\n",
       " [1, 0, 8, 7, 3, 2, 6, 5, 4],\n",
       " [1, 0, 8, 7, 3, 4, 2, 5, 6],\n",
       " [1, 0, 8, 7, 3, 4, 5, 2, 6],\n",
       " [1, 0, 8, 7, 3, 4, 6, 2, 5],\n",
       " [1, 0, 8, 7, 3, 4, 6, 5, 2],\n",
       " [1, 0, 8, 7, 3, 5, 2, 4, 6],\n",
       " [1, 0, 8, 7, 3, 5, 2, 6, 4],\n",
       " [1, 0, 8, 7, 3, 5, 4, 2, 6],\n",
       " [1, 0, 8, 7, 3, 5, 4, 6, 2],\n",
       " [1, 0, 8, 7, 3, 5, 6, 2, 4],\n",
       " [1, 0, 8, 7, 3, 5, 6, 4, 2],\n",
       " [1, 0, 8, 7, 4, 2, 3, 5, 6],\n",
       " [1, 0, 8, 7, 4, 2, 5, 3, 6],\n",
       " [1, 0, 8, 7, 4, 2, 6, 3, 5],\n",
       " [1, 0, 8, 7, 4, 2, 6, 5, 3],\n",
       " [1, 0, 8, 7, 4, 3, 6, 2, 5],\n",
       " [1, 0, 8, 7, 4, 5, 2, 6, 3],\n",
       " [1, 0, 8, 7, 4, 5, 3, 2, 6],\n",
       " [1, 0, 8, 7, 4, 5, 3, 6, 2],\n",
       " [1, 0, 8, 7, 4, 5, 6, 2, 3],\n",
       " [1, 0, 8, 7, 4, 6, 3, 5, 2],\n",
       " [1, 0, 8, 7, 5, 2, 3, 4, 6],\n",
       " [1, 0, 8, 7, 5, 2, 4, 3, 6],\n",
       " [1, 0, 8, 7, 5, 2, 6, 3, 4],\n",
       " [1, 0, 8, 7, 5, 2, 6, 4, 3],\n",
       " [1, 0, 8, 7, 6, 2, 3, 4, 5],\n",
       " [1, 0, 8, 7, 6, 2, 3, 5, 4],\n",
       " [1, 0, 8, 7, 6, 2, 4, 3, 5],\n",
       " [1, 0, 8, 7, 6, 2, 4, 5, 3],\n",
       " [1, 0, 8, 7, 6, 2, 5, 3, 4],\n",
       " [1, 0, 8, 7, 6, 2, 5, 4, 3],\n",
       " [1, 0, 8, 7, 6, 4, 2, 5, 3],\n",
       " [1, 0, 8, 7, 6, 4, 3, 2, 5],\n",
       " [1, 0, 8, 7, 6, 4, 3, 5, 2],\n",
       " [1, 0, 8, 7, 6, 4, 5, 2, 3],\n",
       " [1, 0, 8, 7, 6, 5, 2, 4, 3],\n",
       " [1, 0, 8, 7, 6, 5, 3, 2, 4],\n",
       " [1, 0, 8, 7, 6, 5, 3, 4, 2],\n",
       " [1, 0, 8, 7, 6, 5, 4, 2, 3],\n",
       " [1, 2, 4, 7, 3, 5, 8, 0, 6],\n",
       " [1, 2, 4, 7, 5, 3, 0, 8, 6],\n",
       " [1, 2, 4, 7, 5, 3, 6, 0, 8],\n",
       " [1, 2, 4, 7, 5, 3, 6, 8, 0],\n",
       " [1, 2, 4, 7, 5, 3, 8, 0, 6],\n",
       " [1, 2, 4, 7, 6, 0, 3, 5, 8],\n",
       " [1, 2, 4, 7, 6, 0, 5, 3, 8],\n",
       " [1, 2, 4, 7, 6, 0, 8, 3, 5],\n",
       " [1, 2, 4, 7, 6, 0, 8, 5, 3],\n",
       " [1, 2, 4, 7, 6, 3, 0, 8, 5],\n",
       " [1, 2, 4, 7, 6, 3, 5, 0, 8],\n",
       " [1, 2, 4, 7, 6, 3, 5, 8, 0],\n",
       " [1, 2, 4, 7, 6, 3, 8, 0, 5],\n",
       " [1, 2, 4, 7, 6, 5, 8, 0, 3],\n",
       " [1, 2, 4, 7, 6, 8, 5, 3, 0],\n",
       " [1, 2, 4, 7, 8, 0, 3, 5, 6],\n",
       " [1, 2, 4, 7, 8, 0, 5, 3, 6],\n",
       " [1, 2, 4, 7, 8, 0, 6, 3, 5],\n",
       " [1, 2, 4, 7, 8, 0, 6, 5, 3],\n",
       " [1, 2, 5, 3, 0, 4, 6, 7, 8],\n",
       " [1, 2, 5, 3, 0, 4, 6, 8, 7],\n",
       " [1, 2, 5, 3, 0, 7, 4, 8, 6],\n",
       " [1, 2, 5, 3, 0, 7, 6, 4, 8],\n",
       " [1, 2, 5, 3, 0, 7, 6, 8, 4],\n",
       " [1, 2, 5, 3, 0, 7, 8, 4, 6],\n",
       " [1, 2, 5, 3, 0, 8, 4, 7, 6],\n",
       " [1, 2, 5, 3, 0, 8, 6, 4, 7],\n",
       " [1, 2, 5, 3, 0, 8, 6, 7, 4],\n",
       " [1, 2, 5, 3, 0, 8, 7, 4, 6],\n",
       " [1, 2, 5, 3, 4, 7, 0, 8, 6],\n",
       " [1, 2, 5, 3, 4, 7, 6, 0, 8],\n",
       " [1, 2, 5, 3, 4, 7, 6, 8, 0],\n",
       " [1, 2, 5, 3, 4, 7, 8, 0, 6],\n",
       " [1, 2, 5, 3, 6, 4, 0, 7, 8],\n",
       " [1, 2, 5, 3, 6, 4, 0, 8, 7],\n",
       " [1, 2, 5, 3, 6, 4, 7, 8, 0],\n",
       " [1, 2, 5, 3, 6, 4, 8, 7, 0],\n",
       " [1, 2, 5, 3, 6, 7, 0, 4, 8],\n",
       " [1, 2, 5, 3, 6, 7, 0, 8, 4],\n",
       " [1, 2, 5, 3, 6, 7, 4, 0, 8],\n",
       " [1, 2, 5, 3, 6, 7, 4, 8, 0],\n",
       " [1, 2, 5, 3, 6, 7, 8, 0, 4],\n",
       " [1, 2, 5, 3, 6, 7, 8, 4, 0],\n",
       " [1, 2, 5, 3, 6, 8, 0, 4, 7],\n",
       " [1, 2, 5, 3, 6, 8, 0, 7, 4],\n",
       " [1, 2, 5, 3, 6, 8, 4, 7, 0],\n",
       " [1, 2, 5, 3, 6, 8, 7, 4, 0],\n",
       " [1, 2, 5, 3, 7, 4, 6, 8, 0],\n",
       " [1, 2, 5, 4, 6, 0, 8, 7, 3],\n",
       " [1, 2, 5, 4, 6, 3, 0, 7, 8],\n",
       " [1, 2, 5, 4, 6, 3, 0, 8, 7],\n",
       " [1, 2, 5, 4, 6, 3, 7, 8, 0],\n",
       " [1, 2, 5, 4, 6, 3, 8, 7, 0],\n",
       " [1, 2, 5, 4, 6, 7, 0, 3, 8],\n",
       " [1, 2, 5, 4, 6, 7, 3, 0, 8],\n",
       " [1, 2, 5, 4, 6, 7, 8, 0, 3],\n",
       " [1, 2, 5, 4, 6, 7, 8, 3, 0],\n",
       " [1, 2, 5, 4, 6, 8, 0, 3, 7],\n",
       " [1, 2, 5, 7, 3, 4, 6, 0, 8],\n",
       " [1, 2, 5, 7, 4, 3, 0, 8, 6],\n",
       " [1, 2, 5, 7, 4, 3, 6, 0, 8],\n",
       " [1, 2, 5, 7, 4, 3, 6, 8, 0],\n",
       " [1, 2, 5, 7, 4, 3, 8, 0, 6],\n",
       " [1, 2, 5, 7, 6, 0, 3, 4, 8],\n",
       " [1, 2, 5, 7, 6, 0, 4, 3, 8],\n",
       " [1, 2, 5, 7, 6, 0, 8, 3, 4],\n",
       " [1, 2, 5, 7, 6, 0, 8, 4, 3],\n",
       " [1, 2, 5, 7, 6, 3, 0, 4, 8],\n",
       " [1, 2, 5, 7, 6, 3, 0, 8, 4],\n",
       " [1, 2, 5, 7, 6, 3, 4, 0, 8],\n",
       " [1, 2, 5, 7, 6, 3, 4, 8, 0],\n",
       " [1, 2, 5, 7, 6, 3, 8, 0, 4],\n",
       " [1, 2, 5, 7, 6, 3, 8, 4, 0],\n",
       " [1, 2, 5, 7, 6, 4, 0, 3, 8],\n",
       " [1, 2, 5, 7, 6, 4, 3, 0, 8],\n",
       " [1, 2, 5, 7, 6, 4, 8, 0, 3],\n",
       " [1, 2, 5, 7, 6, 4, 8, 3, 0],\n",
       " [1, 2, 5, 7, 8, 0, 3, 4, 6],\n",
       " [1, 2, 5, 7, 8, 0, 4, 3, 6],\n",
       " [1, 2, 5, 7, 8, 0, 6, 3, 4],\n",
       " [1, 2, 5, 7, 8, 0, 6, 4, 3],\n",
       " [1, 2, 5, 7, 8, 3, 0, 4, 6],\n",
       " [1, 2, 5, 7, 8, 3, 4, 0, 6],\n",
       " [1, 2, 5, 7, 8, 3, 6, 0, 4],\n",
       " [1, 2, 5, 7, 8, 3, 6, 4, 0],\n",
       " [1, 2, 5, 7, 8, 4, 6, 0, 3],\n",
       " [1, 2, 5, 7, 8, 4, 6, 3, 0],\n",
       " [1, 2, 6, 4, 0, 3, 5, 7, 8],\n",
       " [1, 2, 6, 4, 0, 3, 5, 8, 7],\n",
       " [1, 2, 6, 4, 3, 0, 8, 7, 5],\n",
       " [1, 2, 6, 4, 5, 0, 8, 7, 3],\n",
       " [1, 2, 6, 4, 5, 3, 0, 7, 8],\n",
       " [1, 2, 6, 4, 5, 3, 0, 8, 7],\n",
       " [1, 2, 6, 4, 5, 3, 7, 8, 0],\n",
       " [1, 2, 6, 4, 5, 3, 8, 7, 0],\n",
       " [1, 2, 6, 4, 5, 7, 0, 3, 8],\n",
       " [1, 2, 6, 4, 5, 7, 3, 0, 8],\n",
       " [1, 2, 6, 4, 5, 7, 8, 0, 3],\n",
       " [1, 2, 6, 4, 5, 7, 8, 3, 0],\n",
       " [1, 2, 6, 4, 5, 8, 0, 3, 7],\n",
       " [1, 2, 6, 4, 8, 7, 0, 3, 5],\n",
       " [1, 2, 6, 4, 8, 7, 3, 0, 5],\n",
       " [1, 2, 6, 4, 8, 7, 5, 0, 3],\n",
       " [1, 2, 6, 4, 8, 7, 5, 3, 0],\n",
       " [1, 2, 6, 7, 0, 3, 4, 8, 5],\n",
       " [1, 2, 6, 7, 0, 3, 5, 4, 8],\n",
       " [1, 2, 6, 7, 0, 3, 5, 8, 4],\n",
       " [1, 2, 6, 7, 0, 3, 8, 4, 5],\n",
       " [1, 2, 6, 7, 3, 0, 4, 5, 8],\n",
       " [1, 2, 6, 7, 3, 0, 5, 4, 8],\n",
       " [1, 2, 6, 7, 3, 0, 8, 4, 5],\n",
       " [1, 2, 6, 7, 3, 0, 8, 5, 4],\n",
       " [1, 2, 6, 7, 4, 0, 3, 5, 8],\n",
       " [1, 2, 6, 7, 4, 0, 5, 3, 8],\n",
       " [1, 2, 6, 7, 4, 0, 8, 3, 5],\n",
       " [1, 2, 6, 7, 4, 0, 8, 5, 3],\n",
       " [1, 2, 6, 7, 4, 3, 0, 8, 5],\n",
       " [1, 2, 6, 7, 4, 3, 5, 0, 8],\n",
       " [1, 2, 6, 7, 4, 3, 5, 8, 0],\n",
       " [1, 2, 6, 7, 4, 3, 8, 0, 5],\n",
       " [1, 2, 6, 7, 4, 5, 8, 0, 3],\n",
       " [1, 2, 6, 7, 4, 8, 5, 3, 0],\n",
       " [1, 2, 6, 7, 5, 0, 3, 4, 8],\n",
       " [1, 2, 6, 7, 5, 0, 4, 3, 8],\n",
       " [1, 2, 6, 7, 5, 0, 8, 3, 4],\n",
       " [1, 2, 6, 7, 5, 0, 8, 4, 3],\n",
       " [1, 2, 6, 7, 5, 3, 0, 4, 8],\n",
       " [1, 2, 6, 7, 5, 3, 0, 8, 4],\n",
       " [1, 2, 6, 7, 5, 3, 4, 0, 8],\n",
       " [1, 2, 6, 7, 5, 3, 4, 8, 0],\n",
       " [1, 2, 6, 7, 5, 3, 8, 0, 4],\n",
       " [1, 2, 6, 7, 5, 3, 8, 4, 0],\n",
       " [1, 2, 6, 7, 5, 4, 0, 3, 8],\n",
       " [1, 2, 6, 7, 5, 4, 3, 0, 8],\n",
       " [1, 2, 6, 7, 5, 4, 8, 0, 3],\n",
       " [1, 2, 6, 7, 5, 4, 8, 3, 0],\n",
       " [1, 2, 6, 7, 8, 0, 3, 4, 5],\n",
       " [1, 2, 6, 7, 8, 0, 3, 5, 4],\n",
       " [1, 2, 6, 7, 8, 0, 4, 3, 5],\n",
       " [1, 2, 6, 7, 8, 0, 4, 5, 3],\n",
       " [1, 2, 6, 7, 8, 0, 5, 3, 4],\n",
       " [1, 2, 6, 7, 8, 0, 5, 4, 3],\n",
       " [1, 2, 6, 7, 8, 3, 0, 4, 5],\n",
       " [1, 2, 6, 7, 8, 3, 4, 0, 5],\n",
       " [1, 2, 6, 7, 8, 3, 5, 0, 4],\n",
       " [1, 2, 6, 7, 8, 3, 5, 4, 0],\n",
       " [1, 2, 6, 7, 8, 4, 0, 3, 5],\n",
       " [1, 2, 6, 7, 8, 4, 3, 0, 5],\n",
       " [1, 2, 6, 7, 8, 4, 5, 0, 3],\n",
       " [1, 2, 6, 7, 8, 4, 5, 3, 0],\n",
       " [1, 2, 6, 8, 5, 3, 0, 4, 7],\n",
       " [1, 2, 6, 8, 5, 3, 0, 7, 4],\n",
       " [1, 2, 6, 8, 5, 3, 4, 7, 0],\n",
       " [1, 2, 6, 8, 5, 3, 7, 4, 0],\n",
       " [1, 2, 6, 8, 5, 4, 0, 3, 7],\n",
       " [1, 2, 8, 4, 6, 7, 0, 3, 5],\n",
       " [1, 2, 8, 4, 6, 7, 3, 0, 5],\n",
       " [1, 2, 8, 4, 6, 7, 5, 0, 3],\n",
       " [1, 2, 8, 4, 6, 7, 5, 3, 0],\n",
       " [1, 2, 8, 7, 0, 4, 6, 3, 5],\n",
       " [1, 2, 8, 7, 3, 0, 4, 5, 6],\n",
       " [1, 2, 8, 7, 3, 0, 5, 4, 6],\n",
       " [1, 2, 8, 7, 3, 0, 6, 4, 5],\n",
       " [1, 2, 8, 7, 3, 0, 6, 5, 4],\n",
       " [1, 2, 8, 7, 3, 4, 6, 0, 5],\n",
       " [1, 2, 8, 7, 4, 0, 3, 5, 6],\n",
       " [1, 2, 8, 7, 4, 0, 5, 3, 6],\n",
       " [1, 2, 8, 7, 4, 0, 6, 3, 5],\n",
       " [1, 2, 8, 7, 4, 0, 6, 5, 3],\n",
       " [1, 2, 8, 7, 5, 0, 3, 4, 6],\n",
       " [1, 2, 8, 7, 5, 0, 4, 3, 6],\n",
       " [1, 2, 8, 7, 5, 0, 6, 3, 4],\n",
       " [1, 2, 8, 7, 5, 0, 6, 4, 3],\n",
       " [1, 2, 8, 7, 5, 3, 0, 4, 6],\n",
       " [1, 2, 8, 7, 5, 3, 4, 0, 6],\n",
       " [1, 2, 8, 7, 5, 3, 6, 0, 4],\n",
       " [1, 2, 8, 7, 5, 3, 6, 4, 0],\n",
       " [1, 2, 8, 7, 5, 4, 6, 0, 3],\n",
       " [1, 2, 8, 7, 5, 4, 6, 3, 0],\n",
       " [1, 2, 8, 7, 6, 0, 3, 4, 5],\n",
       " [1, 2, 8, 7, 6, 0, 3, 5, 4],\n",
       " [1, 2, 8, 7, 6, 0, 4, 3, 5],\n",
       " [1, 2, 8, 7, 6, 0, 4, 5, 3],\n",
       " [1, 2, 8, 7, 6, 0, 5, 3, 4],\n",
       " [1, 2, 8, 7, 6, 0, 5, 4, 3],\n",
       " [1, 2, 8, 7, 6, 3, 0, 4, 5],\n",
       " [1, 2, 8, 7, 6, 3, 4, 0, 5],\n",
       " [1, 2, 8, 7, 6, 3, 5, 0, 4],\n",
       " [1, 2, 8, 7, 6, 3, 5, 4, 0],\n",
       " [1, 2, 8, 7, 6, 4, 0, 3, 5],\n",
       " [1, 2, 8, 7, 6, 4, 3, 0, 5],\n",
       " [1, 2, 8, 7, 6, 4, 5, 0, 3],\n",
       " [1, 2, 8, 7, 6, 4, 5, 3, 0],\n",
       " [1, 4, 0, 2, 6, 3, 5, 7, 8],\n",
       " [1, 4, 0, 2, 6, 3, 5, 8, 7],\n",
       " [1, 4, 2, 0, 8, 5, 3, 6, 7],\n",
       " [1, 4, 2, 0, 8, 5, 3, 7, 6],\n",
       " [1, 4, 3, 0, 8, 2, 6, 7, 5],\n",
       " [1, 4, 3, 0, 8, 5, 2, 6, 7],\n",
       " [1, 4, 3, 0, 8, 5, 2, 7, 6],\n",
       " [1, 4, 3, 0, 8, 5, 6, 7, 2],\n",
       " [1, 4, 3, 0, 8, 5, 7, 6, 2],\n",
       " [1, 4, 3, 0, 8, 6, 2, 5, 7],\n",
       " [1, 4, 3, 0, 8, 7, 2, 5, 6],\n",
       " [1, 4, 3, 0, 8, 7, 5, 2, 6],\n",
       " [1, 4, 3, 0, 8, 7, 6, 2, 5],\n",
       " [1, 4, 3, 0, 8, 7, 6, 5, 2],\n",
       " [1, 4, 3, 2, 6, 0, 8, 7, 5],\n",
       " [1, 4, 3, 6, 2, 0, 8, 5, 7],\n",
       " [1, 4, 5, 0, 8, 2, 6, 7, 3],\n",
       " [1, 4, 5, 2, 6, 0, 8, 7, 3],\n",
       " [1, 4, 5, 2, 6, 3, 0, 7, 8],\n",
       " [1, 4, 5, 2, 6, 3, 0, 8, 7],\n",
       " [1, 4, 5, 2, 6, 3, 7, 8, 0],\n",
       " [1, 4, 5, 2, 6, 3, 8, 7, 0],\n",
       " [1, 4, 5, 2, 6, 7, 0, 3, 8],\n",
       " [1, 4, 5, 2, 6, 7, 3, 0, 8],\n",
       " [1, 4, 5, 2, 6, 7, 8, 0, 3],\n",
       " [1, 4, 5, 2, 6, 7, 8, 3, 0],\n",
       " [1, 4, 5, 2, 6, 8, 0, 3, 7],\n",
       " [1, 4, 5, 8, 0, 2, 6, 3, 7],\n",
       " [1, 4, 6, 0, 8, 7, 2, 5, 3],\n",
       " [1, 4, 6, 0, 8, 7, 3, 2, 5],\n",
       " [1, 4, 6, 0, 8, 7, 3, 5, 2],\n",
       " [1, 4, 6, 0, 8, 7, 5, 2, 3],\n",
       " [1, 4, 6, 2, 0, 3, 5, 7, 8],\n",
       " [1, 4, 6, 2, 0, 3, 5, 8, 7],\n",
       " [1, 4, 6, 2, 3, 0, 8, 7, 5],\n",
       " [1, 4, 6, 2, 5, 0, 8, 7, 3],\n",
       " [1, 4, 6, 2, 5, 3, 0, 7, 8],\n",
       " [1, 4, 6, 2, 5, 3, 0, 8, 7],\n",
       " [1, 4, 6, 2, 5, 3, 7, 8, 0],\n",
       " [1, 4, 6, 2, 5, 3, 8, 7, 0],\n",
       " [1, 4, 6, 2, 5, 7, 0, 3, 8],\n",
       " [1, 4, 6, 2, 5, 7, 3, 0, 8],\n",
       " [1, 4, 6, 2, 5, 7, 8, 0, 3],\n",
       " [1, 4, 6, 2, 5, 7, 8, 3, 0],\n",
       " [1, 4, 6, 2, 5, 8, 0, 3, 7],\n",
       " [1, 4, 6, 2, 8, 7, 0, 3, 5],\n",
       " [1, 4, 6, 2, 8, 7, 3, 0, 5],\n",
       " [1, 4, 6, 2, 8, 7, 5, 0, 3],\n",
       " [1, 4, 6, 2, 8, 7, 5, 3, 0],\n",
       " [1, 4, 6, 3, 5, 2, 0, 7, 8],\n",
       " [1, 4, 6, 3, 5, 2, 0, 8, 7],\n",
       " [1, 4, 6, 3, 5, 2, 7, 8, 0],\n",
       " [1, 4, 6, 3, 5, 2, 8, 7, 0],\n",
       " [1, 4, 6, 3, 5, 8, 0, 2, 7],\n",
       " [1, 4, 6, 5, 3, 0, 8, 7, 2],\n",
       " [1, 4, 8, 0, 2, 5, 3, 6, 7],\n",
       " [1, 4, 8, 0, 2, 5, 3, 7, 6],\n",
       " [1, 4, 8, 0, 3, 2, 6, 7, 5],\n",
       " [1, 4, 8, 0, 3, 5, 2, 6, 7],\n",
       " [1, 4, 8, 0, 3, 5, 2, 7, 6],\n",
       " [1, 4, 8, 0, 3, 5, 6, 7, 2],\n",
       " [1, 4, 8, 0, 3, 5, 7, 6, 2],\n",
       " [1, 4, 8, 0, 3, 6, 2, 5, 7],\n",
       " [1, 4, 8, 0, 3, 7, 2, 5, 6],\n",
       " [1, 4, 8, 0, 3, 7, 5, 2, 6],\n",
       " [1, 4, 8, 0, 3, 7, 6, 2, 5],\n",
       " [1, 4, 8, 0, 3, 7, 6, 5, 2],\n",
       " [1, 4, 8, 0, 5, 2, 6, 7, 3],\n",
       " [1, 4, 8, 0, 6, 7, 2, 5, 3],\n",
       " [1, 4, 8, 0, 6, 7, 3, 2, 5],\n",
       " [1, 4, 8, 0, 6, 7, 3, 5, 2],\n",
       " [1, 4, 8, 0, 6, 7, 5, 2, 3],\n",
       " [1, 4, 8, 2, 6, 7, 0, 3, 5],\n",
       " [1, 4, 8, 2, 6, 7, 3, 0, 5],\n",
       " [1, 4, 8, 2, 6, 7, 5, 0, 3],\n",
       " [1, 4, 8, 2, 6, 7, 5, 3, 0],\n",
       " [1, 4, 8, 3, 5, 2, 6, 7, 0],\n",
       " [1, 4, 8, 5, 3, 0, 2, 6, 7],\n",
       " [1, 4, 8, 5, 3, 0, 2, 7, 6],\n",
       " [1, 4, 8, 5, 3, 0, 6, 7, 2],\n",
       " [1, 4, 8, 5, 3, 0, 7, 6, 2],\n",
       " [1, 4, 8, 5, 3, 6, 2, 0, 7],\n",
       " [1, 7, 0, 2, 6, 3, 4, 8, 5],\n",
       " [1, 7, 0, 2, 6, 3, 5, 4, 8],\n",
       " [1, 7, 0, 2, 6, 3, 5, 8, 4],\n",
       " [1, 7, 0, 2, 6, 3, 8, 4, 5],\n",
       " [1, 7, 0, 2, 8, 4, 6, 3, 5],\n",
       " [1, 7, 2, 0, 6, 4, 8, 5, 3],\n",
       " [1, 7, 2, 0, 8, 5, 3, 4, 6],\n",
       " [1, 7, 2, 0, 8, 5, 3, 6, 4],\n",
       " [1, 7, 2, 0, 8, 5, 4, 6, 3],\n",
       " [1, 7, 2, 0, 8, 5, 6, 4, 3],\n",
       " [1, 7, 3, 0, 4, 5, 2, 6, 8],\n",
       " [1, 7, 3, 0, 4, 5, 6, 2, 8],\n",
       " [1, 7, 3, 0, 4, 5, 8, 2, 6],\n",
       " [1, 7, 3, 0, 4, 5, 8, 6, 2],\n",
       " [1, 7, 3, 0, 5, 4, 8, 2, 6],\n",
       " [1, 7, 3, 0, 6, 2, 4, 5, 8],\n",
       " [1, 7, 3, 0, 6, 2, 5, 4, 8],\n",
       " [1, 7, 3, 0, 6, 2, 8, 4, 5],\n",
       " [1, 7, 3, 0, 6, 2, 8, 5, 4],\n",
       " [1, 7, 3, 0, 6, 4, 8, 2, 5],\n",
       " [1, 7, 3, 0, 6, 4, 8, 5, 2],\n",
       " [1, 7, 3, 0, 6, 5, 2, 4, 8],\n",
       " [1, 7, 3, 0, 6, 5, 4, 2, 8],\n",
       " [1, 7, 3, 0, 6, 5, 8, 2, 4],\n",
       " [1, 7, 3, 0, 6, 5, 8, 4, 2],\n",
       " [1, 7, 3, 0, 8, 2, 4, 5, 6],\n",
       " [1, 7, 3, 0, 8, 2, 5, 4, 6],\n",
       " [1, 7, 3, 0, 8, 2, 6, 4, 5],\n",
       " [1, 7, 3, 0, 8, 2, 6, 5, 4],\n",
       " [1, 7, 3, 0, 8, 4, 2, 5, 6],\n",
       " [1, 7, 3, 0, 8, 4, 5, 2, 6],\n",
       " [1, 7, 3, 0, 8, 4, 6, 2, 5],\n",
       " [1, 7, 3, 0, 8, 4, 6, 5, 2],\n",
       " [1, 7, 3, 0, 8, 5, 2, 4, 6],\n",
       " [1, 7, 3, 0, 8, 5, 2, 6, 4],\n",
       " [1, 7, 3, 0, 8, 5, 4, 2, 6],\n",
       " [1, 7, 3, 0, 8, 5, 4, 6, 2],\n",
       " [1, 7, 3, 0, 8, 5, 6, 2, 4],\n",
       " [1, 7, 3, 0, 8, 5, 6, 4, 2],\n",
       " [1, 7, 3, 2, 4, 5, 8, 0, 6],\n",
       " [1, 7, 3, 2, 5, 4, 6, 0, 8],\n",
       " [1, 7, 3, 2, 6, 0, 4, 5, 8],\n",
       " [1, 7, 3, 2, 6, 0, 5, 4, 8],\n",
       " [1, 7, 3, 2, 6, 0, 8, 4, 5],\n",
       " [1, 7, 3, 2, 6, 0, 8, 5, 4],\n",
       " [1, 7, 3, 2, 8, 0, 4, 5, 6],\n",
       " [1, 7, 3, 2, 8, 0, 5, 4, 6],\n",
       " [1, 7, 3, 2, 8, 0, 6, 4, 5],\n",
       " [1, 7, 3, 2, 8, 0, 6, 5, 4],\n",
       " [1, 7, 3, 2, 8, 4, 6, 0, 5],\n",
       " [1, 7, 4, 0, 3, 5, 2, 6, 8],\n",
       " [1, 7, 4, 0, 3, 5, 6, 2, 8],\n",
       " [1, 7, 4, 0, 3, 5, 8, 2, 6],\n",
       " [1, 7, 4, 0, 3, 5, 8, 6, 2],\n",
       " [1, 7, 4, 0, 5, 3, 6, 2, 8],\n",
       " [1, 7, 4, 0, 6, 2, 3, 5, 8],\n",
       " [1, 7, 4, 0, 6, 2, 5, 3, 8],\n",
       " [1, 7, 4, 0, 6, 2, 8, 3, 5],\n",
       " [1, 7, 4, 0, 6, 2, 8, 5, 3],\n",
       " [1, 7, 4, 0, 8, 2, 3, 5, 6],\n",
       " [1, 7, 4, 0, 8, 2, 5, 3, 6],\n",
       " [1, 7, 4, 0, 8, 2, 6, 3, 5],\n",
       " [1, 7, 4, 0, 8, 2, 6, 5, 3],\n",
       " [1, 7, 4, 0, 8, 3, 6, 2, 5],\n",
       " [1, 7, 4, 0, 8, 5, 2, 6, 3],\n",
       " [1, 7, 4, 0, 8, 5, 3, 2, 6],\n",
       " [1, 7, 4, 0, 8, 5, 3, 6, 2],\n",
       " [1, 7, 4, 0, 8, 5, 6, 2, 3],\n",
       " [1, 7, 4, 0, 8, 6, 3, 5, 2],\n",
       " [1, 7, 4, 2, 3, 5, 8, 0, 6],\n",
       " [1, 7, 4, 2, 5, 3, 0, 8, 6],\n",
       " [1, 7, 4, 2, 5, 3, 6, 0, 8],\n",
       " [1, 7, 4, 2, 5, 3, 6, 8, 0],\n",
       " [1, 7, 4, 2, 5, 3, 8, 0, 6],\n",
       " [1, 7, 4, 2, 6, 0, 3, 5, 8],\n",
       " [1, 7, 4, 2, 6, 0, 5, 3, 8],\n",
       " [1, 7, 4, 2, 6, 0, 8, 3, 5],\n",
       " [1, 7, 4, 2, 6, 0, 8, 5, 3],\n",
       " [1, 7, 4, 2, 6, 3, 0, 8, 5],\n",
       " [1, 7, 4, 2, 6, 3, 5, 0, 8],\n",
       " [1, 7, 4, 2, 6, 3, 5, 8, 0],\n",
       " [1, 7, 4, 2, 6, 3, 8, 0, 5],\n",
       " [1, 7, 4, 2, 6, 5, 8, 0, 3],\n",
       " [1, 7, 4, 2, 6, 8, 5, 3, 0],\n",
       " [1, 7, 4, 2, 8, 0, 3, 5, 6],\n",
       " [1, 7, 4, 2, 8, 0, 5, 3, 6],\n",
       " [1, 7, 4, 2, 8, 0, 6, 3, 5],\n",
       " [1, 7, 4, 2, 8, 0, 6, 5, 3],\n",
       " [1, 7, 4, 6, 8, 0, 3, 5, 2],\n",
       " [1, 7, 4, 8, 6, 2, 5, 3, 0],\n",
       " [1, 7, 5, 0, 3, 4, 8, 2, 6],\n",
       " [1, 7, 5, 0, 4, 3, 6, 2, 8],\n",
       " [1, 7, 5, 0, 6, 2, 3, 4, 8],\n",
       " [1, 7, 5, 0, 6, 2, 4, 3, 8],\n",
       " [1, 7, 5, 0, 6, 2, 8, 3, 4],\n",
       " [1, 7, 5, 0, 6, 2, 8, 4, 3],\n",
       " [1, 7, 5, 0, 6, 4, 8, 2, 3],\n",
       " [1, 7, 5, 0, 8, 2, 3, 4, 6],\n",
       " [1, 7, 5, 0, 8, 2, 4, 3, 6],\n",
       " [1, 7, 5, 0, 8, 2, 6, 3, 4],\n",
       " [1, 7, 5, 0, 8, 2, 6, 4, 3],\n",
       " [1, 7, 5, 2, 3, 4, 6, 0, 8],\n",
       " [1, 7, 5, 2, 4, 3, 0, 8, 6],\n",
       " [1, 7, 5, 2, 4, 3, 6, 0, 8],\n",
       " [1, 7, 5, 2, 4, 3, 6, 8, 0],\n",
       " [1, 7, 5, 2, 4, 3, 8, 0, 6],\n",
       " [1, 7, 5, 2, 6, 0, 3, 4, 8],\n",
       " [1, 7, 5, 2, 6, 0, 4, 3, 8],\n",
       " [1, 7, 5, 2, 6, 0, 8, 3, 4],\n",
       " [1, 7, 5, 2, 6, 0, 8, 4, 3],\n",
       " [1, 7, 5, 2, 6, 3, 0, 4, 8],\n",
       " [1, 7, 5, 2, 6, 3, 0, 8, 4],\n",
       " [1, 7, 5, 2, 6, 3, 4, 0, 8],\n",
       " [1, 7, 5, 2, 6, 3, 4, 8, 0],\n",
       " [1, 7, 5, 2, 6, 3, 8, 0, 4],\n",
       " [1, 7, 5, 2, 6, 3, 8, 4, 0],\n",
       " [1, 7, 5, 2, 6, 4, 0, 3, 8],\n",
       " [1, 7, 5, 2, 6, 4, 3, 0, 8],\n",
       " [1, 7, 5, 2, 6, 4, 8, 0, 3],\n",
       " [1, 7, 5, 2, 6, 4, 8, 3, 0],\n",
       " [1, 7, 5, 2, 8, 0, 3, 4, 6],\n",
       " [1, 7, 5, 2, 8, 0, 4, 3, 6],\n",
       " [1, 7, 5, 2, 8, 0, 6, 3, 4],\n",
       " [1, 7, 5, 2, 8, 0, 6, 4, 3],\n",
       " [1, 7, 5, 2, 8, 3, 0, 4, 6],\n",
       " [1, 7, 5, 2, 8, 3, 4, 0, 6],\n",
       " [1, 7, 5, 2, 8, 3, 6, 0, 4],\n",
       " [1, 7, 5, 2, 8, 3, 6, 4, 0],\n",
       " [1, 7, 5, 2, 8, 4, 6, 0, 3],\n",
       " [1, 7, 5, 2, 8, 4, 6, 3, 0],\n",
       " [1, 7, 6, 0, 2, 4, 8, 5, 3],\n",
       " [1, 7, 6, 0, 3, 2, 4, 5, 8],\n",
       " [1, 7, 6, 0, 3, 2, 5, 4, 8],\n",
       " [1, 7, 6, 0, 3, 2, 8, 4, 5],\n",
       " [1, 7, 6, 0, 3, 2, 8, 5, 4],\n",
       " [1, 7, 6, 0, 3, 4, 8, 2, 5],\n",
       " [1, 7, 6, 0, 3, 4, 8, 5, 2],\n",
       " [1, 7, 6, 0, 3, 5, 2, 4, 8],\n",
       " [1, 7, 6, 0, 3, 5, 4, 2, 8],\n",
       " [1, 7, 6, 0, 3, 5, 8, 2, 4],\n",
       " [1, 7, 6, 0, 3, 5, 8, 4, 2],\n",
       " [1, 7, 6, 0, 4, 2, 3, 5, 8],\n",
       " [1, 7, 6, 0, 4, 2, 5, 3, 8],\n",
       " [1, 7, 6, 0, 4, 2, 8, 3, 5],\n",
       " [1, 7, 6, 0, 4, 2, 8, 5, 3],\n",
       " [1, 7, 6, 0, 5, 2, 3, 4, 8],\n",
       " [1, 7, 6, 0, 5, 2, 4, 3, 8],\n",
       " [1, 7, 6, 0, 5, 2, 8, 3, 4],\n",
       " [1, 7, 6, 0, 5, 2, 8, 4, 3],\n",
       " [1, 7, 6, 0, 5, 4, 8, 2, 3],\n",
       " [1, 7, 6, 0, 8, 2, 3, 4, 5],\n",
       " [1, 7, 6, 0, 8, 2, 3, 5, 4],\n",
       " [1, 7, 6, 0, 8, 2, 4, 3, 5],\n",
       " [1, 7, 6, 0, 8, 2, 4, 5, 3],\n",
       " [1, 7, 6, 0, 8, 2, 5, 3, 4],\n",
       " [1, 7, 6, 0, 8, 2, 5, 4, 3],\n",
       " [1, 7, 6, 0, 8, 4, 2, 5, 3],\n",
       " [1, 7, 6, 0, 8, 4, 3, 2, 5],\n",
       " [1, 7, 6, 0, 8, 4, 3, 5, 2],\n",
       " [1, 7, 6, 0, 8, 4, 5, 2, 3],\n",
       " [1, 7, 6, 0, 8, 5, 2, 4, 3],\n",
       " [1, 7, 6, 0, 8, 5, 3, 2, 4],\n",
       " [1, 7, 6, 0, 8, 5, 3, 4, 2],\n",
       " [1, 7, 6, 0, 8, 5, 4, 2, 3],\n",
       " [1, 7, 6, 2, 0, 3, 4, 8, 5],\n",
       " [1, 7, 6, 2, 0, 3, 5, 4, 8],\n",
       " [1, 7, 6, 2, 0, 3, 5, 8, 4],\n",
       " [1, 7, 6, 2, 0, 3, 8, 4, 5],\n",
       " [1, 7, 6, 2, 3, 0, 4, 5, 8],\n",
       " [1, 7, 6, 2, 3, 0, 5, 4, 8],\n",
       " [1, 7, 6, 2, 3, 0, 8, 4, 5],\n",
       " [1, 7, 6, 2, 3, 0, 8, 5, 4],\n",
       " [1, 7, 6, 2, 4, 0, 3, 5, 8],\n",
       " [1, 7, 6, 2, 4, 0, 5, 3, 8],\n",
       " [1, 7, 6, 2, 4, 0, 8, 3, 5],\n",
       " [1, 7, 6, 2, 4, 0, 8, 5, 3],\n",
       " [1, 7, 6, 2, 4, 3, 0, 8, 5],\n",
       " [1, 7, 6, 2, 4, 3, 5, 0, 8],\n",
       " [1, 7, 6, 2, 4, 3, 5, 8, 0],\n",
       " [1, 7, 6, 2, 4, 3, 8, 0, 5],\n",
       " [1, 7, 6, 2, 4, 5, 8, 0, 3],\n",
       " [1, 7, 6, 2, 4, 8, 5, 3, 0],\n",
       " [1, 7, 6, 2, 5, 0, 3, 4, 8],\n",
       " [1, 7, 6, 2, 5, 0, 4, 3, 8],\n",
       " [1, 7, 6, 2, 5, 0, 8, 3, 4],\n",
       " [1, 7, 6, 2, 5, 0, 8, 4, 3],\n",
       " [1, 7, 6, 2, 5, 3, 0, 4, 8],\n",
       " [1, 7, 6, 2, 5, 3, 0, 8, 4],\n",
       " [1, 7, 6, 2, 5, 3, 4, 0, 8],\n",
       " [1, 7, 6, 2, 5, 3, 4, 8, 0],\n",
       " [1, 7, 6, 2, 5, 3, 8, 0, 4],\n",
       " [1, 7, 6, 2, 5, 3, 8, 4, 0],\n",
       " [1, 7, 6, 2, 5, 4, 0, 3, 8],\n",
       " [1, 7, 6, 2, 5, 4, 3, 0, 8],\n",
       " [1, 7, 6, 2, 5, 4, 8, 0, 3],\n",
       " [1, 7, 6, 2, 5, 4, 8, 3, 0],\n",
       " [1, 7, 6, 2, 8, 0, 3, 4, 5],\n",
       " [1, 7, 6, 2, 8, 0, 3, 5, 4],\n",
       " [1, 7, 6, 2, 8, 0, 4, 3, 5],\n",
       " [1, 7, 6, 2, 8, 0, 4, 5, 3],\n",
       " [1, 7, 6, 2, 8, 0, 5, 3, 4],\n",
       " [1, 7, 6, 2, 8, 0, 5, 4, 3],\n",
       " [1, 7, 6, 2, 8, 3, 0, 4, 5],\n",
       " [1, 7, 6, 2, 8, 3, 4, 0, 5],\n",
       " [1, 7, 6, 2, 8, 3, 5, 0, 4],\n",
       " [1, 7, 6, 2, 8, 3, 5, 4, 0],\n",
       " [1, 7, 6, 2, 8, 4, 0, 3, 5],\n",
       " [1, 7, 6, 2, 8, 4, 3, 0, 5],\n",
       " [1, 7, 6, 2, 8, 4, 5, 0, 3],\n",
       " [1, 7, 6, 2, 8, 4, 5, 3, 0],\n",
       " [1, 7, 8, 0, 2, 5, 3, 4, 6],\n",
       " [1, 7, 8, 0, 2, 5, 3, 6, 4],\n",
       " [1, 7, 8, 0, 2, 5, 4, 6, 3],\n",
       " [1, 7, 8, 0, 2, 5, 6, 4, 3],\n",
       " [1, 7, 8, 0, 3, 2, 4, 5, 6],\n",
       " [1, 7, 8, 0, 3, 2, 5, 4, 6],\n",
       " [1, 7, 8, 0, 3, 2, 6, 4, 5],\n",
       " [1, 7, 8, 0, 3, 2, 6, 5, 4],\n",
       " [1, 7, 8, 0, 3, 4, 2, 5, 6],\n",
       " [1, 7, 8, 0, 3, 4, 5, 2, 6],\n",
       " [1, 7, 8, 0, 3, 4, 6, 2, 5],\n",
       " [1, 7, 8, 0, 3, 4, 6, 5, 2],\n",
       " [1, 7, 8, 0, 3, 5, 2, 4, 6],\n",
       " [1, 7, 8, 0, 3, 5, 2, 6, 4],\n",
       " [1, 7, 8, 0, 3, 5, 4, 2, 6],\n",
       " [1, 7, 8, 0, 3, 5, 4, 6, 2],\n",
       " [1, 7, 8, 0, 3, 5, 6, 2, 4],\n",
       " [1, 7, 8, 0, 3, 5, 6, 4, 2],\n",
       " [1, 7, 8, 0, 4, 2, 3, 5, 6],\n",
       " [1, 7, 8, 0, 4, 2, 5, 3, 6],\n",
       " [1, 7, 8, 0, 4, 2, 6, 3, 5],\n",
       " [1, 7, 8, 0, 4, 2, 6, 5, 3],\n",
       " [1, 7, 8, 0, 4, 3, 6, 2, 5],\n",
       " [1, 7, 8, 0, 4, 5, 2, 6, 3],\n",
       " [1, 7, 8, 0, 4, 5, 3, 2, 6],\n",
       " [1, 7, 8, 0, 4, 5, 3, 6, 2],\n",
       " [1, 7, 8, 0, 4, 5, 6, 2, 3],\n",
       " [1, 7, 8, 0, 4, 6, 3, 5, 2],\n",
       " [1, 7, 8, 0, 5, 2, 3, 4, 6],\n",
       " [1, 7, 8, 0, 5, 2, 4, 3, 6],\n",
       " [1, 7, 8, 0, 5, 2, 6, 3, 4],\n",
       " [1, 7, 8, 0, 5, 2, 6, 4, 3],\n",
       " [1, 7, 8, 0, 6, 2, 3, 4, 5],\n",
       " [1, 7, 8, 0, 6, 2, 3, 5, 4],\n",
       " [1, 7, 8, 0, 6, 2, 4, 3, 5],\n",
       " [1, 7, 8, 0, 6, 2, 4, 5, 3],\n",
       " [1, 7, 8, 0, 6, 2, 5, 3, 4],\n",
       " [1, 7, 8, 0, 6, 2, 5, 4, 3],\n",
       " [1, 7, 8, 0, 6, 4, 2, 5, 3],\n",
       " [1, 7, 8, 0, 6, 4, 3, 2, 5],\n",
       " [1, 7, 8, 0, 6, 4, 3, 5, 2],\n",
       " [1, 7, 8, 0, 6, 4, 5, 2, 3],\n",
       " [1, 7, 8, 0, 6, 5, 2, 4, 3],\n",
       " [1, 7, 8, 0, 6, 5, 3, 2, 4],\n",
       " [1, 7, 8, 0, 6, 5, 3, 4, 2],\n",
       " [1, 7, 8, 0, 6, 5, 4, 2, 3],\n",
       " [1, 7, 8, 2, 0, 4, 6, 3, 5],\n",
       " [1, 7, 8, 2, 3, 0, 4, 5, 6],\n",
       " [1, 7, 8, 2, 3, 0, 5, 4, 6],\n",
       " [1, 7, 8, 2, 3, 0, 6, 4, 5],\n",
       " [1, 7, 8, 2, 3, 0, 6, 5, 4],\n",
       " [1, 7, 8, 2, 3, 4, 6, 0, 5],\n",
       " [1, 7, 8, 2, 4, 0, 3, 5, 6],\n",
       " [1, 7, 8, 2, 4, 0, 5, 3, 6],\n",
       " [1, 7, 8, 2, 4, 0, 6, 3, 5],\n",
       " [1, 7, 8, 2, 4, 0, 6, 5, 3],\n",
       " [1, 7, 8, 2, 5, 0, 3, 4, 6],\n",
       " [1, 7, 8, 2, 5, 0, 4, 3, 6],\n",
       " [1, 7, 8, 2, 5, 0, 6, 3, 4],\n",
       " [1, 7, 8, 2, 5, 0, 6, 4, 3],\n",
       " [1, 7, 8, 2, 5, 3, 0, 4, 6],\n",
       " [1, 7, 8, 2, 5, 3, 4, 0, 6],\n",
       " [1, 7, 8, 2, 5, 3, 6, 0, 4],\n",
       " [1, 7, 8, 2, 5, 3, 6, 4, 0],\n",
       " [1, 7, 8, 2, 5, 4, 6, 0, 3],\n",
       " [1, 7, 8, 2, 5, 4, 6, 3, 0],\n",
       " [1, 7, 8, 2, 6, 0, 3, 4, 5],\n",
       " [1, 7, 8, 2, 6, 0, 3, 5, 4],\n",
       " [1, 7, 8, 2, 6, 0, 4, 3, 5],\n",
       " [1, 7, 8, 2, 6, 0, 4, 5, 3],\n",
       " [1, 7, 8, 2, 6, 0, 5, 3, 4],\n",
       " [1, 7, 8, 2, 6, 0, 5, 4, 3],\n",
       " [1, 7, 8, 2, 6, 3, 0, 4, 5],\n",
       " [1, 7, 8, 2, 6, 3, 4, 0, 5],\n",
       " [1, 7, 8, 2, 6, 3, 5, 0, 4],\n",
       " [1, 7, 8, 2, 6, 3, 5, 4, 0],\n",
       " [1, 7, 8, 2, 6, 4, 0, 3, 5],\n",
       " [1, 7, 8, 2, 6, 4, 3, 0, 5],\n",
       " [1, 7, 8, 2, 6, 4, 5, 0, 3],\n",
       " [1, 7, 8, 2, 6, 4, 5, 3, 0],\n",
       " [2, 4, 0, 1, 7, 3, 5, 8, 6],\n",
       " [2, 4, 0, 1, 7, 5, 3, 6, 8],\n",
       " [2, 4, 0, 1, 7, 6, 3, 5, 8],\n",
       " [2, 4, 0, 1, 7, 6, 3, 8, 5],\n",
       " [2, 4, 0, 1, 7, 6, 5, 8, 3],\n",
       " [2, 4, 0, 1, 7, 6, 8, 5, 3],\n",
       " [2, 4, 0, 1, 7, 8, 3, 6, 5],\n",
       " [2, 4, 0, 1, 7, 8, 5, 3, 6],\n",
       " [2, 4, 0, 1, 7, 8, 5, 6, 3],\n",
       " [2, 4, 0, 1, 7, 8, 6, 3, 5],\n",
       " [2, 4, 1, 0, 8, 5, 3, 6, 7],\n",
       " [2, 4, 1, 0, 8, 5, 3, 7, 6],\n",
       " [2, 4, 3, 0, 8, 5, 1, 6, 7],\n",
       " [2, 4, 3, 0, 8, 5, 1, 7, 6],\n",
       " [2, 4, 3, 0, 8, 5, 6, 7, 1],\n",
       " [2, 4, 3, 0, 8, 5, 7, 6, 1],\n",
       " [2, 4, 3, 1, 7, 6, 0, 5, 8],\n",
       " [2, 4, 3, 1, 7, 6, 0, 8, 5],\n",
       " [2, 4, 3, 1, 7, 6, 5, 8, 0],\n",
       " [2, 4, 3, 1, 7, 6, 8, 5, 0],\n",
       " [2, 4, 3, 1, 7, 8, 0, 6, 5],\n",
       " [2, 4, 3, 6, 0, 1, 7, 5, 8],\n",
       " [2, 4, 3, 6, 0, 1, 7, 8, 5],\n",
       " [2, 4, 3, 6, 1, 0, 8, 5, 7],\n",
       " [2, 4, 3, 6, 7, 0, 8, 5, 1],\n",
       " [2, 4, 3, 6, 7, 1, 0, 5, 8],\n",
       " [2, 4, 3, 6, 7, 1, 0, 8, 5],\n",
       " [2, 4, 3, 6, 7, 1, 5, 8, 0],\n",
       " [2, 4, 3, 6, 7, 1, 8, 5, 0],\n",
       " [2, 4, 3, 6, 7, 5, 0, 1, 8],\n",
       " [2, 4, 3, 6, 7, 5, 1, 0, 8],\n",
       " [2, 4, 3, 6, 7, 5, 8, 0, 1],\n",
       " [2, 4, 3, 6, 7, 5, 8, 1, 0],\n",
       " [2, 4, 3, 6, 7, 8, 0, 1, 5],\n",
       " [2, 4, 3, 6, 8, 5, 0, 1, 7],\n",
       " [2, 4, 3, 6, 8, 5, 1, 0, 7],\n",
       " [2, 4, 3, 6, 8, 5, 7, 0, 1],\n",
       " [2, 4, 3, 6, 8, 5, 7, 1, 0],\n",
       " [2, 4, 3, 7, 1, 0, 8, 5, 6],\n",
       " [2, 4, 5, 8, 0, 1, 7, 3, 6],\n",
       " [2, 4, 5, 8, 0, 1, 7, 6, 3],\n",
       " [2, 4, 6, 1, 7, 8, 0, 3, 5],\n",
       " [2, 4, 6, 3, 5, 8, 0, 1, 7],\n",
       " [2, 4, 6, 5, 3, 0, 8, 7, 1],\n",
       " [2, 4, 6, 7, 1, 0, 8, 5, 3],\n",
       " [2, 4, 7, 3, 5, 8, 0, 1, 6],\n",
       " [2, 4, 7, 5, 3, 0, 8, 6, 1],\n",
       " [2, 4, 7, 5, 3, 6, 0, 1, 8],\n",
       " [2, 4, 7, 5, 3, 6, 1, 0, 8],\n",
       " [2, 4, 7, 5, 3, 6, 8, 0, 1],\n",
       " [2, 4, 7, 5, 3, 6, 8, 1, 0],\n",
       " [2, 4, 7, 6, 0, 1, 3, 5, 8],\n",
       " [2, 4, 7, 6, 0, 1, 3, 8, 5],\n",
       " [2, 4, 7, 6, 0, 1, 5, 8, 3],\n",
       " [2, 4, 7, 6, 0, 1, 8, 5, 3],\n",
       " [2, 4, 7, 6, 3, 0, 8, 5, 1],\n",
       " [2, 4, 7, 6, 3, 1, 0, 5, 8],\n",
       " [2, 4, 7, 6, 3, 1, 0, 8, 5],\n",
       " [2, 4, 7, 6, 3, 1, 5, 8, 0],\n",
       " [2, 4, 7, 6, 3, 1, 8, 5, 0],\n",
       " [2, 4, 7, 6, 3, 5, 0, 1, 8],\n",
       " [2, 4, 7, 6, 3, 5, 1, 0, 8],\n",
       " [2, 4, 7, 6, 3, 5, 8, 0, 1],\n",
       " [2, 4, 7, 6, 3, 5, 8, 1, 0],\n",
       " [2, 4, 7, 6, 3, 8, 0, 1, 5],\n",
       " [2, 4, 7, 6, 5, 8, 0, 1, 3],\n",
       " [2, 4, 7, 6, 8, 5, 3, 0, 1],\n",
       " [2, 4, 7, 6, 8, 5, 3, 1, 0],\n",
       " [2, 4, 7, 8, 0, 1, 3, 6, 5],\n",
       " [2, 4, 7, 8, 0, 1, 5, 3, 6],\n",
       " [2, 4, 7, 8, 0, 1, 5, 6, 3],\n",
       " [2, 4, 7, 8, 0, 1, 6, 3, 5],\n",
       " [2, 4, 8, 5, 3, 0, 1, 6, 7],\n",
       " [2, 4, 8, 5, 3, 0, 1, 7, 6],\n",
       " [2, 4, 8, 5, 3, 0, 6, 7, 1],\n",
       " [2, 4, 8, 5, 3, 0, 7, 6, 1],\n",
       " [2, 4, 8, 5, 3, 1, 7, 6, 0],\n",
       " [2, 4, 8, 5, 3, 6, 0, 1, 7],\n",
       " [2, 4, 8, 5, 3, 6, 1, 0, 7],\n",
       " [2, 4, 8, 5, 3, 6, 7, 0, 1],\n",
       " [2, 4, 8, 5, 3, 6, 7, 1, 0],\n",
       " [2, 4, 8, 5, 3, 7, 1, 0, 6],\n",
       " [3, 0, 1, 4, 8, 2, 6, 7, 5],\n",
       " [3, 0, 1, 4, 8, 5, 2, 6, 7],\n",
       " [3, 0, 1, 4, 8, 5, 2, 7, 6],\n",
       " [3, 0, 1, 4, 8, 5, 6, 7, 2],\n",
       " [3, 0, 1, 4, 8, 5, 7, 6, 2],\n",
       " [3, 0, 1, 4, 8, 6, 2, 5, 7],\n",
       " [3, 0, 1, 4, 8, 7, 2, 5, 6],\n",
       " [3, 0, 1, 4, 8, 7, 5, 2, 6],\n",
       " [3, 0, 1, 4, 8, 7, 6, 2, 5],\n",
       " [3, 0, 1, 4, 8, 7, 6, 5, 2],\n",
       " [3, 0, 1, 5, 2, 4, 8, 6, 7],\n",
       " [3, 0, 1, 5, 2, 4, 8, 7, 6],\n",
       " [3, 0, 1, 5, 2, 6, 4, 7, 8],\n",
       " [3, 0, 1, 5, 2, 6, 7, 4, 8],\n",
       " [3, 0, 1, 5, 2, 6, 8, 4, 7],\n",
       " [3, 0, 1, 5, 2, 6, 8, 7, 4],\n",
       " [3, 0, 1, 5, 2, 7, 4, 6, 8],\n",
       " [3, 0, 1, 5, 2, 7, 6, 4, 8],\n",
       " [3, 0, 1, 5, 2, 7, 8, 4, 6],\n",
       " [3, 0, 1, 5, 2, 7, 8, 6, 4],\n",
       " [3, 0, 1, 5, 4, 7, 2, 6, 8],\n",
       " [3, 0, 1, 5, 4, 7, 6, 2, 8],\n",
       " [3, 0, 1, 5, 4, 7, 8, 2, 6],\n",
       " [3, 0, 1, 5, 4, 7, 8, 6, 2],\n",
       " [3, 0, 1, 5, 7, 4, 8, 6, 2],\n",
       " [3, 0, 1, 5, 8, 4, 2, 6, 7],\n",
       " [3, 0, 1, 5, 8, 4, 2, 7, 6],\n",
       " [3, 0, 1, 5, 8, 4, 6, 7, 2],\n",
       " [3, 0, 1, 5, 8, 4, 7, 6, 2],\n",
       " [3, 0, 1, 5, 8, 6, 2, 4, 7],\n",
       " [3, 0, 1, 5, 8, 6, 2, 7, 4],\n",
       " [3, 0, 1, 5, 8, 6, 4, 7, 2],\n",
       " [3, 0, 1, 5, 8, 6, 7, 4, 2],\n",
       " [3, 0, 1, 5, 8, 7, 2, 4, 6],\n",
       " [3, 0, 1, 5, 8, 7, 2, 6, 4],\n",
       " [3, 0, 1, 5, 8, 7, 4, 2, 6],\n",
       " [3, 0, 1, 5, 8, 7, 4, 6, 2],\n",
       " [3, 0, 1, 5, 8, 7, 6, 2, 4],\n",
       " [3, 0, 1, 5, 8, 7, 6, 4, 2],\n",
       " [3, 0, 1, 7, 4, 5, 2, 6, 8],\n",
       " [3, 0, 1, 7, 4, 5, 6, 2, 8],\n",
       " [3, 0, 1, 7, 4, 5, 8, 2, 6],\n",
       " [3, 0, 1, 7, 4, 5, 8, 6, 2],\n",
       " [3, 0, 1, 7, 5, 4, 8, 2, 6],\n",
       " [3, 0, 1, 7, 6, 2, 4, 5, 8],\n",
       " [3, 0, 1, 7, 6, 2, 5, 4, 8],\n",
       " [3, 0, 1, 7, 6, 2, 8, 4, 5],\n",
       " [3, 0, 1, 7, 6, 2, 8, 5, 4],\n",
       " [3, 0, 1, 7, 6, 4, 8, 2, 5],\n",
       " [3, 0, 1, 7, 6, 4, 8, 5, 2],\n",
       " [3, 0, 1, 7, 6, 5, 2, 4, 8],\n",
       " [3, 0, 1, 7, 6, 5, 4, 2, 8],\n",
       " [3, 0, 1, 7, 6, 5, 8, 2, 4],\n",
       " [3, 0, 1, 7, 6, 5, 8, 4, 2],\n",
       " [3, 0, 1, 7, 8, 2, 4, 5, 6],\n",
       " [3, 0, 1, 7, 8, 2, 5, 4, 6],\n",
       " [3, 0, 1, 7, 8, 2, 6, 4, 5],\n",
       " [3, 0, 1, 7, 8, 2, 6, 5, 4],\n",
       " [3, 0, 1, 7, 8, 4, 2, 5, 6],\n",
       " [3, 0, 1, 7, 8, 4, 5, 2, 6],\n",
       " [3, 0, 1, 7, 8, 4, 6, 2, 5],\n",
       " [3, 0, 1, 7, 8, 4, 6, 5, 2],\n",
       " [3, 0, 1, 7, 8, 5, 2, 4, 6],\n",
       " [3, 0, 1, 7, 8, 5, 2, 6, 4],\n",
       " [3, 0, 1, 7, 8, 5, 4, 2, 6],\n",
       " [3, 0, 1, 7, 8, 5, 4, 6, 2],\n",
       " [3, 0, 1, 7, 8, 5, 6, 2, 4],\n",
       " [3, 0, 1, 7, 8, 5, 6, 4, 2],\n",
       " [3, 0, 2, 4, 8, 5, 1, 6, 7],\n",
       " [3, 0, 2, 4, 8, 5, 1, 7, 6],\n",
       " [3, 0, 2, 4, 8, 5, 6, 7, 1],\n",
       " [3, 0, 2, 4, 8, 5, 7, 6, 1],\n",
       " [3, 0, 2, 5, 1, 4, 8, 6, 7],\n",
       " [3, 0, 2, 5, 1, 4, 8, 7, 6],\n",
       " [3, 0, 2, 5, 1, 6, 4, 7, 8],\n",
       " [3, 0, 2, 5, 1, 6, 7, 4, 8],\n",
       " [3, 0, 2, 5, 1, 6, 8, 4, 7],\n",
       " [3, 0, 2, 5, 1, 6, 8, 7, 4],\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = [game.moves_played for game in game_list]\n",
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [10,1]\n",
    "output_seq = [1,9]\n",
    "zeros = [0.] * 10\n",
    "first_output = [0.] * 10\n",
    "first_output[1] = 1.\n",
    "second_output = [0.] * 10\n",
    "second_output[9] = 1.\n",
    "output = torch.tensor([first_output, second_output])\n",
    "\n",
    "\n",
    "logit_base = torch.tensor([-10000000000.] * 10)\n",
    "first_logit = torch.clone(logit_base)\n",
    "first_logit[1] = 100000.\n",
    "second_logit = torch.clone(logit_base)\n",
    "second_logit[9] = 100000.\n",
    "logits = torch.stack([first_logit, second_logit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor([[-1.0000e+10,  1.0000e+05, -1.0000e+10, -1.0000e+10, -1.0000e+10,\n",
      "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
      "        [-1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10,\n",
      "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10,  1.0000e+05]])\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n",
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_fn(logits, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [10,1]\n",
    "output_seq = [1,9]\n",
    "zeros = [0] * 10\n",
    "first_output = [0] * 10\n",
    "first_output[1] = 1\n",
    "second_output = [0] * 10\n",
    "second_output[9] = 1\n",
    "output = torch.tensor([first_output, second_output])\n",
    "\n",
    "\n",
    "logit_base = torch.tensor([-np.inf] * 10)\n",
    "first_logit = torch.clone(logit_base)\n",
    "first_logit[1] = np.inf\n",
    "second_logit = torch.clone(logit_base)\n",
    "second_logit[9] = np.inf\n",
    "logits = torch.stack([first_logit, second_logit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  1,  7,  5,  2,  6,  3,  4,  8,  0], device='cuda:0')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2868"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n",
<<<<<<< Updated upstream
      "Epoch 0 | Train Loss: 2.8080050945281982 | Test Loss: 2.3766825199127197\n",
      "Epoch 0 | Train Loss: 2.37743878364563 | Test Loss: 2.243098497390747\n",
      "Epoch 0 | Train Loss: 2.242861270904541 | Test Loss: 2.147594690322876\n",
      "Epoch 0 | Train Loss: 2.1462807655334473 | Test Loss: 2.0750679969787598\n",
      "Epoch 0 | Train Loss: 2.0747716426849365 | Test Loss: 2.017258405685425\n",
      "Epoch 0 | Train Loss: 2.0150792598724365 | Test Loss: 1.9754102230072021\n",
      "Epoch 0 | Train Loss: 1.9754637479782104 | Test Loss: 1.9378716945648193\n",
      "Epoch 0 | Train Loss: 1.9352155923843384 | Test Loss: 1.8938804864883423\n",
      "Epoch 0 | Train Loss: 1.8929462432861328 | Test Loss: 1.8461593389511108\n",
      "Epoch 0 | Train Loss: 1.8454378843307495 | Test Loss: 1.801153540611267\n",
      "Epoch 0 | Train Loss: 1.798885703086853 | Test Loss: 1.7607389688491821\n",
      "Epoch 0 | Train Loss: 1.7615665197372437 | Test Loss: 1.719709038734436\n",
      "Epoch 0 | Train Loss: 1.7215832471847534 | Test Loss: 1.6757651567459106\n",
      "Epoch 0 | Train Loss: 1.6756536960601807 | Test Loss: 1.6326981782913208\n",
      "Epoch 0 | Train Loss: 1.6301854848861694 | Test Loss: 1.5933970212936401\n",
      "Epoch 0 | Train Loss: 1.591797947883606 | Test Loss: 1.5557435750961304\n",
      "Epoch 0 | Train Loss: 1.5564578771591187 | Test Loss: 1.5171303749084473\n",
      "Epoch 0 | Train Loss: 1.5193551778793335 | Test Loss: 1.4770243167877197\n",
      "Epoch 0 | Train Loss: 1.4755833148956299 | Test Loss: 1.436069369316101\n",
      "Epoch 0 | Train Loss: 1.4367454051971436 | Test Loss: 1.3944423198699951\n",
      "Epoch 0 | Train Loss: 1.3959301710128784 | Test Loss: 1.3520495891571045\n",
      "Epoch 0 | Train Loss: 1.3505833148956299 | Test Loss: 1.3098030090332031\n",
      "Epoch 0 | Train Loss: 1.3131237030029297 | Test Loss: 1.267351746559143\n",
      "Epoch 0 | Train Loss: 1.2706594467163086 | Test Loss: 1.2248327732086182\n",
      "Epoch 0 | Train Loss: 1.224825143814087 | Test Loss: 1.1827198266983032\n",
      "Epoch 1 | Train Loss: 1.182677149772644 | Test Loss: 1.1409310102462769\n",
      "Epoch 1 | Train Loss: 1.1408798694610596 | Test Loss: 1.0995064973831177\n",
      "Epoch 1 | Train Loss: 1.1016119718551636 | Test Loss: 1.0587974786758423\n",
      "Epoch 1 | Train Loss: 1.0592880249023438 | Test Loss: 1.018149495124817\n",
      "Epoch 1 | Train Loss: 1.0177980661392212 | Test Loss: 0.9774212837219238\n",
      "Epoch 1 | Train Loss: 0.9775671362876892 | Test Loss: 0.93719482421875\n",
      "Epoch 1 | Train Loss: 0.9371286630630493 | Test Loss: 0.8973662257194519\n",
      "Epoch 1 | Train Loss: 0.895053505897522 | Test Loss: 0.8577096462249756\n",
      "Epoch 1 | Train Loss: 0.8566175699234009 | Test Loss: 0.8190063834190369\n",
      "Epoch 1 | Train Loss: 0.8209537863731384 | Test Loss: 0.7809986472129822\n",
      "Epoch 1 | Train Loss: 0.7793704867362976 | Test Loss: 0.743642270565033\n",
      "Epoch 1 | Train Loss: 0.7448383569717407 | Test Loss: 0.7073895931243896\n",
      "Epoch 1 | Train Loss: 0.7081493735313416 | Test Loss: 0.6722399592399597\n",
      "Epoch 1 | Train Loss: 0.6728139519691467 | Test Loss: 0.638526439666748\n",
      "Epoch 1 | Train Loss: 0.6401405930519104 | Test Loss: 0.6063086986541748\n",
      "Epoch 1 | Train Loss: 0.6059673428535461 | Test Loss: 0.575282633304596\n",
      "Epoch 1 | Train Loss: 0.5742062926292419 | Test Loss: 0.5455979704856873\n",
      "Epoch 1 | Train Loss: 0.5450895428657532 | Test Loss: 0.5171860456466675\n",
      "Epoch 1 | Train Loss: 0.5155925750732422 | Test Loss: 0.49040189385414124\n",
      "Epoch 1 | Train Loss: 0.48695945739746094 | Test Loss: 0.46444106101989746\n",
      "Epoch 1 | Train Loss: 0.4649779498577118 | Test Loss: 0.4406437873840332\n",
      "Epoch 1 | Train Loss: 0.4414531886577606 | Test Loss: 0.4180130958557129\n",
      "Epoch 1 | Train Loss: 0.4192572236061096 | Test Loss: 0.3971012532711029\n",
      "Epoch 1 | Train Loss: 0.3950992226600647 | Test Loss: 0.3774178922176361\n",
      "Epoch 1 | Train Loss: 0.3796736001968384 | Test Loss: 0.35905033349990845\n",
      "Epoch 2 | Train Loss: 0.3576085567474365 | Test Loss: 0.3411436975002289\n",
      "Epoch 2 | Train Loss: 0.339712917804718 | Test Loss: 0.325325608253479\n",
      "Epoch 2 | Train Loss: 0.32445740699768066 | Test Loss: 0.3102540969848633\n",
      "Epoch 2 | Train Loss: 0.3120124638080597 | Test Loss: 0.2965911030769348\n",
      "Epoch 2 | Train Loss: 0.30084356665611267 | Test Loss: 0.28397661447525024\n",
      "Epoch 2 | Train Loss: 0.2828828990459442 | Test Loss: 0.27216655015945435\n",
      "Epoch 2 | Train Loss: 0.2716478407382965 | Test Loss: 0.2613648474216461\n",
      "Epoch 2 | Train Loss: 0.26104292273521423 | Test Loss: 0.2513301968574524\n",
      "Epoch 2 | Train Loss: 0.24947766959667206 | Test Loss: 0.24190662801265717\n",
      "Epoch 2 | Train Loss: 0.243340402841568 | Test Loss: 0.23316815495491028\n",
      "Epoch 2 | Train Loss: 0.2355431169271469 | Test Loss: 0.22519390285015106\n",
      "Epoch 2 | Train Loss: 0.2265046387910843 | Test Loss: 0.2179746776819229\n",
      "Epoch 2 | Train Loss: 0.21649034321308136 | Test Loss: 0.21117649972438812\n",
      "Epoch 2 | Train Loss: 0.2109721451997757 | Test Loss: 0.20505620539188385\n",
      "Epoch 2 | Train Loss: 0.20444755256175995 | Test Loss: 0.19952842593193054\n",
      "Epoch 2 | Train Loss: 0.19893959164619446 | Test Loss: 0.1941417157649994\n",
      "Epoch 2 | Train Loss: 0.19276586174964905 | Test Loss: 0.1898326277732849\n",
      "Epoch 2 | Train Loss: 0.18757449090480804 | Test Loss: 0.18527798354625702\n",
      "Epoch 2 | Train Loss: 0.18337956070899963 | Test Loss: 0.1810338944196701\n",
      "Epoch 2 | Train Loss: 0.17841672897338867 | Test Loss: 0.1772795021533966\n",
      "Epoch 2 | Train Loss: 0.17890039086341858 | Test Loss: 0.17369140684604645\n",
      "Epoch 2 | Train Loss: 0.17289531230926514 | Test Loss: 0.1705644428730011\n",
      "Epoch 2 | Train Loss: 0.17229528725147247 | Test Loss: 0.16754387319087982\n",
      "Epoch 2 | Train Loss: 0.16412030160427094 | Test Loss: 0.16491487622261047\n",
      "Epoch 2 | Train Loss: 0.1663275957107544 | Test Loss: 0.16251228749752045\n",
      "Epoch 3 | Train Loss: 0.16123409569263458 | Test Loss: 0.1601942926645279\n",
      "Epoch 3 | Train Loss: 0.1574077606201172 | Test Loss: 0.15807980298995972\n",
      "Epoch 3 | Train Loss: 0.15517966449260712 | Test Loss: 0.1559157371520996\n",
      "Epoch 3 | Train Loss: 0.15757887065410614 | Test Loss: 0.154312863945961\n",
      "Epoch 3 | Train Loss: 0.1580035537481308 | Test Loss: 0.15265434980392456\n",
      "Epoch 3 | Train Loss: 0.15334421396255493 | Test Loss: 0.15105432271957397\n",
      "Epoch 3 | Train Loss: 0.15008904039859772 | Test Loss: 0.14959289133548737\n",
      "Epoch 3 | Train Loss: 0.1485394984483719 | Test Loss: 0.14813493192195892\n",
      "Epoch 3 | Train Loss: 0.14596442878246307 | Test Loss: 0.1471344381570816\n",
      "Epoch 3 | Train Loss: 0.14840319752693176 | Test Loss: 0.14598987996578217\n",
      "Epoch 3 | Train Loss: 0.14760343730449677 | Test Loss: 0.14462873339653015\n",
      "Epoch 3 | Train Loss: 0.1449640840291977 | Test Loss: 0.14376425743103027\n",
      "Epoch 3 | Train Loss: 0.14187653362751007 | Test Loss: 0.14274372160434723\n",
      "Epoch 3 | Train Loss: 0.14242736995220184 | Test Loss: 0.14180906116962433\n",
      "Epoch 3 | Train Loss: 0.1406169980764389 | Test Loss: 0.14101456105709076\n",
      "Epoch 3 | Train Loss: 0.1404487043619156 | Test Loss: 0.14023438096046448\n",
      "Epoch 3 | Train Loss: 0.138347789645195 | Test Loss: 0.13936254382133484\n",
      "Epoch 3 | Train Loss: 0.13727052509784698 | Test Loss: 0.13881482183933258\n",
      "Epoch 3 | Train Loss: 0.13664136826992035 | Test Loss: 0.13805489242076874\n",
      "Epoch 3 | Train Loss: 0.13566812872886658 | Test Loss: 0.13742142915725708\n",
      "Epoch 3 | Train Loss: 0.13908539712429047 | Test Loss: 0.13672257959842682\n",
      "Epoch 3 | Train Loss: 0.136225625872612 | Test Loss: 0.136131152510643\n",
      "Epoch 3 | Train Loss: 0.13769488036632538 | Test Loss: 0.13567402958869934\n",
      "Epoch 3 | Train Loss: 0.13198979198932648 | Test Loss: 0.13514035940170288\n",
      "Epoch 3 | Train Loss: 0.1364511251449585 | Test Loss: 0.1346680074930191\n",
      "Epoch 4 | Train Loss: 0.13344939053058624 | Test Loss: 0.13424664735794067\n",
      "Epoch 4 | Train Loss: 0.13162153959274292 | Test Loss: 0.13375923037528992\n",
      "Epoch 4 | Train Loss: 0.1301063895225525 | Test Loss: 0.13334056735038757\n",
      "Epoch 4 | Train Loss: 0.13494303822517395 | Test Loss: 0.13308562338352203\n",
      "Epoch 4 | Train Loss: 0.13633720576763153 | Test Loss: 0.13261397182941437\n",
      "Epoch 4 | Train Loss: 0.1333167552947998 | Test Loss: 0.13227230310440063\n",
      "Epoch 4 | Train Loss: 0.1313001960515976 | Test Loss: 0.13195592164993286\n",
      "Epoch 4 | Train Loss: 0.13076014816761017 | Test Loss: 0.13156571984291077\n",
      "Epoch 4 | Train Loss: 0.12954512238502502 | Test Loss: 0.13138259947299957\n",
      "Epoch 4 | Train Loss: 0.13276457786560059 | Test Loss: 0.13098491728305817\n",
      "Epoch 4 | Train Loss: 0.13228514790534973 | Test Loss: 0.1306731104850769\n",
      "Epoch 4 | Train Loss: 0.13124020397663116 | Test Loss: 0.13045324385166168\n",
      "Epoch 4 | Train Loss: 0.12862665951251984 | Test Loss: 0.13011083006858826\n",
      "Epoch 4 | Train Loss: 0.12958310544490814 | Test Loss: 0.129908949136734\n",
      "Epoch 4 | Train Loss: 0.1288212090730667 | Test Loss: 0.12967781722545624\n",
      "Epoch 4 | Train Loss: 0.12912054359912872 | Test Loss: 0.12943555414676666\n",
      "Epoch 4 | Train Loss: 0.12731991708278656 | Test Loss: 0.12918099761009216\n",
      "Epoch 4 | Train Loss: 0.12724918127059937 | Test Loss: 0.12899203598499298\n",
      "Epoch 4 | Train Loss: 0.12677748501300812 | Test Loss: 0.12873370945453644\n",
      "Epoch 4 | Train Loss: 0.12640024721622467 | Test Loss: 0.12863802909851074\n",
      "Epoch 4 | Train Loss: 0.13035990297794342 | Test Loss: 0.12837918102741241\n",
      "Epoch 4 | Train Loss: 0.12796296179294586 | Test Loss: 0.12820610404014587\n",
      "Epoch 4 | Train Loss: 0.12979304790496826 | Test Loss: 0.12804816663265228\n",
      "Epoch 4 | Train Loss: 0.1244659423828125 | Test Loss: 0.12782511115074158\n",
      "Epoch 4 | Train Loss: 0.12907132506370544 | Test Loss: 0.1276494413614273\n",
      "Epoch 5 | Train Loss: 0.12642233073711395 | Test Loss: 0.1274939626455307\n",
      "Epoch 5 | Train Loss: 0.12488564103841782 | Test Loss: 0.12732204794883728\n",
      "Epoch 5 | Train Loss: 0.12348911911249161 | Test Loss: 0.12718097865581512\n",
      "Epoch 5 | Train Loss: 0.12887659668922424 | Test Loss: 0.12706401944160461\n",
      "Epoch 5 | Train Loss: 0.13015270233154297 | Test Loss: 0.12687084078788757\n",
      "Epoch 5 | Train Loss: 0.1275065392255783 | Test Loss: 0.12677150964736938\n",
      "Epoch 5 | Train Loss: 0.12577739357948303 | Test Loss: 0.12661373615264893\n",
      "Epoch 5 | Train Loss: 0.12545843422412872 | Test Loss: 0.12649324536323547\n",
      "Epoch 5 | Train Loss: 0.12434855848550797 | Test Loss: 0.12640416622161865\n",
      "Epoch 5 | Train Loss: 0.127783864736557 | Test Loss: 0.1262119561433792\n",
      "Epoch 5 | Train Loss: 0.12754352390766144 | Test Loss: 0.12612706422805786\n",
      "Epoch 5 | Train Loss: 0.12662984430789948 | Test Loss: 0.1260467916727066\n",
      "Epoch 5 | Train Loss: 0.12417848408222198 | Test Loss: 0.12585808336734772\n",
      "Epoch 5 | Train Loss: 0.12537841498851776 | Test Loss: 0.12577015161514282\n",
      "Epoch 5 | Train Loss: 0.12466259300708771 | Test Loss: 0.12572064995765686\n",
      "Epoch 5 | Train Loss: 0.12502296268939972 | Test Loss: 0.12558934092521667\n",
      "Epoch 5 | Train Loss: 0.12339873611927032 | Test Loss: 0.12544681131839752\n",
      "Epoch 5 | Train Loss: 0.12363679707050323 | Test Loss: 0.1254195272922516\n",
      "Epoch 5 | Train Loss: 0.12311770021915436 | Test Loss: 0.12522165477275848\n",
      "Epoch 5 | Train Loss: 0.1229594349861145 | Test Loss: 0.1251934915781021\n",
      "Epoch 5 | Train Loss: 0.1270655393600464 | Test Loss: 0.1250678300857544\n",
      "Epoch 5 | Train Loss: 0.12471484392881393 | Test Loss: 0.12494595348834991\n",
      "Epoch 5 | Train Loss: 0.12643995881080627 | Test Loss: 0.1248895674943924\n",
      "Epoch 5 | Train Loss: 0.12131829559803009 | Test Loss: 0.12480498850345612\n",
      "Epoch 5 | Train Loss: 0.12587769329547882 | Test Loss: 0.12468466907739639\n",
      "Epoch 6 | Train Loss: 0.12332047522068024 | Test Loss: 0.12467289716005325\n",
      "Epoch 6 | Train Loss: 0.12210772186517715 | Test Loss: 0.12459263950586319\n",
      "Epoch 6 | Train Loss: 0.12062633037567139 | Test Loss: 0.1244625523686409\n",
      "Epoch 6 | Train Loss: 0.12610729038715363 | Test Loss: 0.12446795403957367\n",
      "Epoch 6 | Train Loss: 0.1274273842573166 | Test Loss: 0.12432662397623062\n",
      "Epoch 6 | Train Loss: 0.12502646446228027 | Test Loss: 0.12421496957540512\n",
      "Epoch 6 | Train Loss: 0.12324948608875275 | Test Loss: 0.12417152523994446\n",
      "Epoch 6 | Train Loss: 0.12295923382043839 | Test Loss: 0.12407737970352173\n",
      "Epoch 6 | Train Loss: 0.12197156250476837 | Test Loss: 0.12403745949268341\n",
      "Epoch 6 | Train Loss: 0.12536396086215973 | Test Loss: 0.12396295368671417\n",
      "Epoch 6 | Train Loss: 0.12518177926540375 | Test Loss: 0.12385241687297821\n",
      "Epoch 6 | Train Loss: 0.12438696622848511 | Test Loss: 0.12384855002164841\n",
      "Epoch 6 | Train Loss: 0.12190687656402588 | Test Loss: 0.12378422915935516\n",
      "Epoch 6 | Train Loss: 0.12330164760351181 | Test Loss: 0.12367603182792664\n",
      "Epoch 6 | Train Loss: 0.12258534878492355 | Test Loss: 0.12372440844774246\n",
      "Epoch 6 | Train Loss: 0.12301500141620636 | Test Loss: 0.12371271103620529\n",
      "Epoch 6 | Train Loss: 0.12156889587640762 | Test Loss: 0.12349551171064377\n",
      "Epoch 6 | Train Loss: 0.12177393585443497 | Test Loss: 0.12353197485208511\n",
      "Epoch 6 | Train Loss: 0.12116211652755737 | Test Loss: 0.12339400500059128\n",
      "Epoch 6 | Train Loss: 0.12110910564661026 | Test Loss: 0.1233416348695755\n",
      "Epoch 6 | Train Loss: 0.12519033253192902 | Test Loss: 0.12334941327571869\n",
      "Epoch 6 | Train Loss: 0.12299495190382004 | Test Loss: 0.12324462085962296\n",
      "Epoch 6 | Train Loss: 0.12481977790594101 | Test Loss: 0.1231575533747673\n",
      "Epoch 6 | Train Loss: 0.11970718950033188 | Test Loss: 0.12316480278968811\n",
      "Epoch 6 | Train Loss: 0.12417113035917282 | Test Loss: 0.12305299937725067\n",
      "Epoch 7 | Train Loss: 0.12166740745306015 | Test Loss: 0.12302396446466446\n",
      "Epoch 7 | Train Loss: 0.1204736977815628 | Test Loss: 0.1230241060256958\n",
      "Epoch 7 | Train Loss: 0.11908479034900665 | Test Loss: 0.12290588766336441\n",
      "Epoch 7 | Train Loss: 0.12451737374067307 | Test Loss: 0.12289337813854218\n",
      "Epoch 7 | Train Loss: 0.12583990395069122 | Test Loss: 0.12285258620977402\n",
      "Epoch 7 | Train Loss: 0.12355773895978928 | Test Loss: 0.1227385401725769\n",
      "Epoch 7 | Train Loss: 0.12176044285297394 | Test Loss: 0.1227421686053276\n",
      "Epoch 7 | Train Loss: 0.12158817052841187 | Test Loss: 0.1226942166686058\n",
      "Epoch 7 | Train Loss: 0.12050749361515045 | Test Loss: 0.12264102697372437\n",
      "Epoch 7 | Train Loss: 0.12396373599767685 | Test Loss: 0.122640460729599\n",
      "Epoch 7 | Train Loss: 0.1238357350230217 | Test Loss: 0.12255144119262695\n",
      "Epoch 7 | Train Loss: 0.12316518276929855 | Test Loss: 0.12253663688898087\n",
      "Epoch 7 | Train Loss: 0.12067241966724396 | Test Loss: 0.1225740984082222\n",
      "Epoch 7 | Train Loss: 0.12213434278964996 | Test Loss: 0.12244506180286407\n",
      "Epoch 7 | Train Loss: 0.12137094885110855 | Test Loss: 0.12245526909828186\n",
      "Epoch 7 | Train Loss: 0.1217108964920044 | Test Loss: 0.12255458533763885\n",
      "Epoch 7 | Train Loss: 0.12039065361022949 | Test Loss: 0.1223139613866806\n",
      "Epoch 7 | Train Loss: 0.12052621692419052 | Test Loss: 0.12234976887702942\n",
      "Epoch 7 | Train Loss: 0.11994265764951706 | Test Loss: 0.12230558693408966\n",
      "Epoch 7 | Train Loss: 0.11995726078748703 | Test Loss: 0.12221413850784302\n",
      "Epoch 7 | Train Loss: 0.12411611527204514 | Test Loss: 0.12227678298950195\n",
      "Epoch 7 | Train Loss: 0.12190039455890656 | Test Loss: 0.12221277505159378\n",
      "Epoch 7 | Train Loss: 0.12372063845396042 | Test Loss: 0.12209614366292953\n",
      "Epoch 7 | Train Loss: 0.11859257519245148 | Test Loss: 0.12218058109283447\n",
      "Epoch 7 | Train Loss: 0.1230611801147461 | Test Loss: 0.1221042200922966\n",
      "Epoch 8 | Train Loss: 0.12062595039606094 | Test Loss: 0.12203095853328705\n",
      "Epoch 8 | Train Loss: 0.11945686489343643 | Test Loss: 0.1220800057053566\n",
      "Epoch 8 | Train Loss: 0.11813177168369293 | Test Loss: 0.12196334451436996\n",
      "Epoch 8 | Train Loss: 0.1235460564494133 | Test Loss: 0.12191268056631088\n",
      "Epoch 8 | Train Loss: 0.12480511516332626 | Test Loss: 0.12194591015577316\n",
      "Epoch 8 | Train Loss: 0.1226939782500267 | Test Loss: 0.12185800075531006\n",
      "Epoch 8 | Train Loss: 0.12083547562360764 | Test Loss: 0.12180592119693756\n",
      "Epoch 8 | Train Loss: 0.12064038962125778 | Test Loss: 0.12180979549884796\n",
      "Epoch 8 | Train Loss: 0.11965620517730713 | Test Loss: 0.12174836546182632\n",
      "Epoch 8 | Train Loss: 0.1229865700006485 | Test Loss: 0.12173545360565186\n",
      "Epoch 8 | Train Loss: 0.12288022041320801 | Test Loss: 0.12173071503639221\n",
      "Epoch 8 | Train Loss: 0.12231471389532089 | Test Loss: 0.12165571749210358\n",
      "Epoch 8 | Train Loss: 0.11979684978723526 | Test Loss: 0.12168478965759277\n",
      "Epoch 8 | Train Loss: 0.12123581022024155 | Test Loss: 0.12164175510406494\n",
      "Epoch 8 | Train Loss: 0.12055826187133789 | Test Loss: 0.12158062309026718\n",
      "Epoch 8 | Train Loss: 0.12082727253437042 | Test Loss: 0.12167223542928696\n",
      "Epoch 8 | Train Loss: 0.11954834312200546 | Test Loss: 0.12155064195394516\n",
      "Epoch 8 | Train Loss: 0.11975874751806259 | Test Loss: 0.12151813507080078\n",
      "Epoch 8 | Train Loss: 0.11906421184539795 | Test Loss: 0.12149982899427414\n",
      "Epoch 8 | Train Loss: 0.11907706409692764 | Test Loss: 0.12143408507108688\n",
      "Epoch 8 | Train Loss: 0.12337090075016022 | Test Loss: 0.12146475166082382\n",
      "Epoch 8 | Train Loss: 0.12105735391378403 | Test Loss: 0.12145056575536728\n",
      "Epoch 8 | Train Loss: 0.12299793213605881 | Test Loss: 0.12137669324874878\n",
      "Epoch 8 | Train Loss: 0.11794954538345337 | Test Loss: 0.12140581011772156\n",
      "Epoch 8 | Train Loss: 0.12227001041173935 | Test Loss: 0.12138185650110245\n",
      "Epoch 9 | Train Loss: 0.11994011700153351 | Test Loss: 0.12129182368516922\n",
      "Epoch 9 | Train Loss: 0.11877176910638809 | Test Loss: 0.12130820006132126\n",
      "Epoch 9 | Train Loss: 0.11737262457609177 | Test Loss: 0.12126059085130692\n",
      "Epoch 9 | Train Loss: 0.12281733006238937 | Test Loss: 0.12120625376701355\n",
      "Epoch 9 | Train Loss: 0.12410900741815567 | Test Loss: 0.12123458087444305\n",
      "Epoch 9 | Train Loss: 0.1220371350646019 | Test Loss: 0.12120376527309418\n",
      "Epoch 9 | Train Loss: 0.12017934769392014 | Test Loss: 0.12115079909563065\n",
      "Epoch 9 | Train Loss: 0.12003438919782639 | Test Loss: 0.1211354210972786\n",
      "Epoch 9 | Train Loss: 0.11900551617145538 | Test Loss: 0.12110085040330887\n",
      "Epoch 9 | Train Loss: 0.12245338410139084 | Test Loss: 0.12106317281723022\n",
      "Epoch 9 | Train Loss: 0.1221892386674881 | Test Loss: 0.12105805426836014\n",
      "Epoch 9 | Train Loss: 0.12169792503118515 | Test Loss: 0.12102461606264114\n",
      "Epoch 9 | Train Loss: 0.11916277557611465 | Test Loss: 0.12104025483131409\n",
      "Epoch 9 | Train Loss: 0.12058339267969131 | Test Loss: 0.12103430181741714\n",
      "Epoch 9 | Train Loss: 0.11998011916875839 | Test Loss: 0.12098214030265808\n",
      "Epoch 9 | Train Loss: 0.12024205178022385 | Test Loss: 0.12102384865283966\n",
      "Epoch 9 | Train Loss: 0.1189141795039177 | Test Loss: 0.12096960842609406\n",
      "Epoch 9 | Train Loss: 0.11919911205768585 | Test Loss: 0.12093254923820496\n",
      "Epoch 9 | Train Loss: 0.11852140724658966 | Test Loss: 0.12093579024076462\n",
      "Epoch 9 | Train Loss: 0.11849541962146759 | Test Loss: 0.12090100347995758\n",
      "Epoch 9 | Train Loss: 0.12283433973789215 | Test Loss: 0.12089741975069046\n",
      "Epoch 9 | Train Loss: 0.12048450857400894 | Test Loss: 0.12087824195623398\n",
      "Epoch 9 | Train Loss: 0.1224217340350151 | Test Loss: 0.12082477658987045\n",
      "Epoch 9 | Train Loss: 0.11744692176580429 | Test Loss: 0.12082652747631073\n",
      "Epoch 9 | Train Loss: 0.1217244416475296 | Test Loss: 0.1208309531211853\n"
=======
      "Epoch 0 | Train Loss: 2.708627700805664 | Test Loss: 2.3364152908325195\n",
      "Epoch 1 | Train Loss: 2.330667495727539 | Test Loss: 2.1717469692230225\n",
      "Epoch 2 | Train Loss: 2.16935133934021 | Test Loss: 2.0614676475524902\n",
      "Epoch 3 | Train Loss: 2.0626955032348633 | Test Loss: 1.9807125329971313\n",
      "Epoch 4 | Train Loss: 1.9821646213531494 | Test Loss: 1.9069902896881104\n",
      "Epoch 5 | Train Loss: 1.9065356254577637 | Test Loss: 1.8403311967849731\n",
      "Epoch 6 | Train Loss: 1.838087558746338 | Test Loss: 1.777667760848999\n",
      "Epoch 7 | Train Loss: 1.7749899625778198 | Test Loss: 1.7234357595443726\n",
      "Epoch 8 | Train Loss: 1.720491647720337 | Test Loss: 1.6702353954315186\n",
      "Epoch 9 | Train Loss: 1.6670901775360107 | Test Loss: 1.615211009979248\n",
      "Epoch 10 | Train Loss: 1.6113582849502563 | Test Loss: 1.5629500150680542\n",
      "Epoch 11 | Train Loss: 1.5581475496292114 | Test Loss: 1.5141409635543823\n",
      "Epoch 12 | Train Loss: 1.5081480741500854 | Test Loss: 1.465851902961731\n",
      "Epoch 13 | Train Loss: 1.4585500955581665 | Test Loss: 1.4165810346603394\n",
      "Epoch 14 | Train Loss: 1.4089151620864868 | Test Loss: 1.3670223951339722\n",
      "Epoch 15 | Train Loss: 1.3592606782913208 | Test Loss: 1.3167474269866943\n",
      "Epoch 16 | Train Loss: 1.3087527751922607 | Test Loss: 1.2671650648117065\n",
      "Epoch 17 | Train Loss: 1.2586358785629272 | Test Loss: 1.2193142175674438\n",
      "Epoch 18 | Train Loss: 1.2098952531814575 | Test Loss: 1.1714305877685547\n",
      "Epoch 19 | Train Loss: 1.1610217094421387 | Test Loss: 1.123378038406372\n",
      "Epoch 20 | Train Loss: 1.11220383644104 | Test Loss: 1.074352502822876\n",
      "Epoch 21 | Train Loss: 1.0628529787063599 | Test Loss: 1.0263121128082275\n",
      "Epoch 22 | Train Loss: 1.0143698453903198 | Test Loss: 0.979041337966919\n",
      "Epoch 23 | Train Loss: 0.966727077960968 | Test Loss: 0.9318333864212036\n",
      "Epoch 24 | Train Loss: 0.9190192818641663 | Test Loss: 0.885591983795166\n",
      "Epoch 25 | Train Loss: 0.872333288192749 | Test Loss: 0.8402994871139526\n",
      "Epoch 26 | Train Loss: 0.8267281651496887 | Test Loss: 0.7956629991531372\n",
      "Epoch 27 | Train Loss: 0.7819027900695801 | Test Loss: 0.7518687844276428\n",
      "Epoch 28 | Train Loss: 0.7381013035774231 | Test Loss: 0.70888751745224\n",
      "Epoch 29 | Train Loss: 0.695344090461731 | Test Loss: 0.6672607660293579\n",
      "Epoch 30 | Train Loss: 0.6538994312286377 | Test Loss: 0.6271449327468872\n",
      "Epoch 31 | Train Loss: 0.6142241358757019 | Test Loss: 0.587822675704956\n",
      "Epoch 32 | Train Loss: 0.5754508972167969 | Test Loss: 0.5497565269470215\n",
      "Epoch 33 | Train Loss: 0.5378066897392273 | Test Loss: 0.513300359249115\n",
      "Epoch 34 | Train Loss: 0.5014932751655579 | Test Loss: 0.4778883457183838\n",
      "Epoch 35 | Train Loss: 0.466451495885849 | Test Loss: 0.4437173306941986\n",
      "Epoch 36 | Train Loss: 0.432929128408432 | Test Loss: 0.4104442298412323\n",
      "Epoch 37 | Train Loss: 0.400402694940567 | Test Loss: 0.3786226511001587\n",
      "Epoch 38 | Train Loss: 0.36920565366744995 | Test Loss: 0.3489663600921631\n",
      "Epoch 39 | Train Loss: 0.3397253751754761 | Test Loss: 0.32128122448921204\n",
      "Epoch 40 | Train Loss: 0.3121185302734375 | Test Loss: 0.29557177424430847\n",
      "Epoch 41 | Train Loss: 0.28628596663475037 | Test Loss: 0.27232569456100464\n",
      "Epoch 42 | Train Loss: 0.2620919346809387 | Test Loss: 0.25083985924720764\n",
      "Epoch 43 | Train Loss: 0.23914583027362823 | Test Loss: 0.23085123300552368\n",
      "Epoch 44 | Train Loss: 0.21802671253681183 | Test Loss: 0.2127237170934677\n",
      "Epoch 45 | Train Loss: 0.19937771558761597 | Test Loss: 0.19523577392101288\n",
      "Epoch 46 | Train Loss: 0.18177473545074463 | Test Loss: 0.17934414744377136\n",
      "Epoch 47 | Train Loss: 0.16590291261672974 | Test Loss: 0.16575852036476135\n",
      "Epoch 48 | Train Loss: 0.15185979008674622 | Test Loss: 0.15273740887641907\n",
      "Epoch 49 | Train Loss: 0.13831576704978943 | Test Loss: 0.13991472125053406\n",
      "Epoch 50 | Train Loss: 0.12586064636707306 | Test Loss: 0.12858735024929047\n",
      "Epoch 51 | Train Loss: 0.11429888755083084 | Test Loss: 0.11855662614107132\n",
      "Epoch 52 | Train Loss: 0.10437104105949402 | Test Loss: 0.10846744477748871\n",
      "Epoch 53 | Train Loss: 0.09485045075416565 | Test Loss: 0.09974608570337296\n",
      "Epoch 54 | Train Loss: 0.08605324476957321 | Test Loss: 0.09154169261455536\n",
      "Epoch 55 | Train Loss: 0.07814629375934601 | Test Loss: 0.08430119603872299\n",
      "Epoch 56 | Train Loss: 0.07124782353639603 | Test Loss: 0.07729702442884445\n",
      "Epoch 57 | Train Loss: 0.06499136239290237 | Test Loss: 0.07094373553991318\n",
      "Epoch 58 | Train Loss: 0.05928661301732063 | Test Loss: 0.06568070501089096\n",
      "Epoch 59 | Train Loss: 0.054149359464645386 | Test Loss: 0.061305005103349686\n",
      "Epoch 60 | Train Loss: 0.049453865736722946 | Test Loss: 0.05684711039066315\n",
      "Epoch 61 | Train Loss: 0.045177243649959564 | Test Loss: 0.05295427516102791\n",
      "Epoch 62 | Train Loss: 0.04161228612065315 | Test Loss: 0.049541279673576355\n",
      "Epoch 63 | Train Loss: 0.038164205849170685 | Test Loss: 0.04624722898006439\n",
      "Epoch 64 | Train Loss: 0.035121768712997437 | Test Loss: 0.04327085241675377\n",
      "Epoch 65 | Train Loss: 0.03239566460251808 | Test Loss: 0.040954649448394775\n",
      "Epoch 66 | Train Loss: 0.029892675578594208 | Test Loss: 0.03876335918903351\n",
      "Epoch 67 | Train Loss: 0.027592798694968224 | Test Loss: 0.03661860525608063\n",
      "Epoch 68 | Train Loss: 0.02548365294933319 | Test Loss: 0.03494998812675476\n",
      "Epoch 69 | Train Loss: 0.023528272286057472 | Test Loss: 0.033478233963251114\n",
      "Epoch 70 | Train Loss: 0.02177748829126358 | Test Loss: 0.03200160712003708\n",
      "Epoch 71 | Train Loss: 0.020194152370095253 | Test Loss: 0.03052583336830139\n",
      "Epoch 72 | Train Loss: 0.018902838230133057 | Test Loss: 0.029292799532413483\n",
      "Epoch 73 | Train Loss: 0.017577260732650757 | Test Loss: 0.027863861992955208\n",
      "Epoch 74 | Train Loss: 0.016367264091968536 | Test Loss: 0.026565665379166603\n",
      "Epoch 75 | Train Loss: 0.015299172140657902 | Test Loss: 0.025181813165545464\n",
      "Epoch 76 | Train Loss: 0.01426932867616415 | Test Loss: 0.024270718917250633\n",
      "Epoch 77 | Train Loss: 0.013465426862239838 | Test Loss: 0.02349788323044777\n",
      "Epoch 78 | Train Loss: 0.012639811262488365 | Test Loss: 0.022876430302858353\n",
      "Epoch 79 | Train Loss: 0.011956075206398964 | Test Loss: 0.02224106155335903\n",
      "Epoch 80 | Train Loss: 0.011286423541605473 | Test Loss: 0.021413540467619896\n",
      "Epoch 81 | Train Loss: 0.010617482475936413 | Test Loss: 0.02039368264377117\n",
      "Epoch 82 | Train Loss: 0.010031248442828655 | Test Loss: 0.019637813791632652\n",
      "Epoch 83 | Train Loss: 0.009518799372017384 | Test Loss: 0.019127143546938896\n",
      "Epoch 84 | Train Loss: 0.009009463712573051 | Test Loss: 0.01863972470164299\n",
      "Epoch 85 | Train Loss: 0.008554433472454548 | Test Loss: 0.018303267657756805\n",
      "Epoch 86 | Train Loss: 0.008181274868547916 | Test Loss: 0.018035732209682465\n",
      "Epoch 87 | Train Loss: 0.007786961272358894 | Test Loss: 0.01771327294409275\n",
      "Epoch 88 | Train Loss: 0.0074243308044970036 | Test Loss: 0.01741146109998226\n",
      "Epoch 89 | Train Loss: 0.007103155832737684 | Test Loss: 0.01727922633290291\n",
      "Epoch 90 | Train Loss: 0.006795975379645824 | Test Loss: 0.01703048311173916\n",
      "Epoch 91 | Train Loss: 0.006504167336970568 | Test Loss: 0.016621213406324387\n",
      "Epoch 92 | Train Loss: 0.006252107676118612 | Test Loss: 0.01627453975379467\n",
      "Epoch 93 | Train Loss: 0.006004977505654097 | Test Loss: 0.01597256027162075\n",
      "Epoch 94 | Train Loss: 0.0057667759247124195 | Test Loss: 0.015687020495533943\n",
      "Epoch 95 | Train Loss: 0.005555633921176195 | Test Loss: 0.015409618616104126\n",
      "Epoch 96 | Train Loss: 0.005351439118385315 | Test Loss: 0.015177899040281773\n",
      "Epoch 97 | Train Loss: 0.005162429064512253 | Test Loss: 0.015009766444563866\n",
      "Epoch 98 | Train Loss: 0.004980996251106262 | Test Loss: 0.014880796894431114\n",
      "Epoch 99 | Train Loss: 0.004813725128769875 | Test Loss: 0.014674707315862179\n",
      "Epoch 100 | Train Loss: 0.004646368324756622 | Test Loss: 0.014430095441639423\n",
      "Epoch 101 | Train Loss: 0.004498384427279234 | Test Loss: 0.014260132797062397\n",
      "Epoch 102 | Train Loss: 0.0043568480759859085 | Test Loss: 0.01418521162122488\n",
      "Epoch 103 | Train Loss: 0.004219568334519863 | Test Loss: 0.01403076946735382\n",
      "Epoch 104 | Train Loss: 0.004090110305696726 | Test Loss: 0.013810311444103718\n",
      "Epoch 105 | Train Loss: 0.0039718374609947205 | Test Loss: 0.013649731874465942\n",
      "Epoch 106 | Train Loss: 0.00385714927688241 | Test Loss: 0.013559719547629356\n",
      "Epoch 107 | Train Loss: 0.003749110968783498 | Test Loss: 0.01340921875089407\n",
      "Epoch 108 | Train Loss: 0.003647822653874755 | Test Loss: 0.01319108996540308\n",
      "Epoch 109 | Train Loss: 0.003548241686075926 | Test Loss: 0.013068370521068573\n",
      "Epoch 110 | Train Loss: 0.0034555441234260798 | Test Loss: 0.01302975695580244\n",
      "Epoch 111 | Train Loss: 0.003367012133821845 | Test Loss: 0.012919174507260323\n",
      "Epoch 112 | Train Loss: 0.0032817423343658447 | Test Loss: 0.012724892236292362\n",
      "Epoch 113 | Train Loss: 0.0032010821159929037 | Test Loss: 0.012555867433547974\n",
      "Epoch 114 | Train Loss: 0.0031251695472747087 | Test Loss: 0.012445257976651192\n",
      "Epoch 115 | Train Loss: 0.003050734754651785 | Test Loss: 0.01232389360666275\n",
      "Epoch 116 | Train Loss: 0.002980454359203577 | Test Loss: 0.01215868629515171\n",
      "Epoch 117 | Train Loss: 0.0029124291613698006 | Test Loss: 0.012052102945744991\n",
      "Epoch 118 | Train Loss: 0.002847073832526803 | Test Loss: 0.011997699737548828\n",
      "Epoch 119 | Train Loss: 0.0027848512399941683 | Test Loss: 0.011901910416781902\n",
      "Epoch 120 | Train Loss: 0.002724560210481286 | Test Loss: 0.011758855544030666\n",
      "Epoch 121 | Train Loss: 0.0026663055177778006 | Test Loss: 0.011646782979369164\n",
      "Epoch 122 | Train Loss: 0.0026100859977304935 | Test Loss: 0.011572879739105701\n",
      "Epoch 123 | Train Loss: 0.002556625986471772 | Test Loss: 0.011497820727527142\n",
      "Epoch 124 | Train Loss: 0.00250437599606812 | Test Loss: 0.011419528163969517\n",
      "Epoch 125 | Train Loss: 0.00245442776940763 | Test Loss: 0.011358049698174\n",
      "Epoch 126 | Train Loss: 0.0024054718669503927 | Test Loss: 0.011292173527181149\n",
      "Epoch 127 | Train Loss: 0.0023584836162626743 | Test Loss: 0.011207149364054203\n",
      "Epoch 128 | Train Loss: 0.002312527969479561 | Test Loss: 0.011120470240712166\n",
      "Epoch 129 | Train Loss: 0.0022685208823531866 | Test Loss: 0.011050551198422909\n",
      "Epoch 130 | Train Loss: 0.002225677017122507 | Test Loss: 0.010986624285578728\n",
      "Epoch 131 | Train Loss: 0.002184554236009717 | Test Loss: 0.01092054694890976\n",
      "Epoch 132 | Train Loss: 0.0021444251760840416 | Test Loss: 0.010865701362490654\n",
      "Epoch 133 | Train Loss: 0.0021058644633740187 | Test Loss: 0.010812388733029366\n",
      "Epoch 134 | Train Loss: 0.0020682543981820345 | Test Loss: 0.0107338298112154\n",
      "Epoch 135 | Train Loss: 0.0020318510942161083 | Test Loss: 0.010640542954206467\n",
      "Epoch 136 | Train Loss: 0.00199635187163949 | Test Loss: 0.010564771480858326\n",
      "Epoch 137 | Train Loss: 0.001961885020136833 | Test Loss: 0.01049710065126419\n",
      "Epoch 138 | Train Loss: 0.0019284987356513739 | Test Loss: 0.010418585501611233\n",
      "Epoch 139 | Train Loss: 0.0018960784655064344 | Test Loss: 0.010340062901377678\n",
      "Epoch 140 | Train Loss: 0.0018645128002390265 | Test Loss: 0.01028049923479557\n",
      "Epoch 141 | Train Loss: 0.0018338114023208618 | Test Loss: 0.010233317501842976\n",
      "Epoch 142 | Train Loss: 0.0018038817215710878 | Test Loss: 0.010171995498239994\n",
      "Epoch 143 | Train Loss: 0.0017747670644894242 | Test Loss: 0.01010055746883154\n",
      "Epoch 144 | Train Loss: 0.0017464238917455077 | Test Loss: 0.010046972893178463\n",
      "Epoch 145 | Train Loss: 0.001718738116323948 | Test Loss: 0.010008786804974079\n",
      "Epoch 146 | Train Loss: 0.0016917219618335366 | Test Loss: 0.009958823211491108\n",
      "Epoch 147 | Train Loss: 0.0016654172213748097 | Test Loss: 0.009893692098557949\n",
      "Epoch 148 | Train Loss: 0.0016397560248151422 | Test Loss: 0.009836556389927864\n",
      "Epoch 149 | Train Loss: 0.001614724867977202 | Test Loss: 0.009797031059861183\n",
      "Epoch 150 | Train Loss: 0.001590265310369432 | Test Loss: 0.009756561368703842\n",
      "Epoch 151 | Train Loss: 0.0015664243837818503 | Test Loss: 0.009704380296170712\n",
      "Epoch 152 | Train Loss: 0.001543155056424439 | Test Loss: 0.009652121923863888\n",
      "Epoch 153 | Train Loss: 0.001520439051091671 | Test Loss: 0.009609371423721313\n",
      "Epoch 154 | Train Loss: 0.001498201978392899 | Test Loss: 0.009567308239638805\n",
      "Epoch 155 | Train Loss: 0.0014764675870537758 | Test Loss: 0.009520355612039566\n",
      "Epoch 156 | Train Loss: 0.0014552202774211764 | Test Loss: 0.009476350620388985\n",
      "Epoch 157 | Train Loss: 0.0014344430528581142 | Test Loss: 0.009438317269086838\n",
      "Epoch 158 | Train Loss: 0.00141413533128798 | Test Loss: 0.009403940290212631\n",
      "Epoch 159 | Train Loss: 0.0013942853547632694 | Test Loss: 0.009366597048938274\n",
      "Epoch 160 | Train Loss: 0.0013748644851148129 | Test Loss: 0.009325828403234482\n",
      "Epoch 161 | Train Loss: 0.0013558685313910246 | Test Loss: 0.009285925887525082\n",
      "Epoch 162 | Train Loss: 0.0013373077381402254 | Test Loss: 0.009244197979569435\n",
      "Epoch 163 | Train Loss: 0.001319158123806119 | Test Loss: 0.009205318056046963\n",
      "Epoch 164 | Train Loss: 0.001301390933804214 | Test Loss: 0.009167667478322983\n",
      "Epoch 165 | Train Loss: 0.0012840036069974303 | Test Loss: 0.009131853468716145\n",
      "Epoch 166 | Train Loss: 0.0012669585412368178 | Test Loss: 0.009096094407141209\n",
      "Epoch 167 | Train Loss: 0.0012502616737037897 | Test Loss: 0.009061263874173164\n",
      "Epoch 168 | Train Loss: 0.0012339095119386911 | Test Loss: 0.009029540233314037\n",
      "Epoch 169 | Train Loss: 0.001217903452925384 | Test Loss: 0.009000379592180252\n",
      "Epoch 170 | Train Loss: 0.001202218234539032 | Test Loss: 0.008971410803496838\n",
      "Epoch 171 | Train Loss: 0.0011868398869410157 | Test Loss: 0.00894186645746231\n",
      "Epoch 172 | Train Loss: 0.0011717602610588074 | Test Loss: 0.008914178237318993\n",
      "Epoch 173 | Train Loss: 0.001156984711997211 | Test Loss: 0.008886737748980522\n",
      "Epoch 174 | Train Loss: 0.0011424882104620337 | Test Loss: 0.008855471387505531\n",
      "Epoch 175 | Train Loss: 0.0011282555060461164 | Test Loss: 0.008821663446724415\n",
      "Epoch 176 | Train Loss: 0.0011142767034471035 | Test Loss: 0.008784887380897999\n",
      "Epoch 177 | Train Loss: 0.0011005542473867536 | Test Loss: 0.008742831647396088\n",
      "Epoch 178 | Train Loss: 0.0010870774276554585 | Test Loss: 0.008698509074747562\n",
      "Epoch 179 | Train Loss: 0.0010738522978499532 | Test Loss: 0.008648831397294998\n",
      "Epoch 180 | Train Loss: 0.0010608851443976164 | Test Loss: 0.008607674390077591\n",
      "Epoch 181 | Train Loss: 0.001048176665790379 | Test Loss: 0.008574537932872772\n",
      "Epoch 182 | Train Loss: 0.001035687979310751 | Test Loss: 0.008540935814380646\n",
      "Epoch 183 | Train Loss: 0.0010234221117570996 | Test Loss: 0.008505342528223991\n",
      "Epoch 184 | Train Loss: 0.001011381158605218 | Test Loss: 0.008471471257507801\n",
      "Epoch 185 | Train Loss: 0.0009995432337746024 | Test Loss: 0.008438976481556892\n",
      "Epoch 186 | Train Loss: 0.000987913692370057 | Test Loss: 0.008409100584685802\n",
      "Epoch 187 | Train Loss: 0.0009764584247022867 | Test Loss: 0.008382601663470268\n",
      "Epoch 188 | Train Loss: 0.0009652027511037886 | Test Loss: 0.008354416117072105\n",
      "Epoch 189 | Train Loss: 0.000954131712205708 | Test Loss: 0.008321413770318031\n",
      "Epoch 190 | Train Loss: 0.0009432615479454398 | Test Loss: 0.008287454955279827\n",
      "Epoch 191 | Train Loss: 0.000932566705159843 | Test Loss: 0.008253723382949829\n",
      "Epoch 192 | Train Loss: 0.0009220488136634231 | Test Loss: 0.008218726143240929\n",
      "Epoch 193 | Train Loss: 0.000911676965188235 | Test Loss: 0.008180906064808369\n",
      "Epoch 194 | Train Loss: 0.000901467283256352 | Test Loss: 0.008143345825374126\n",
      "Epoch 195 | Train Loss: 0.0008914411882869899 | Test Loss: 0.008107063360512257\n",
      "Epoch 196 | Train Loss: 0.0008816043264232576 | Test Loss: 0.008070782758295536\n",
      "Epoch 197 | Train Loss: 0.000871945871040225 | Test Loss: 0.00803637970238924\n",
      "Epoch 198 | Train Loss: 0.000862453191075474 | Test Loss: 0.00800071470439434\n",
      "Epoch 199 | Train Loss: 0.0008531077764928341 | Test Loss: 0.00796500127762556\n",
      "Epoch 200 | Train Loss: 0.0008439169032499194 | Test Loss: 0.00792632345110178\n",
      "Epoch 201 | Train Loss: 0.0008348727133125067 | Test Loss: 0.007890474982559681\n",
      "Epoch 202 | Train Loss: 0.0008259728783741593 | Test Loss: 0.007859300822019577\n",
      "Epoch 203 | Train Loss: 0.0008172196103259921 | Test Loss: 0.007833508774638176\n",
      "Epoch 204 | Train Loss: 0.0008086029556579888 | Test Loss: 0.007810420822352171\n",
      "Epoch 205 | Train Loss: 0.0008001138921827078 | Test Loss: 0.007789929863065481\n",
      "Epoch 206 | Train Loss: 0.000791763246525079 | Test Loss: 0.007771119941025972\n",
      "Epoch 207 | Train Loss: 0.0007835444994270802 | Test Loss: 0.0077513763681054115\n",
      "Epoch 208 | Train Loss: 0.000775451713707298 | Test Loss: 0.007729706820100546\n",
      "Epoch 209 | Train Loss: 0.0007674797088839114 | Test Loss: 0.0077050733380019665\n",
      "Epoch 210 | Train Loss: 0.0007596306386403739 | Test Loss: 0.00767969386652112\n",
      "Epoch 211 | Train Loss: 0.000751899613533169 | Test Loss: 0.007654556538909674\n",
      "Epoch 212 | Train Loss: 0.0007442861096933484 | Test Loss: 0.007632063701748848\n",
      "Epoch 213 | Train Loss: 0.0007367859361693263 | Test Loss: 0.007612895220518112\n",
      "Epoch 214 | Train Loss: 0.0007294114329852164 | Test Loss: 0.007597039919346571\n",
      "Epoch 215 | Train Loss: 0.0007221484556794167 | Test Loss: 0.007582901511341333\n",
      "Epoch 216 | Train Loss: 0.0007149959565140307 | Test Loss: 0.007568942382931709\n",
      "Epoch 217 | Train Loss: 0.0007079571369104087 | Test Loss: 0.0075547960586845875\n",
      "Epoch 218 | Train Loss: 0.0007010212284512818 | Test Loss: 0.007537220139056444\n",
      "Epoch 219 | Train Loss: 0.0006941903266124427 | Test Loss: 0.007517566904425621\n",
      "Epoch 220 | Train Loss: 0.0006874576210975647 | Test Loss: 0.007497186306864023\n",
      "Epoch 221 | Train Loss: 0.0006808244506828487 | Test Loss: 0.007476504892110825\n",
      "Epoch 222 | Train Loss: 0.0006742851110175252 | Test Loss: 0.0074555897153913975\n",
      "Epoch 223 | Train Loss: 0.0006678412319160998 | Test Loss: 0.0074365753680467606\n",
      "Epoch 224 | Train Loss: 0.0006614894373342395 | Test Loss: 0.007420395966619253\n",
      "Epoch 225 | Train Loss: 0.000655225245282054 | Test Loss: 0.007406090851873159\n",
      "Epoch 226 | Train Loss: 0.0006490468513220549 | Test Loss: 0.007393306586891413\n",
      "Epoch 227 | Train Loss: 0.0006429603090509772 | Test Loss: 0.007380079012364149\n",
      "Epoch 228 | Train Loss: 0.0006369616603478789 | Test Loss: 0.007364111021161079\n",
      "Epoch 229 | Train Loss: 0.0006310451426543295 | Test Loss: 0.007346067577600479\n",
      "Epoch 230 | Train Loss: 0.0006252145976759493 | Test Loss: 0.007327341008931398\n",
      "Epoch 231 | Train Loss: 0.0006194531451910734 | Test Loss: 0.007306796032935381\n",
      "Epoch 232 | Train Loss: 0.0006137759191915393 | Test Loss: 0.007285956293344498\n",
      "Epoch 233 | Train Loss: 0.0006081766914576292 | Test Loss: 0.007266925647854805\n",
      "Epoch 234 | Train Loss: 0.0006026531918905675 | Test Loss: 0.007248719688504934\n",
      "Epoch 235 | Train Loss: 0.0005972065264359117 | Test Loss: 0.007230711635202169\n",
      "Epoch 236 | Train Loss: 0.000591826334130019 | Test Loss: 0.0072141364216804504\n",
      "Epoch 237 | Train Loss: 0.0005865118000656366 | Test Loss: 0.007198108360171318\n",
      "Epoch 238 | Train Loss: 0.0005812678136862814 | Test Loss: 0.007180630695074797\n",
      "Epoch 239 | Train Loss: 0.000576095946598798 | Test Loss: 0.007163055706769228\n",
      "Epoch 240 | Train Loss: 0.0005709970719181001 | Test Loss: 0.0071452222764492035\n",
      "Epoch 241 | Train Loss: 0.0005659586749970913 | Test Loss: 0.007126093842089176\n",
      "Epoch 242 | Train Loss: 0.0005609773215837777 | Test Loss: 0.007105650845915079\n",
      "Epoch 243 | Train Loss: 0.0005560607532970607 | Test Loss: 0.007086768746376038\n",
      "Epoch 244 | Train Loss: 0.000551203906070441 | Test Loss: 0.0070693534798920155\n",
      "Epoch 245 | Train Loss: 0.0005464100977405906 | Test Loss: 0.007052336819469929\n",
      "Epoch 246 | Train Loss: 0.0005416770582087338 | Test Loss: 0.007036255672574043\n",
      "Epoch 247 | Train Loss: 0.0005369997234083712 | Test Loss: 0.007021336350589991\n",
      "Epoch 248 | Train Loss: 0.0005323817022144794 | Test Loss: 0.007007130887359381\n",
      "Epoch 249 | Train Loss: 0.0005278229364193976 | Test Loss: 0.0069926027208566666\n",
      "Epoch 250 | Train Loss: 0.0005233190022408962 | Test Loss: 0.00697818910703063\n",
      "Epoch 251 | Train Loss: 0.0005188763607293367 | Test Loss: 0.006964521482586861\n",
      "Epoch 252 | Train Loss: 0.0005144886672496796 | Test Loss: 0.0069500356912612915\n",
      "Epoch 253 | Train Loss: 0.000510156387463212 | Test Loss: 0.006934160366654396\n",
      "Epoch 254 | Train Loss: 0.0005058792303316295 | Test Loss: 0.006918686907738447\n",
      "Epoch 255 | Train Loss: 0.0005016520153731108 | Test Loss: 0.006903449073433876\n",
      "Epoch 256 | Train Loss: 0.0004974788171239197 | Test Loss: 0.006887682713568211\n",
      "Epoch 257 | Train Loss: 0.0004933553282171488 | Test Loss: 0.00687218876555562\n",
      "Epoch 258 | Train Loss: 0.0004892852739430964 | Test Loss: 0.006857669446617365\n",
      "Epoch 259 | Train Loss: 0.0004852650163229555 | Test Loss: 0.006843160837888718\n",
      "Epoch 260 | Train Loss: 0.00048128992784768343 | Test Loss: 0.006826863624155521\n",
      "Epoch 261 | Train Loss: 0.0004773586697410792 | Test Loss: 0.006809989921748638\n",
      "Epoch 262 | Train Loss: 0.0004734774702228606 | Test Loss: 0.006794186774641275\n",
      "Epoch 263 | Train Loss: 0.000469639286166057 | Test Loss: 0.006778606213629246\n",
      "Epoch 264 | Train Loss: 0.00046584795927628875 | Test Loss: 0.006762262433767319\n",
      "Epoch 265 | Train Loss: 0.00046210380969569087 | Test Loss: 0.006745940074324608\n",
      "Epoch 266 | Train Loss: 0.0004584029084071517 | Test Loss: 0.006730431225150824\n",
      "Epoch 267 | Train Loss: 0.0004547439457383007 | Test Loss: 0.006715388502925634\n",
      "Epoch 268 | Train Loss: 0.0004511279985308647 | Test Loss: 0.006699398625642061\n",
      "Epoch 269 | Train Loss: 0.0004475518362596631 | Test Loss: 0.006683695130050182\n",
      "Epoch 270 | Train Loss: 0.00044402002822607756 | Test Loss: 0.006669313181191683\n",
      "Epoch 271 | Train Loss: 0.000440525560406968 | Test Loss: 0.006655749399214983\n",
      "Epoch 272 | Train Loss: 0.00043707233271561563 | Test Loss: 0.006641787476837635\n",
      "Epoch 273 | Train Loss: 0.0004336551937740296 | Test Loss: 0.006627214606851339\n",
      "Epoch 274 | Train Loss: 0.00043027568608522415 | Test Loss: 0.006611427757889032\n",
      "Epoch 275 | Train Loss: 0.00042693590512499213 | Test Loss: 0.006594635546207428\n",
      "Epoch 276 | Train Loss: 0.0004236318345647305 | Test Loss: 0.006576926913112402\n",
      "Epoch 277 | Train Loss: 0.00042036434751935303 | Test Loss: 0.0065595065243542194\n",
      "Epoch 278 | Train Loss: 0.000417134549934417 | Test Loss: 0.006542309187352657\n",
      "Epoch 279 | Train Loss: 0.0004139377560932189 | Test Loss: 0.0065254103392362595\n",
      "Epoch 280 | Train Loss: 0.00041077687637880445 | Test Loss: 0.006509656086564064\n",
      "Epoch 281 | Train Loss: 0.0004076510085724294 | Test Loss: 0.006495154928416014\n",
      "Epoch 282 | Train Loss: 0.0004045602399855852 | Test Loss: 0.006480967625975609\n",
      "Epoch 283 | Train Loss: 0.000401507830247283 | Test Loss: 0.006467212922871113\n",
      "Epoch 284 | Train Loss: 0.00039849194581620395 | Test Loss: 0.006453863810747862\n",
      "Epoch 285 | Train Loss: 0.0003955113352276385 | Test Loss: 0.0064407517202198505\n",
      "Epoch 286 | Train Loss: 0.0003925605269614607 | Test Loss: 0.00642822403460741\n",
      "Epoch 287 | Train Loss: 0.0003896442649420351 | Test Loss: 0.006416636053472757\n",
      "Epoch 288 | Train Loss: 0.0003867612686008215 | Test Loss: 0.0064050909131765366\n",
      "Epoch 289 | Train Loss: 0.0003839036507997662 | Test Loss: 0.006393436808139086\n",
      "Epoch 290 | Train Loss: 0.00038107699947431684 | Test Loss: 0.006381981540471315\n",
      "Epoch 291 | Train Loss: 0.00037828099448233843 | Test Loss: 0.006370970979332924\n",
      "Epoch 292 | Train Loss: 0.00037551819696091115 | Test Loss: 0.006360670085996389\n",
      "Epoch 293 | Train Loss: 0.0003727849980350584 | Test Loss: 0.006350229494273663\n",
      "Epoch 294 | Train Loss: 0.00037008034996688366 | Test Loss: 0.006340002175420523\n",
      "Epoch 295 | Train Loss: 0.0003674033796414733 | Test Loss: 0.006330042611807585\n",
      "Epoch 296 | Train Loss: 0.00036475725937634706 | Test Loss: 0.006320477928966284\n",
      "Epoch 297 | Train Loss: 0.00036213992279954255 | Test Loss: 0.006311008241027594\n",
      "Epoch 298 | Train Loss: 0.0003595482266973704 | Test Loss: 0.006301692221313715\n",
      "Epoch 299 | Train Loss: 0.000356990029104054 | Test Loss: 0.006292673293501139\n",
      "Epoch 300 | Train Loss: 0.0003544585779309273 | Test Loss: 0.006284058094024658\n",
      "Epoch 301 | Train Loss: 0.00035195742384530604 | Test Loss: 0.006275599356740713\n",
      "Epoch 302 | Train Loss: 0.00034948272514156997 | Test Loss: 0.006267464254051447\n",
      "Epoch 303 | Train Loss: 0.0003470318333711475 | Test Loss: 0.006259748712182045\n",
      "Epoch 304 | Train Loss: 0.00034461007453501225 | Test Loss: 0.006252317223697901\n",
      "Epoch 305 | Train Loss: 0.00034221317037008703 | Test Loss: 0.0062453290447592735\n",
      "Epoch 306 | Train Loss: 0.00033984382753260434 | Test Loss: 0.006237946450710297\n",
      "Epoch 307 | Train Loss: 0.00033749916474334896 | Test Loss: 0.006230607628822327\n",
      "Epoch 308 | Train Loss: 0.00033518002601340413 | Test Loss: 0.00622291024774313\n",
      "Epoch 309 | Train Loss: 0.00033288440317846835 | Test Loss: 0.0062155406922101974\n",
      "Epoch 310 | Train Loss: 0.00033061482827179134 | Test Loss: 0.006208532489836216\n",
      "Epoch 311 | Train Loss: 0.0003283684782218188 | Test Loss: 0.006201834883540869\n",
      "Epoch 312 | Train Loss: 0.0003261443052906543 | Test Loss: 0.006194956600666046\n",
      "Epoch 313 | Train Loss: 0.0003239471698179841 | Test Loss: 0.006188097409904003\n",
      "Epoch 314 | Train Loss: 0.00032177093089558184 | Test Loss: 0.006181028205901384\n",
      "Epoch 315 | Train Loss: 0.00031961590866558254 | Test Loss: 0.0061740567907691\n",
      "Epoch 316 | Train Loss: 0.000317482219543308 | Test Loss: 0.006167442537844181\n",
      "Epoch 317 | Train Loss: 0.0003153713187202811 | Test Loss: 0.006161099765449762\n",
      "Epoch 318 | Train Loss: 0.00031328178010880947 | Test Loss: 0.0061545101925730705\n",
      "Epoch 319 | Train Loss: 0.0003112147969659418 | Test Loss: 0.006147377192974091\n",
      "Epoch 320 | Train Loss: 0.0003091699618380517 | Test Loss: 0.006139968056231737\n",
      "Epoch 321 | Train Loss: 0.000307144015096128 | Test Loss: 0.0061326599679887295\n",
      "Epoch 322 | Train Loss: 0.0003051379171665758 | Test Loss: 0.006125481799244881\n",
      "Epoch 323 | Train Loss: 0.0003031500964425504 | Test Loss: 0.00611863425001502\n",
      "Epoch 324 | Train Loss: 0.00030118130962364376 | Test Loss: 0.006111877039074898\n",
      "Epoch 325 | Train Loss: 0.00029923260444775224 | Test Loss: 0.0061056423000991344\n",
      "Epoch 326 | Train Loss: 0.00029730264213867486 | Test Loss: 0.006099597550928593\n",
      "Epoch 327 | Train Loss: 0.00029539389652200043 | Test Loss: 0.006093266885727644\n",
      "Epoch 328 | Train Loss: 0.0002935027296189219 | Test Loss: 0.006086804438382387\n",
      "Epoch 329 | Train Loss: 0.00029163126600906253 | Test Loss: 0.006080241873860359\n",
      "Epoch 330 | Train Loss: 0.00028977717738598585 | Test Loss: 0.006074185017496347\n",
      "Epoch 331 | Train Loss: 0.0002879446547012776 | Test Loss: 0.006068305112421513\n",
      "Epoch 332 | Train Loss: 0.000286125490674749 | Test Loss: 0.006062827538698912\n",
      "Epoch 333 | Train Loss: 0.0002843230904545635 | Test Loss: 0.0060574086382985115\n",
      "Epoch 334 | Train Loss: 0.0002825411793310195 | Test Loss: 0.006051958538591862\n",
      "Epoch 335 | Train Loss: 0.0002807730052154511 | Test Loss: 0.006046554073691368\n",
      "Epoch 336 | Train Loss: 0.0002790235448628664 | Test Loss: 0.006041154731065035\n",
      "Epoch 337 | Train Loss: 0.0002772885200101882 | Test Loss: 0.006035628728568554\n",
      "Epoch 338 | Train Loss: 0.0002755695313680917 | Test Loss: 0.006029521580785513\n",
      "Epoch 339 | Train Loss: 0.0002738690236583352 | Test Loss: 0.006022690329700708\n",
      "Epoch 340 | Train Loss: 0.00027218295144848526 | Test Loss: 0.006015479099005461\n",
      "Epoch 341 | Train Loss: 0.00027051285724155605 | Test Loss: 0.0060084485448896885\n",
      "Epoch 342 | Train Loss: 0.00026885882834903896 | Test Loss: 0.00600144499912858\n",
      "Epoch 343 | Train Loss: 0.00026721987524069846 | Test Loss: 0.005994824226945639\n",
      "Epoch 344 | Train Loss: 0.0002655965799931437 | Test Loss: 0.00598879624158144\n",
      "Epoch 345 | Train Loss: 0.0002639883605297655 | Test Loss: 0.0059831952676177025\n",
      "Epoch 346 | Train Loss: 0.00026239483850076795 | Test Loss: 0.005977606866508722\n",
      "Epoch 347 | Train Loss: 0.00026081380201503634 | Test Loss: 0.005971603561192751\n",
      "Epoch 348 | Train Loss: 0.0002592477831058204 | Test Loss: 0.00596515042707324\n",
      "Epoch 349 | Train Loss: 0.00025769343483261764 | Test Loss: 0.00595847750082612\n",
      "Epoch 350 | Train Loss: 0.0002561543951742351 | Test Loss: 0.005951606668531895\n",
      "Epoch 351 | Train Loss: 0.0002546228060964495 | Test Loss: 0.005944301374256611\n",
      "Epoch 352 | Train Loss: 0.0002531000063754618 | Test Loss: 0.00593752833083272\n",
      "Epoch 353 | Train Loss: 0.00025159650249406695 | Test Loss: 0.005933813285082579\n",
      "Epoch 354 | Train Loss: 0.00025010918034240603 | Test Loss: 0.005930351559072733\n",
      "Epoch 355 | Train Loss: 0.0002486285229679197 | Test Loss: 0.005927633959800005\n",
      "Epoch 356 | Train Loss: 0.00024716503685340285 | Test Loss: 0.005924403667449951\n",
      "Epoch 357 | Train Loss: 0.00024571752874180675 | Test Loss: 0.005920334253460169\n",
      "Epoch 358 | Train Loss: 0.0002442824770696461 | Test Loss: 0.005914869252592325\n",
      "Epoch 359 | Train Loss: 0.00024285570543725044 | Test Loss: 0.0059075672179460526\n",
      "Epoch 360 | Train Loss: 0.00024143750488292426 | Test Loss: 0.005898998584598303\n",
      "Epoch 361 | Train Loss: 0.00024003046564757824 | Test Loss: 0.005889974534511566\n",
      "Epoch 362 | Train Loss: 0.0002386379346717149 | Test Loss: 0.005880812648683786\n",
      "Epoch 363 | Train Loss: 0.00023725956270936877 | Test Loss: 0.005872267764061689\n",
      "Epoch 364 | Train Loss: 0.00023589526244904846 | Test Loss: 0.005864457692950964\n",
      "Epoch 365 | Train Loss: 0.00023454100301023573 | Test Loss: 0.0058578141033649445\n",
      "Epoch 366 | Train Loss: 0.00023319928732234985 | Test Loss: 0.005852611735463142\n",
      "Epoch 367 | Train Loss: 0.00023186721955426037 | Test Loss: 0.0058483243919909\n",
      "Epoch 368 | Train Loss: 0.000230545672820881 | Test Loss: 0.005844511557370424\n",
      "Epoch 369 | Train Loss: 0.000229238357860595 | Test Loss: 0.005840609315782785\n",
      "Epoch 370 | Train Loss: 0.00022794307733420283 | Test Loss: 0.0058358581736683846\n",
      "Epoch 371 | Train Loss: 0.00022666003496851772 | Test Loss: 0.005830048583447933\n",
      "Epoch 372 | Train Loss: 0.0002253865241073072 | Test Loss: 0.005823428276926279\n",
      "Epoch 373 | Train Loss: 0.0002241237962152809 | Test Loss: 0.005816264543682337\n",
      "Epoch 374 | Train Loss: 0.0002228665689472109 | Test Loss: 0.0058090416714549065\n",
      "Epoch 375 | Train Loss: 0.00022162709501571953 | Test Loss: 0.00580231798812747\n",
      "Epoch 376 | Train Loss: 0.000220395959331654 | Test Loss: 0.0057962145656347275\n",
      "Epoch 377 | Train Loss: 0.00021917656704317778 | Test Loss: 0.005790694151073694\n",
      "Epoch 378 | Train Loss: 0.0002179681760026142 | Test Loss: 0.0057862745597958565\n",
      "Epoch 379 | Train Loss: 0.00021676672622561455 | Test Loss: 0.005782255437225103\n",
      "Epoch 380 | Train Loss: 0.00021557601576205343 | Test Loss: 0.005778667517006397\n",
      "Epoch 381 | Train Loss: 0.00021439712145365775 | Test Loss: 0.00577537901699543\n",
      "Epoch 382 | Train Loss: 0.00021322848624549806 | Test Loss: 0.005772142205387354\n",
      "Epoch 383 | Train Loss: 0.00021206872770562768 | Test Loss: 0.005768921691924334\n",
      "Epoch 384 | Train Loss: 0.00021091791859362274 | Test Loss: 0.005765897687524557\n",
      "Epoch 385 | Train Loss: 0.0002097778778988868 | Test Loss: 0.005762588232755661\n",
      "Epoch 386 | Train Loss: 0.00020864562247879803 | Test Loss: 0.005758904851973057\n",
      "Epoch 387 | Train Loss: 0.00020752438285853714 | Test Loss: 0.005755096208304167\n",
      "Epoch 388 | Train Loss: 0.00020641232549678534 | Test Loss: 0.0057513113133609295\n",
      "Epoch 389 | Train Loss: 0.0002053089701803401 | Test Loss: 0.005747106391936541\n",
      "Epoch 390 | Train Loss: 0.00020421513181645423 | Test Loss: 0.0057425894774496555\n",
      "Epoch 391 | Train Loss: 0.00020313089771661907 | Test Loss: 0.00573794636875391\n",
      "Epoch 392 | Train Loss: 0.0002020577376242727 | Test Loss: 0.00573386438190937\n",
      "Epoch 393 | Train Loss: 0.00020099249377381057 | Test Loss: 0.005730537232011557\n",
      "Epoch 394 | Train Loss: 0.00019993433670606464 | Test Loss: 0.005727529060095549\n",
      "Epoch 395 | Train Loss: 0.0001988866861211136 | Test Loss: 0.005724496673792601\n",
      "Epoch 396 | Train Loss: 0.00019784615142270923 | Test Loss: 0.005721312947571278\n",
      "Epoch 397 | Train Loss: 0.00019681506091728806 | Test Loss: 0.005717611871659756\n",
      "Epoch 398 | Train Loss: 0.00019579271611291915 | Test Loss: 0.005713421851396561\n",
      "Epoch 399 | Train Loss: 0.00019477904425002635 | Test Loss: 0.005708769429475069\n",
      "Epoch 400 | Train Loss: 0.00019377384160179645 | Test Loss: 0.0057044485583901405\n",
      "Epoch 401 | Train Loss: 0.0001927748671732843 | Test Loss: 0.005700434558093548\n",
      "Epoch 402 | Train Loss: 0.0001917866466101259 | Test Loss: 0.005696763284504414\n",
      "Epoch 403 | Train Loss: 0.00019080359197687358 | Test Loss: 0.005693093407899141\n",
      "Epoch 404 | Train Loss: 0.00018982896290253848 | Test Loss: 0.005689979996532202\n",
      "Epoch 405 | Train Loss: 0.0001888617844088003 | Test Loss: 0.005686687305569649\n",
      "Epoch 406 | Train Loss: 0.00018790349713526666 | Test Loss: 0.005683003459125757\n",
      "Epoch 407 | Train Loss: 0.00018695168546400964 | Test Loss: 0.005678936839103699\n",
      "Epoch 408 | Train Loss: 0.00018600616022013128 | Test Loss: 0.005675134714692831\n",
      "Epoch 409 | Train Loss: 0.00018506990454625338 | Test Loss: 0.005671650171279907\n",
      "Epoch 410 | Train Loss: 0.0001841405319282785 | Test Loss: 0.005667916964739561\n",
      "Epoch 411 | Train Loss: 0.00018321712559554726 | Test Loss: 0.005663767922669649\n",
      "Epoch 412 | Train Loss: 0.00018230198475066572 | Test Loss: 0.005659244954586029\n",
      "Epoch 413 | Train Loss: 0.00018139323219656944 | Test Loss: 0.005654800683259964\n",
      "Epoch 414 | Train Loss: 0.00018049083882942796 | Test Loss: 0.005650395527482033\n",
      "Epoch 415 | Train Loss: 0.0001795952266547829 | Test Loss: 0.005645615980029106\n",
      "Epoch 416 | Train Loss: 0.00017870691954158247 | Test Loss: 0.005640474613755941\n",
      "Epoch 417 | Train Loss: 0.00017782599024940282 | Test Loss: 0.005635413806885481\n",
      "Epoch 418 | Train Loss: 0.00017695128917694092 | Test Loss: 0.005630364175885916\n",
      "Epoch 419 | Train Loss: 0.00017608316557016224 | Test Loss: 0.005625059362500906\n",
      "Epoch 420 | Train Loss: 0.00017522268171887845 | Test Loss: 0.005619867239147425\n",
      "Epoch 421 | Train Loss: 0.00017436886264476925 | Test Loss: 0.005615802016109228\n",
      "Epoch 422 | Train Loss: 0.0001735207042656839 | Test Loss: 0.005612022243440151\n",
      "Epoch 423 | Train Loss: 0.0001726787886582315 | Test Loss: 0.0056084198877215385\n",
      "Epoch 424 | Train Loss: 0.0001718435378279537 | Test Loss: 0.005604732781648636\n",
      "Epoch 425 | Train Loss: 0.0001710145006654784 | Test Loss: 0.00560070900246501\n",
      "Epoch 426 | Train Loss: 0.00017019198276102543 | Test Loss: 0.005596593488007784\n",
      "Epoch 427 | Train Loss: 0.00016937540203798562 | Test Loss: 0.005593018606305122\n",
      "Epoch 428 | Train Loss: 0.0001685652241576463 | Test Loss: 0.005589670967310667\n",
      "Epoch 429 | Train Loss: 0.0001677571126492694 | Test Loss: 0.005586318206042051\n",
      "Epoch 430 | Train Loss: 0.00016695707745384425 | Test Loss: 0.005583279300481081\n",
      "Epoch 431 | Train Loss: 0.0001661636051721871 | Test Loss: 0.005580323748290539\n",
      "Epoch 432 | Train Loss: 0.00016537769988644868 | Test Loss: 0.005576912313699722\n",
      "Epoch 433 | Train Loss: 0.00016459486505482346 | Test Loss: 0.005573037546128035\n",
      "Epoch 434 | Train Loss: 0.00016381900059059262 | Test Loss: 0.005569659173488617\n",
      "Epoch 435 | Train Loss: 0.00016304814198520035 | Test Loss: 0.005565890576690435\n",
      "Epoch 436 | Train Loss: 0.00016228380263783038 | Test Loss: 0.00556214852258563\n",
      "Epoch 437 | Train Loss: 0.00016152359603438526 | Test Loss: 0.005558487959206104\n",
      "Epoch 438 | Train Loss: 0.00016076830797828734 | Test Loss: 0.0055548991076648235\n",
      "Epoch 439 | Train Loss: 0.00016002063057385385 | Test Loss: 0.0055517470464110374\n",
      "Epoch 440 | Train Loss: 0.0001592771732248366 | Test Loss: 0.005548490677028894\n",
      "Epoch 441 | Train Loss: 0.0001585386780789122 | Test Loss: 0.005544917192310095\n",
      "Epoch 442 | Train Loss: 0.0001578041265020147 | Test Loss: 0.005541508086025715\n",
      "Epoch 443 | Train Loss: 0.00015707590500824153 | Test Loss: 0.005539052188396454\n",
      "Epoch 444 | Train Loss: 0.00015635366435162723 | Test Loss: 0.00553592573851347\n",
      "Epoch 445 | Train Loss: 0.00015563644410576671 | Test Loss: 0.005532182287424803\n",
      "Epoch 446 | Train Loss: 0.00015492462262045592 | Test Loss: 0.0055286032147705555\n",
      "Epoch 447 | Train Loss: 0.00015421674470417202 | Test Loss: 0.0055254544131457806\n",
      "Epoch 448 | Train Loss: 0.0001535145565867424 | Test Loss: 0.005523025058209896\n",
      "Epoch 449 | Train Loss: 0.0001528168941149488 | Test Loss: 0.005520172417163849\n",
      "Epoch 450 | Train Loss: 0.00015212495054583997 | Test Loss: 0.005516794975847006\n",
      "Epoch 451 | Train Loss: 0.00015143580094445497 | Test Loss: 0.005512907635420561\n",
      "Epoch 452 | Train Loss: 0.00015075162809807807 | Test Loss: 0.005510095041245222\n",
      "Epoch 453 | Train Loss: 0.00015007215552031994 | Test Loss: 0.005508288275450468\n",
      "Epoch 454 | Train Loss: 0.00014939723769202828 | Test Loss: 0.0055063823238015175\n",
      "Epoch 455 | Train Loss: 0.0001487253757659346 | Test Loss: 0.005503935739398003\n",
      "Epoch 456 | Train Loss: 0.00014805991668254137 | Test Loss: 0.00550093362107873\n",
      "Epoch 457 | Train Loss: 0.00014739840116817504 | Test Loss: 0.005497328005731106\n",
      "Epoch 458 | Train Loss: 0.00014674049452878535 | Test Loss: 0.005494262557476759\n",
      "Epoch 459 | Train Loss: 0.00014608704077545553 | Test Loss: 0.005491606891155243\n",
      "Epoch 460 | Train Loss: 0.00014543994620908052 | Test Loss: 0.005488497205078602\n",
      "Epoch 461 | Train Loss: 0.000144793521030806 | Test Loss: 0.005485054105520248\n",
      "Epoch 462 | Train Loss: 0.00014415332407224923 | Test Loss: 0.005481330212205648\n",
      "Epoch 463 | Train Loss: 0.0001435172016499564 | Test Loss: 0.005478177685290575\n",
      "Epoch 464 | Train Loss: 0.00014288628881331533 | Test Loss: 0.0054756952449679375\n",
      "Epoch 465 | Train Loss: 0.00014226035273168236 | Test Loss: 0.005472831893712282\n",
      "Epoch 466 | Train Loss: 0.00014163655578158796 | Test Loss: 0.005469788797199726\n",
      "Epoch 467 | Train Loss: 0.00014101718261372298 | Test Loss: 0.00546649843454361\n",
      "Epoch 468 | Train Loss: 0.00014040233509149402 | Test Loss: 0.005463854875415564\n",
      "Epoch 469 | Train Loss: 0.00013979070354253054 | Test Loss: 0.0054616001434624195\n",
      "Epoch 470 | Train Loss: 0.0001391838741255924 | Test Loss: 0.00545854028314352\n",
      "Epoch 471 | Train Loss: 0.0001385809446219355 | Test Loss: 0.005455141421407461\n",
      "Epoch 472 | Train Loss: 0.00013798226427752525 | Test Loss: 0.00545161310583353\n",
      "Epoch 473 | Train Loss: 0.00013738802226725966 | Test Loss: 0.0054481676779687405\n",
      "Epoch 474 | Train Loss: 0.0001367968216072768 | Test Loss: 0.005445762537419796\n",
      "Epoch 475 | Train Loss: 0.00013620959362015128 | Test Loss: 0.0054440852254629135\n",
      "Epoch 476 | Train Loss: 0.00013562588719651103 | Test Loss: 0.0054422589018940926\n",
      "Epoch 477 | Train Loss: 0.0001350471138721332 | Test Loss: 0.00543978251516819\n",
      "Epoch 478 | Train Loss: 0.00013447055243887007 | Test Loss: 0.0054368809796869755\n",
      "Epoch 479 | Train Loss: 0.00013389856030698866 | Test Loss: 0.00543341925367713\n",
      "Epoch 480 | Train Loss: 0.00013332825619727373 | Test Loss: 0.005430871620774269\n",
      "Epoch 481 | Train Loss: 0.00013276300160214305 | Test Loss: 0.0054292986169457436\n",
      "Epoch 482 | Train Loss: 0.0001322009920841083 | Test Loss: 0.005427882540971041\n",
      "Epoch 483 | Train Loss: 0.00013164302799850702 | Test Loss: 0.005425871815532446\n",
      "Epoch 484 | Train Loss: 0.0001310883671976626 | Test Loss: 0.005423394031822681\n",
      "Epoch 485 | Train Loss: 0.00013053714064881206 | Test Loss: 0.00542054558172822\n",
      "Epoch 486 | Train Loss: 0.00012998962483834475 | Test Loss: 0.005418153014034033\n",
      "Epoch 487 | Train Loss: 0.00012944494665134698 | Test Loss: 0.005416340194642544\n",
      "Epoch 488 | Train Loss: 0.00012890151992905885 | Test Loss: 0.005414031911641359\n",
      "Epoch 489 | Train Loss: 0.0001283638266613707 | Test Loss: 0.0054112887009978294\n",
      "Epoch 490 | Train Loss: 0.00012782879639416933 | Test Loss: 0.005408427678048611\n",
      "Epoch 491 | Train Loss: 0.0001272961962968111 | Test Loss: 0.005405673291534185\n",
      "Epoch 492 | Train Loss: 0.00012676794722210616 | Test Loss: 0.005403279792517424\n",
      "Epoch 493 | Train Loss: 0.0001262403093278408 | Test Loss: 0.005401131231337786\n",
      "Epoch 494 | Train Loss: 0.00012571763363666832 | Test Loss: 0.0053991880267858505\n",
      "Epoch 495 | Train Loss: 0.0001251959620276466 | Test Loss: 0.005396663676947355\n",
      "Epoch 496 | Train Loss: 0.00012467903434298933 | Test Loss: 0.005394101142883301\n",
      "Epoch 497 | Train Loss: 0.0001241655700141564 | Test Loss: 0.005391764920204878\n",
      "Epoch 498 | Train Loss: 0.0001236557145603001 | Test Loss: 0.005389511585235596\n",
      "Epoch 499 | Train Loss: 0.0001231488276971504 | Test Loss: 0.0053869872353971004\n",
      "Epoch 500 | Train Loss: 0.0001226445601787418 | Test Loss: 0.005384262651205063\n",
      "Epoch 501 | Train Loss: 0.000122142126201652 | Test Loss: 0.005381403956562281\n",
      "Epoch 502 | Train Loss: 0.00012164238432887942 | Test Loss: 0.005378613714128733\n",
      "Epoch 503 | Train Loss: 0.00012114607670810074 | Test Loss: 0.005375876557081938\n",
      "Epoch 504 | Train Loss: 0.00012065270129824057 | Test Loss: 0.005372942425310612\n",
      "Epoch 505 | Train Loss: 0.00012016433174721897 | Test Loss: 0.00536991935223341\n",
      "Epoch 506 | Train Loss: 0.00011967632599407807 | Test Loss: 0.005366855766624212\n",
      "Epoch 507 | Train Loss: 0.00011919271491933614 | Test Loss: 0.005363829899579287\n",
      "Epoch 508 | Train Loss: 0.00011871261085616425 | Test Loss: 0.005360843148082495\n",
      "Epoch 509 | Train Loss: 0.00011823573731817305 | Test Loss: 0.005358206108212471\n",
      "Epoch 510 | Train Loss: 0.00011776095198001713 | Test Loss: 0.00535580376163125\n",
      "Epoch 511 | Train Loss: 0.00011728855315595865 | Test Loss: 0.0053535448387265205\n",
      "Epoch 512 | Train Loss: 0.00011682025069603696 | Test Loss: 0.005351029336452484\n",
      "Epoch 513 | Train Loss: 0.00011635409464361146 | Test Loss: 0.005348287522792816\n",
      "Epoch 514 | Train Loss: 0.0001158919112640433 | Test Loss: 0.005345560610294342\n",
      "Epoch 515 | Train Loss: 0.00011543116852408275 | Test Loss: 0.005342737305909395\n",
      "Epoch 516 | Train Loss: 0.00011497204832267016 | Test Loss: 0.005340033210813999\n",
      "Epoch 517 | Train Loss: 0.00011451721366029233 | Test Loss: 0.005337032023817301\n",
      "Epoch 518 | Train Loss: 0.00011406384874135256 | Test Loss: 0.005334119778126478\n",
      "Epoch 519 | Train Loss: 0.00011361323413439095 | Test Loss: 0.005331478081643581\n",
      "Epoch 520 | Train Loss: 0.00011316689051454887 | Test Loss: 0.005329174920916557\n",
      "Epoch 521 | Train Loss: 0.00011272184201516211 | Test Loss: 0.0053269644267857075\n",
      "Epoch 522 | Train Loss: 0.00011227950017200783 | Test Loss: 0.005324915982782841\n",
      "Epoch 523 | Train Loss: 0.00011184169125044718 | Test Loss: 0.005322709679603577\n",
      "Epoch 524 | Train Loss: 0.00011140362039441243 | Test Loss: 0.005320652388036251\n",
      "Epoch 525 | Train Loss: 0.0001109694640035741 | Test Loss: 0.005318527575582266\n",
      "Epoch 526 | Train Loss: 0.0001105383489630185 | Test Loss: 0.005316269584000111\n",
      "Epoch 527 | Train Loss: 0.00011010935850208625 | Test Loss: 0.005314167123287916\n",
      "Epoch 528 | Train Loss: 0.00010968352580675855 | Test Loss: 0.005312096327543259\n",
      "Epoch 529 | Train Loss: 0.00010926030518021435 | Test Loss: 0.005310141947120428\n",
      "Epoch 530 | Train Loss: 0.00010883690265472978 | Test Loss: 0.005308377090841532\n",
      "Epoch 531 | Train Loss: 0.00010841710172826424 | Test Loss: 0.005306526552885771\n",
      "Epoch 532 | Train Loss: 0.0001080012516467832 | Test Loss: 0.005304444581270218\n",
      "Epoch 533 | Train Loss: 0.00010758664575405419 | Test Loss: 0.0053023686632514\n",
      "Epoch 534 | Train Loss: 0.00010717447003116831 | Test Loss: 0.0053004128858447075\n",
      "Epoch 535 | Train Loss: 0.00010676650708774105 | Test Loss: 0.00529838353395462\n",
      "Epoch 536 | Train Loss: 0.00010636010119924322 | Test Loss: 0.005296352319419384\n",
      "Epoch 537 | Train Loss: 0.00010595488856779411 | Test Loss: 0.005294501315802336\n",
      "Epoch 538 | Train Loss: 0.00010555451444815844 | Test Loss: 0.005292439367622137\n",
      "Epoch 539 | Train Loss: 0.00010515346366446465 | Test Loss: 0.005290400702506304\n",
      "Epoch 540 | Train Loss: 0.00010475541785126552 | Test Loss: 0.005288110580295324\n",
      "Epoch 541 | Train Loss: 0.00010436051525175571 | Test Loss: 0.0052859047427773476\n",
      "Epoch 542 | Train Loss: 0.00010396780999144539 | Test Loss: 0.005283914506435394\n",
      "Epoch 543 | Train Loss: 0.00010357489372836426 | Test Loss: 0.005281945690512657\n",
      "Epoch 544 | Train Loss: 0.00010318706335965544 | Test Loss: 0.00527998199686408\n",
      "Epoch 545 | Train Loss: 0.0001028002516250126 | Test Loss: 0.005278293043375015\n",
      "Epoch 546 | Train Loss: 0.00010241492418572307 | Test Loss: 0.005276791751384735\n",
      "Epoch 547 | Train Loss: 0.00010203174315392971 | Test Loss: 0.005275321193039417\n",
      "Epoch 548 | Train Loss: 0.00010165254934690893 | Test Loss: 0.005273912101984024\n",
      "Epoch 549 | Train Loss: 0.00010127574932994321 | Test Loss: 0.0052726962603628635\n",
      "Epoch 550 | Train Loss: 0.00010089890565723181 | Test Loss: 0.005271511152386665\n",
      "Epoch 551 | Train Loss: 0.00010052577999886125 | Test Loss: 0.005270181689411402\n",
      "Epoch 552 | Train Loss: 0.0001001537311822176 | Test Loss: 0.005268825683742762\n",
      "Epoch 553 | Train Loss: 9.978410525945947e-05 | Test Loss: 0.005267547443509102\n",
      "Epoch 554 | Train Loss: 9.941616735886782e-05 | Test Loss: 0.005265961866825819\n",
      "Epoch 555 | Train Loss: 9.905083425110206e-05 | Test Loss: 0.005264176521450281\n",
      "Epoch 556 | Train Loss: 9.868723282124847e-05 | Test Loss: 0.005262596532702446\n",
      "Epoch 557 | Train Loss: 9.83253339654766e-05 | Test Loss: 0.005261119455099106\n",
      "Epoch 558 | Train Loss: 9.796644008019939e-05 | Test Loss: 0.0052597010508179665\n",
      "Epoch 559 | Train Loss: 9.760935790836811e-05 | Test Loss: 0.005258401855826378\n",
      "Epoch 560 | Train Loss: 9.72523121163249e-05 | Test Loss: 0.005256939213722944\n",
      "Epoch 561 | Train Loss: 9.689966827863827e-05 | Test Loss: 0.005255102179944515\n",
      "Epoch 562 | Train Loss: 9.654745372245088e-05 | Test Loss: 0.0052533275447785854\n",
      "Epoch 563 | Train Loss: 9.619735646992922e-05 | Test Loss: 0.005251956172287464\n",
      "Epoch 564 | Train Loss: 9.584915824234486e-05 | Test Loss: 0.005250636022537947\n",
      "Epoch 565 | Train Loss: 9.550333925290033e-05 | Test Loss: 0.005249135661870241\n",
      "Epoch 566 | Train Loss: 9.515857527730986e-05 | Test Loss: 0.005247654393315315\n",
      "Epoch 567 | Train Loss: 9.481675078859553e-05 | Test Loss: 0.00524619547650218\n",
      "Epoch 568 | Train Loss: 9.447681804886088e-05 | Test Loss: 0.005244691856205463\n",
      "Epoch 569 | Train Loss: 9.413735824637115e-05 | Test Loss: 0.005243346095085144\n",
      "Epoch 570 | Train Loss: 9.380182746099308e-05 | Test Loss: 0.0052422042936086655\n",
      "Epoch 571 | Train Loss: 9.346561273559928e-05 | Test Loss: 0.005241231061518192\n",
      "Epoch 572 | Train Loss: 9.313309419667348e-05 | Test Loss: 0.005240317899733782\n",
      "Epoch 573 | Train Loss: 9.280181984649971e-05 | Test Loss: 0.00523929949849844\n",
      "Epoch 574 | Train Loss: 9.247224079445004e-05 | Test Loss: 0.005238075274974108\n",
      "Epoch 575 | Train Loss: 9.214424790116027e-05 | Test Loss: 0.005236829165369272\n",
      "Epoch 576 | Train Loss: 9.181605855701491e-05 | Test Loss: 0.005235609598457813\n",
      "Epoch 577 | Train Loss: 9.14924603421241e-05 | Test Loss: 0.005234288517385721\n",
      "Epoch 578 | Train Loss: 9.116933506447822e-05 | Test Loss: 0.0052329739555716515\n",
      "Epoch 579 | Train Loss: 9.084877092391253e-05 | Test Loss: 0.005231678485870361\n",
      "Epoch 580 | Train Loss: 9.052896348293871e-05 | Test Loss: 0.005230681970715523\n",
      "Epoch 581 | Train Loss: 9.021100413519889e-05 | Test Loss: 0.005229822359979153\n",
      "Epoch 582 | Train Loss: 8.989514026325196e-05 | Test Loss: 0.0052291229367256165\n",
      "Epoch 583 | Train Loss: 8.958005491876975e-05 | Test Loss: 0.00522826611995697\n",
      "Epoch 584 | Train Loss: 8.926826558308676e-05 | Test Loss: 0.005227407440543175\n",
      "Epoch 585 | Train Loss: 8.895717473933473e-05 | Test Loss: 0.00522637227550149\n",
      "Epoch 586 | Train Loss: 8.86473135324195e-05 | Test Loss: 0.005225765518844128\n",
      "Epoch 587 | Train Loss: 8.833775791572407e-05 | Test Loss: 0.005225041881203651\n",
      "Epoch 588 | Train Loss: 8.803258242551237e-05 | Test Loss: 0.005224017892032862\n",
      "Epoch 589 | Train Loss: 8.772576256887987e-05 | Test Loss: 0.00522282300516963\n",
      "Epoch 590 | Train Loss: 8.74219331308268e-05 | Test Loss: 0.005221685394644737\n",
      "Epoch 591 | Train Loss: 8.71214724611491e-05 | Test Loss: 0.005220762919634581\n",
      "Epoch 592 | Train Loss: 8.682095358381048e-05 | Test Loss: 0.005219938233494759\n",
      "Epoch 593 | Train Loss: 8.652253745822236e-05 | Test Loss: 0.005219040438532829\n",
      "Epoch 594 | Train Loss: 8.622586028650403e-05 | Test Loss: 0.005218277219682932\n",
      "Epoch 595 | Train Loss: 8.592984522692859e-05 | Test Loss: 0.005217469297349453\n",
      "Epoch 596 | Train Loss: 8.563481242163107e-05 | Test Loss: 0.005216863006353378\n",
      "Epoch 597 | Train Loss: 8.534226071787998e-05 | Test Loss: 0.005216569639742374\n",
      "Epoch 598 | Train Loss: 8.505032019456849e-05 | Test Loss: 0.005216308403760195\n",
      "Epoch 599 | Train Loss: 8.476103539578617e-05 | Test Loss: 0.005215852055698633\n",
      "Epoch 600 | Train Loss: 8.447231084574014e-05 | Test Loss: 0.00521516939625144\n",
      "Epoch 601 | Train Loss: 8.418400102527812e-05 | Test Loss: 0.0052145011723041534\n",
      "Epoch 602 | Train Loss: 8.389806316699833e-05 | Test Loss: 0.005214078351855278\n",
      "Epoch 603 | Train Loss: 8.361475920537487e-05 | Test Loss: 0.005213849246501923\n",
      "Epoch 604 | Train Loss: 8.333122968906537e-05 | Test Loss: 0.005213846918195486\n",
      "Epoch 605 | Train Loss: 8.304938091896474e-05 | Test Loss: 0.00521383062005043\n",
      "Epoch 606 | Train Loss: 8.276924927486107e-05 | Test Loss: 0.00521370442584157\n",
      "Epoch 607 | Train Loss: 8.249087841250002e-05 | Test Loss: 0.005213210824877024\n",
      "Epoch 608 | Train Loss: 8.221332245739177e-05 | Test Loss: 0.005212523974478245\n",
      "Epoch 609 | Train Loss: 8.193685789592564e-05 | Test Loss: 0.005211730021983385\n",
      "Epoch 610 | Train Loss: 8.166355110006407e-05 | Test Loss: 0.00521112373098731\n",
      "Epoch 611 | Train Loss: 8.138951670844108e-05 | Test Loss: 0.005210761912167072\n",
      "Epoch 612 | Train Loss: 8.111682836897671e-05 | Test Loss: 0.005210442468523979\n",
      "Epoch 613 | Train Loss: 8.08449913165532e-05 | Test Loss: 0.005210017319768667\n",
      "Epoch 614 | Train Loss: 8.057626837398857e-05 | Test Loss: 0.005209306254982948\n",
      "Epoch 615 | Train Loss: 8.030764729483053e-05 | Test Loss: 0.005208516027778387\n",
      "Epoch 616 | Train Loss: 8.004160918062553e-05 | Test Loss: 0.00520774582400918\n",
      "Epoch 617 | Train Loss: 7.977493805810809e-05 | Test Loss: 0.005207198206335306\n",
      "Epoch 618 | Train Loss: 7.951027509989217e-05 | Test Loss: 0.0052069867961108685\n",
      "Epoch 619 | Train Loss: 7.924802775960416e-05 | Test Loss: 0.0052067674696445465\n",
      "Epoch 620 | Train Loss: 7.898562762420624e-05 | Test Loss: 0.005206219851970673\n",
      "Epoch 621 | Train Loss: 7.872561400290579e-05 | Test Loss: 0.005205392837524414\n",
      "Epoch 622 | Train Loss: 7.846520747989416e-05 | Test Loss: 0.005204549990594387\n",
      "Epoch 623 | Train Loss: 7.820783503120765e-05 | Test Loss: 0.005203691311180592\n",
      "Epoch 624 | Train Loss: 7.795105193508789e-05 | Test Loss: 0.005202827043831348\n",
      "Epoch 625 | Train Loss: 7.769496005494148e-05 | Test Loss: 0.005202397704124451\n",
      "Epoch 626 | Train Loss: 7.744043978163972e-05 | Test Loss: 0.005202248692512512\n",
      "Epoch 627 | Train Loss: 7.718799315625802e-05 | Test Loss: 0.00520215043798089\n",
      "Epoch 628 | Train Loss: 7.693510997341946e-05 | Test Loss: 0.005201876163482666\n",
      "Epoch 629 | Train Loss: 7.668506441405043e-05 | Test Loss: 0.00520135136321187\n",
      "Epoch 630 | Train Loss: 7.643416756764054e-05 | Test Loss: 0.005200483370572329\n",
      "Epoch 631 | Train Loss: 7.618491508765146e-05 | Test Loss: 0.005199573468416929\n",
      "Epoch 632 | Train Loss: 7.593792543048039e-05 | Test Loss: 0.0051985145546495914\n",
      "Epoch 633 | Train Loss: 7.569142326246947e-05 | Test Loss: 0.005197685677558184\n",
      "Epoch 634 | Train Loss: 7.544473191956058e-05 | Test Loss: 0.005196807906031609\n",
      "Epoch 635 | Train Loss: 7.520009239669889e-05 | Test Loss: 0.005195995792746544\n",
      "Epoch 636 | Train Loss: 7.495729369111359e-05 | Test Loss: 0.005195197183638811\n",
      "Epoch 637 | Train Loss: 7.471551361959428e-05 | Test Loss: 0.005194242112338543\n",
      "Epoch 638 | Train Loss: 7.447444659192115e-05 | Test Loss: 0.0051934183575212955\n",
      "Epoch 639 | Train Loss: 7.423389615723863e-05 | Test Loss: 0.005192610435187817\n",
      "Epoch 640 | Train Loss: 7.399544847430661e-05 | Test Loss: 0.005191681440919638\n",
      "Epoch 641 | Train Loss: 7.375737914117053e-05 | Test Loss: 0.00519071938470006\n",
      "Epoch 642 | Train Loss: 7.351980457315221e-05 | Test Loss: 0.005189794115722179\n",
      "Epoch 643 | Train Loss: 7.328415813390166e-05 | Test Loss: 0.0051888879388570786\n",
      "Epoch 644 | Train Loss: 7.305036706384271e-05 | Test Loss: 0.00518829096108675\n",
      "Epoch 645 | Train Loss: 7.281713624252006e-05 | Test Loss: 0.005187998991459608\n",
      "Epoch 646 | Train Loss: 7.258498953888193e-05 | Test Loss: 0.005187519360333681\n",
      "Epoch 647 | Train Loss: 7.235401426441967e-05 | Test Loss: 0.005186644848436117\n",
      "Epoch 648 | Train Loss: 7.212494529085234e-05 | Test Loss: 0.005185904912650585\n",
      "Epoch 649 | Train Loss: 7.189575262600556e-05 | Test Loss: 0.0051849884912371635\n",
      "Epoch 650 | Train Loss: 7.16696449671872e-05 | Test Loss: 0.005184687674045563\n",
      "Epoch 651 | Train Loss: 7.144328992580995e-05 | Test Loss: 0.005184714682400227\n",
      "Epoch 652 | Train Loss: 7.121822272893041e-05 | Test Loss: 0.005184359382838011\n",
      "Epoch 653 | Train Loss: 7.099312642822042e-05 | Test Loss: 0.0051837642677128315\n",
      "Epoch 654 | Train Loss: 7.07698636688292e-05 | Test Loss: 0.005183657631278038\n",
      "Epoch 655 | Train Loss: 7.054759043967351e-05 | Test Loss: 0.0051840622909367085\n",
      "Epoch 656 | Train Loss: 7.032719440758228e-05 | Test Loss: 0.005183776840567589\n",
      "Epoch 657 | Train Loss: 7.010684930719435e-05 | Test Loss: 0.0051829274743795395\n",
      "Epoch 658 | Train Loss: 6.988686800468713e-05 | Test Loss: 0.005182330496609211\n",
      "Epoch 659 | Train Loss: 6.966909859329462e-05 | Test Loss: 0.0051822662353515625\n",
      "Epoch 660 | Train Loss: 6.94515256327577e-05 | Test Loss: 0.00518248463049531\n",
      "Epoch 661 | Train Loss: 6.923465116415173e-05 | Test Loss: 0.005182875785976648\n",
      "Epoch 662 | Train Loss: 6.901956658111885e-05 | Test Loss: 0.005182976834475994\n",
      "Epoch 663 | Train Loss: 6.880496948724613e-05 | Test Loss: 0.005182397551834583\n",
      "Epoch 664 | Train Loss: 6.859075801912695e-05 | Test Loss: 0.005181590095162392\n",
      "Epoch 665 | Train Loss: 6.837905675638467e-05 | Test Loss: 0.0051812962628901005\n",
      "Epoch 666 | Train Loss: 6.816800305387005e-05 | Test Loss: 0.005181699059903622\n",
      "Epoch 667 | Train Loss: 6.795718218199909e-05 | Test Loss: 0.005181708838790655\n",
      "Epoch 668 | Train Loss: 6.77476855344139e-05 | Test Loss: 0.005181311164051294\n",
      "Epoch 669 | Train Loss: 6.75399205647409e-05 | Test Loss: 0.005180926527827978\n",
      "Epoch 670 | Train Loss: 6.733110058121383e-05 | Test Loss: 0.005180340260267258\n",
      "Epoch 671 | Train Loss: 6.712375761708245e-05 | Test Loss: 0.005180347245186567\n",
      "Epoch 672 | Train Loss: 6.691923772450536e-05 | Test Loss: 0.0051805698312819\n",
      "Epoch 673 | Train Loss: 6.671465234830976e-05 | Test Loss: 0.005180805921554565\n",
      "Epoch 674 | Train Loss: 6.65108163957484e-05 | Test Loss: 0.0051810708828270435\n",
      "Epoch 675 | Train Loss: 6.630896677961573e-05 | Test Loss: 0.005180967040359974\n",
      "Epoch 676 | Train Loss: 6.610614218516275e-05 | Test Loss: 0.005180488806217909\n",
      "Epoch 677 | Train Loss: 6.590428529307246e-05 | Test Loss: 0.005180115811526775\n",
      "Epoch 678 | Train Loss: 6.570441473741084e-05 | Test Loss: 0.005180384498089552\n",
      "Epoch 679 | Train Loss: 6.550583202624694e-05 | Test Loss: 0.0051808543503284454\n",
      "Epoch 680 | Train Loss: 6.53062597848475e-05 | Test Loss: 0.0051812962628901005\n",
      "Epoch 681 | Train Loss: 6.510873936349526e-05 | Test Loss: 0.005181418266147375\n",
      "Epoch 682 | Train Loss: 6.491231761174276e-05 | Test Loss: 0.005181006155908108\n",
      "Epoch 683 | Train Loss: 6.471601955126971e-05 | Test Loss: 0.005180562846362591\n",
      "Epoch 684 | Train Loss: 6.452148227253929e-05 | Test Loss: 0.005180841311812401\n",
      "Epoch 685 | Train Loss: 6.432701047742739e-05 | Test Loss: 0.005181338172405958\n",
      "Epoch 686 | Train Loss: 6.41354126855731e-05 | Test Loss: 0.0051816352643072605\n",
      "Epoch 687 | Train Loss: 6.39411446172744e-05 | Test Loss: 0.005181454122066498\n",
      "Epoch 688 | Train Loss: 6.375009252224118e-05 | Test Loss: 0.005181124433875084\n",
      "Epoch 689 | Train Loss: 6.355920049827546e-05 | Test Loss: 0.005180584266781807\n",
      "Epoch 690 | Train Loss: 6.336982914945111e-05 | Test Loss: 0.005180182866752148\n",
      "Epoch 691 | Train Loss: 6.318134546745569e-05 | Test Loss: 0.00518017215654254\n",
      "Epoch 692 | Train Loss: 6.299291999312118e-05 | Test Loss: 0.0051801507361233234\n",
      "Epoch 693 | Train Loss: 6.280618981691077e-05 | Test Loss: 0.005180248059332371\n",
      "Epoch 694 | Train Loss: 6.261938688112423e-05 | Test Loss: 0.005180078558623791\n",
      "Epoch 695 | Train Loss: 6.243384268600494e-05 | Test Loss: 0.005179679952561855\n",
      "Epoch 696 | Train Loss: 6.225019751582295e-05 | Test Loss: 0.005179429426789284\n",
      "Epoch 697 | Train Loss: 6.206557736732066e-05 | Test Loss: 0.005179989151656628\n",
      "Epoch 698 | Train Loss: 6.188257975736633e-05 | Test Loss: 0.005180885083973408\n",
      "Epoch 699 | Train Loss: 6.169998232508078e-05 | Test Loss: 0.005181928630918264\n",
      "Epoch 700 | Train Loss: 6.151901470730081e-05 | Test Loss: 0.005182348657399416\n",
      "Epoch 701 | Train Loss: 6.133793067419901e-05 | Test Loss: 0.005182179622352123\n",
      "Epoch 702 | Train Loss: 6.115851283539087e-05 | Test Loss: 0.005181765183806419\n",
      "Epoch 703 | Train Loss: 6.097894220147282e-05 | Test Loss: 0.005181699525564909\n",
      "Epoch 704 | Train Loss: 6.080103412386961e-05 | Test Loss: 0.0051824916154146194\n",
      "Epoch 705 | Train Loss: 6.062408283469267e-05 | Test Loss: 0.005183201748877764\n",
      "Epoch 706 | Train Loss: 6.044749534339644e-05 | Test Loss: 0.005184059031307697\n",
      "Epoch 707 | Train Loss: 6.0270511312410235e-05 | Test Loss: 0.005184627138078213\n",
      "Epoch 708 | Train Loss: 6.009522985550575e-05 | Test Loss: 0.005184746813029051\n",
      "Epoch 709 | Train Loss: 5.992033038637601e-05 | Test Loss: 0.005184877663850784\n",
      "Epoch 710 | Train Loss: 5.974638042971492e-05 | Test Loss: 0.005185220390558243\n",
      "Epoch 711 | Train Loss: 5.957322719041258e-05 | Test Loss: 0.005185827612876892\n",
      "Epoch 712 | Train Loss: 5.940045593888499e-05 | Test Loss: 0.005186218768358231\n",
      "Epoch 713 | Train Loss: 5.922889613430016e-05 | Test Loss: 0.005186452530324459\n",
      "Epoch 714 | Train Loss: 5.905830403207801e-05 | Test Loss: 0.005186750553548336\n",
      "Epoch 715 | Train Loss: 5.88884977332782e-05 | Test Loss: 0.005187048111110926\n",
      "Epoch 716 | Train Loss: 5.871907342225313e-05 | Test Loss: 0.0051874094642698765\n",
      "Epoch 717 | Train Loss: 5.8550271205604076e-05 | Test Loss: 0.005187779664993286\n",
      "Epoch 718 | Train Loss: 5.838170909555629e-05 | Test Loss: 0.00518809026107192\n",
      "Epoch 719 | Train Loss: 5.821403465233743e-05 | Test Loss: 0.005188478156924248\n",
      "Epoch 720 | Train Loss: 5.8048011851496994e-05 | Test Loss: 0.005188710521906614\n",
      "Epoch 721 | Train Loss: 5.788242560811341e-05 | Test Loss: 0.005188902374356985\n",
      "Epoch 722 | Train Loss: 5.771735231974162e-05 | Test Loss: 0.005189450923353434\n",
      "Epoch 723 | Train Loss: 5.755190795753151e-05 | Test Loss: 0.005190253723412752\n",
      "Epoch 724 | Train Loss: 5.738798063248396e-05 | Test Loss: 0.005191546864807606\n",
      "Epoch 725 | Train Loss: 5.7225304772146046e-05 | Test Loss: 0.005192417651414871\n",
      "Epoch 726 | Train Loss: 5.706294177798554e-05 | Test Loss: 0.005193027667701244\n",
      "Epoch 727 | Train Loss: 5.690018224413507e-05 | Test Loss: 0.005193261429667473\n",
      "Epoch 728 | Train Loss: 5.673876512446441e-05 | Test Loss: 0.005193847697228193\n",
      "Epoch 729 | Train Loss: 5.6578701332909986e-05 | Test Loss: 0.005194616038352251\n",
      "Epoch 730 | Train Loss: 5.6419099564664066e-05 | Test Loss: 0.005195735953748226\n",
      "Epoch 731 | Train Loss: 5.625907942885533e-05 | Test Loss: 0.00519653270021081\n",
      "Epoch 732 | Train Loss: 5.610030348179862e-05 | Test Loss: 0.00519711896777153\n",
      "Epoch 733 | Train Loss: 5.5942731705727056e-05 | Test Loss: 0.005197747610509396\n",
      "Epoch 734 | Train Loss: 5.5785705626476556e-05 | Test Loss: 0.005198552738875151\n",
      "Epoch 735 | Train Loss: 5.562917431234382e-05 | Test Loss: 0.005199729464948177\n",
      "Epoch 736 | Train Loss: 5.5470805818913504e-05 | Test Loss: 0.005200693849474192\n",
      "Epoch 737 | Train Loss: 5.5315667850663885e-05 | Test Loss: 0.005201343446969986\n",
      "Epoch 738 | Train Loss: 5.5160846386570483e-05 | Test Loss: 0.005201802123337984\n",
      "Epoch 739 | Train Loss: 5.500594852492213e-05 | Test Loss: 0.005202113185077906\n",
      "Epoch 740 | Train Loss: 5.485268775373697e-05 | Test Loss: 0.005202413536608219\n",
      "Epoch 741 | Train Loss: 5.469847747008316e-05 | Test Loss: 0.005202926695346832\n",
      "Epoch 742 | Train Loss: 5.4546075261896476e-05 | Test Loss: 0.0052033173851668835\n",
      "Epoch 743 | Train Loss: 5.439394954009913e-05 | Test Loss: 0.005203348584473133\n",
      "Epoch 744 | Train Loss: 5.4242809710558504e-05 | Test Loss: 0.0052031842060387135\n",
      "Epoch 745 | Train Loss: 5.4091637139208615e-05 | Test Loss: 0.005203519482165575\n",
      "Epoch 746 | Train Loss: 5.394218533183448e-05 | Test Loss: 0.005203898064792156\n",
      "Epoch 747 | Train Loss: 5.379231515689753e-05 | Test Loss: 0.005204583518207073\n",
      "Epoch 748 | Train Loss: 5.3642525017494336e-05 | Test Loss: 0.005204841028898954\n",
      "Epoch 749 | Train Loss: 5.349485218175687e-05 | Test Loss: 0.005204852670431137\n",
      "Epoch 750 | Train Loss: 5.3345687774708495e-05 | Test Loss: 0.005204830318689346\n",
      "Epoch 751 | Train Loss: 5.3199335525278e-05 | Test Loss: 0.005204861052334309\n",
      "Epoch 752 | Train Loss: 5.305230661178939e-05 | Test Loss: 0.005205248016864061\n",
      "Epoch 753 | Train Loss: 5.290675107971765e-05 | Test Loss: 0.00520556652918458\n",
      "Epoch 754 | Train Loss: 5.276082447380759e-05 | Test Loss: 0.005205477122217417\n",
      "Epoch 755 | Train Loss: 5.2616287575801834e-05 | Test Loss: 0.005205417983233929\n",
      "Epoch 756 | Train Loss: 5.2471219532890245e-05 | Test Loss: 0.005205267108976841\n",
      "Epoch 757 | Train Loss: 5.232780677033588e-05 | Test Loss: 0.005205071065574884\n",
      "Epoch 758 | Train Loss: 5.2183913794578984e-05 | Test Loss: 0.005205267574638128\n",
      "Epoch 759 | Train Loss: 5.204082845011726e-05 | Test Loss: 0.005205538589507341\n",
      "Epoch 760 | Train Loss: 5.1898445235565305e-05 | Test Loss: 0.005205884110182524\n",
      "Epoch 761 | Train Loss: 5.175569458515383e-05 | Test Loss: 0.005205884110182524\n",
      "Epoch 762 | Train Loss: 5.1614340918604285e-05 | Test Loss: 0.0052056992426514626\n",
      "Epoch 763 | Train Loss: 5.147410774952732e-05 | Test Loss: 0.005205580033361912\n",
      "Epoch 764 | Train Loss: 5.133360537001863e-05 | Test Loss: 0.005205827299505472\n",
      "Epoch 765 | Train Loss: 5.1192648243159056e-05 | Test Loss: 0.005206105299293995\n",
      "Epoch 766 | Train Loss: 5.1052971684839576e-05 | Test Loss: 0.0052062696777284145\n",
      "Epoch 767 | Train Loss: 5.091431739856489e-05 | Test Loss: 0.005206075496971607\n",
      "Epoch 768 | Train Loss: 5.077681998955086e-05 | Test Loss: 0.005206238012760878\n",
      "Epoch 769 | Train Loss: 5.0639402616070583e-05 | Test Loss: 0.005206651519984007\n",
      "Epoch 770 | Train Loss: 5.0502039812272415e-05 | Test Loss: 0.005206832196563482\n",
      "Epoch 771 | Train Loss: 5.036530637880787e-05 | Test Loss: 0.0052075921557843685\n",
      "Epoch 772 | Train Loss: 5.0229278713231906e-05 | Test Loss: 0.005208320915699005\n",
      "Epoch 773 | Train Loss: 5.0093720346922055e-05 | Test Loss: 0.00520930765196681\n",
      "Epoch 774 | Train Loss: 4.995979543309659e-05 | Test Loss: 0.005209957715123892\n",
      "Epoch 775 | Train Loss: 4.9825888709165156e-05 | Test Loss: 0.0052107288502156734\n",
      "Epoch 776 | Train Loss: 4.969117799191736e-05 | Test Loss: 0.005211103707551956\n",
      "Epoch 777 | Train Loss: 4.9558784667169675e-05 | Test Loss: 0.0052117169834673405\n",
      "Epoch 778 | Train Loss: 4.942519080941565e-05 | Test Loss: 0.005211998708546162\n",
      "Epoch 779 | Train Loss: 4.9293379561277106e-05 | Test Loss: 0.005212831776589155\n",
      "Epoch 780 | Train Loss: 4.9162423238158226e-05 | Test Loss: 0.005213376600295305\n",
      "Epoch 781 | Train Loss: 4.903171429759823e-05 | Test Loss: 0.005214319098740816\n",
      "Epoch 782 | Train Loss: 4.890061973128468e-05 | Test Loss: 0.005214857403188944\n",
      "Epoch 783 | Train Loss: 4.877153332927264e-05 | Test Loss: 0.0052155437879264355\n",
      "Epoch 784 | Train Loss: 4.864191942033358e-05 | Test Loss: 0.005215772427618504\n",
      "Epoch 785 | Train Loss: 4.851310950471088e-05 | Test Loss: 0.0052162460051476955\n",
      "Epoch 786 | Train Loss: 4.838455788558349e-05 | Test Loss: 0.005216493736952543\n",
      "Epoch 787 | Train Loss: 4.825621726922691e-05 | Test Loss: 0.005217062775045633\n",
      "Epoch 788 | Train Loss: 4.8129855713341385e-05 | Test Loss: 0.005217636935412884\n",
      "Epoch 789 | Train Loss: 4.800254464498721e-05 | Test Loss: 0.0052177575416862965\n",
      "Epoch 790 | Train Loss: 4.787667785421945e-05 | Test Loss: 0.005218410864472389\n",
      "Epoch 791 | Train Loss: 4.7751131205586717e-05 | Test Loss: 0.005219141952693462\n",
      "Epoch 792 | Train Loss: 4.762468597618863e-05 | Test Loss: 0.005219604820013046\n",
      "Epoch 793 | Train Loss: 4.7500929213128984e-05 | Test Loss: 0.005219695623964071\n",
      "Epoch 794 | Train Loss: 4.737719427794218e-05 | Test Loss: 0.0052200197242200375\n",
      "Epoch 795 | Train Loss: 4.7252724471036345e-05 | Test Loss: 0.005220703314989805\n",
      "Epoch 796 | Train Loss: 4.712933150585741e-05 | Test Loss: 0.0052217463962733746\n",
      "Epoch 797 | Train Loss: 4.7005371015984565e-05 | Test Loss: 0.00522248400375247\n",
      "Epoch 798 | Train Loss: 4.688282933784649e-05 | Test Loss: 0.0052228099666535854\n",
      "Epoch 799 | Train Loss: 4.6761106204940006e-05 | Test Loss: 0.005223123822361231\n",
      "Epoch 800 | Train Loss: 4.6640358050353825e-05 | Test Loss: 0.005223799962550402\n",
      "Epoch 801 | Train Loss: 4.65198427264113e-05 | Test Loss: 0.005224593449383974\n",
      "Epoch 802 | Train Loss: 4.639971302822232e-05 | Test Loss: 0.005225721746683121\n",
      "Epoch 803 | Train Loss: 4.6278473746497184e-05 | Test Loss: 0.005226821172982454\n",
      "Epoch 804 | Train Loss: 4.61593153886497e-05 | Test Loss: 0.005227393936365843\n",
      "Epoch 805 | Train Loss: 4.604098285199143e-05 | Test Loss: 0.005227603483945131\n",
      "Epoch 806 | Train Loss: 4.592072946252301e-05 | Test Loss: 0.005227288696914911\n",
      "Epoch 807 | Train Loss: 4.580285894917324e-05 | Test Loss: 0.005227680318057537\n",
      "Epoch 808 | Train Loss: 4.568565418594517e-05 | Test Loss: 0.005228262860327959\n",
      "Epoch 809 | Train Loss: 4.556633211905137e-05 | Test Loss: 0.0052290866151452065\n",
      "Epoch 810 | Train Loss: 4.544975308817811e-05 | Test Loss: 0.00522985914722085\n",
      "Epoch 811 | Train Loss: 4.5333628804655746e-05 | Test Loss: 0.005230496637523174\n",
      "Epoch 812 | Train Loss: 4.5217570004751906e-05 | Test Loss: 0.005230812821537256\n",
      "Epoch 813 | Train Loss: 4.510297003434971e-05 | Test Loss: 0.005230790935456753\n",
      "Epoch 814 | Train Loss: 4.498691487242468e-05 | Test Loss: 0.005230894312262535\n",
      "Epoch 815 | Train Loss: 4.4873359001940116e-05 | Test Loss: 0.005231437273323536\n",
      "Epoch 816 | Train Loss: 4.4759064621757716e-05 | Test Loss: 0.005232114810496569\n",
      "Epoch 817 | Train Loss: 4.4644584704656154e-05 | Test Loss: 0.005233092233538628\n",
      "Epoch 818 | Train Loss: 4.453126894077286e-05 | Test Loss: 0.005233901087194681\n",
      "Epoch 819 | Train Loss: 4.44189936388284e-05 | Test Loss: 0.005234573036432266\n",
      "Epoch 820 | Train Loss: 4.4305616029305384e-05 | Test Loss: 0.005234685260802507\n",
      "Epoch 821 | Train Loss: 4.4193882786203176e-05 | Test Loss: 0.005234397482126951\n",
      "Epoch 822 | Train Loss: 4.4082604290451854e-05 | Test Loss: 0.005234336014837027\n",
      "Epoch 823 | Train Loss: 4.3970783735858276e-05 | Test Loss: 0.005234672222286463\n",
      "Epoch 824 | Train Loss: 4.3860654841409996e-05 | Test Loss: 0.005235347896814346\n",
      "Epoch 825 | Train Loss: 4.3750587792601436e-05 | Test Loss: 0.005236179102212191\n",
      "Epoch 826 | Train Loss: 4.3640284275170416e-05 | Test Loss: 0.00523675000295043\n",
      "Epoch 827 | Train Loss: 4.353083568275906e-05 | Test Loss: 0.005237096920609474\n",
      "Epoch 828 | Train Loss: 4.3421947339084e-05 | Test Loss: 0.005237190052866936\n",
      "Epoch 829 | Train Loss: 4.3312873458489776e-05 | Test Loss: 0.005237160250544548\n",
      "Epoch 830 | Train Loss: 4.320349762565456e-05 | Test Loss: 0.005237236153334379\n",
      "Epoch 831 | Train Loss: 4.3096319132018834e-05 | Test Loss: 0.005237509962171316\n",
      "Epoch 832 | Train Loss: 4.298847488826141e-05 | Test Loss: 0.0052378359250724316\n",
      "Epoch 833 | Train Loss: 4.288162381271832e-05 | Test Loss: 0.005237986799329519\n",
      "Epoch 834 | Train Loss: 4.277483458281495e-05 | Test Loss: 0.005238131154328585\n",
      "Epoch 835 | Train Loss: 4.266901669325307e-05 | Test Loss: 0.005238138139247894\n",
      "Epoch 836 | Train Loss: 4.2563598981359974e-05 | Test Loss: 0.005238220561295748\n",
      "Epoch 837 | Train Loss: 4.245768650434911e-05 | Test Loss: 0.005238160025328398\n",
      "Epoch 838 | Train Loss: 4.235121014062315e-05 | Test Loss: 0.005238571669906378\n",
      "Epoch 839 | Train Loss: 4.2246330849593505e-05 | Test Loss: 0.005238580983132124\n",
      "Epoch 840 | Train Loss: 4.214138971292414e-05 | Test Loss: 0.0052384850569069386\n",
      "Epoch 841 | Train Loss: 4.2037419916596264e-05 | Test Loss: 0.005238590762019157\n",
      "Epoch 842 | Train Loss: 4.19337629864458e-05 | Test Loss: 0.005238850601017475\n",
      "Epoch 843 | Train Loss: 4.183077908237465e-05 | Test Loss: 0.005238629877567291\n",
      "Epoch 844 | Train Loss: 4.172772241872735e-05 | Test Loss: 0.005238331854343414\n",
      "Epoch 845 | Train Loss: 4.1624971345299855e-05 | Test Loss: 0.005238252691924572\n",
      "Epoch 846 | Train Loss: 4.152345354668796e-05 | Test Loss: 0.005238478071987629\n",
      "Epoch 847 | Train Loss: 4.142075340496376e-05 | Test Loss: 0.005238275974988937\n",
      "Epoch 848 | Train Loss: 4.132047251914628e-05 | Test Loss: 0.005238179117441177\n",
      "Epoch 849 | Train Loss: 4.121982055949047e-05 | Test Loss: 0.00523843290284276\n",
      "Epoch 850 | Train Loss: 4.111844828003086e-05 | Test Loss: 0.005238807760179043\n",
      "Epoch 851 | Train Loss: 4.101773811271414e-05 | Test Loss: 0.00523902103304863\n",
      "Epoch 852 | Train Loss: 4.091762821190059e-05 | Test Loss: 0.005238696001470089\n",
      "Epoch 853 | Train Loss: 4.08183186664246e-05 | Test Loss: 0.005238185171037912\n",
      "Epoch 854 | Train Loss: 4.071837611263618e-05 | Test Loss: 0.005237911827862263\n",
      "Epoch 855 | Train Loss: 4.061923755216412e-05 | Test Loss: 0.005237888544797897\n",
      "Epoch 856 | Train Loss: 4.0520702896174043e-05 | Test Loss: 0.005237962584942579\n",
      "Epoch 857 | Train Loss: 4.042166256112978e-05 | Test Loss: 0.005238020792603493\n",
      "Epoch 858 | Train Loss: 4.032464494230226e-05 | Test Loss: 0.005237489473074675\n",
      "Epoch 859 | Train Loss: 4.022672146675177e-05 | Test Loss: 0.0052370550110936165\n",
      "Epoch 860 | Train Loss: 4.0130518755177036e-05 | Test Loss: 0.005236959084868431\n",
      "Epoch 861 | Train Loss: 4.003275535069406e-05 | Test Loss: 0.005237032659351826\n",
      "Epoch 862 | Train Loss: 3.9936167013365775e-05 | Test Loss: 0.005237249191850424\n",
      "Epoch 863 | Train Loss: 3.983988062827848e-05 | Test Loss: 0.005237269680947065\n",
      "Epoch 864 | Train Loss: 3.9743990782881156e-05 | Test Loss: 0.005237121134996414\n",
      "Epoch 865 | Train Loss: 3.964777715737e-05 | Test Loss: 0.005236993543803692\n",
      "Epoch 866 | Train Loss: 3.955294596380554e-05 | Test Loss: 0.0052369460463523865\n",
      "Epoch 867 | Train Loss: 3.945833304896951e-05 | Test Loss: 0.00523682776838541\n",
      "Epoch 868 | Train Loss: 3.936339635401964e-05 | Test Loss: 0.0052360356785357\n",
      "Epoch 869 | Train Loss: 3.926998397218995e-05 | Test Loss: 0.005235286429524422\n",
      "Epoch 870 | Train Loss: 3.9175884012365714e-05 | Test Loss: 0.005234856158494949\n",
      "Epoch 871 | Train Loss: 3.9081725844880566e-05 | Test Loss: 0.005234809126704931\n",
      "Epoch 872 | Train Loss: 3.8989623135421425e-05 | Test Loss: 0.005235020071268082\n",
      "Epoch 873 | Train Loss: 3.889589788741432e-05 | Test Loss: 0.005234984215348959\n",
      "Epoch 874 | Train Loss: 3.8803478673798963e-05 | Test Loss: 0.005234502721577883\n",
      "Epoch 875 | Train Loss: 3.871106309816241e-05 | Test Loss: 0.005234049167484045\n",
      "Epoch 876 | Train Loss: 3.8618716644123197e-05 | Test Loss: 0.0052339849062263966\n",
      "Epoch 877 | Train Loss: 3.852709414786659e-05 | Test Loss: 0.005233692470937967\n",
      "Epoch 878 | Train Loss: 3.843595914077014e-05 | Test Loss: 0.005233222618699074\n",
      "Epoch 879 | Train Loss: 3.834551534964703e-05 | Test Loss: 0.005232700612396002\n",
      "Epoch 880 | Train Loss: 3.8254598621279e-05 | Test Loss: 0.005232309456914663\n",
      "Epoch 881 | Train Loss: 3.8164802390383556e-05 | Test Loss: 0.0052321674302220345\n",
      "Epoch 882 | Train Loss: 3.807482062256895e-05 | Test Loss: 0.005231910385191441\n",
      "Epoch 883 | Train Loss: 3.798494071816094e-05 | Test Loss: 0.00523162679746747\n",
      "Epoch 884 | Train Loss: 3.7894660636084154e-05 | Test Loss: 0.005231058690696955\n",
      "Epoch 885 | Train Loss: 3.78059376089368e-05 | Test Loss: 0.005230306647717953\n",
      "Epoch 886 | Train Loss: 3.771680349018425e-05 | Test Loss: 0.005229692440479994\n",
      "Epoch 887 | Train Loss: 3.7628818972734734e-05 | Test Loss: 0.005229552276432514\n",
      "Epoch 888 | Train Loss: 3.753991404664703e-05 | Test Loss: 0.0052295285277068615\n",
      "Epoch 889 | Train Loss: 3.7452391552506015e-05 | Test Loss: 0.005229241214692593\n",
      "Epoch 890 | Train Loss: 3.736375947482884e-05 | Test Loss: 0.005228802096098661\n",
      "Epoch 891 | Train Loss: 3.7276462535373867e-05 | Test Loss: 0.005228359252214432\n",
      "Epoch 892 | Train Loss: 3.71907590306364e-05 | Test Loss: 0.005227998830378056\n",
      "Epoch 893 | Train Loss: 3.710438613779843e-05 | Test Loss: 0.005227882415056229\n",
      "Epoch 894 | Train Loss: 3.7018264265498146e-05 | Test Loss: 0.005227891728281975\n",
      "Epoch 895 | Train Loss: 3.69318513548933e-05 | Test Loss: 0.005227625370025635\n",
      "Epoch 896 | Train Loss: 3.6845365684712306e-05 | Test Loss: 0.005227095913141966\n",
      "Epoch 897 | Train Loss: 3.676006963360123e-05 | Test Loss: 0.005226512905210257\n",
      "Epoch 898 | Train Loss: 3.667563578346744e-05 | Test Loss: 0.005225948989391327\n",
      "Epoch 899 | Train Loss: 3.6590583476936445e-05 | Test Loss: 0.005225637927651405\n",
      "Epoch 900 | Train Loss: 3.6505134630715474e-05 | Test Loss: 0.005225456785410643\n",
      "Epoch 901 | Train Loss: 3.641967487055808e-05 | Test Loss: 0.0052250344306230545\n",
      "Epoch 902 | Train Loss: 3.6335888580651954e-05 | Test Loss: 0.005224382039159536\n",
      "Epoch 903 | Train Loss: 3.625294266385026e-05 | Test Loss: 0.0052237980999052525\n",
      "Epoch 904 | Train Loss: 3.6169818486087024e-05 | Test Loss: 0.0052237180061638355\n",
      "Epoch 905 | Train Loss: 3.608671613619663e-05 | Test Loss: 0.0052236043848097324\n",
      "Epoch 906 | Train Loss: 3.6002784327138215e-05 | Test Loss: 0.005223228130489588\n",
      "Epoch 907 | Train Loss: 3.592049688450061e-05 | Test Loss: 0.005222691223025322\n",
      "Epoch 908 | Train Loss: 3.583750731195323e-05 | Test Loss: 0.005222519859671593\n",
      "Epoch 909 | Train Loss: 3.575563459889963e-05 | Test Loss: 0.005222155712544918\n",
      "Epoch 910 | Train Loss: 3.567376916180365e-05 | Test Loss: 0.005222010891884565\n",
      "Epoch 911 | Train Loss: 3.5591576306615025e-05 | Test Loss: 0.005221607629209757\n",
      "Epoch 912 | Train Loss: 3.551046393113211e-05 | Test Loss: 0.005221343133598566\n",
      "Epoch 913 | Train Loss: 3.542825288604945e-05 | Test Loss: 0.0052210865542292595\n",
      "Epoch 914 | Train Loss: 3.534720235620625e-05 | Test Loss: 0.00522057618945837\n",
      "Epoch 915 | Train Loss: 3.5266868508188054e-05 | Test Loss: 0.005220041144639254\n",
      "Epoch 916 | Train Loss: 3.518680023262277e-05 | Test Loss: 0.0052196793258190155\n",
      "Epoch 917 | Train Loss: 3.510768146952614e-05 | Test Loss: 0.005219216458499432\n",
      "Epoch 918 | Train Loss: 3.5027194826398045e-05 | Test Loss: 0.005218951962888241\n",
      "Epoch 919 | Train Loss: 3.494739212328568e-05 | Test Loss: 0.005218564998358488\n",
      "Epoch 920 | Train Loss: 3.4868491638917476e-05 | Test Loss: 0.0052180360071361065\n",
      "Epoch 921 | Train Loss: 3.478983853710815e-05 | Test Loss: 0.005217899568378925\n",
      "Epoch 922 | Train Loss: 3.4711029002210125e-05 | Test Loss: 0.005217481404542923\n",
      "Epoch 923 | Train Loss: 3.4633623727131635e-05 | Test Loss: 0.0052171614952385426\n",
      "Epoch 924 | Train Loss: 3.455470141489059e-05 | Test Loss: 0.005216976627707481\n",
      "Epoch 925 | Train Loss: 3.4477347071515396e-05 | Test Loss: 0.005216533318161964\n",
      "Epoch 926 | Train Loss: 3.4400181903038174e-05 | Test Loss: 0.005215815734118223\n",
      "Epoch 927 | Train Loss: 3.432342055020854e-05 | Test Loss: 0.0052153910510241985\n",
      "Epoch 928 | Train Loss: 3.4245906135765836e-05 | Test Loss: 0.005215035285800695\n",
      "Epoch 929 | Train Loss: 3.416930849198252e-05 | Test Loss: 0.005214386153966188\n",
      "Epoch 930 | Train Loss: 3.4092845453415066e-05 | Test Loss: 0.005213557742536068\n",
      "Epoch 931 | Train Loss: 3.401578214834444e-05 | Test Loss: 0.00521316472440958\n",
      "Epoch 932 | Train Loss: 3.394008308532648e-05 | Test Loss: 0.0052129412069916725\n",
      "Epoch 933 | Train Loss: 3.3863856515381485e-05 | Test Loss: 0.005212500225752592\n",
      "Epoch 934 | Train Loss: 3.378920882823877e-05 | Test Loss: 0.005211952608078718\n",
      "Epoch 935 | Train Loss: 3.371297862031497e-05 | Test Loss: 0.005211306270211935\n",
      "Epoch 936 | Train Loss: 3.363805080880411e-05 | Test Loss: 0.005210959352552891\n",
      "Epoch 937 | Train Loss: 3.356302477186546e-05 | Test Loss: 0.0052109528332948685\n",
      "Epoch 938 | Train Loss: 3.348864265717566e-05 | Test Loss: 0.0052106804214417934\n",
      "Epoch 939 | Train Loss: 3.3415049983887e-05 | Test Loss: 0.0052101826295256615\n",
      "Epoch 940 | Train Loss: 3.3340329537168145e-05 | Test Loss: 0.005209470633417368\n",
      "Epoch 941 | Train Loss: 3.326652222312987e-05 | Test Loss: 0.005209031980484724\n",
      "Epoch 942 | Train Loss: 3.3193562558153644e-05 | Test Loss: 0.005208936054259539\n",
      "Epoch 943 | Train Loss: 3.311986802145839e-05 | Test Loss: 0.005208726041018963\n",
      "Epoch 944 | Train Loss: 3.3045853342628106e-05 | Test Loss: 0.005208180285990238\n",
      "Epoch 945 | Train Loss: 3.297328294138424e-05 | Test Loss: 0.005207570269703865\n",
      "Epoch 946 | Train Loss: 3.2900727092055604e-05 | Test Loss: 0.0052069006487727165\n",
      "Epoch 947 | Train Loss: 3.282861507614143e-05 | Test Loss: 0.005206575617194176\n",
      "Epoch 948 | Train Loss: 3.275558628956787e-05 | Test Loss: 0.005206120666116476\n",
      "Epoch 949 | Train Loss: 3.268379805376753e-05 | Test Loss: 0.005205680150538683\n",
      "Epoch 950 | Train Loss: 3.261221354478039e-05 | Test Loss: 0.005205104127526283\n",
      "Epoch 951 | Train Loss: 3.254086914239451e-05 | Test Loss: 0.005204548127949238\n",
      "Epoch 952 | Train Loss: 3.246912456233986e-05 | Test Loss: 0.005204183980822563\n",
      "Epoch 953 | Train Loss: 3.239732177462429e-05 | Test Loss: 0.0052039772272109985\n",
      "Epoch 954 | Train Loss: 3.232697781641036e-05 | Test Loss: 0.0052034491673111916\n",
      "Epoch 955 | Train Loss: 3.2256000849884003e-05 | Test Loss: 0.005202701315283775\n",
      "Epoch 956 | Train Loss: 3.218604251742363e-05 | Test Loss: 0.005202251486480236\n",
      "Epoch 957 | Train Loss: 3.2116597139975056e-05 | Test Loss: 0.005201887805014849\n",
      "Epoch 958 | Train Loss: 3.204719541827217e-05 | Test Loss: 0.005201177205890417\n",
      "Epoch 959 | Train Loss: 3.1978212064132094e-05 | Test Loss: 0.005200278479605913\n",
      "Epoch 960 | Train Loss: 3.1907537049846724e-05 | Test Loss: 0.005199629347771406\n",
      "Epoch 961 | Train Loss: 3.1838346330914646e-05 | Test Loss: 0.005199027247726917\n",
      "Epoch 962 | Train Loss: 3.1769348424859345e-05 | Test Loss: 0.005198560655117035\n",
      "Epoch 963 | Train Loss: 3.1700074032414705e-05 | Test Loss: 0.005198191851377487\n",
      "Epoch 964 | Train Loss: 3.163096334901638e-05 | Test Loss: 0.005197544116526842\n",
      "Epoch 965 | Train Loss: 3.1563286029268056e-05 | Test Loss: 0.005196761805564165\n",
      "Epoch 966 | Train Loss: 3.149493568344042e-05 | Test Loss: 0.005196176934987307\n",
      "Epoch 967 | Train Loss: 3.142670539091341e-05 | Test Loss: 0.005195736885070801\n",
      "Epoch 968 | Train Loss: 3.135828592348844e-05 | Test Loss: 0.005195258650928736\n",
      "Epoch 969 | Train Loss: 3.129092146991752e-05 | Test Loss: 0.0051946984604001045\n",
      "Epoch 970 | Train Loss: 3.1224117265082896e-05 | Test Loss: 0.005194392055273056\n",
      "Epoch 971 | Train Loss: 3.115698928013444e-05 | Test Loss: 0.005194102879613638\n",
      "Epoch 972 | Train Loss: 3.1089784897631034e-05 | Test Loss: 0.005193476099520922\n",
      "Epoch 973 | Train Loss: 3.1023660994833335e-05 | Test Loss: 0.005192915443331003\n",
      "Epoch 974 | Train Loss: 3.095767897320911e-05 | Test Loss: 0.005192419048398733\n",
      "Epoch 975 | Train Loss: 3.0890954803908244e-05 | Test Loss: 0.005192036274820566\n",
      "Epoch 976 | Train Loss: 3.082389594055712e-05 | Test Loss: 0.005191374570131302\n",
      "Epoch 977 | Train Loss: 3.075795029872097e-05 | Test Loss: 0.005190979223698378\n",
      "Epoch 978 | Train Loss: 3.06931760860607e-05 | Test Loss: 0.005190732888877392\n",
      "Epoch 979 | Train Loss: 3.06272559100762e-05 | Test Loss: 0.005190165247768164\n",
      "Epoch 980 | Train Loss: 3.0561630410375074e-05 | Test Loss: 0.005189507734030485\n",
      "Epoch 981 | Train Loss: 3.0496590625261888e-05 | Test Loss: 0.005189162213355303\n",
      "Epoch 982 | Train Loss: 3.0431434424826875e-05 | Test Loss: 0.005188872572034597\n",
      "Epoch 983 | Train Loss: 3.036681482626591e-05 | Test Loss: 0.005188241600990295\n",
      "Epoch 984 | Train Loss: 3.030249717994593e-05 | Test Loss: 0.005187517032027245\n",
      "Epoch 985 | Train Loss: 3.0237964892876334e-05 | Test Loss: 0.005187066271901131\n",
      "Epoch 986 | Train Loss: 3.0173065169947222e-05 | Test Loss: 0.005186628084629774\n",
      "Epoch 987 | Train Loss: 3.010949876625091e-05 | Test Loss: 0.005186502356082201\n",
      "Epoch 988 | Train Loss: 3.0044593586353585e-05 | Test Loss: 0.005186190363019705\n",
      "Epoch 989 | Train Loss: 2.9981130865053274e-05 | Test Loss: 0.0051856678910553455\n",
      "Epoch 990 | Train Loss: 2.9918450309196487e-05 | Test Loss: 0.005185356363654137\n",
      "Epoch 991 | Train Loss: 2.9855562388547696e-05 | Test Loss: 0.005185261834412813\n",
      "Epoch 992 | Train Loss: 2.9791626730002463e-05 | Test Loss: 0.005185037385672331\n",
      "Epoch 993 | Train Loss: 2.9729519155807793e-05 | Test Loss: 0.005184578243643045\n",
      "Epoch 994 | Train Loss: 2.9666611226275563e-05 | Test Loss: 0.005184363108128309\n",
      "Epoch 995 | Train Loss: 2.9604258088511415e-05 | Test Loss: 0.0051842075772583485\n",
      "Epoch 996 | Train Loss: 2.9542254196712747e-05 | Test Loss: 0.0051839048974215984\n",
      "Epoch 997 | Train Loss: 2.9480479497578926e-05 | Test Loss: 0.00518330093473196\n",
      "Epoch 998 | Train Loss: 2.9417769837891683e-05 | Test Loss: 0.0051824371330440044\n",
      "Epoch 999 | Train Loss: 2.9356113373069093e-05 | Test Loss: 0.005181836895644665\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "# ALPHATOE\n",
    "model = HookedTransformer(cfg).to(cfg.device)\n",
    "optimizer = t.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# for epoch in tqdm.tqdm(range(epochs)):\n",
    "for epoch in range(epochs):\n",
    "    for batch in range(0, len(train_data), batch_size):\n",
    "        train_logits = model(train_data[batch:batch+batch_size])\n",
    "        train_loss = loss_fn(train_logits, train_labels[batch:batch+batch_size])\n",
    "\n",
    "        train_loss.backward()\n",
    "\n",
    "        train_losses.append(train_loss.item())\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with t.inference_mode():\n",
    "            test_logits = model(test_data)\n",
    "            test_loss = loss_fn(test_logits, test_labels)\n",
    "            test_losses.append(test_loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch} | Train Loss: {train_loss.item()} | Test Loss: {test_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.2244, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3, device='cuda:0')\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "seq_test = [10,3,1,7]\n",
    "print(t.max(model(t.tensor(seq_test))[0, -1]))\n",
    "print(t.argmax(model(t.tensor(seq_test))[0, -1]))\n",
    "print(model(t.tensor(seq_test))[0, -1].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "0",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249
         ],
         "y": [
<<<<<<< Updated upstream
          2.3766825199127197,
          2.243098497390747,
          2.147594690322876,
          2.0750679969787598,
          2.017258405685425,
          1.9754102230072021,
          1.9378716945648193,
          1.8938804864883423,
          1.8461593389511108,
          1.801153540611267,
          1.7607389688491821,
          1.719709038734436,
          1.6757651567459106,
          1.6326981782913208,
          1.5933970212936401,
          1.5557435750961304,
          1.5171303749084473,
          1.4770243167877197,
          1.436069369316101,
          1.3944423198699951,
          1.3520495891571045,
          1.3098030090332031,
          1.267351746559143,
          1.2248327732086182,
          1.1827198266983032,
          1.1409310102462769,
          1.0995064973831177,
          1.0587974786758423,
          1.018149495124817,
          0.9774212837219238,
          0.93719482421875,
          0.8973662257194519,
          0.8577096462249756,
          0.8190063834190369,
          0.7809986472129822,
          0.743642270565033,
          0.7073895931243896,
          0.6722399592399597,
          0.638526439666748,
          0.6063086986541748,
          0.575282633304596,
          0.5455979704856873,
          0.5171860456466675,
          0.49040189385414124,
          0.46444106101989746,
          0.4406437873840332,
          0.4180130958557129,
          0.3971012532711029,
          0.3774178922176361,
          0.35905033349990845,
          0.3411436975002289,
          0.325325608253479,
          0.3102540969848633,
          0.2965911030769348,
          0.28397661447525024,
          0.27216655015945435,
          0.2613648474216461,
          0.2513301968574524,
          0.24190662801265717,
          0.23316815495491028,
          0.22519390285015106,
          0.2179746776819229,
          0.21117649972438812,
          0.20505620539188385,
          0.19952842593193054,
          0.1941417157649994,
          0.1898326277732849,
          0.18527798354625702,
          0.1810338944196701,
          0.1772795021533966,
          0.17369140684604645,
          0.1705644428730011,
          0.16754387319087982,
          0.16491487622261047,
          0.16251228749752045,
          0.1601942926645279,
          0.15807980298995972,
          0.1559157371520996,
          0.154312863945961,
          0.15265434980392456,
          0.15105432271957397,
          0.14959289133548737,
          0.14813493192195892,
          0.1471344381570816,
          0.14598987996578217,
          0.14462873339653015,
          0.14376425743103027,
          0.14274372160434723,
          0.14180906116962433,
          0.14101456105709076,
          0.14023438096046448,
          0.13936254382133484,
          0.13881482183933258,
          0.13805489242076874,
          0.13742142915725708,
          0.13672257959842682,
          0.136131152510643,
          0.13567402958869934,
          0.13514035940170288,
          0.1346680074930191,
          0.13424664735794067,
          0.13375923037528992,
          0.13334056735038757,
          0.13308562338352203,
          0.13261397182941437,
          0.13227230310440063,
          0.13195592164993286,
          0.13156571984291077,
          0.13138259947299957,
          0.13098491728305817,
          0.1306731104850769,
          0.13045324385166168,
          0.13011083006858826,
          0.129908949136734,
          0.12967781722545624,
          0.12943555414676666,
          0.12918099761009216,
          0.12899203598499298,
          0.12873370945453644,
          0.12863802909851074,
          0.12837918102741241,
          0.12820610404014587,
          0.12804816663265228,
          0.12782511115074158,
          0.1276494413614273,
          0.1274939626455307,
          0.12732204794883728,
          0.12718097865581512,
          0.12706401944160461,
          0.12687084078788757,
          0.12677150964736938,
          0.12661373615264893,
          0.12649324536323547,
          0.12640416622161865,
          0.1262119561433792,
          0.12612706422805786,
          0.1260467916727066,
          0.12585808336734772,
          0.12577015161514282,
          0.12572064995765686,
          0.12558934092521667,
          0.12544681131839752,
          0.1254195272922516,
          0.12522165477275848,
          0.1251934915781021,
          0.1250678300857544,
          0.12494595348834991,
          0.1248895674943924,
          0.12480498850345612,
          0.12468466907739639,
          0.12467289716005325,
          0.12459263950586319,
          0.1244625523686409,
          0.12446795403957367,
          0.12432662397623062,
          0.12421496957540512,
          0.12417152523994446,
          0.12407737970352173,
          0.12403745949268341,
          0.12396295368671417,
          0.12385241687297821,
          0.12384855002164841,
          0.12378422915935516,
          0.12367603182792664,
          0.12372440844774246,
          0.12371271103620529,
          0.12349551171064377,
          0.12353197485208511,
          0.12339400500059128,
          0.1233416348695755,
          0.12334941327571869,
          0.12324462085962296,
          0.1231575533747673,
          0.12316480278968811,
          0.12305299937725067,
          0.12302396446466446,
          0.1230241060256958,
          0.12290588766336441,
          0.12289337813854218,
          0.12285258620977402,
          0.1227385401725769,
          0.1227421686053276,
          0.1226942166686058,
          0.12264102697372437,
          0.122640460729599,
          0.12255144119262695,
          0.12253663688898087,
          0.1225740984082222,
          0.12244506180286407,
          0.12245526909828186,
          0.12255458533763885,
          0.1223139613866806,
          0.12234976887702942,
          0.12230558693408966,
          0.12221413850784302,
          0.12227678298950195,
          0.12221277505159378,
          0.12209614366292953,
          0.12218058109283447,
          0.1221042200922966,
          0.12203095853328705,
          0.1220800057053566,
          0.12196334451436996,
          0.12191268056631088,
          0.12194591015577316,
          0.12185800075531006,
          0.12180592119693756,
          0.12180979549884796,
          0.12174836546182632,
          0.12173545360565186,
          0.12173071503639221,
          0.12165571749210358,
          0.12168478965759277,
          0.12164175510406494,
          0.12158062309026718,
          0.12167223542928696,
          0.12155064195394516,
          0.12151813507080078,
          0.12149982899427414,
          0.12143408507108688,
          0.12146475166082382,
          0.12145056575536728,
          0.12137669324874878,
          0.12140581011772156,
          0.12138185650110245,
          0.12129182368516922,
          0.12130820006132126,
          0.12126059085130692,
          0.12120625376701355,
          0.12123458087444305,
          0.12120376527309418,
          0.12115079909563065,
          0.1211354210972786,
          0.12110085040330887,
          0.12106317281723022,
          0.12105805426836014,
          0.12102461606264114,
          0.12104025483131409,
          0.12103430181741714,
          0.12098214030265808,
          0.12102384865283966,
          0.12096960842609406,
          0.12093254923820496,
          0.12093579024076462,
          0.12090100347995758,
          0.12089741975069046,
          0.12087824195623398,
          0.12082477658987045,
          0.12082652747631073,
          0.1208309531211853
=======
          2.3364152908325195,
          2.1717469692230225,
          2.0614676475524902,
          1.9807125329971313,
          1.9069902896881104,
          1.8403311967849731,
          1.777667760848999,
          1.7234357595443726,
          1.6702353954315186,
          1.615211009979248,
          1.5629500150680542,
          1.5141409635543823,
          1.465851902961731,
          1.4165810346603394,
          1.3670223951339722,
          1.3167474269866943,
          1.2671650648117065,
          1.2193142175674438,
          1.1714305877685547,
          1.123378038406372,
          1.074352502822876,
          1.0263121128082275,
          0.979041337966919,
          0.9318333864212036,
          0.885591983795166,
          0.8402994871139526,
          0.7956629991531372,
          0.7518687844276428,
          0.70888751745224,
          0.6672607660293579,
          0.6271449327468872,
          0.587822675704956,
          0.5497565269470215,
          0.513300359249115,
          0.4778883457183838,
          0.4437173306941986,
          0.4104442298412323,
          0.3786226511001587,
          0.3489663600921631,
          0.32128122448921204,
          0.29557177424430847,
          0.27232569456100464,
          0.25083985924720764,
          0.23085123300552368,
          0.2127237170934677,
          0.19523577392101288,
          0.17934414744377136,
          0.16575852036476135,
          0.15273740887641907,
          0.13991472125053406,
          0.12858735024929047,
          0.11855662614107132,
          0.10846744477748871,
          0.09974608570337296,
          0.09154169261455536,
          0.08430119603872299,
          0.07729702442884445,
          0.07094373553991318,
          0.06568070501089096,
          0.061305005103349686,
          0.05684711039066315,
          0.05295427516102791,
          0.049541279673576355,
          0.04624722898006439,
          0.04327085241675377,
          0.040954649448394775,
          0.03876335918903351,
          0.03661860525608063,
          0.03494998812675476,
          0.033478233963251114,
          0.03200160712003708,
          0.03052583336830139,
          0.029292799532413483,
          0.027863861992955208,
          0.026565665379166603,
          0.025181813165545464,
          0.024270718917250633,
          0.02349788323044777,
          0.022876430302858353,
          0.02224106155335903,
          0.021413540467619896,
          0.02039368264377117,
          0.019637813791632652,
          0.019127143546938896,
          0.01863972470164299,
          0.018303267657756805,
          0.018035732209682465,
          0.01771327294409275,
          0.01741146109998226,
          0.01727922633290291,
          0.01703048311173916,
          0.016621213406324387,
          0.01627453975379467,
          0.01597256027162075,
          0.015687020495533943,
          0.015409618616104126,
          0.015177899040281773,
          0.015009766444563866,
          0.014880796894431114,
          0.014674707315862179,
          0.014430095441639423,
          0.014260132797062397,
          0.01418521162122488,
          0.01403076946735382,
          0.013810311444103718,
          0.013649731874465942,
          0.013559719547629356,
          0.01340921875089407,
          0.01319108996540308,
          0.013068370521068573,
          0.01302975695580244,
          0.012919174507260323,
          0.012724892236292362,
          0.012555867433547974,
          0.012445257976651192,
          0.01232389360666275,
          0.01215868629515171,
          0.012052102945744991,
          0.011997699737548828,
          0.011901910416781902,
          0.011758855544030666,
          0.011646782979369164,
          0.011572879739105701,
          0.011497820727527142,
          0.011419528163969517,
          0.011358049698174,
          0.011292173527181149,
          0.011207149364054203,
          0.011120470240712166,
          0.011050551198422909,
          0.010986624285578728,
          0.01092054694890976,
          0.010865701362490654,
          0.010812388733029366,
          0.0107338298112154,
          0.010640542954206467,
          0.010564771480858326,
          0.01049710065126419,
          0.010418585501611233,
          0.010340062901377678,
          0.01028049923479557,
          0.010233317501842976,
          0.010171995498239994,
          0.01010055746883154,
          0.010046972893178463,
          0.010008786804974079,
          0.009958823211491108,
          0.009893692098557949,
          0.009836556389927864,
          0.009797031059861183,
          0.009756561368703842,
          0.009704380296170712,
          0.009652121923863888,
          0.009609371423721313,
          0.009567308239638805,
          0.009520355612039566,
          0.009476350620388985,
          0.009438317269086838,
          0.009403940290212631,
          0.009366597048938274,
          0.009325828403234482,
          0.009285925887525082,
          0.009244197979569435,
          0.009205318056046963,
          0.009167667478322983,
          0.009131853468716145,
          0.009096094407141209,
          0.009061263874173164,
          0.009029540233314037,
          0.009000379592180252,
          0.008971410803496838,
          0.00894186645746231,
          0.008914178237318993,
          0.008886737748980522,
          0.008855471387505531,
          0.008821663446724415,
          0.008784887380897999,
          0.008742831647396088,
          0.008698509074747562,
          0.008648831397294998,
          0.008607674390077591,
          0.008574537932872772,
          0.008540935814380646,
          0.008505342528223991,
          0.008471471257507801,
          0.008438976481556892,
          0.008409100584685802,
          0.008382601663470268,
          0.008354416117072105,
          0.008321413770318031,
          0.008287454955279827,
          0.008253723382949829,
          0.008218726143240929,
          0.008180906064808369,
          0.008143345825374126,
          0.008107063360512257,
          0.008070782758295536,
          0.00803637970238924,
          0.00800071470439434,
          0.00796500127762556,
          0.00792632345110178,
          0.007890474982559681,
          0.007859300822019577,
          0.007833508774638176,
          0.007810420822352171,
          0.007789929863065481,
          0.007771119941025972,
          0.0077513763681054115,
          0.007729706820100546,
          0.0077050733380019665,
          0.00767969386652112,
          0.007654556538909674,
          0.007632063701748848,
          0.007612895220518112,
          0.007597039919346571,
          0.007582901511341333,
          0.007568942382931709,
          0.0075547960586845875,
          0.007537220139056444,
          0.007517566904425621,
          0.007497186306864023,
          0.007476504892110825,
          0.0074555897153913975,
          0.0074365753680467606,
          0.007420395966619253,
          0.007406090851873159,
          0.007393306586891413,
          0.007380079012364149,
          0.007364111021161079,
          0.007346067577600479,
          0.007327341008931398,
          0.007306796032935381,
          0.007285956293344498,
          0.007266925647854805,
          0.007248719688504934,
          0.007230711635202169,
          0.0072141364216804504,
          0.007198108360171318,
          0.007180630695074797,
          0.007163055706769228,
          0.0071452222764492035,
          0.007126093842089176,
          0.007105650845915079,
          0.007086768746376038,
          0.0070693534798920155,
          0.007052336819469929,
          0.007036255672574043,
          0.007021336350589991,
          0.007007130887359381,
          0.0069926027208566666,
          0.00697818910703063,
          0.006964521482586861,
          0.0069500356912612915,
          0.006934160366654396,
          0.006918686907738447,
          0.006903449073433876,
          0.006887682713568211,
          0.00687218876555562,
          0.006857669446617365,
          0.006843160837888718,
          0.006826863624155521,
          0.006809989921748638,
          0.006794186774641275,
          0.006778606213629246,
          0.006762262433767319,
          0.006745940074324608,
          0.006730431225150824,
          0.006715388502925634,
          0.006699398625642061,
          0.006683695130050182,
          0.006669313181191683,
          0.006655749399214983,
          0.006641787476837635,
          0.006627214606851339,
          0.006611427757889032,
          0.006594635546207428,
          0.006576926913112402,
          0.0065595065243542194,
          0.006542309187352657,
          0.0065254103392362595,
          0.006509656086564064,
          0.006495154928416014,
          0.006480967625975609,
          0.006467212922871113,
          0.006453863810747862,
          0.0064407517202198505,
          0.00642822403460741,
          0.006416636053472757,
          0.0064050909131765366,
          0.006393436808139086,
          0.006381981540471315,
          0.006370970979332924,
          0.006360670085996389,
          0.006350229494273663,
          0.006340002175420523,
          0.006330042611807585,
          0.006320477928966284,
          0.006311008241027594,
          0.006301692221313715,
          0.006292673293501139,
          0.006284058094024658,
          0.006275599356740713,
          0.006267464254051447,
          0.006259748712182045,
          0.006252317223697901,
          0.0062453290447592735,
          0.006237946450710297,
          0.006230607628822327,
          0.00622291024774313,
          0.0062155406922101974,
          0.006208532489836216,
          0.006201834883540869,
          0.006194956600666046,
          0.006188097409904003,
          0.006181028205901384,
          0.0061740567907691,
          0.006167442537844181,
          0.006161099765449762,
          0.0061545101925730705,
          0.006147377192974091,
          0.006139968056231737,
          0.0061326599679887295,
          0.006125481799244881,
          0.00611863425001502,
          0.006111877039074898,
          0.0061056423000991344,
          0.006099597550928593,
          0.006093266885727644,
          0.006086804438382387,
          0.006080241873860359,
          0.006074185017496347,
          0.006068305112421513,
          0.006062827538698912,
          0.0060574086382985115,
          0.006051958538591862,
          0.006046554073691368,
          0.006041154731065035,
          0.006035628728568554,
          0.006029521580785513,
          0.006022690329700708,
          0.006015479099005461,
          0.0060084485448896885,
          0.00600144499912858,
          0.005994824226945639,
          0.00598879624158144,
          0.0059831952676177025,
          0.005977606866508722,
          0.005971603561192751,
          0.00596515042707324,
          0.00595847750082612,
          0.005951606668531895,
          0.005944301374256611,
          0.00593752833083272,
          0.005933813285082579,
          0.005930351559072733,
          0.005927633959800005,
          0.005924403667449951,
          0.005920334253460169,
          0.005914869252592325,
          0.0059075672179460526,
          0.005898998584598303,
          0.005889974534511566,
          0.005880812648683786,
          0.005872267764061689,
          0.005864457692950964,
          0.0058578141033649445,
          0.005852611735463142,
          0.0058483243919909,
          0.005844511557370424,
          0.005840609315782785,
          0.0058358581736683846,
          0.005830048583447933,
          0.005823428276926279,
          0.005816264543682337,
          0.0058090416714549065,
          0.00580231798812747,
          0.0057962145656347275,
          0.005790694151073694,
          0.0057862745597958565,
          0.005782255437225103,
          0.005778667517006397,
          0.00577537901699543,
          0.005772142205387354,
          0.005768921691924334,
          0.005765897687524557,
          0.005762588232755661,
          0.005758904851973057,
          0.005755096208304167,
          0.0057513113133609295,
          0.005747106391936541,
          0.0057425894774496555,
          0.00573794636875391,
          0.00573386438190937,
          0.005730537232011557,
          0.005727529060095549,
          0.005724496673792601,
          0.005721312947571278,
          0.005717611871659756,
          0.005713421851396561,
          0.005708769429475069,
          0.0057044485583901405,
          0.005700434558093548,
          0.005696763284504414,
          0.005693093407899141,
          0.005689979996532202,
          0.005686687305569649,
          0.005683003459125757,
          0.005678936839103699,
          0.005675134714692831,
          0.005671650171279907,
          0.005667916964739561,
          0.005663767922669649,
          0.005659244954586029,
          0.005654800683259964,
          0.005650395527482033,
          0.005645615980029106,
          0.005640474613755941,
          0.005635413806885481,
          0.005630364175885916,
          0.005625059362500906,
          0.005619867239147425,
          0.005615802016109228,
          0.005612022243440151,
          0.0056084198877215385,
          0.005604732781648636,
          0.00560070900246501,
          0.005596593488007784,
          0.005593018606305122,
          0.005589670967310667,
          0.005586318206042051,
          0.005583279300481081,
          0.005580323748290539,
          0.005576912313699722,
          0.005573037546128035,
          0.005569659173488617,
          0.005565890576690435,
          0.00556214852258563,
          0.005558487959206104,
          0.0055548991076648235,
          0.0055517470464110374,
          0.005548490677028894,
          0.005544917192310095,
          0.005541508086025715,
          0.005539052188396454,
          0.00553592573851347,
          0.005532182287424803,
          0.0055286032147705555,
          0.0055254544131457806,
          0.005523025058209896,
          0.005520172417163849,
          0.005516794975847006,
          0.005512907635420561,
          0.005510095041245222,
          0.005508288275450468,
          0.0055063823238015175,
          0.005503935739398003,
          0.00550093362107873,
          0.005497328005731106,
          0.005494262557476759,
          0.005491606891155243,
          0.005488497205078602,
          0.005485054105520248,
          0.005481330212205648,
          0.005478177685290575,
          0.0054756952449679375,
          0.005472831893712282,
          0.005469788797199726,
          0.00546649843454361,
          0.005463854875415564,
          0.0054616001434624195,
          0.00545854028314352,
          0.005455141421407461,
          0.00545161310583353,
          0.0054481676779687405,
          0.005445762537419796,
          0.0054440852254629135,
          0.0054422589018940926,
          0.00543978251516819,
          0.0054368809796869755,
          0.00543341925367713,
          0.005430871620774269,
          0.0054292986169457436,
          0.005427882540971041,
          0.005425871815532446,
          0.005423394031822681,
          0.00542054558172822,
          0.005418153014034033,
          0.005416340194642544,
          0.005414031911641359,
          0.0054112887009978294,
          0.005408427678048611,
          0.005405673291534185,
          0.005403279792517424,
          0.005401131231337786,
          0.0053991880267858505,
          0.005396663676947355,
          0.005394101142883301,
          0.005391764920204878,
          0.005389511585235596,
          0.0053869872353971004,
          0.005384262651205063,
          0.005381403956562281,
          0.005378613714128733,
          0.005375876557081938,
          0.005372942425310612,
          0.00536991935223341,
          0.005366855766624212,
          0.005363829899579287,
          0.005360843148082495,
          0.005358206108212471,
          0.00535580376163125,
          0.0053535448387265205,
          0.005351029336452484,
          0.005348287522792816,
          0.005345560610294342,
          0.005342737305909395,
          0.005340033210813999,
          0.005337032023817301,
          0.005334119778126478,
          0.005331478081643581,
          0.005329174920916557,
          0.0053269644267857075,
          0.005324915982782841,
          0.005322709679603577,
          0.005320652388036251,
          0.005318527575582266,
          0.005316269584000111,
          0.005314167123287916,
          0.005312096327543259,
          0.005310141947120428,
          0.005308377090841532,
          0.005306526552885771,
          0.005304444581270218,
          0.0053023686632514,
          0.0053004128858447075,
          0.00529838353395462,
          0.005296352319419384,
          0.005294501315802336,
          0.005292439367622137,
          0.005290400702506304,
          0.005288110580295324,
          0.0052859047427773476,
          0.005283914506435394,
          0.005281945690512657,
          0.00527998199686408,
          0.005278293043375015,
          0.005276791751384735,
          0.005275321193039417,
          0.005273912101984024,
          0.0052726962603628635,
          0.005271511152386665,
          0.005270181689411402,
          0.005268825683742762,
          0.005267547443509102,
          0.005265961866825819,
          0.005264176521450281,
          0.005262596532702446,
          0.005261119455099106,
          0.0052597010508179665,
          0.005258401855826378,
          0.005256939213722944,
          0.005255102179944515,
          0.0052533275447785854,
          0.005251956172287464,
          0.005250636022537947,
          0.005249135661870241,
          0.005247654393315315,
          0.00524619547650218,
          0.005244691856205463,
          0.005243346095085144,
          0.0052422042936086655,
          0.005241231061518192,
          0.005240317899733782,
          0.00523929949849844,
          0.005238075274974108,
          0.005236829165369272,
          0.005235609598457813,
          0.005234288517385721,
          0.0052329739555716515,
          0.005231678485870361,
          0.005230681970715523,
          0.005229822359979153,
          0.0052291229367256165,
          0.00522826611995697,
          0.005227407440543175,
          0.00522637227550149,
          0.005225765518844128,
          0.005225041881203651,
          0.005224017892032862,
          0.00522282300516963,
          0.005221685394644737,
          0.005220762919634581,
          0.005219938233494759,
          0.005219040438532829,
          0.005218277219682932,
          0.005217469297349453,
          0.005216863006353378,
          0.005216569639742374,
          0.005216308403760195,
          0.005215852055698633,
          0.00521516939625144,
          0.0052145011723041534,
          0.005214078351855278,
          0.005213849246501923,
          0.005213846918195486,
          0.00521383062005043,
          0.00521370442584157,
          0.005213210824877024,
          0.005212523974478245,
          0.005211730021983385,
          0.00521112373098731,
          0.005210761912167072,
          0.005210442468523979,
          0.005210017319768667,
          0.005209306254982948,
          0.005208516027778387,
          0.00520774582400918,
          0.005207198206335306,
          0.0052069867961108685,
          0.0052067674696445465,
          0.005206219851970673,
          0.005205392837524414,
          0.005204549990594387,
          0.005203691311180592,
          0.005202827043831348,
          0.005202397704124451,
          0.005202248692512512,
          0.00520215043798089,
          0.005201876163482666,
          0.00520135136321187,
          0.005200483370572329,
          0.005199573468416929,
          0.0051985145546495914,
          0.005197685677558184,
          0.005196807906031609,
          0.005195995792746544,
          0.005195197183638811,
          0.005194242112338543,
          0.0051934183575212955,
          0.005192610435187817,
          0.005191681440919638,
          0.00519071938470006,
          0.005189794115722179,
          0.0051888879388570786,
          0.00518829096108675,
          0.005187998991459608,
          0.005187519360333681,
          0.005186644848436117,
          0.005185904912650585,
          0.0051849884912371635,
          0.005184687674045563,
          0.005184714682400227,
          0.005184359382838011,
          0.0051837642677128315,
          0.005183657631278038,
          0.0051840622909367085,
          0.005183776840567589,
          0.0051829274743795395,
          0.005182330496609211,
          0.0051822662353515625,
          0.00518248463049531,
          0.005182875785976648,
          0.005182976834475994,
          0.005182397551834583,
          0.005181590095162392,
          0.0051812962628901005,
          0.005181699059903622,
          0.005181708838790655,
          0.005181311164051294,
          0.005180926527827978,
          0.005180340260267258,
          0.005180347245186567,
          0.0051805698312819,
          0.005180805921554565,
          0.0051810708828270435,
          0.005180967040359974,
          0.005180488806217909,
          0.005180115811526775,
          0.005180384498089552,
          0.0051808543503284454,
          0.0051812962628901005,
          0.005181418266147375,
          0.005181006155908108,
          0.005180562846362591,
          0.005180841311812401,
          0.005181338172405958,
          0.0051816352643072605,
          0.005181454122066498,
          0.005181124433875084,
          0.005180584266781807,
          0.005180182866752148,
          0.00518017215654254,
          0.0051801507361233234,
          0.005180248059332371,
          0.005180078558623791,
          0.005179679952561855,
          0.005179429426789284,
          0.005179989151656628,
          0.005180885083973408,
          0.005181928630918264,
          0.005182348657399416,
          0.005182179622352123,
          0.005181765183806419,
          0.005181699525564909,
          0.0051824916154146194,
          0.005183201748877764,
          0.005184059031307697,
          0.005184627138078213,
          0.005184746813029051,
          0.005184877663850784,
          0.005185220390558243,
          0.005185827612876892,
          0.005186218768358231,
          0.005186452530324459,
          0.005186750553548336,
          0.005187048111110926,
          0.0051874094642698765,
          0.005187779664993286,
          0.00518809026107192,
          0.005188478156924248,
          0.005188710521906614,
          0.005188902374356985,
          0.005189450923353434,
          0.005190253723412752,
          0.005191546864807606,
          0.005192417651414871,
          0.005193027667701244,
          0.005193261429667473,
          0.005193847697228193,
          0.005194616038352251,
          0.005195735953748226,
          0.00519653270021081,
          0.00519711896777153,
          0.005197747610509396,
          0.005198552738875151,
          0.005199729464948177,
          0.005200693849474192,
          0.005201343446969986,
          0.005201802123337984,
          0.005202113185077906,
          0.005202413536608219,
          0.005202926695346832,
          0.0052033173851668835,
          0.005203348584473133,
          0.0052031842060387135,
          0.005203519482165575,
          0.005203898064792156,
          0.005204583518207073,
          0.005204841028898954,
          0.005204852670431137,
          0.005204830318689346,
          0.005204861052334309,
          0.005205248016864061,
          0.00520556652918458,
          0.005205477122217417,
          0.005205417983233929,
          0.005205267108976841,
          0.005205071065574884,
          0.005205267574638128,
          0.005205538589507341,
          0.005205884110182524,
          0.005205884110182524,
          0.0052056992426514626,
          0.005205580033361912,
          0.005205827299505472,
          0.005206105299293995,
          0.0052062696777284145,
          0.005206075496971607,
          0.005206238012760878,
          0.005206651519984007,
          0.005206832196563482,
          0.0052075921557843685,
          0.005208320915699005,
          0.00520930765196681,
          0.005209957715123892,
          0.0052107288502156734,
          0.005211103707551956,
          0.0052117169834673405,
          0.005211998708546162,
          0.005212831776589155,
          0.005213376600295305,
          0.005214319098740816,
          0.005214857403188944,
          0.0052155437879264355,
          0.005215772427618504,
          0.0052162460051476955,
          0.005216493736952543,
          0.005217062775045633,
          0.005217636935412884,
          0.0052177575416862965,
          0.005218410864472389,
          0.005219141952693462,
          0.005219604820013046,
          0.005219695623964071,
          0.0052200197242200375,
          0.005220703314989805,
          0.0052217463962733746,
          0.00522248400375247,
          0.0052228099666535854,
          0.005223123822361231,
          0.005223799962550402,
          0.005224593449383974,
          0.005225721746683121,
          0.005226821172982454,
          0.005227393936365843,
          0.005227603483945131,
          0.005227288696914911,
          0.005227680318057537,
          0.005228262860327959,
          0.0052290866151452065,
          0.00522985914722085,
          0.005230496637523174,
          0.005230812821537256,
          0.005230790935456753,
          0.005230894312262535,
          0.005231437273323536,
          0.005232114810496569,
          0.005233092233538628,
          0.005233901087194681,
          0.005234573036432266,
          0.005234685260802507,
          0.005234397482126951,
          0.005234336014837027,
          0.005234672222286463,
          0.005235347896814346,
          0.005236179102212191,
          0.00523675000295043,
          0.005237096920609474,
          0.005237190052866936,
          0.005237160250544548,
          0.005237236153334379,
          0.005237509962171316,
          0.0052378359250724316,
          0.005237986799329519,
          0.005238131154328585,
          0.005238138139247894,
          0.005238220561295748,
          0.005238160025328398,
          0.005238571669906378,
          0.005238580983132124,
          0.0052384850569069386,
          0.005238590762019157,
          0.005238850601017475,
          0.005238629877567291,
          0.005238331854343414,
          0.005238252691924572,
          0.005238478071987629,
          0.005238275974988937,
          0.005238179117441177,
          0.00523843290284276,
          0.005238807760179043,
          0.00523902103304863,
          0.005238696001470089,
          0.005238185171037912,
          0.005237911827862263,
          0.005237888544797897,
          0.005237962584942579,
          0.005238020792603493,
          0.005237489473074675,
          0.0052370550110936165,
          0.005236959084868431,
          0.005237032659351826,
          0.005237249191850424,
          0.005237269680947065,
          0.005237121134996414,
          0.005236993543803692,
          0.0052369460463523865,
          0.00523682776838541,
          0.0052360356785357,
          0.005235286429524422,
          0.005234856158494949,
          0.005234809126704931,
          0.005235020071268082,
          0.005234984215348959,
          0.005234502721577883,
          0.005234049167484045,
          0.0052339849062263966,
          0.005233692470937967,
          0.005233222618699074,
          0.005232700612396002,
          0.005232309456914663,
          0.0052321674302220345,
          0.005231910385191441,
          0.00523162679746747,
          0.005231058690696955,
          0.005230306647717953,
          0.005229692440479994,
          0.005229552276432514,
          0.0052295285277068615,
          0.005229241214692593,
          0.005228802096098661,
          0.005228359252214432,
          0.005227998830378056,
          0.005227882415056229,
          0.005227891728281975,
          0.005227625370025635,
          0.005227095913141966,
          0.005226512905210257,
          0.005225948989391327,
          0.005225637927651405,
          0.005225456785410643,
          0.0052250344306230545,
          0.005224382039159536,
          0.0052237980999052525,
          0.0052237180061638355,
          0.0052236043848097324,
          0.005223228130489588,
          0.005222691223025322,
          0.005222519859671593,
          0.005222155712544918,
          0.005222010891884565,
          0.005221607629209757,
          0.005221343133598566,
          0.0052210865542292595,
          0.00522057618945837,
          0.005220041144639254,
          0.0052196793258190155,
          0.005219216458499432,
          0.005218951962888241,
          0.005218564998358488,
          0.0052180360071361065,
          0.005217899568378925,
          0.005217481404542923,
          0.0052171614952385426,
          0.005216976627707481,
          0.005216533318161964,
          0.005215815734118223,
          0.0052153910510241985,
          0.005215035285800695,
          0.005214386153966188,
          0.005213557742536068,
          0.00521316472440958,
          0.0052129412069916725,
          0.005212500225752592,
          0.005211952608078718,
          0.005211306270211935,
          0.005210959352552891,
          0.0052109528332948685,
          0.0052106804214417934,
          0.0052101826295256615,
          0.005209470633417368,
          0.005209031980484724,
          0.005208936054259539,
          0.005208726041018963,
          0.005208180285990238,
          0.005207570269703865,
          0.0052069006487727165,
          0.005206575617194176,
          0.005206120666116476,
          0.005205680150538683,
          0.005205104127526283,
          0.005204548127949238,
          0.005204183980822563,
          0.0052039772272109985,
          0.0052034491673111916,
          0.005202701315283775,
          0.005202251486480236,
          0.005201887805014849,
          0.005201177205890417,
          0.005200278479605913,
          0.005199629347771406,
          0.005199027247726917,
          0.005198560655117035,
          0.005198191851377487,
          0.005197544116526842,
          0.005196761805564165,
          0.005196176934987307,
          0.005195736885070801,
          0.005195258650928736,
          0.0051946984604001045,
          0.005194392055273056,
          0.005194102879613638,
          0.005193476099520922,
          0.005192915443331003,
          0.005192419048398733,
          0.005192036274820566,
          0.005191374570131302,
          0.005190979223698378,
          0.005190732888877392,
          0.005190165247768164,
          0.005189507734030485,
          0.005189162213355303,
          0.005188872572034597,
          0.005188241600990295,
          0.005187517032027245,
          0.005187066271901131,
          0.005186628084629774,
          0.005186502356082201,
          0.005186190363019705,
          0.0051856678910553455,
          0.005185356363654137,
          0.005185261834412813,
          0.005185037385672331,
          0.005184578243643045,
          0.005184363108128309,
          0.0051842075772583485,
          0.0051839048974215984,
          0.00518330093473196,
          0.0051824371330440044,
          0.005181836895644665
>>>>>>> Stashed changes
         ]
        },
        {
         "mode": "lines",
         "name": "1",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249
         ],
         "y": [
<<<<<<< Updated upstream
          2.8080050945281982,
          2.37743878364563,
          2.242861270904541,
          2.1462807655334473,
          2.0747716426849365,
          2.0150792598724365,
          1.9754637479782104,
          1.9352155923843384,
          1.8929462432861328,
          1.8454378843307495,
          1.798885703086853,
          1.7615665197372437,
          1.7215832471847534,
          1.6756536960601807,
          1.6301854848861694,
          1.591797947883606,
          1.5564578771591187,
          1.5193551778793335,
          1.4755833148956299,
          1.4367454051971436,
          1.3959301710128784,
          1.3505833148956299,
          1.3131237030029297,
          1.2706594467163086,
          1.224825143814087,
          1.182677149772644,
          1.1408798694610596,
          1.1016119718551636,
          1.0592880249023438,
          1.0177980661392212,
          0.9775671362876892,
          0.9371286630630493,
          0.895053505897522,
          0.8566175699234009,
          0.8209537863731384,
          0.7793704867362976,
          0.7448383569717407,
          0.7081493735313416,
          0.6728139519691467,
          0.6401405930519104,
          0.6059673428535461,
          0.5742062926292419,
          0.5450895428657532,
          0.5155925750732422,
          0.48695945739746094,
          0.4649779498577118,
          0.4414531886577606,
          0.4192572236061096,
          0.3950992226600647,
          0.3796736001968384,
          0.3576085567474365,
          0.339712917804718,
          0.32445740699768066,
          0.3120124638080597,
          0.30084356665611267,
          0.2828828990459442,
          0.2716478407382965,
          0.26104292273521423,
          0.24947766959667206,
          0.243340402841568,
          0.2355431169271469,
          0.2265046387910843,
          0.21649034321308136,
          0.2109721451997757,
          0.20444755256175995,
          0.19893959164619446,
          0.19276586174964905,
          0.18757449090480804,
          0.18337956070899963,
          0.17841672897338867,
          0.17890039086341858,
          0.17289531230926514,
          0.17229528725147247,
          0.16412030160427094,
          0.1663275957107544,
          0.16123409569263458,
          0.1574077606201172,
          0.15517966449260712,
          0.15757887065410614,
          0.1580035537481308,
          0.15334421396255493,
          0.15008904039859772,
          0.1485394984483719,
          0.14596442878246307,
          0.14840319752693176,
          0.14760343730449677,
          0.1449640840291977,
          0.14187653362751007,
          0.14242736995220184,
          0.1406169980764389,
          0.1404487043619156,
          0.138347789645195,
          0.13727052509784698,
          0.13664136826992035,
          0.13566812872886658,
          0.13908539712429047,
          0.136225625872612,
          0.13769488036632538,
          0.13198979198932648,
          0.1364511251449585,
          0.13344939053058624,
          0.13162153959274292,
          0.1301063895225525,
          0.13494303822517395,
          0.13633720576763153,
          0.1333167552947998,
          0.1313001960515976,
          0.13076014816761017,
          0.12954512238502502,
          0.13276457786560059,
          0.13228514790534973,
          0.13124020397663116,
          0.12862665951251984,
          0.12958310544490814,
          0.1288212090730667,
          0.12912054359912872,
          0.12731991708278656,
          0.12724918127059937,
          0.12677748501300812,
          0.12640024721622467,
          0.13035990297794342,
          0.12796296179294586,
          0.12979304790496826,
          0.1244659423828125,
          0.12907132506370544,
          0.12642233073711395,
          0.12488564103841782,
          0.12348911911249161,
          0.12887659668922424,
          0.13015270233154297,
          0.1275065392255783,
          0.12577739357948303,
          0.12545843422412872,
          0.12434855848550797,
          0.127783864736557,
          0.12754352390766144,
          0.12662984430789948,
          0.12417848408222198,
          0.12537841498851776,
          0.12466259300708771,
          0.12502296268939972,
          0.12339873611927032,
          0.12363679707050323,
          0.12311770021915436,
          0.1229594349861145,
          0.1270655393600464,
          0.12471484392881393,
          0.12643995881080627,
          0.12131829559803009,
          0.12587769329547882,
          0.12332047522068024,
          0.12210772186517715,
          0.12062633037567139,
          0.12610729038715363,
          0.1274273842573166,
          0.12502646446228027,
          0.12324948608875275,
          0.12295923382043839,
          0.12197156250476837,
          0.12536396086215973,
          0.12518177926540375,
          0.12438696622848511,
          0.12190687656402588,
          0.12330164760351181,
          0.12258534878492355,
          0.12301500141620636,
          0.12156889587640762,
          0.12177393585443497,
          0.12116211652755737,
          0.12110910564661026,
          0.12519033253192902,
          0.12299495190382004,
          0.12481977790594101,
          0.11970718950033188,
          0.12417113035917282,
          0.12166740745306015,
          0.1204736977815628,
          0.11908479034900665,
          0.12451737374067307,
          0.12583990395069122,
          0.12355773895978928,
          0.12176044285297394,
          0.12158817052841187,
          0.12050749361515045,
          0.12396373599767685,
          0.1238357350230217,
          0.12316518276929855,
          0.12067241966724396,
          0.12213434278964996,
          0.12137094885110855,
          0.1217108964920044,
          0.12039065361022949,
          0.12052621692419052,
          0.11994265764951706,
          0.11995726078748703,
          0.12411611527204514,
          0.12190039455890656,
          0.12372063845396042,
          0.11859257519245148,
          0.1230611801147461,
          0.12062595039606094,
          0.11945686489343643,
          0.11813177168369293,
          0.1235460564494133,
          0.12480511516332626,
          0.1226939782500267,
          0.12083547562360764,
          0.12064038962125778,
          0.11965620517730713,
          0.1229865700006485,
          0.12288022041320801,
          0.12231471389532089,
          0.11979684978723526,
          0.12123581022024155,
          0.12055826187133789,
          0.12082727253437042,
          0.11954834312200546,
          0.11975874751806259,
          0.11906421184539795,
          0.11907706409692764,
          0.12337090075016022,
          0.12105735391378403,
          0.12299793213605881,
          0.11794954538345337,
          0.12227001041173935,
          0.11994011700153351,
          0.11877176910638809,
          0.11737262457609177,
          0.12281733006238937,
          0.12410900741815567,
          0.1220371350646019,
          0.12017934769392014,
          0.12003438919782639,
          0.11900551617145538,
          0.12245338410139084,
          0.1221892386674881,
          0.12169792503118515,
          0.11916277557611465,
          0.12058339267969131,
          0.11998011916875839,
          0.12024205178022385,
          0.1189141795039177,
          0.11919911205768585,
          0.11852140724658966,
          0.11849541962146759,
          0.12283433973789215,
          0.12048450857400894,
          0.1224217340350151,
          0.11744692176580429,
          0.1217244416475296
=======
          2.708627700805664,
          2.330667495727539,
          2.16935133934021,
          2.0626955032348633,
          1.9821646213531494,
          1.9065356254577637,
          1.838087558746338,
          1.7749899625778198,
          1.720491647720337,
          1.6670901775360107,
          1.6113582849502563,
          1.5581475496292114,
          1.5081480741500854,
          1.4585500955581665,
          1.4089151620864868,
          1.3592606782913208,
          1.3087527751922607,
          1.2586358785629272,
          1.2098952531814575,
          1.1610217094421387,
          1.11220383644104,
          1.0628529787063599,
          1.0143698453903198,
          0.966727077960968,
          0.9190192818641663,
          0.872333288192749,
          0.8267281651496887,
          0.7819027900695801,
          0.7381013035774231,
          0.695344090461731,
          0.6538994312286377,
          0.6142241358757019,
          0.5754508972167969,
          0.5378066897392273,
          0.5014932751655579,
          0.466451495885849,
          0.432929128408432,
          0.400402694940567,
          0.36920565366744995,
          0.3397253751754761,
          0.3121185302734375,
          0.28628596663475037,
          0.2620919346809387,
          0.23914583027362823,
          0.21802671253681183,
          0.19937771558761597,
          0.18177473545074463,
          0.16590291261672974,
          0.15185979008674622,
          0.13831576704978943,
          0.12586064636707306,
          0.11429888755083084,
          0.10437104105949402,
          0.09485045075416565,
          0.08605324476957321,
          0.07814629375934601,
          0.07124782353639603,
          0.06499136239290237,
          0.05928661301732063,
          0.054149359464645386,
          0.049453865736722946,
          0.045177243649959564,
          0.04161228612065315,
          0.038164205849170685,
          0.035121768712997437,
          0.03239566460251808,
          0.029892675578594208,
          0.027592798694968224,
          0.02548365294933319,
          0.023528272286057472,
          0.02177748829126358,
          0.020194152370095253,
          0.018902838230133057,
          0.017577260732650757,
          0.016367264091968536,
          0.015299172140657902,
          0.01426932867616415,
          0.013465426862239838,
          0.012639811262488365,
          0.011956075206398964,
          0.011286423541605473,
          0.010617482475936413,
          0.010031248442828655,
          0.009518799372017384,
          0.009009463712573051,
          0.008554433472454548,
          0.008181274868547916,
          0.007786961272358894,
          0.0074243308044970036,
          0.007103155832737684,
          0.006795975379645824,
          0.006504167336970568,
          0.006252107676118612,
          0.006004977505654097,
          0.0057667759247124195,
          0.005555633921176195,
          0.005351439118385315,
          0.005162429064512253,
          0.004980996251106262,
          0.004813725128769875,
          0.004646368324756622,
          0.004498384427279234,
          0.0043568480759859085,
          0.004219568334519863,
          0.004090110305696726,
          0.0039718374609947205,
          0.00385714927688241,
          0.003749110968783498,
          0.003647822653874755,
          0.003548241686075926,
          0.0034555441234260798,
          0.003367012133821845,
          0.0032817423343658447,
          0.0032010821159929037,
          0.0031251695472747087,
          0.003050734754651785,
          0.002980454359203577,
          0.0029124291613698006,
          0.002847073832526803,
          0.0027848512399941683,
          0.002724560210481286,
          0.0026663055177778006,
          0.0026100859977304935,
          0.002556625986471772,
          0.00250437599606812,
          0.00245442776940763,
          0.0024054718669503927,
          0.0023584836162626743,
          0.002312527969479561,
          0.0022685208823531866,
          0.002225677017122507,
          0.002184554236009717,
          0.0021444251760840416,
          0.0021058644633740187,
          0.0020682543981820345,
          0.0020318510942161083,
          0.00199635187163949,
          0.001961885020136833,
          0.0019284987356513739,
          0.0018960784655064344,
          0.0018645128002390265,
          0.0018338114023208618,
          0.0018038817215710878,
          0.0017747670644894242,
          0.0017464238917455077,
          0.001718738116323948,
          0.0016917219618335366,
          0.0016654172213748097,
          0.0016397560248151422,
          0.001614724867977202,
          0.001590265310369432,
          0.0015664243837818503,
          0.001543155056424439,
          0.001520439051091671,
          0.001498201978392899,
          0.0014764675870537758,
          0.0014552202774211764,
          0.0014344430528581142,
          0.00141413533128798,
          0.0013942853547632694,
          0.0013748644851148129,
          0.0013558685313910246,
          0.0013373077381402254,
          0.001319158123806119,
          0.001301390933804214,
          0.0012840036069974303,
          0.0012669585412368178,
          0.0012502616737037897,
          0.0012339095119386911,
          0.001217903452925384,
          0.001202218234539032,
          0.0011868398869410157,
          0.0011717602610588074,
          0.001156984711997211,
          0.0011424882104620337,
          0.0011282555060461164,
          0.0011142767034471035,
          0.0011005542473867536,
          0.0010870774276554585,
          0.0010738522978499532,
          0.0010608851443976164,
          0.001048176665790379,
          0.001035687979310751,
          0.0010234221117570996,
          0.001011381158605218,
          0.0009995432337746024,
          0.000987913692370057,
          0.0009764584247022867,
          0.0009652027511037886,
          0.000954131712205708,
          0.0009432615479454398,
          0.000932566705159843,
          0.0009220488136634231,
          0.000911676965188235,
          0.000901467283256352,
          0.0008914411882869899,
          0.0008816043264232576,
          0.000871945871040225,
          0.000862453191075474,
          0.0008531077764928341,
          0.0008439169032499194,
          0.0008348727133125067,
          0.0008259728783741593,
          0.0008172196103259921,
          0.0008086029556579888,
          0.0008001138921827078,
          0.000791763246525079,
          0.0007835444994270802,
          0.000775451713707298,
          0.0007674797088839114,
          0.0007596306386403739,
          0.000751899613533169,
          0.0007442861096933484,
          0.0007367859361693263,
          0.0007294114329852164,
          0.0007221484556794167,
          0.0007149959565140307,
          0.0007079571369104087,
          0.0007010212284512818,
          0.0006941903266124427,
          0.0006874576210975647,
          0.0006808244506828487,
          0.0006742851110175252,
          0.0006678412319160998,
          0.0006614894373342395,
          0.000655225245282054,
          0.0006490468513220549,
          0.0006429603090509772,
          0.0006369616603478789,
          0.0006310451426543295,
          0.0006252145976759493,
          0.0006194531451910734,
          0.0006137759191915393,
          0.0006081766914576292,
          0.0006026531918905675,
          0.0005972065264359117,
          0.000591826334130019,
          0.0005865118000656366,
          0.0005812678136862814,
          0.000576095946598798,
          0.0005709970719181001,
          0.0005659586749970913,
          0.0005609773215837777,
          0.0005560607532970607,
          0.000551203906070441,
          0.0005464100977405906,
          0.0005416770582087338,
          0.0005369997234083712,
          0.0005323817022144794,
          0.0005278229364193976,
          0.0005233190022408962,
          0.0005188763607293367,
          0.0005144886672496796,
          0.000510156387463212,
          0.0005058792303316295,
          0.0005016520153731108,
          0.0004974788171239197,
          0.0004933553282171488,
          0.0004892852739430964,
          0.0004852650163229555,
          0.00048128992784768343,
          0.0004773586697410792,
          0.0004734774702228606,
          0.000469639286166057,
          0.00046584795927628875,
          0.00046210380969569087,
          0.0004584029084071517,
          0.0004547439457383007,
          0.0004511279985308647,
          0.0004475518362596631,
          0.00044402002822607756,
          0.000440525560406968,
          0.00043707233271561563,
          0.0004336551937740296,
          0.00043027568608522415,
          0.00042693590512499213,
          0.0004236318345647305,
          0.00042036434751935303,
          0.000417134549934417,
          0.0004139377560932189,
          0.00041077687637880445,
          0.0004076510085724294,
          0.0004045602399855852,
          0.000401507830247283,
          0.00039849194581620395,
          0.0003955113352276385,
          0.0003925605269614607,
          0.0003896442649420351,
          0.0003867612686008215,
          0.0003839036507997662,
          0.00038107699947431684,
          0.00037828099448233843,
          0.00037551819696091115,
          0.0003727849980350584,
          0.00037008034996688366,
          0.0003674033796414733,
          0.00036475725937634706,
          0.00036213992279954255,
          0.0003595482266973704,
          0.000356990029104054,
          0.0003544585779309273,
          0.00035195742384530604,
          0.00034948272514156997,
          0.0003470318333711475,
          0.00034461007453501225,
          0.00034221317037008703,
          0.00033984382753260434,
          0.00033749916474334896,
          0.00033518002601340413,
          0.00033288440317846835,
          0.00033061482827179134,
          0.0003283684782218188,
          0.0003261443052906543,
          0.0003239471698179841,
          0.00032177093089558184,
          0.00031961590866558254,
          0.000317482219543308,
          0.0003153713187202811,
          0.00031328178010880947,
          0.0003112147969659418,
          0.0003091699618380517,
          0.000307144015096128,
          0.0003051379171665758,
          0.0003031500964425504,
          0.00030118130962364376,
          0.00029923260444775224,
          0.00029730264213867486,
          0.00029539389652200043,
          0.0002935027296189219,
          0.00029163126600906253,
          0.00028977717738598585,
          0.0002879446547012776,
          0.000286125490674749,
          0.0002843230904545635,
          0.0002825411793310195,
          0.0002807730052154511,
          0.0002790235448628664,
          0.0002772885200101882,
          0.0002755695313680917,
          0.0002738690236583352,
          0.00027218295144848526,
          0.00027051285724155605,
          0.00026885882834903896,
          0.00026721987524069846,
          0.0002655965799931437,
          0.0002639883605297655,
          0.00026239483850076795,
          0.00026081380201503634,
          0.0002592477831058204,
          0.00025769343483261764,
          0.0002561543951742351,
          0.0002546228060964495,
          0.0002531000063754618,
          0.00025159650249406695,
          0.00025010918034240603,
          0.0002486285229679197,
          0.00024716503685340285,
          0.00024571752874180675,
          0.0002442824770696461,
          0.00024285570543725044,
          0.00024143750488292426,
          0.00024003046564757824,
          0.0002386379346717149,
          0.00023725956270936877,
          0.00023589526244904846,
          0.00023454100301023573,
          0.00023319928732234985,
          0.00023186721955426037,
          0.000230545672820881,
          0.000229238357860595,
          0.00022794307733420283,
          0.00022666003496851772,
          0.0002253865241073072,
          0.0002241237962152809,
          0.0002228665689472109,
          0.00022162709501571953,
          0.000220395959331654,
          0.00021917656704317778,
          0.0002179681760026142,
          0.00021676672622561455,
          0.00021557601576205343,
          0.00021439712145365775,
          0.00021322848624549806,
          0.00021206872770562768,
          0.00021091791859362274,
          0.0002097778778988868,
          0.00020864562247879803,
          0.00020752438285853714,
          0.00020641232549678534,
          0.0002053089701803401,
          0.00020421513181645423,
          0.00020313089771661907,
          0.0002020577376242727,
          0.00020099249377381057,
          0.00019993433670606464,
          0.0001988866861211136,
          0.00019784615142270923,
          0.00019681506091728806,
          0.00019579271611291915,
          0.00019477904425002635,
          0.00019377384160179645,
          0.0001927748671732843,
          0.0001917866466101259,
          0.00019080359197687358,
          0.00018982896290253848,
          0.0001888617844088003,
          0.00018790349713526666,
          0.00018695168546400964,
          0.00018600616022013128,
          0.00018506990454625338,
          0.0001841405319282785,
          0.00018321712559554726,
          0.00018230198475066572,
          0.00018139323219656944,
          0.00018049083882942796,
          0.0001795952266547829,
          0.00017870691954158247,
          0.00017782599024940282,
          0.00017695128917694092,
          0.00017608316557016224,
          0.00017522268171887845,
          0.00017436886264476925,
          0.0001735207042656839,
          0.0001726787886582315,
          0.0001718435378279537,
          0.0001710145006654784,
          0.00017019198276102543,
          0.00016937540203798562,
          0.0001685652241576463,
          0.0001677571126492694,
          0.00016695707745384425,
          0.0001661636051721871,
          0.00016537769988644868,
          0.00016459486505482346,
          0.00016381900059059262,
          0.00016304814198520035,
          0.00016228380263783038,
          0.00016152359603438526,
          0.00016076830797828734,
          0.00016002063057385385,
          0.0001592771732248366,
          0.0001585386780789122,
          0.0001578041265020147,
          0.00015707590500824153,
          0.00015635366435162723,
          0.00015563644410576671,
          0.00015492462262045592,
          0.00015421674470417202,
          0.0001535145565867424,
          0.0001528168941149488,
          0.00015212495054583997,
          0.00015143580094445497,
          0.00015075162809807807,
          0.00015007215552031994,
          0.00014939723769202828,
          0.0001487253757659346,
          0.00014805991668254137,
          0.00014739840116817504,
          0.00014674049452878535,
          0.00014608704077545553,
          0.00014543994620908052,
          0.000144793521030806,
          0.00014415332407224923,
          0.0001435172016499564,
          0.00014288628881331533,
          0.00014226035273168236,
          0.00014163655578158796,
          0.00014101718261372298,
          0.00014040233509149402,
          0.00013979070354253054,
          0.0001391838741255924,
          0.0001385809446219355,
          0.00013798226427752525,
          0.00013738802226725966,
          0.0001367968216072768,
          0.00013620959362015128,
          0.00013562588719651103,
          0.0001350471138721332,
          0.00013447055243887007,
          0.00013389856030698866,
          0.00013332825619727373,
          0.00013276300160214305,
          0.0001322009920841083,
          0.00013164302799850702,
          0.0001310883671976626,
          0.00013053714064881206,
          0.00012998962483834475,
          0.00012944494665134698,
          0.00012890151992905885,
          0.0001283638266613707,
          0.00012782879639416933,
          0.0001272961962968111,
          0.00012676794722210616,
          0.0001262403093278408,
          0.00012571763363666832,
          0.0001251959620276466,
          0.00012467903434298933,
          0.0001241655700141564,
          0.0001236557145603001,
          0.0001231488276971504,
          0.0001226445601787418,
          0.000122142126201652,
          0.00012164238432887942,
          0.00012114607670810074,
          0.00012065270129824057,
          0.00012016433174721897,
          0.00011967632599407807,
          0.00011919271491933614,
          0.00011871261085616425,
          0.00011823573731817305,
          0.00011776095198001713,
          0.00011728855315595865,
          0.00011682025069603696,
          0.00011635409464361146,
          0.0001158919112640433,
          0.00011543116852408275,
          0.00011497204832267016,
          0.00011451721366029233,
          0.00011406384874135256,
          0.00011361323413439095,
          0.00011316689051454887,
          0.00011272184201516211,
          0.00011227950017200783,
          0.00011184169125044718,
          0.00011140362039441243,
          0.0001109694640035741,
          0.0001105383489630185,
          0.00011010935850208625,
          0.00010968352580675855,
          0.00010926030518021435,
          0.00010883690265472978,
          0.00010841710172826424,
          0.0001080012516467832,
          0.00010758664575405419,
          0.00010717447003116831,
          0.00010676650708774105,
          0.00010636010119924322,
          0.00010595488856779411,
          0.00010555451444815844,
          0.00010515346366446465,
          0.00010475541785126552,
          0.00010436051525175571,
          0.00010396780999144539,
          0.00010357489372836426,
          0.00010318706335965544,
          0.0001028002516250126,
          0.00010241492418572307,
          0.00010203174315392971,
          0.00010165254934690893,
          0.00010127574932994321,
          0.00010089890565723181,
          0.00010052577999886125,
          0.0001001537311822176,
          0.00009978410525945947,
          0.00009941616735886782,
          0.00009905083425110206,
          0.00009868723282124847,
          0.0000983253339654766,
          0.00009796644008019939,
          0.00009760935790836811,
          0.0000972523121163249,
          0.00009689966827863827,
          0.00009654745372245088,
          0.00009619735646992922,
          0.00009584915824234486,
          0.00009550333925290033,
          0.00009515857527730986,
          0.00009481675078859553,
          0.00009447681804886088,
          0.00009413735824637115,
          0.00009380182746099308,
          0.00009346561273559928,
          0.00009313309419667348,
          0.00009280181984649971,
          0.00009247224079445004,
          0.00009214424790116027,
          0.00009181605855701491,
          0.0000914924603421241,
          0.00009116933506447822,
          0.00009084877092391253,
          0.00009052896348293871,
          0.00009021100413519889,
          0.00008989514026325196,
          0.00008958005491876975,
          0.00008926826558308676,
          0.00008895717473933473,
          0.0000886473135324195,
          0.00008833775791572407,
          0.00008803258242551237,
          0.00008772576256887987,
          0.0000874219331308268,
          0.0000871214724611491,
          0.00008682095358381048,
          0.00008652253745822236,
          0.00008622586028650403,
          0.00008592984522692859,
          0.00008563481242163107,
          0.00008534226071787998,
          0.00008505032019456849,
          0.00008476103539578617,
          0.00008447231084574014,
          0.00008418400102527812,
          0.00008389806316699833,
          0.00008361475920537487,
          0.00008333122968906537,
          0.00008304938091896474,
          0.00008276924927486107,
          0.00008249087841250002,
          0.00008221332245739177,
          0.00008193685789592564,
          0.00008166355110006407,
          0.00008138951670844108,
          0.00008111682836897671,
          0.0000808449913165532,
          0.00008057626837398857,
          0.00008030764729483053,
          0.00008004160918062553,
          0.00007977493805810809,
          0.00007951027509989217,
          0.00007924802775960416,
          0.00007898562762420624,
          0.00007872561400290579,
          0.00007846520747989416,
          0.00007820783503120765,
          0.00007795105193508789,
          0.00007769496005494148,
          0.00007744043978163972,
          0.00007718799315625802,
          0.00007693510997341946,
          0.00007668506441405043,
          0.00007643416756764054,
          0.00007618491508765146,
          0.00007593792543048039,
          0.00007569142326246947,
          0.00007544473191956058,
          0.00007520009239669889,
          0.00007495729369111359,
          0.00007471551361959428,
          0.00007447444659192115,
          0.00007423389615723863,
          0.00007399544847430661,
          0.00007375737914117053,
          0.00007351980457315221,
          0.00007328415813390166,
          0.00007305036706384271,
          0.00007281713624252006,
          0.00007258498953888193,
          0.00007235401426441967,
          0.00007212494529085234,
          0.00007189575262600556,
          0.0000716696449671872,
          0.00007144328992580995,
          0.00007121822272893041,
          0.00007099312642822042,
          0.0000707698636688292,
          0.00007054759043967351,
          0.00007032719440758228,
          0.00007010684930719435,
          0.00006988686800468713,
          0.00006966909859329462,
          0.0000694515256327577,
          0.00006923465116415173,
          0.00006901956658111885,
          0.00006880496948724613,
          0.00006859075801912695,
          0.00006837905675638467,
          0.00006816800305387005,
          0.00006795718218199909,
          0.0000677476855344139,
          0.0000675399205647409,
          0.00006733110058121383,
          0.00006712375761708245,
          0.00006691923772450536,
          0.00006671465234830976,
          0.0000665108163957484,
          0.00006630896677961573,
          0.00006610614218516275,
          0.00006590428529307246,
          0.00006570441473741084,
          0.00006550583202624694,
          0.0000653062597848475,
          0.00006510873936349526,
          0.00006491231761174276,
          0.00006471601955126971,
          0.00006452148227253929,
          0.00006432701047742739,
          0.0000641354126855731,
          0.0000639411446172744,
          0.00006375009252224118,
          0.00006355920049827546,
          0.00006336982914945111,
          0.00006318134546745569,
          0.00006299291999312118,
          0.00006280618981691077,
          0.00006261938688112423,
          0.00006243384268600494,
          0.00006225019751582295,
          0.00006206557736732066,
          0.00006188257975736633,
          0.00006169998232508078,
          0.00006151901470730081,
          0.00006133793067419901,
          0.00006115851283539087,
          0.00006097894220147282,
          0.00006080103412386961,
          0.00006062408283469267,
          0.00006044749534339644,
          0.000060270511312410235,
          0.00006009522985550575,
          0.00005992033038637601,
          0.00005974638042971492,
          0.00005957322719041258,
          0.00005940045593888499,
          0.00005922889613430016,
          0.00005905830403207801,
          0.0000588884977332782,
          0.00005871907342225313,
          0.000058550271205604076,
          0.00005838170909555629,
          0.00005821403465233743,
          0.000058048011851496994,
          0.00005788242560811341,
          0.00005771735231974162,
          0.00005755190795753151,
          0.00005738798063248396,
          0.000057225304772146046,
          0.00005706294177798554,
          0.00005690018224413507,
          0.00005673876512446441,
          0.000056578701332909986,
          0.000056419099564664066,
          0.00005625907942885533,
          0.00005610030348179862,
          0.000055942731705727056,
          0.000055785705626476556,
          0.00005562917431234382,
          0.000055470805818913504,
          0.000055315667850663885,
          0.000055160846386570483,
          0.00005500594852492213,
          0.00005485268775373697,
          0.00005469847747008316,
          0.000054546075261896476,
          0.00005439394954009913,
          0.000054242809710558504,
          0.000054091637139208615,
          0.00005394218533183448,
          0.00005379231515689753,
          0.000053642525017494336,
          0.00005349485218175687,
          0.000053345687774708495,
          0.000053199335525278,
          0.00005305230661178939,
          0.00005290675107971765,
          0.00005276082447380759,
          0.000052616287575801834,
          0.000052471219532890245,
          0.00005232780677033588,
          0.000052183913794578984,
          0.00005204082845011726,
          0.000051898445235565305,
          0.00005175569458515383,
          0.000051614340918604285,
          0.00005147410774952732,
          0.00005133360537001863,
          0.000051192648243159056,
          0.000051052971684839576,
          0.00005091431739856489,
          0.00005077681998955086,
          0.000050639402616070583,
          0.000050502039812272415,
          0.00005036530637880787,
          0.000050229278713231906,
          0.000050093720346922055,
          0.00004995979543309659,
          0.000049825888709165156,
          0.00004969117799191736,
          0.000049558784667169675,
          0.00004942519080941565,
          0.000049293379561277106,
          0.000049162423238158226,
          0.00004903171429759823,
          0.00004890061973128468,
          0.00004877153332927264,
          0.00004864191942033358,
          0.00004851310950471088,
          0.00004838455788558349,
          0.00004825621726922691,
          0.000048129855713341385,
          0.00004800254464498721,
          0.00004787667785421945,
          0.000047751131205586717,
          0.00004762468597618863,
          0.000047500929213128984,
          0.00004737719427794218,
          0.000047252724471036345,
          0.00004712933150585741,
          0.000047005371015984565,
          0.00004688282933784649,
          0.000046761106204940006,
          0.000046640358050353825,
          0.0000465198427264113,
          0.00004639971302822232,
          0.000046278473746497184,
          0.0000461593153886497,
          0.00004604098285199143,
          0.00004592072946252301,
          0.00004580285894917324,
          0.00004568565418594517,
          0.00004556633211905137,
          0.00004544975308817811,
          0.000045333628804655746,
          0.000045217570004751906,
          0.00004510297003434971,
          0.00004498691487242468,
          0.000044873359001940116,
          0.000044759064621757716,
          0.000044644584704656154,
          0.00004453126894077286,
          0.0000444189936388284,
          0.000044305616029305384,
          0.000044193882786203176,
          0.000044082604290451854,
          0.000043970783735858276,
          0.000043860654841409996,
          0.000043750587792601436,
          0.000043640284275170416,
          0.00004353083568275906,
          0.000043421947339084,
          0.000043312873458489776,
          0.00004320349762565456,
          0.000043096319132018834,
          0.00004298847488826141,
          0.00004288162381271832,
          0.00004277483458281495,
          0.00004266901669325307,
          0.000042563598981359974,
          0.00004245768650434911,
          0.00004235121014062315,
          0.000042246330849593505,
          0.00004214138971292414,
          0.000042037419916596264,
          0.0000419337629864458,
          0.00004183077908237465,
          0.00004172772241872735,
          0.000041624971345299855,
          0.00004152345354668796,
          0.00004142075340496376,
          0.00004132047251914628,
          0.00004121982055949047,
          0.00004111844828003086,
          0.00004101773811271414,
          0.00004091762821190059,
          0.0000408183186664246,
          0.00004071837611263618,
          0.00004061923755216412,
          0.000040520702896174043,
          0.00004042166256112978,
          0.00004032464494230226,
          0.00004022672146675177,
          0.000040130518755177036,
          0.00004003275535069406,
          0.000039936167013365775,
          0.00003983988062827848,
          0.000039743990782881156,
          0.00003964777715737,
          0.00003955294596380554,
          0.00003945833304896951,
          0.00003936339635401964,
          0.00003926998397218995,
          0.000039175884012365714,
          0.000039081725844880566,
          0.000038989623135421425,
          0.00003889589788741432,
          0.000038803478673798963,
          0.00003871106309816241,
          0.000038618716644123197,
          0.00003852709414786659,
          0.00003843595914077014,
          0.00003834551534964703,
          0.000038254598621279,
          0.000038164802390383556,
          0.00003807482062256895,
          0.00003798494071816094,
          0.000037894660636084154,
          0.0000378059376089368,
          0.00003771680349018425,
          0.000037628818972734734,
          0.00003753991404664703,
          0.000037452391552506015,
          0.00003736375947482884,
          0.000037276462535373867,
          0.0000371907590306364,
          0.00003710438613779843,
          0.000037018264265498146,
          0.0000369318513548933,
          0.000036845365684712306,
          0.00003676006963360123,
          0.00003667563578346744,
          0.000036590583476936445,
          0.000036505134630715474,
          0.00003641967487055808,
          0.000036335888580651954,
          0.00003625294266385026,
          0.000036169818486087024,
          0.00003608671613619663,
          0.000036002784327138215,
          0.00003592049688450061,
          0.00003583750731195323,
          0.00003575563459889963,
          0.00003567376916180365,
          0.000035591576306615025,
          0.00003551046393113211,
          0.00003542825288604945,
          0.00003534720235620625,
          0.000035266868508188054,
          0.00003518680023262277,
          0.00003510768146952614,
          0.000035027194826398045,
          0.00003494739212328568,
          0.000034868491638917476,
          0.00003478983853710815,
          0.000034711029002210125,
          0.000034633623727131635,
          0.00003455470141489059,
          0.000034477347071515396,
          0.000034400181903038174,
          0.00003432342055020854,
          0.000034245906135765836,
          0.00003416930849198252,
          0.000034092845453415066,
          0.00003401578214834444,
          0.00003394008308532648,
          0.000033863856515381485,
          0.00003378920882823877,
          0.00003371297862031497,
          0.00003363805080880411,
          0.00003356302477186546,
          0.00003348864265717566,
          0.000033415049983887,
          0.000033340329537168145,
          0.00003326652222312987,
          0.000033193562558153644,
          0.00003311986802145839,
          0.000033045853342628106,
          0.00003297328294138424,
          0.000032900727092055604,
          0.00003282861507614143,
          0.00003275558628956787,
          0.00003268379805376753,
          0.00003261221354478039,
          0.00003254086914239451,
          0.00003246912456233986,
          0.00003239732177462429,
          0.00003232697781641036,
          0.000032256000849884003,
          0.00003218604251742363,
          0.000032116597139975056,
          0.00003204719541827217,
          0.000031978212064132094,
          0.000031907537049846724,
          0.000031838346330914646,
          0.000031769348424859345,
          0.000031700074032414705,
          0.00003163096334901638,
          0.000031563286029268056,
          0.00003149493568344042,
          0.00003142670539091341,
          0.00003135828592348844,
          0.00003129092146991752,
          0.000031224117265082896,
          0.00003115698928013444,
          0.000031089784897631034,
          0.000031023660994833335,
          0.00003095767897320911,
          0.000030890954803908244,
          0.00003082389594055712,
          0.00003075795029872097,
          0.0000306931760860607,
          0.0000306272559100762,
          0.000030561630410375074,
          0.000030496590625261888,
          0.000030431434424826875,
          0.00003036681482626591,
          0.00003030249717994593,
          0.000030237964892876334,
          0.000030173065169947222,
          0.00003010949876625091,
          0.000030044593586353585,
          0.000029981130865053274,
          0.000029918450309196487,
          0.000029855562388547696,
          0.000029791626730002463,
          0.000029729519155807793,
          0.000029666611226275563,
          0.000029604258088511415,
          0.000029542254196712747,
          0.000029480479497578926,
          0.000029417769837891683,
          0.000029356113373069093
>>>>>>> Stashed changes
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": ""
        },
        "xaxis": {
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "title": {
          "text": ""
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lines([test_losses, train_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 100.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#difference of lists test_losses and train_losses\n",
    "diff = [test_losses[i] - train_losses[i] for i in range(len(test_losses))]\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(diff)\n",
    "#xlim\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = t.tensor([10] * 10).to(cfg.device)\n",
    "out = model(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-68.5691, -53.3248, -33.7109,  28.4673, -47.1521,  49.8403,  20.7787,\n",
       "          18.6870, -19.6562,  14.9037]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 20,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "xaxis": "x",
         "y": [
          2.3364152908325195,
          2.1717469692230225,
          2.0614676475524902,
          1.9807125329971313,
          1.9069902896881104,
          1.8403311967849731,
          1.777667760848999,
          1.7234357595443726,
          1.6702353954315186,
          1.615211009979248,
          1.5629500150680542,
          1.5141409635543823,
          1.465851902961731,
          1.4165810346603394,
          1.3670223951339722,
          1.3167474269866943,
          1.2671650648117065,
          1.2193142175674438,
          1.1714305877685547,
          1.123378038406372,
          1.074352502822876,
          1.0263121128082275,
          0.979041337966919,
          0.9318333864212036,
          0.885591983795166,
          0.8402994871139526,
          0.7956629991531372,
          0.7518687844276428,
          0.70888751745224,
          0.6672607660293579,
          0.6271449327468872,
          0.587822675704956,
          0.5497565269470215,
          0.513300359249115,
          0.4778883457183838,
          0.4437173306941986,
          0.4104442298412323,
          0.3786226511001587,
          0.3489663600921631,
          0.32128122448921204,
          0.29557177424430847,
          0.27232569456100464,
          0.25083985924720764,
          0.23085123300552368,
          0.2127237170934677,
          0.19523577392101288,
          0.17934414744377136,
          0.16575852036476135,
          0.15273740887641907,
          0.13991472125053406,
          0.12858735024929047,
          0.11855662614107132,
          0.10846744477748871,
          0.09974608570337296,
          0.09154169261455536,
          0.08430119603872299,
          0.07729702442884445,
          0.07094373553991318,
          0.06568070501089096,
          0.061305005103349686,
          0.05684711039066315,
          0.05295427516102791,
          0.049541279673576355,
          0.04624722898006439,
          0.04327085241675377,
          0.040954649448394775,
          0.03876335918903351,
          0.03661860525608063,
          0.03494998812675476,
          0.033478233963251114,
          0.03200160712003708,
          0.03052583336830139,
          0.029292799532413483,
          0.027863861992955208,
          0.026565665379166603,
          0.025181813165545464,
          0.024270718917250633,
          0.02349788323044777,
          0.022876430302858353,
          0.02224106155335903,
          0.021413540467619896,
          0.02039368264377117,
          0.019637813791632652,
          0.019127143546938896,
          0.01863972470164299,
          0.018303267657756805,
          0.018035732209682465,
          0.01771327294409275,
          0.01741146109998226,
          0.01727922633290291,
          0.01703048311173916,
          0.016621213406324387,
          0.01627453975379467,
          0.01597256027162075,
          0.015687020495533943,
          0.015409618616104126,
          0.015177899040281773,
          0.015009766444563866,
          0.014880796894431114,
          0.014674707315862179,
          0.014430095441639423,
          0.014260132797062397,
          0.01418521162122488,
          0.01403076946735382,
          0.013810311444103718,
          0.013649731874465942,
          0.013559719547629356,
          0.01340921875089407,
          0.01319108996540308,
          0.013068370521068573,
          0.01302975695580244,
          0.012919174507260323,
          0.012724892236292362,
          0.012555867433547974,
          0.012445257976651192,
          0.01232389360666275,
          0.01215868629515171,
          0.012052102945744991,
          0.011997699737548828,
          0.011901910416781902,
          0.011758855544030666,
          0.011646782979369164,
          0.011572879739105701,
          0.011497820727527142,
          0.011419528163969517,
          0.011358049698174,
          0.011292173527181149,
          0.011207149364054203,
          0.011120470240712166,
          0.011050551198422909,
          0.010986624285578728,
          0.01092054694890976,
          0.010865701362490654,
          0.010812388733029366,
          0.0107338298112154,
          0.010640542954206467,
          0.010564771480858326,
          0.01049710065126419,
          0.010418585501611233,
          0.010340062901377678,
          0.01028049923479557,
          0.010233317501842976,
          0.010171995498239994,
          0.01010055746883154,
          0.010046972893178463,
          0.010008786804974079,
          0.009958823211491108,
          0.009893692098557949,
          0.009836556389927864,
          0.009797031059861183,
          0.009756561368703842,
          0.009704380296170712,
          0.009652121923863888,
          0.009609371423721313,
          0.009567308239638805,
          0.009520355612039566,
          0.009476350620388985,
          0.009438317269086838,
          0.009403940290212631,
          0.009366597048938274,
          0.009325828403234482,
          0.009285925887525082,
          0.009244197979569435,
          0.009205318056046963,
          0.009167667478322983,
          0.009131853468716145,
          0.009096094407141209,
          0.009061263874173164,
          0.009029540233314037,
          0.009000379592180252,
          0.008971410803496838,
          0.00894186645746231,
          0.008914178237318993,
          0.008886737748980522,
          0.008855471387505531,
          0.008821663446724415,
          0.008784887380897999,
          0.008742831647396088,
          0.008698509074747562,
          0.008648831397294998,
          0.008607674390077591,
          0.008574537932872772,
          0.008540935814380646,
          0.008505342528223991,
          0.008471471257507801,
          0.008438976481556892,
          0.008409100584685802,
          0.008382601663470268,
          0.008354416117072105,
          0.008321413770318031,
          0.008287454955279827,
          0.008253723382949829,
          0.008218726143240929,
          0.008180906064808369,
          0.008143345825374126,
          0.008107063360512257,
          0.008070782758295536,
          0.00803637970238924,
          0.00800071470439434,
          0.00796500127762556,
          0.00792632345110178,
          0.007890474982559681,
          0.007859300822019577,
          0.007833508774638176,
          0.007810420822352171,
          0.007789929863065481,
          0.007771119941025972,
          0.0077513763681054115,
          0.007729706820100546,
          0.0077050733380019665,
          0.00767969386652112,
          0.007654556538909674,
          0.007632063701748848,
          0.007612895220518112,
          0.007597039919346571,
          0.007582901511341333,
          0.007568942382931709,
          0.0075547960586845875,
          0.007537220139056444,
          0.007517566904425621,
          0.007497186306864023,
          0.007476504892110825,
          0.0074555897153913975,
          0.0074365753680467606,
          0.007420395966619253,
          0.007406090851873159,
          0.007393306586891413,
          0.007380079012364149,
          0.007364111021161079,
          0.007346067577600479,
          0.007327341008931398,
          0.007306796032935381,
          0.007285956293344498,
          0.007266925647854805,
          0.007248719688504934,
          0.007230711635202169,
          0.0072141364216804504,
          0.007198108360171318,
          0.007180630695074797,
          0.007163055706769228,
          0.0071452222764492035,
          0.007126093842089176,
          0.007105650845915079,
          0.007086768746376038,
          0.0070693534798920155,
          0.007052336819469929,
          0.007036255672574043,
          0.007021336350589991,
          0.007007130887359381,
          0.0069926027208566666,
          0.00697818910703063,
          0.006964521482586861,
          0.0069500356912612915,
          0.006934160366654396,
          0.006918686907738447,
          0.006903449073433876,
          0.006887682713568211,
          0.00687218876555562,
          0.006857669446617365,
          0.006843160837888718,
          0.006826863624155521,
          0.006809989921748638,
          0.006794186774641275,
          0.006778606213629246,
          0.006762262433767319,
          0.006745940074324608,
          0.006730431225150824,
          0.006715388502925634,
          0.006699398625642061,
          0.006683695130050182,
          0.006669313181191683,
          0.006655749399214983,
          0.006641787476837635,
          0.006627214606851339,
          0.006611427757889032,
          0.006594635546207428,
          0.006576926913112402,
          0.0065595065243542194,
          0.006542309187352657,
          0.0065254103392362595,
          0.006509656086564064,
          0.006495154928416014,
          0.006480967625975609,
          0.006467212922871113,
          0.006453863810747862,
          0.0064407517202198505,
          0.00642822403460741,
          0.006416636053472757,
          0.0064050909131765366,
          0.006393436808139086,
          0.006381981540471315,
          0.006370970979332924,
          0.006360670085996389,
          0.006350229494273663,
          0.006340002175420523,
          0.006330042611807585,
          0.006320477928966284,
          0.006311008241027594,
          0.006301692221313715,
          0.006292673293501139,
          0.006284058094024658,
          0.006275599356740713,
          0.006267464254051447,
          0.006259748712182045,
          0.006252317223697901,
          0.0062453290447592735,
          0.006237946450710297,
          0.006230607628822327,
          0.00622291024774313,
          0.0062155406922101974,
          0.006208532489836216,
          0.006201834883540869,
          0.006194956600666046,
          0.006188097409904003,
          0.006181028205901384,
          0.0061740567907691,
          0.006167442537844181,
          0.006161099765449762,
          0.0061545101925730705,
          0.006147377192974091,
          0.006139968056231737,
          0.0061326599679887295,
          0.006125481799244881,
          0.00611863425001502,
          0.006111877039074898,
          0.0061056423000991344,
          0.006099597550928593,
          0.006093266885727644,
          0.006086804438382387,
          0.006080241873860359,
          0.006074185017496347,
          0.006068305112421513,
          0.006062827538698912,
          0.0060574086382985115,
          0.006051958538591862,
          0.006046554073691368,
          0.006041154731065035,
          0.006035628728568554,
          0.006029521580785513,
          0.006022690329700708,
          0.006015479099005461,
          0.0060084485448896885,
          0.00600144499912858,
          0.005994824226945639,
          0.00598879624158144,
          0.0059831952676177025,
          0.005977606866508722,
          0.005971603561192751,
          0.00596515042707324,
          0.00595847750082612,
          0.005951606668531895,
          0.005944301374256611,
          0.00593752833083272,
          0.005933813285082579,
          0.005930351559072733,
          0.005927633959800005,
          0.005924403667449951,
          0.005920334253460169,
          0.005914869252592325,
          0.0059075672179460526,
          0.005898998584598303,
          0.005889974534511566,
          0.005880812648683786,
          0.005872267764061689,
          0.005864457692950964,
          0.0058578141033649445,
          0.005852611735463142,
          0.0058483243919909,
          0.005844511557370424,
          0.005840609315782785,
          0.0058358581736683846,
          0.005830048583447933,
          0.005823428276926279,
          0.005816264543682337,
          0.0058090416714549065,
          0.00580231798812747,
          0.0057962145656347275,
          0.005790694151073694,
          0.0057862745597958565,
          0.005782255437225103,
          0.005778667517006397,
          0.00577537901699543,
          0.005772142205387354,
          0.005768921691924334,
          0.005765897687524557,
          0.005762588232755661,
          0.005758904851973057,
          0.005755096208304167,
          0.0057513113133609295,
          0.005747106391936541,
          0.0057425894774496555,
          0.00573794636875391,
          0.00573386438190937,
          0.005730537232011557,
          0.005727529060095549,
          0.005724496673792601,
          0.005721312947571278,
          0.005717611871659756,
          0.005713421851396561,
          0.005708769429475069,
          0.0057044485583901405,
          0.005700434558093548,
          0.005696763284504414,
          0.005693093407899141,
          0.005689979996532202,
          0.005686687305569649,
          0.005683003459125757,
          0.005678936839103699,
          0.005675134714692831,
          0.005671650171279907,
          0.005667916964739561,
          0.005663767922669649,
          0.005659244954586029,
          0.005654800683259964,
          0.005650395527482033,
          0.005645615980029106,
          0.005640474613755941,
          0.005635413806885481,
          0.005630364175885916,
          0.005625059362500906,
          0.005619867239147425,
          0.005615802016109228,
          0.005612022243440151,
          0.0056084198877215385,
          0.005604732781648636,
          0.00560070900246501,
          0.005596593488007784,
          0.005593018606305122,
          0.005589670967310667,
          0.005586318206042051,
          0.005583279300481081,
          0.005580323748290539,
          0.005576912313699722,
          0.005573037546128035,
          0.005569659173488617,
          0.005565890576690435,
          0.00556214852258563,
          0.005558487959206104,
          0.0055548991076648235,
          0.0055517470464110374,
          0.005548490677028894,
          0.005544917192310095,
          0.005541508086025715,
          0.005539052188396454,
          0.00553592573851347,
          0.005532182287424803,
          0.0055286032147705555,
          0.0055254544131457806,
          0.005523025058209896,
          0.005520172417163849,
          0.005516794975847006,
          0.005512907635420561,
          0.005510095041245222,
          0.005508288275450468,
          0.0055063823238015175,
          0.005503935739398003,
          0.00550093362107873,
          0.005497328005731106,
          0.005494262557476759,
          0.005491606891155243,
          0.005488497205078602,
          0.005485054105520248,
          0.005481330212205648,
          0.005478177685290575,
          0.0054756952449679375,
          0.005472831893712282,
          0.005469788797199726,
          0.00546649843454361,
          0.005463854875415564,
          0.0054616001434624195,
          0.00545854028314352,
          0.005455141421407461,
          0.00545161310583353,
          0.0054481676779687405,
          0.005445762537419796,
          0.0054440852254629135,
          0.0054422589018940926,
          0.00543978251516819,
          0.0054368809796869755,
          0.00543341925367713,
          0.005430871620774269,
          0.0054292986169457436,
          0.005427882540971041,
          0.005425871815532446,
          0.005423394031822681,
          0.00542054558172822,
          0.005418153014034033,
          0.005416340194642544,
          0.005414031911641359,
          0.0054112887009978294,
          0.005408427678048611,
          0.005405673291534185,
          0.005403279792517424,
          0.005401131231337786,
          0.0053991880267858505,
          0.005396663676947355,
          0.005394101142883301,
          0.005391764920204878,
          0.005389511585235596,
          0.0053869872353971004,
          0.005384262651205063,
          0.005381403956562281,
          0.005378613714128733,
          0.005375876557081938,
          0.005372942425310612,
          0.00536991935223341,
          0.005366855766624212,
          0.005363829899579287,
          0.005360843148082495,
          0.005358206108212471,
          0.00535580376163125,
          0.0053535448387265205,
          0.005351029336452484,
          0.005348287522792816,
          0.005345560610294342,
          0.005342737305909395,
          0.005340033210813999,
          0.005337032023817301,
          0.005334119778126478,
          0.005331478081643581,
          0.005329174920916557,
          0.0053269644267857075,
          0.005324915982782841,
          0.005322709679603577,
          0.005320652388036251,
          0.005318527575582266,
          0.005316269584000111,
          0.005314167123287916,
          0.005312096327543259,
          0.005310141947120428,
          0.005308377090841532,
          0.005306526552885771,
          0.005304444581270218,
          0.0053023686632514,
          0.0053004128858447075,
          0.00529838353395462,
          0.005296352319419384,
          0.005294501315802336,
          0.005292439367622137,
          0.005290400702506304,
          0.005288110580295324,
          0.0052859047427773476,
          0.005283914506435394,
          0.005281945690512657,
          0.00527998199686408,
          0.005278293043375015,
          0.005276791751384735,
          0.005275321193039417,
          0.005273912101984024,
          0.0052726962603628635,
          0.005271511152386665,
          0.005270181689411402,
          0.005268825683742762,
          0.005267547443509102,
          0.005265961866825819,
          0.005264176521450281,
          0.005262596532702446,
          0.005261119455099106,
          0.0052597010508179665,
          0.005258401855826378,
          0.005256939213722944,
          0.005255102179944515,
          0.0052533275447785854,
          0.005251956172287464,
          0.005250636022537947,
          0.005249135661870241,
          0.005247654393315315,
          0.00524619547650218,
          0.005244691856205463,
          0.005243346095085144,
          0.0052422042936086655,
          0.005241231061518192,
          0.005240317899733782,
          0.00523929949849844,
          0.005238075274974108,
          0.005236829165369272,
          0.005235609598457813,
          0.005234288517385721,
          0.0052329739555716515,
          0.005231678485870361,
          0.005230681970715523,
          0.005229822359979153,
          0.0052291229367256165,
          0.00522826611995697,
          0.005227407440543175,
          0.00522637227550149,
          0.005225765518844128,
          0.005225041881203651,
          0.005224017892032862,
          0.00522282300516963,
          0.005221685394644737,
          0.005220762919634581,
          0.005219938233494759,
          0.005219040438532829,
          0.005218277219682932,
          0.005217469297349453,
          0.005216863006353378,
          0.005216569639742374,
          0.005216308403760195,
          0.005215852055698633,
          0.00521516939625144,
          0.0052145011723041534,
          0.005214078351855278,
          0.005213849246501923,
          0.005213846918195486,
          0.00521383062005043,
          0.00521370442584157,
          0.005213210824877024,
          0.005212523974478245,
          0.005211730021983385,
          0.00521112373098731,
          0.005210761912167072,
          0.005210442468523979,
          0.005210017319768667,
          0.005209306254982948,
          0.005208516027778387,
          0.00520774582400918,
          0.005207198206335306,
          0.0052069867961108685,
          0.0052067674696445465,
          0.005206219851970673,
          0.005205392837524414,
          0.005204549990594387,
          0.005203691311180592,
          0.005202827043831348,
          0.005202397704124451,
          0.005202248692512512,
          0.00520215043798089,
          0.005201876163482666,
          0.00520135136321187,
          0.005200483370572329,
          0.005199573468416929,
          0.0051985145546495914,
          0.005197685677558184,
          0.005196807906031609,
          0.005195995792746544,
          0.005195197183638811,
          0.005194242112338543,
          0.0051934183575212955,
          0.005192610435187817,
          0.005191681440919638,
          0.00519071938470006,
          0.005189794115722179,
          0.0051888879388570786,
          0.00518829096108675,
          0.005187998991459608,
          0.005187519360333681,
          0.005186644848436117,
          0.005185904912650585,
          0.0051849884912371635,
          0.005184687674045563,
          0.005184714682400227,
          0.005184359382838011,
          0.0051837642677128315,
          0.005183657631278038,
          0.0051840622909367085,
          0.005183776840567589,
          0.0051829274743795395,
          0.005182330496609211,
          0.0051822662353515625,
          0.00518248463049531,
          0.005182875785976648,
          0.005182976834475994,
          0.005182397551834583,
          0.005181590095162392,
          0.0051812962628901005,
          0.005181699059903622,
          0.005181708838790655,
          0.005181311164051294,
          0.005180926527827978,
          0.005180340260267258,
          0.005180347245186567,
          0.0051805698312819,
          0.005180805921554565,
          0.0051810708828270435,
          0.005180967040359974,
          0.005180488806217909,
          0.005180115811526775,
          0.005180384498089552,
          0.0051808543503284454,
          0.0051812962628901005,
          0.005181418266147375,
          0.005181006155908108,
          0.005180562846362591,
          0.005180841311812401,
          0.005181338172405958,
          0.0051816352643072605,
          0.005181454122066498,
          0.005181124433875084,
          0.005180584266781807,
          0.005180182866752148,
          0.00518017215654254,
          0.0051801507361233234,
          0.005180248059332371,
          0.005180078558623791,
          0.005179679952561855,
          0.005179429426789284,
          0.005179989151656628,
          0.005180885083973408,
          0.005181928630918264,
          0.005182348657399416,
          0.005182179622352123,
          0.005181765183806419,
          0.005181699525564909,
          0.0051824916154146194,
          0.005183201748877764,
          0.005184059031307697,
          0.005184627138078213,
          0.005184746813029051,
          0.005184877663850784,
          0.005185220390558243,
          0.005185827612876892,
          0.005186218768358231,
          0.005186452530324459,
          0.005186750553548336,
          0.005187048111110926,
          0.0051874094642698765,
          0.005187779664993286,
          0.00518809026107192,
          0.005188478156924248,
          0.005188710521906614,
          0.005188902374356985,
          0.005189450923353434,
          0.005190253723412752,
          0.005191546864807606,
          0.005192417651414871,
          0.005193027667701244,
          0.005193261429667473,
          0.005193847697228193,
          0.005194616038352251,
          0.005195735953748226,
          0.00519653270021081,
          0.00519711896777153,
          0.005197747610509396,
          0.005198552738875151,
          0.005199729464948177,
          0.005200693849474192,
          0.005201343446969986,
          0.005201802123337984,
          0.005202113185077906,
          0.005202413536608219,
          0.005202926695346832,
          0.0052033173851668835,
          0.005203348584473133,
          0.0052031842060387135,
          0.005203519482165575,
          0.005203898064792156,
          0.005204583518207073,
          0.005204841028898954,
          0.005204852670431137,
          0.005204830318689346,
          0.005204861052334309,
          0.005205248016864061,
          0.00520556652918458,
          0.005205477122217417,
          0.005205417983233929,
          0.005205267108976841,
          0.005205071065574884,
          0.005205267574638128,
          0.005205538589507341,
          0.005205884110182524,
          0.005205884110182524,
          0.0052056992426514626,
          0.005205580033361912,
          0.005205827299505472,
          0.005206105299293995,
          0.0052062696777284145,
          0.005206075496971607,
          0.005206238012760878,
          0.005206651519984007,
          0.005206832196563482,
          0.0052075921557843685,
          0.005208320915699005,
          0.00520930765196681,
          0.005209957715123892,
          0.0052107288502156734,
          0.005211103707551956,
          0.0052117169834673405,
          0.005211998708546162,
          0.005212831776589155,
          0.005213376600295305,
          0.005214319098740816,
          0.005214857403188944,
          0.0052155437879264355,
          0.005215772427618504,
          0.0052162460051476955,
          0.005216493736952543,
          0.005217062775045633,
          0.005217636935412884,
          0.0052177575416862965,
          0.005218410864472389,
          0.005219141952693462,
          0.005219604820013046,
          0.005219695623964071,
          0.0052200197242200375,
          0.005220703314989805,
          0.0052217463962733746,
          0.00522248400375247,
          0.0052228099666535854,
          0.005223123822361231,
          0.005223799962550402,
          0.005224593449383974,
          0.005225721746683121,
          0.005226821172982454,
          0.005227393936365843,
          0.005227603483945131,
          0.005227288696914911,
          0.005227680318057537,
          0.005228262860327959,
          0.0052290866151452065,
          0.00522985914722085,
          0.005230496637523174,
          0.005230812821537256,
          0.005230790935456753,
          0.005230894312262535,
          0.005231437273323536,
          0.005232114810496569,
          0.005233092233538628,
          0.005233901087194681,
          0.005234573036432266,
          0.005234685260802507,
          0.005234397482126951,
          0.005234336014837027,
          0.005234672222286463,
          0.005235347896814346,
          0.005236179102212191,
          0.00523675000295043,
          0.005237096920609474,
          0.005237190052866936,
          0.005237160250544548,
          0.005237236153334379,
          0.005237509962171316,
          0.0052378359250724316,
          0.005237986799329519,
          0.005238131154328585,
          0.005238138139247894,
          0.005238220561295748,
          0.005238160025328398,
          0.005238571669906378,
          0.005238580983132124,
          0.0052384850569069386,
          0.005238590762019157,
          0.005238850601017475,
          0.005238629877567291,
          0.005238331854343414,
          0.005238252691924572,
          0.005238478071987629,
          0.005238275974988937,
          0.005238179117441177,
          0.00523843290284276,
          0.005238807760179043,
          0.00523902103304863,
          0.005238696001470089,
          0.005238185171037912,
          0.005237911827862263,
          0.005237888544797897,
          0.005237962584942579,
          0.005238020792603493,
          0.005237489473074675,
          0.0052370550110936165,
          0.005236959084868431,
          0.005237032659351826,
          0.005237249191850424,
          0.005237269680947065,
          0.005237121134996414,
          0.005236993543803692,
          0.0052369460463523865,
          0.00523682776838541,
          0.0052360356785357,
          0.005235286429524422,
          0.005234856158494949,
          0.005234809126704931,
          0.005235020071268082,
          0.005234984215348959,
          0.005234502721577883,
          0.005234049167484045,
          0.0052339849062263966,
          0.005233692470937967,
          0.005233222618699074,
          0.005232700612396002,
          0.005232309456914663,
          0.0052321674302220345,
          0.005231910385191441,
          0.00523162679746747,
          0.005231058690696955,
          0.005230306647717953,
          0.005229692440479994,
          0.005229552276432514,
          0.0052295285277068615,
          0.005229241214692593,
          0.005228802096098661,
          0.005228359252214432,
          0.005227998830378056,
          0.005227882415056229,
          0.005227891728281975,
          0.005227625370025635,
          0.005227095913141966,
          0.005226512905210257,
          0.005225948989391327,
          0.005225637927651405,
          0.005225456785410643,
          0.0052250344306230545,
          0.005224382039159536,
          0.0052237980999052525,
          0.0052237180061638355,
          0.0052236043848097324,
          0.005223228130489588,
          0.005222691223025322,
          0.005222519859671593,
          0.005222155712544918,
          0.005222010891884565,
          0.005221607629209757,
          0.005221343133598566,
          0.0052210865542292595,
          0.00522057618945837,
          0.005220041144639254,
          0.0052196793258190155,
          0.005219216458499432,
          0.005218951962888241,
          0.005218564998358488,
          0.0052180360071361065,
          0.005217899568378925,
          0.005217481404542923,
          0.0052171614952385426,
          0.005216976627707481,
          0.005216533318161964,
          0.005215815734118223,
          0.0052153910510241985,
          0.005215035285800695,
          0.005214386153966188,
          0.005213557742536068,
          0.00521316472440958,
          0.0052129412069916725,
          0.005212500225752592,
          0.005211952608078718,
          0.005211306270211935,
          0.005210959352552891,
          0.0052109528332948685,
          0.0052106804214417934,
          0.0052101826295256615,
          0.005209470633417368,
          0.005209031980484724,
          0.005208936054259539,
          0.005208726041018963,
          0.005208180285990238,
          0.005207570269703865,
          0.0052069006487727165,
          0.005206575617194176,
          0.005206120666116476,
          0.005205680150538683,
          0.005205104127526283,
          0.005204548127949238,
          0.005204183980822563,
          0.0052039772272109985,
          0.0052034491673111916,
          0.005202701315283775,
          0.005202251486480236,
          0.005201887805014849,
          0.005201177205890417,
          0.005200278479605913,
          0.005199629347771406,
          0.005199027247726917,
          0.005198560655117035,
          0.005198191851377487,
          0.005197544116526842,
          0.005196761805564165,
          0.005196176934987307,
          0.005195736885070801,
          0.005195258650928736,
          0.0051946984604001045,
          0.005194392055273056,
          0.005194102879613638,
          0.005193476099520922,
          0.005192915443331003,
          0.005192419048398733,
          0.005192036274820566,
          0.005191374570131302,
          0.005190979223698378,
          0.005190732888877392,
          0.005190165247768164,
          0.005189507734030485,
          0.005189162213355303,
          0.005188872572034597,
          0.005188241600990295,
          0.005187517032027245,
          0.005187066271901131,
          0.005186628084629774,
          0.005186502356082201,
          0.005186190363019705,
          0.0051856678910553455,
          0.005185356363654137,
          0.005185261834412813,
          0.005185037385672331,
          0.005184578243643045,
          0.005184363108128309,
          0.0051842075772583485,
          0.0051839048974215984,
          0.00518330093473196,
          0.0051824371330440044,
          0.005181836895644665
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line(test_losses, log_y=True)\n",
    "# plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 21,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "xaxis": "x",
         "y": [
          2.708627700805664,
          2.330667495727539,
          2.16935133934021,
          2.0626955032348633,
          1.9821646213531494,
          1.9065356254577637,
          1.838087558746338,
          1.7749899625778198,
          1.720491647720337,
          1.6670901775360107,
          1.6113582849502563,
          1.5581475496292114,
          1.5081480741500854,
          1.4585500955581665,
          1.4089151620864868,
          1.3592606782913208,
          1.3087527751922607,
          1.2586358785629272,
          1.2098952531814575,
          1.1610217094421387,
          1.11220383644104,
          1.0628529787063599,
          1.0143698453903198,
          0.966727077960968,
          0.9190192818641663,
          0.872333288192749,
          0.8267281651496887,
          0.7819027900695801,
          0.7381013035774231,
          0.695344090461731,
          0.6538994312286377,
          0.6142241358757019,
          0.5754508972167969,
          0.5378066897392273,
          0.5014932751655579,
          0.466451495885849,
          0.432929128408432,
          0.400402694940567,
          0.36920565366744995,
          0.3397253751754761,
          0.3121185302734375,
          0.28628596663475037,
          0.2620919346809387,
          0.23914583027362823,
          0.21802671253681183,
          0.19937771558761597,
          0.18177473545074463,
          0.16590291261672974,
          0.15185979008674622,
          0.13831576704978943,
          0.12586064636707306,
          0.11429888755083084,
          0.10437104105949402,
          0.09485045075416565,
          0.08605324476957321,
          0.07814629375934601,
          0.07124782353639603,
          0.06499136239290237,
          0.05928661301732063,
          0.054149359464645386,
          0.049453865736722946,
          0.045177243649959564,
          0.04161228612065315,
          0.038164205849170685,
          0.035121768712997437,
          0.03239566460251808,
          0.029892675578594208,
          0.027592798694968224,
          0.02548365294933319,
          0.023528272286057472,
          0.02177748829126358,
          0.020194152370095253,
          0.018902838230133057,
          0.017577260732650757,
          0.016367264091968536,
          0.015299172140657902,
          0.01426932867616415,
          0.013465426862239838,
          0.012639811262488365,
          0.011956075206398964,
          0.011286423541605473,
          0.010617482475936413,
          0.010031248442828655,
          0.009518799372017384,
          0.009009463712573051,
          0.008554433472454548,
          0.008181274868547916,
          0.007786961272358894,
          0.0074243308044970036,
          0.007103155832737684,
          0.006795975379645824,
          0.006504167336970568,
          0.006252107676118612,
          0.006004977505654097,
          0.0057667759247124195,
          0.005555633921176195,
          0.005351439118385315,
          0.005162429064512253,
          0.004980996251106262,
          0.004813725128769875,
          0.004646368324756622,
          0.004498384427279234,
          0.0043568480759859085,
          0.004219568334519863,
          0.004090110305696726,
          0.0039718374609947205,
          0.00385714927688241,
          0.003749110968783498,
          0.003647822653874755,
          0.003548241686075926,
          0.0034555441234260798,
          0.003367012133821845,
          0.0032817423343658447,
          0.0032010821159929037,
          0.0031251695472747087,
          0.003050734754651785,
          0.002980454359203577,
          0.0029124291613698006,
          0.002847073832526803,
          0.0027848512399941683,
          0.002724560210481286,
          0.0026663055177778006,
          0.0026100859977304935,
          0.002556625986471772,
          0.00250437599606812,
          0.00245442776940763,
          0.0024054718669503927,
          0.0023584836162626743,
          0.002312527969479561,
          0.0022685208823531866,
          0.002225677017122507,
          0.002184554236009717,
          0.0021444251760840416,
          0.0021058644633740187,
          0.0020682543981820345,
          0.0020318510942161083,
          0.00199635187163949,
          0.001961885020136833,
          0.0019284987356513739,
          0.0018960784655064344,
          0.0018645128002390265,
          0.0018338114023208618,
          0.0018038817215710878,
          0.0017747670644894242,
          0.0017464238917455077,
          0.001718738116323948,
          0.0016917219618335366,
          0.0016654172213748097,
          0.0016397560248151422,
          0.001614724867977202,
          0.001590265310369432,
          0.0015664243837818503,
          0.001543155056424439,
          0.001520439051091671,
          0.001498201978392899,
          0.0014764675870537758,
          0.0014552202774211764,
          0.0014344430528581142,
          0.00141413533128798,
          0.0013942853547632694,
          0.0013748644851148129,
          0.0013558685313910246,
          0.0013373077381402254,
          0.001319158123806119,
          0.001301390933804214,
          0.0012840036069974303,
          0.0012669585412368178,
          0.0012502616737037897,
          0.0012339095119386911,
          0.001217903452925384,
          0.001202218234539032,
          0.0011868398869410157,
          0.0011717602610588074,
          0.001156984711997211,
          0.0011424882104620337,
          0.0011282555060461164,
          0.0011142767034471035,
          0.0011005542473867536,
          0.0010870774276554585,
          0.0010738522978499532,
          0.0010608851443976164,
          0.001048176665790379,
          0.001035687979310751,
          0.0010234221117570996,
          0.001011381158605218,
          0.0009995432337746024,
          0.000987913692370057,
          0.0009764584247022867,
          0.0009652027511037886,
          0.000954131712205708,
          0.0009432615479454398,
          0.000932566705159843,
          0.0009220488136634231,
          0.000911676965188235,
          0.000901467283256352,
          0.0008914411882869899,
          0.0008816043264232576,
          0.000871945871040225,
          0.000862453191075474,
          0.0008531077764928341,
          0.0008439169032499194,
          0.0008348727133125067,
          0.0008259728783741593,
          0.0008172196103259921,
          0.0008086029556579888,
          0.0008001138921827078,
          0.000791763246525079,
          0.0007835444994270802,
          0.000775451713707298,
          0.0007674797088839114,
          0.0007596306386403739,
          0.000751899613533169,
          0.0007442861096933484,
          0.0007367859361693263,
          0.0007294114329852164,
          0.0007221484556794167,
          0.0007149959565140307,
          0.0007079571369104087,
          0.0007010212284512818,
          0.0006941903266124427,
          0.0006874576210975647,
          0.0006808244506828487,
          0.0006742851110175252,
          0.0006678412319160998,
          0.0006614894373342395,
          0.000655225245282054,
          0.0006490468513220549,
          0.0006429603090509772,
          0.0006369616603478789,
          0.0006310451426543295,
          0.0006252145976759493,
          0.0006194531451910734,
          0.0006137759191915393,
          0.0006081766914576292,
          0.0006026531918905675,
          0.0005972065264359117,
          0.000591826334130019,
          0.0005865118000656366,
          0.0005812678136862814,
          0.000576095946598798,
          0.0005709970719181001,
          0.0005659586749970913,
          0.0005609773215837777,
          0.0005560607532970607,
          0.000551203906070441,
          0.0005464100977405906,
          0.0005416770582087338,
          0.0005369997234083712,
          0.0005323817022144794,
          0.0005278229364193976,
          0.0005233190022408962,
          0.0005188763607293367,
          0.0005144886672496796,
          0.000510156387463212,
          0.0005058792303316295,
          0.0005016520153731108,
          0.0004974788171239197,
          0.0004933553282171488,
          0.0004892852739430964,
          0.0004852650163229555,
          0.00048128992784768343,
          0.0004773586697410792,
          0.0004734774702228606,
          0.000469639286166057,
          0.00046584795927628875,
          0.00046210380969569087,
          0.0004584029084071517,
          0.0004547439457383007,
          0.0004511279985308647,
          0.0004475518362596631,
          0.00044402002822607756,
          0.000440525560406968,
          0.00043707233271561563,
          0.0004336551937740296,
          0.00043027568608522415,
          0.00042693590512499213,
          0.0004236318345647305,
          0.00042036434751935303,
          0.000417134549934417,
          0.0004139377560932189,
          0.00041077687637880445,
          0.0004076510085724294,
          0.0004045602399855852,
          0.000401507830247283,
          0.00039849194581620395,
          0.0003955113352276385,
          0.0003925605269614607,
          0.0003896442649420351,
          0.0003867612686008215,
          0.0003839036507997662,
          0.00038107699947431684,
          0.00037828099448233843,
          0.00037551819696091115,
          0.0003727849980350584,
          0.00037008034996688366,
          0.0003674033796414733,
          0.00036475725937634706,
          0.00036213992279954255,
          0.0003595482266973704,
          0.000356990029104054,
          0.0003544585779309273,
          0.00035195742384530604,
          0.00034948272514156997,
          0.0003470318333711475,
          0.00034461007453501225,
          0.00034221317037008703,
          0.00033984382753260434,
          0.00033749916474334896,
          0.00033518002601340413,
          0.00033288440317846835,
          0.00033061482827179134,
          0.0003283684782218188,
          0.0003261443052906543,
          0.0003239471698179841,
          0.00032177093089558184,
          0.00031961590866558254,
          0.000317482219543308,
          0.0003153713187202811,
          0.00031328178010880947,
          0.0003112147969659418,
          0.0003091699618380517,
          0.000307144015096128,
          0.0003051379171665758,
          0.0003031500964425504,
          0.00030118130962364376,
          0.00029923260444775224,
          0.00029730264213867486,
          0.00029539389652200043,
          0.0002935027296189219,
          0.00029163126600906253,
          0.00028977717738598585,
          0.0002879446547012776,
          0.000286125490674749,
          0.0002843230904545635,
          0.0002825411793310195,
          0.0002807730052154511,
          0.0002790235448628664,
          0.0002772885200101882,
          0.0002755695313680917,
          0.0002738690236583352,
          0.00027218295144848526,
          0.00027051285724155605,
          0.00026885882834903896,
          0.00026721987524069846,
          0.0002655965799931437,
          0.0002639883605297655,
          0.00026239483850076795,
          0.00026081380201503634,
          0.0002592477831058204,
          0.00025769343483261764,
          0.0002561543951742351,
          0.0002546228060964495,
          0.0002531000063754618,
          0.00025159650249406695,
          0.00025010918034240603,
          0.0002486285229679197,
          0.00024716503685340285,
          0.00024571752874180675,
          0.0002442824770696461,
          0.00024285570543725044,
          0.00024143750488292426,
          0.00024003046564757824,
          0.0002386379346717149,
          0.00023725956270936877,
          0.00023589526244904846,
          0.00023454100301023573,
          0.00023319928732234985,
          0.00023186721955426037,
          0.000230545672820881,
          0.000229238357860595,
          0.00022794307733420283,
          0.00022666003496851772,
          0.0002253865241073072,
          0.0002241237962152809,
          0.0002228665689472109,
          0.00022162709501571953,
          0.000220395959331654,
          0.00021917656704317778,
          0.0002179681760026142,
          0.00021676672622561455,
          0.00021557601576205343,
          0.00021439712145365775,
          0.00021322848624549806,
          0.00021206872770562768,
          0.00021091791859362274,
          0.0002097778778988868,
          0.00020864562247879803,
          0.00020752438285853714,
          0.00020641232549678534,
          0.0002053089701803401,
          0.00020421513181645423,
          0.00020313089771661907,
          0.0002020577376242727,
          0.00020099249377381057,
          0.00019993433670606464,
          0.0001988866861211136,
          0.00019784615142270923,
          0.00019681506091728806,
          0.00019579271611291915,
          0.00019477904425002635,
          0.00019377384160179645,
          0.0001927748671732843,
          0.0001917866466101259,
          0.00019080359197687358,
          0.00018982896290253848,
          0.0001888617844088003,
          0.00018790349713526666,
          0.00018695168546400964,
          0.00018600616022013128,
          0.00018506990454625338,
          0.0001841405319282785,
          0.00018321712559554726,
          0.00018230198475066572,
          0.00018139323219656944,
          0.00018049083882942796,
          0.0001795952266547829,
          0.00017870691954158247,
          0.00017782599024940282,
          0.00017695128917694092,
          0.00017608316557016224,
          0.00017522268171887845,
          0.00017436886264476925,
          0.0001735207042656839,
          0.0001726787886582315,
          0.0001718435378279537,
          0.0001710145006654784,
          0.00017019198276102543,
          0.00016937540203798562,
          0.0001685652241576463,
          0.0001677571126492694,
          0.00016695707745384425,
          0.0001661636051721871,
          0.00016537769988644868,
          0.00016459486505482346,
          0.00016381900059059262,
          0.00016304814198520035,
          0.00016228380263783038,
          0.00016152359603438526,
          0.00016076830797828734,
          0.00016002063057385385,
          0.0001592771732248366,
          0.0001585386780789122,
          0.0001578041265020147,
          0.00015707590500824153,
          0.00015635366435162723,
          0.00015563644410576671,
          0.00015492462262045592,
          0.00015421674470417202,
          0.0001535145565867424,
          0.0001528168941149488,
          0.00015212495054583997,
          0.00015143580094445497,
          0.00015075162809807807,
          0.00015007215552031994,
          0.00014939723769202828,
          0.0001487253757659346,
          0.00014805991668254137,
          0.00014739840116817504,
          0.00014674049452878535,
          0.00014608704077545553,
          0.00014543994620908052,
          0.000144793521030806,
          0.00014415332407224923,
          0.0001435172016499564,
          0.00014288628881331533,
          0.00014226035273168236,
          0.00014163655578158796,
          0.00014101718261372298,
          0.00014040233509149402,
          0.00013979070354253054,
          0.0001391838741255924,
          0.0001385809446219355,
          0.00013798226427752525,
          0.00013738802226725966,
          0.0001367968216072768,
          0.00013620959362015128,
          0.00013562588719651103,
          0.0001350471138721332,
          0.00013447055243887007,
          0.00013389856030698866,
          0.00013332825619727373,
          0.00013276300160214305,
          0.0001322009920841083,
          0.00013164302799850702,
          0.0001310883671976626,
          0.00013053714064881206,
          0.00012998962483834475,
          0.00012944494665134698,
          0.00012890151992905885,
          0.0001283638266613707,
          0.00012782879639416933,
          0.0001272961962968111,
          0.00012676794722210616,
          0.0001262403093278408,
          0.00012571763363666832,
          0.0001251959620276466,
          0.00012467903434298933,
          0.0001241655700141564,
          0.0001236557145603001,
          0.0001231488276971504,
          0.0001226445601787418,
          0.000122142126201652,
          0.00012164238432887942,
          0.00012114607670810074,
          0.00012065270129824057,
          0.00012016433174721897,
          0.00011967632599407807,
          0.00011919271491933614,
          0.00011871261085616425,
          0.00011823573731817305,
          0.00011776095198001713,
          0.00011728855315595865,
          0.00011682025069603696,
          0.00011635409464361146,
          0.0001158919112640433,
          0.00011543116852408275,
          0.00011497204832267016,
          0.00011451721366029233,
          0.00011406384874135256,
          0.00011361323413439095,
          0.00011316689051454887,
          0.00011272184201516211,
          0.00011227950017200783,
          0.00011184169125044718,
          0.00011140362039441243,
          0.0001109694640035741,
          0.0001105383489630185,
          0.00011010935850208625,
          0.00010968352580675855,
          0.00010926030518021435,
          0.00010883690265472978,
          0.00010841710172826424,
          0.0001080012516467832,
          0.00010758664575405419,
          0.00010717447003116831,
          0.00010676650708774105,
          0.00010636010119924322,
          0.00010595488856779411,
          0.00010555451444815844,
          0.00010515346366446465,
          0.00010475541785126552,
          0.00010436051525175571,
          0.00010396780999144539,
          0.00010357489372836426,
          0.00010318706335965544,
          0.0001028002516250126,
          0.00010241492418572307,
          0.00010203174315392971,
          0.00010165254934690893,
          0.00010127574932994321,
          0.00010089890565723181,
          0.00010052577999886125,
          0.0001001537311822176,
          0.00009978410525945947,
          0.00009941616735886782,
          0.00009905083425110206,
          0.00009868723282124847,
          0.0000983253339654766,
          0.00009796644008019939,
          0.00009760935790836811,
          0.0000972523121163249,
          0.00009689966827863827,
          0.00009654745372245088,
          0.00009619735646992922,
          0.00009584915824234486,
          0.00009550333925290033,
          0.00009515857527730986,
          0.00009481675078859553,
          0.00009447681804886088,
          0.00009413735824637115,
          0.00009380182746099308,
          0.00009346561273559928,
          0.00009313309419667348,
          0.00009280181984649971,
          0.00009247224079445004,
          0.00009214424790116027,
          0.00009181605855701491,
          0.0000914924603421241,
          0.00009116933506447822,
          0.00009084877092391253,
          0.00009052896348293871,
          0.00009021100413519889,
          0.00008989514026325196,
          0.00008958005491876975,
          0.00008926826558308676,
          0.00008895717473933473,
          0.0000886473135324195,
          0.00008833775791572407,
          0.00008803258242551237,
          0.00008772576256887987,
          0.0000874219331308268,
          0.0000871214724611491,
          0.00008682095358381048,
          0.00008652253745822236,
          0.00008622586028650403,
          0.00008592984522692859,
          0.00008563481242163107,
          0.00008534226071787998,
          0.00008505032019456849,
          0.00008476103539578617,
          0.00008447231084574014,
          0.00008418400102527812,
          0.00008389806316699833,
          0.00008361475920537487,
          0.00008333122968906537,
          0.00008304938091896474,
          0.00008276924927486107,
          0.00008249087841250002,
          0.00008221332245739177,
          0.00008193685789592564,
          0.00008166355110006407,
          0.00008138951670844108,
          0.00008111682836897671,
          0.0000808449913165532,
          0.00008057626837398857,
          0.00008030764729483053,
          0.00008004160918062553,
          0.00007977493805810809,
          0.00007951027509989217,
          0.00007924802775960416,
          0.00007898562762420624,
          0.00007872561400290579,
          0.00007846520747989416,
          0.00007820783503120765,
          0.00007795105193508789,
          0.00007769496005494148,
          0.00007744043978163972,
          0.00007718799315625802,
          0.00007693510997341946,
          0.00007668506441405043,
          0.00007643416756764054,
          0.00007618491508765146,
          0.00007593792543048039,
          0.00007569142326246947,
          0.00007544473191956058,
          0.00007520009239669889,
          0.00007495729369111359,
          0.00007471551361959428,
          0.00007447444659192115,
          0.00007423389615723863,
          0.00007399544847430661,
          0.00007375737914117053,
          0.00007351980457315221,
          0.00007328415813390166,
          0.00007305036706384271,
          0.00007281713624252006,
          0.00007258498953888193,
          0.00007235401426441967,
          0.00007212494529085234,
          0.00007189575262600556,
          0.0000716696449671872,
          0.00007144328992580995,
          0.00007121822272893041,
          0.00007099312642822042,
          0.0000707698636688292,
          0.00007054759043967351,
          0.00007032719440758228,
          0.00007010684930719435,
          0.00006988686800468713,
          0.00006966909859329462,
          0.0000694515256327577,
          0.00006923465116415173,
          0.00006901956658111885,
          0.00006880496948724613,
          0.00006859075801912695,
          0.00006837905675638467,
          0.00006816800305387005,
          0.00006795718218199909,
          0.0000677476855344139,
          0.0000675399205647409,
          0.00006733110058121383,
          0.00006712375761708245,
          0.00006691923772450536,
          0.00006671465234830976,
          0.0000665108163957484,
          0.00006630896677961573,
          0.00006610614218516275,
          0.00006590428529307246,
          0.00006570441473741084,
          0.00006550583202624694,
          0.0000653062597848475,
          0.00006510873936349526,
          0.00006491231761174276,
          0.00006471601955126971,
          0.00006452148227253929,
          0.00006432701047742739,
          0.0000641354126855731,
          0.0000639411446172744,
          0.00006375009252224118,
          0.00006355920049827546,
          0.00006336982914945111,
          0.00006318134546745569,
          0.00006299291999312118,
          0.00006280618981691077,
          0.00006261938688112423,
          0.00006243384268600494,
          0.00006225019751582295,
          0.00006206557736732066,
          0.00006188257975736633,
          0.00006169998232508078,
          0.00006151901470730081,
          0.00006133793067419901,
          0.00006115851283539087,
          0.00006097894220147282,
          0.00006080103412386961,
          0.00006062408283469267,
          0.00006044749534339644,
          0.000060270511312410235,
          0.00006009522985550575,
          0.00005992033038637601,
          0.00005974638042971492,
          0.00005957322719041258,
          0.00005940045593888499,
          0.00005922889613430016,
          0.00005905830403207801,
          0.0000588884977332782,
          0.00005871907342225313,
          0.000058550271205604076,
          0.00005838170909555629,
          0.00005821403465233743,
          0.000058048011851496994,
          0.00005788242560811341,
          0.00005771735231974162,
          0.00005755190795753151,
          0.00005738798063248396,
          0.000057225304772146046,
          0.00005706294177798554,
          0.00005690018224413507,
          0.00005673876512446441,
          0.000056578701332909986,
          0.000056419099564664066,
          0.00005625907942885533,
          0.00005610030348179862,
          0.000055942731705727056,
          0.000055785705626476556,
          0.00005562917431234382,
          0.000055470805818913504,
          0.000055315667850663885,
          0.000055160846386570483,
          0.00005500594852492213,
          0.00005485268775373697,
          0.00005469847747008316,
          0.000054546075261896476,
          0.00005439394954009913,
          0.000054242809710558504,
          0.000054091637139208615,
          0.00005394218533183448,
          0.00005379231515689753,
          0.000053642525017494336,
          0.00005349485218175687,
          0.000053345687774708495,
          0.000053199335525278,
          0.00005305230661178939,
          0.00005290675107971765,
          0.00005276082447380759,
          0.000052616287575801834,
          0.000052471219532890245,
          0.00005232780677033588,
          0.000052183913794578984,
          0.00005204082845011726,
          0.000051898445235565305,
          0.00005175569458515383,
          0.000051614340918604285,
          0.00005147410774952732,
          0.00005133360537001863,
          0.000051192648243159056,
          0.000051052971684839576,
          0.00005091431739856489,
          0.00005077681998955086,
          0.000050639402616070583,
          0.000050502039812272415,
          0.00005036530637880787,
          0.000050229278713231906,
          0.000050093720346922055,
          0.00004995979543309659,
          0.000049825888709165156,
          0.00004969117799191736,
          0.000049558784667169675,
          0.00004942519080941565,
          0.000049293379561277106,
          0.000049162423238158226,
          0.00004903171429759823,
          0.00004890061973128468,
          0.00004877153332927264,
          0.00004864191942033358,
          0.00004851310950471088,
          0.00004838455788558349,
          0.00004825621726922691,
          0.000048129855713341385,
          0.00004800254464498721,
          0.00004787667785421945,
          0.000047751131205586717,
          0.00004762468597618863,
          0.000047500929213128984,
          0.00004737719427794218,
          0.000047252724471036345,
          0.00004712933150585741,
          0.000047005371015984565,
          0.00004688282933784649,
          0.000046761106204940006,
          0.000046640358050353825,
          0.0000465198427264113,
          0.00004639971302822232,
          0.000046278473746497184,
          0.0000461593153886497,
          0.00004604098285199143,
          0.00004592072946252301,
          0.00004580285894917324,
          0.00004568565418594517,
          0.00004556633211905137,
          0.00004544975308817811,
          0.000045333628804655746,
          0.000045217570004751906,
          0.00004510297003434971,
          0.00004498691487242468,
          0.000044873359001940116,
          0.000044759064621757716,
          0.000044644584704656154,
          0.00004453126894077286,
          0.0000444189936388284,
          0.000044305616029305384,
          0.000044193882786203176,
          0.000044082604290451854,
          0.000043970783735858276,
          0.000043860654841409996,
          0.000043750587792601436,
          0.000043640284275170416,
          0.00004353083568275906,
          0.000043421947339084,
          0.000043312873458489776,
          0.00004320349762565456,
          0.000043096319132018834,
          0.00004298847488826141,
          0.00004288162381271832,
          0.00004277483458281495,
          0.00004266901669325307,
          0.000042563598981359974,
          0.00004245768650434911,
          0.00004235121014062315,
          0.000042246330849593505,
          0.00004214138971292414,
          0.000042037419916596264,
          0.0000419337629864458,
          0.00004183077908237465,
          0.00004172772241872735,
          0.000041624971345299855,
          0.00004152345354668796,
          0.00004142075340496376,
          0.00004132047251914628,
          0.00004121982055949047,
          0.00004111844828003086,
          0.00004101773811271414,
          0.00004091762821190059,
          0.0000408183186664246,
          0.00004071837611263618,
          0.00004061923755216412,
          0.000040520702896174043,
          0.00004042166256112978,
          0.00004032464494230226,
          0.00004022672146675177,
          0.000040130518755177036,
          0.00004003275535069406,
          0.000039936167013365775,
          0.00003983988062827848,
          0.000039743990782881156,
          0.00003964777715737,
          0.00003955294596380554,
          0.00003945833304896951,
          0.00003936339635401964,
          0.00003926998397218995,
          0.000039175884012365714,
          0.000039081725844880566,
          0.000038989623135421425,
          0.00003889589788741432,
          0.000038803478673798963,
          0.00003871106309816241,
          0.000038618716644123197,
          0.00003852709414786659,
          0.00003843595914077014,
          0.00003834551534964703,
          0.000038254598621279,
          0.000038164802390383556,
          0.00003807482062256895,
          0.00003798494071816094,
          0.000037894660636084154,
          0.0000378059376089368,
          0.00003771680349018425,
          0.000037628818972734734,
          0.00003753991404664703,
          0.000037452391552506015,
          0.00003736375947482884,
          0.000037276462535373867,
          0.0000371907590306364,
          0.00003710438613779843,
          0.000037018264265498146,
          0.0000369318513548933,
          0.000036845365684712306,
          0.00003676006963360123,
          0.00003667563578346744,
          0.000036590583476936445,
          0.000036505134630715474,
          0.00003641967487055808,
          0.000036335888580651954,
          0.00003625294266385026,
          0.000036169818486087024,
          0.00003608671613619663,
          0.000036002784327138215,
          0.00003592049688450061,
          0.00003583750731195323,
          0.00003575563459889963,
          0.00003567376916180365,
          0.000035591576306615025,
          0.00003551046393113211,
          0.00003542825288604945,
          0.00003534720235620625,
          0.000035266868508188054,
          0.00003518680023262277,
          0.00003510768146952614,
          0.000035027194826398045,
          0.00003494739212328568,
          0.000034868491638917476,
          0.00003478983853710815,
          0.000034711029002210125,
          0.000034633623727131635,
          0.00003455470141489059,
          0.000034477347071515396,
          0.000034400181903038174,
          0.00003432342055020854,
          0.000034245906135765836,
          0.00003416930849198252,
          0.000034092845453415066,
          0.00003401578214834444,
          0.00003394008308532648,
          0.000033863856515381485,
          0.00003378920882823877,
          0.00003371297862031497,
          0.00003363805080880411,
          0.00003356302477186546,
          0.00003348864265717566,
          0.000033415049983887,
          0.000033340329537168145,
          0.00003326652222312987,
          0.000033193562558153644,
          0.00003311986802145839,
          0.000033045853342628106,
          0.00003297328294138424,
          0.000032900727092055604,
          0.00003282861507614143,
          0.00003275558628956787,
          0.00003268379805376753,
          0.00003261221354478039,
          0.00003254086914239451,
          0.00003246912456233986,
          0.00003239732177462429,
          0.00003232697781641036,
          0.000032256000849884003,
          0.00003218604251742363,
          0.000032116597139975056,
          0.00003204719541827217,
          0.000031978212064132094,
          0.000031907537049846724,
          0.000031838346330914646,
          0.000031769348424859345,
          0.000031700074032414705,
          0.00003163096334901638,
          0.000031563286029268056,
          0.00003149493568344042,
          0.00003142670539091341,
          0.00003135828592348844,
          0.00003129092146991752,
          0.000031224117265082896,
          0.00003115698928013444,
          0.000031089784897631034,
          0.000031023660994833335,
          0.00003095767897320911,
          0.000030890954803908244,
          0.00003082389594055712,
          0.00003075795029872097,
          0.0000306931760860607,
          0.0000306272559100762,
          0.000030561630410375074,
          0.000030496590625261888,
          0.000030431434424826875,
          0.00003036681482626591,
          0.00003030249717994593,
          0.000030237964892876334,
          0.000030173065169947222,
          0.00003010949876625091,
          0.000030044593586353585,
          0.000029981130865053274,
          0.000029918450309196487,
          0.000029855562388547696,
          0.000029791626730002463,
          0.000029729519155807793,
          0.000029666611226275563,
          0.000029604258088511415,
          0.000029542254196712747,
          0.000029480479497578926,
          0.000029417769837891683,
          0.000029356113373069093
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line(train_losses, log_y=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 17,
=======
   "execution_count": 22,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
<<<<<<< Updated upstream
           0.014990489,
           -0.0017157671,
           -0.025079815,
           -0.06260852,
           0.04395788,
           -0.0005217633,
           0.0718814,
           0.0008011282,
           0.028232686,
           0.08256022,
           -0.09430053,
           -0.03475543,
           0.013821922,
           -0.017815601,
           -0.06680304,
           0.11308761,
           0.09927825,
           -0.0070235776,
           0.018649196,
           0.073381625,
           -0.147253,
           0.04016489,
           0.105138816,
           0.047662452,
           0.012149092,
           -0.112045966,
           -0.08498347,
           -0.024371097,
           0.037236616,
           -0.05941191,
           0.10320724,
           0.17889516,
           -0.051811166,
           -0.02177628,
           0.07401117,
           0.012219758,
           0.01373771,
           0.082893275,
           -0.07956709,
           -0.017961336,
           -0.0364994,
           -0.061465587,
           0.03841881,
           -0.1101263,
           -0.08446932,
           0.041207667,
           -0.04135979,
           -0.051282242,
           0.11176498,
           -0.05855611,
           0.091856316,
           -0.022039616,
           -0.1171811,
           0.14255221,
           0.20050529,
           -0.12349571,
           0.10793029,
           -0.1058911,
           0.06096942,
           -0.014191632,
           0.055988945,
           0.11456419,
           0.118134886,
           -0.023278134,
           -0.06494809,
           0.039850734,
           0.0007339936,
           -0.005747151,
           -0.03335358,
           0.038729064,
           -0.01737773,
           -0.07606777,
           0.14560358,
           -0.042341627,
           0.018012691,
           0.053188,
           -0.10594352,
           0.062030267,
           0.010619442,
           0.019916654,
           0.18199804,
           -0.08838186,
           0.075191066,
           0.035509408,
           -0.11175803,
           -0.090157166,
           0.04619784,
           -0.010988197,
           0.028245823,
           -0.029026482,
           0.031906918,
           -0.052328583,
           -0.03125356,
           -0.0323402,
           -0.07248,
           -0.035183426,
           -0.11302138,
           -0.10110314,
           -0.0127419485,
           0.063274086,
           -0.0037468649,
           -0.046956584,
           -0.019801326,
           0.00272006,
           -0.010285398,
           -0.010941009,
           0.02579493,
           0.1051007,
           0.0069785607,
           0.18575493,
           -0.047383007,
           -0.14413182,
           -0.022796351,
           0.0028352507,
           0.07077765,
           -0.13851282,
           0.012080378,
           0.037495553,
           -0.13018717,
           0.043354414,
           0.12647685,
           0.016540034,
           0.017611561,
           -0.043303028,
           -0.045138847,
           0.019577822,
           -0.04464861,
           -0.10392817
          ],
          [
           -0.14818557,
           0.13342254,
           0.09687745,
           -0.036694676,
           0.09546691,
           0.122122616,
           -0.0066750073,
           -0.12536924,
           0.0025096168,
           0.009599952,
           0.07907317,
           0.047144394,
           0.017043967,
           -0.04750304,
           0.050659746,
           0.060220476,
           0.16785435,
           0.07377062,
           -0.11260541,
           -0.023956107,
           -0.0122723365,
           -0.029088486,
           -0.049180727,
           0.07820225,
           -0.07087406,
           0.0111435205,
           0.08276421,
           -0.0124809975,
           -0.07781306,
           -0.05084437,
           0.115862,
           -0.0538216,
           -0.062048834,
           0.0019847543,
           -0.0043405117,
           0.17144041,
           -0.19799423,
           0.041873332,
           -0.060591713,
           -0.015568297,
           0.002692819,
           0.14073275,
           -0.014779077,
           -0.017251886,
           -0.098396905,
           -0.0072150743,
           -0.13713989,
           -0.101816624,
           -0.03119083,
           -0.07951179,
           0.01169537,
           0.014232628,
           0.05160028,
           0.06690393,
           -0.1253782,
           0.094734505,
           0.064074315,
           0.080138735,
           0.049006045,
           -0.09305951,
           -0.052633736,
           0.15416268,
           0.032432348,
           0.09292125,
           0.011794916,
           -0.019513592,
           0.13068886,
           0.10347524,
           0.08023105,
           -0.04714596,
           -0.037210044,
           0.042963486,
           0.005105123,
           -0.12243517,
           0.079162516,
           0.032635193,
           -0.08801652,
           -0.07092858,
           -0.004901498,
           0.0030413251,
           0.025365772,
           -0.045906287,
           -0.025001105,
           -0.034922324,
           0.041437764,
           0.03958205,
           0.09147294,
           0.05462759,
           0.036478266,
           0.05727581,
           -0.01698746,
           -0.04886303,
           -0.04542125,
           0.020515595,
           -0.036982518,
           -0.026563084,
           -0.04105986,
           -0.020223726,
           -0.0011388755,
           -0.026441768,
           -0.0051616547,
           0.06056891,
           -0.0033978825,
           -0.0279437,
           0.050131883,
           -0.10534526,
           0.03713667,
           -0.1357185,
           -0.0748035,
           0.0010332812,
           -0.031870876,
           -0.029112225,
           0.11127222,
           -0.0069710277,
           -0.056575704,
           -0.08741133,
           0.030150156,
           -0.017253768,
           -0.0059687067,
           -0.059710227,
           -0.018807575,
           0.01330719,
           -0.06370905,
           -0.09296638,
           0.0828829,
           -0.14023475,
           -0.039566267,
           0.074577175
          ],
          [
           0.035436653,
           -0.08068835,
           -0.05873687,
           0.13464856,
           0.055276677,
           -0.008396674,
           0.10434285,
           0.024115613,
           -0.13584344,
           0.014788745,
           -0.08318765,
           -0.005439839,
           -0.13047476,
           -0.05435629,
           -0.033004805,
           -0.08888284,
           -0.020804081,
           0.0647531,
           -0.05372052,
           0.00973958,
           0.050612338,
           -0.0047322786,
           -0.055842932,
           0.073039986,
           -0.0525269,
           -0.11117422,
           -0.19771254,
           -0.20468503,
           -0.017391425,
           0.007204776,
           -0.041272547,
           -0.18556267,
           -0.001914827,
           0.07653403,
           -0.08466265,
           0.016897615,
           -0.04920486,
           -0.025130732,
           -0.093471356,
           -0.07928534,
           0.018821687,
           -0.058417737,
           0.05254025,
           0.03640628,
           0.052104086,
           -0.094013445,
           0.036217786,
           0.007953261,
           0.030428467,
           -0.11209734,
           -0.058396105,
           0.0032973127,
           0.07600354,
           -0.018490992,
           0.07317518,
           -0.1462563,
           -0.101014845,
           0.08773045,
           -0.07964874,
           0.036107983,
           -0.09642196,
           0.061528064,
           -0.08216944,
           0.09070985,
           0.1587927,
           -0.016878998,
           0.037980616,
           0.18333085,
           -0.032114882,
           -0.011362529,
           0.031699836,
           -0.021840576,
           -0.09995995,
           0.00055061904,
           -0.015304026,
           -0.11576972,
           -0.002229549,
           -0.0024576564,
           -0.040380437,
           -0.03317174,
           -0.01838104,
           -0.15382595,
           0.056172773,
           0.052711226,
           -0.086772986,
           0.043384816,
           -0.14885306,
           -0.035220537,
           -0.049556803,
           -0.051569898,
           0.021944433,
           -0.093437366,
           0.021458467,
           -0.04815937,
           0.08105195,
           -0.059244603,
           0.025269384,
           0.0928692,
           0.09096624,
           -0.025580853,
           -0.1502357,
           0.07984805,
           -0.07201574,
           0.068932116,
           -0.0005484747,
           0.08220553,
           0.012165063,
           0.03323414,
           0.12215597,
           0.04539383,
           -0.1318802,
           0.08709149,
           -0.022357885,
           -0.1390986,
           0.040392693,
           0.06132209,
           -0.062731095,
           0.032002237,
           -0.068628035,
           -0.05665317,
           0.010619586,
           0.041093398,
           0.002544013,
           -0.06462535,
           0.107651316,
           0.03317864,
           -0.02800114,
           0.027973862
          ],
          [
           0.0061120237,
           -0.006705488,
           0.064452335,
           -0.03480793,
           0.07043824,
           0.11597075,
           0.02627213,
           0.020155884,
           -0.033845156,
           -0.052540895,
           0.06724601,
           -0.07021217,
           0.09589882,
           -0.15567486,
           0.0422302,
           -0.009968056,
           0.012789557,
           0.003740423,
           -0.083712764,
           -0.07396285,
           -0.01987753,
           -0.05278747,
           0.011854462,
           -0.10027691,
           0.069845736,
           -0.055541746,
           -0.12174235,
           0.053374033,
           -0.020141173,
           0.02185945,
           0.0130390255,
           0.03990575,
           0.0264627,
           0.084539086,
           -0.15287374,
           -0.073190406,
           0.07385762,
           0.23270525,
           -0.27050915,
           -0.036846425,
           0.050655592,
           -0.11366865,
           -0.04249961,
           -0.020007342,
           0.04105719,
           -0.08709734,
           0.071602896,
           0.050857056,
           -0.10264544,
           0.09087537,
           0.003095808,
           -0.15809605,
           -0.075751774,
           0.17562933,
           0.11318345,
           -0.13077097,
           0.14474922,
           0.013250277,
           0.0049637384,
           -0.0126040755,
           0.12054556,
           0.04254196,
           0.046169203,
           0.040174693,
           0.011393967,
           -0.019123655,
           0.055154532,
           -0.06313864,
           -0.11620314,
           -0.06641005,
           -0.10916962,
           0.021349948,
           -0.119890004,
           0.026589792,
           0.03812361,
           -0.051482208,
           -0.07139091,
           0.0012735671,
           -0.0008324508,
           0.0071150144,
           0.007935678,
           -0.11108894,
           -0.1453433,
           -0.086109586,
           0.0009748021,
           0.04408184,
           -0.032169454,
           -0.016075103,
           0.00043545358,
           0.0000953112,
           0.0007415558,
           -0.08991472,
           0.080960706,
           -0.115224294,
           0.09637319,
           0.053647444,
           0.0519243,
           -0.021894721,
           -0.07263222,
           0.063754074,
           0.09525457,
           0.038468227,
           -0.036091343,
           -0.03667813,
           0.08348478,
           -0.044015475,
           -0.0018337643,
           -0.08517855,
           0.035679754,
           0.027928492,
           -0.04593567,
           0.09078469,
           -0.054477476,
           0.02669381,
           0.011726052,
           -0.15651324,
           0.12437254,
           -0.0028722556,
           -0.008829316,
           0.06949498,
           -0.003537546,
           0.021164177,
           0.040457428,
           -0.060554467,
           0.12903586,
           0.0075001162,
           -0.022663424,
           -0.03233832
          ],
          [
           -0.045602992,
           0.12954512,
           0.025884686,
           0.0023768132,
           0.15606965,
           -0.05254388,
           -0.11667052,
           -0.013782733,
           0.08471961,
           0.064198546,
           -0.16795772,
           -0.09661755,
           -0.073410004,
           -0.145515,
           -0.0069966186,
           -0.0535256,
           0.060555197,
           -0.11028605,
           0.009254162,
           -0.12264508,
           0.14607875,
           -0.034207173,
           -0.0056477254,
           -0.021304559,
           0.093013294,
           -0.021898095,
           -0.087388635,
           -0.059355292,
           -0.019347297,
           0.06621929,
           0.06574584,
           0.013528346,
           -0.015861578,
           -0.012518018,
           0.0021873785,
           0.06601665,
           0.06275905,
           -0.009489036,
           0.055588726,
           0.10510467,
           -0.03457561,
           -0.08545687,
           0.020348618,
           0.022395432,
           -0.10990803,
           -0.027519224,
           0.054586794,
           0.022760686,
           0.07680938,
           0.024761938,
           0.0043340344,
           -0.010362917,
           0.026775502,
           0.015305371,
           -0.09215906,
           0.124334075,
           0.06680562,
           0.012068623,
           0.032803662,
           0.02154778,
           -0.027508989,
           0.053792838,
           0.055135768,
           -0.036027,
           -0.07958391,
           0.042262357,
           -0.060339376,
           0.029749095,
           0.016882423,
           -0.16041848,
           0.02654868,
           0.107749775,
           -0.07925831,
           -0.07034767,
           -0.044275865,
           0.02967952,
           0.021951903,
           -0.06147411,
           0.02900729,
           -0.040396698,
           -0.00047959294,
           -0.031942163,
           0.0037603753,
           0.12287159,
           -0.14810528,
           -0.13739637,
           -0.058001626,
           0.025581788,
           0.08981785,
           0.022658069,
           -0.0013197274,
           0.06533549,
           -0.11655968,
           0.0760442,
           0.040185295,
           -0.034324322,
           0.09074786,
           -0.15571864,
           0.07137143,
           -0.11613193,
           0.024084337,
           -0.069750346,
           0.17560497,
           -0.053082164,
           0.188452,
           0.07293368,
           -0.028190868,
           -0.011401584,
           -0.0009344735,
           -0.0035635992,
           -0.16545555,
           -0.0041466947,
           -0.0003957102,
           0.032862995,
           0.027627734,
           0.028625224,
           0.0024501309,
           0.18463102,
           -0.096702136,
           -0.032237105,
           -0.016080663,
           -0.097885534,
           -0.00667544,
           -0.0073857643,
           -0.071947664,
           0.044177897,
           0.012828482,
           0.041263506
          ],
          [
           -0.051032845,
           0.008363552,
           0.09217248,
           -0.05265489,
           -0.04183068,
           0.033445273,
           -0.15775587,
           0.020883095,
           0.0079476135,
           -0.22016285,
           -0.09495077,
           -0.022976525,
           -0.047505774,
           -0.05011116,
           0.044824667,
           0.043451376,
           0.00801566,
           -0.13290697,
           0.095974326,
           0.124798454,
           0.04138523,
           -0.08781043,
           -0.08395681,
           0.05181522,
           0.0021599368,
           0.2580832,
           -0.009867135,
           -0.038125917,
           -0.100211576,
           0.006719836,
           -0.07467928,
           0.033469696,
           -0.05136789,
           -0.05257144,
           -0.015679536,
           0.0526825,
           0.000241717,
           -0.083715364,
           0.06419006,
           -0.09076882,
           -0.15521249,
           -0.14311981,
           0.051448565,
           -0.044041306,
           0.07601751,
           -0.030573891,
           -0.01534167,
           -0.13422976,
           0.04187916,
           0.013090373,
           -0.0011876276,
           -0.07893403,
           0.05823893,
           0.027844453,
           -0.14606154,
           0.07624535,
           0.03852494,
           0.039520442,
           -0.039114255,
           -0.0022116937,
           0.017289706,
           -0.14035112,
           -0.08194286,
           -0.014054592,
           0.08020826,
           0.08658015,
           0.037007894,
           -0.058552973,
           0.030283513,
           0.002332604,
           0.0570167,
           0.12737152,
           0.106014,
           -0.09734054,
           0.09355184,
           -0.02293127,
           0.029935261,
           -0.024442287,
           -0.13909525,
           -0.09679629,
           -0.005100972,
           -0.09527044,
           -0.06904531,
           0.09717805,
           0.029547956,
           0.039176423,
           0.070370525,
           0.057041127,
           0.1682739,
           -0.11720726,
           -0.12953097,
           0.023924612,
           0.008520428,
           0.037853107,
           0.0026755878,
           0.0054694377,
           0.008860458,
           0.08207525,
           0.054162707,
           0.0276342,
           -0.063016705,
           -0.08955938,
           0.0035732253,
           0.007562043,
           0.032892488,
           0.079588726,
           0.011173915,
           0.0035443336,
           -0.026140025,
           -0.017404879,
           -0.1858068,
           -0.006389737,
           -0.074246675,
           0.009689557,
           0.11651268,
           -0.046254426,
           -0.10526767,
           -0.013186446,
           -0.03525537,
           -0.05791368,
           -0.00035860963,
           0.033309795,
           0.043988954,
           -0.10860157,
           -0.058239855,
           0.030789249,
           -0.06520786,
           0.039856594
          ],
          [
           0.021140076,
           0.07757827,
           0.025104148,
           -0.0786137,
           -0.0031689436,
           -0.09119811,
           -0.05662252,
           0.04940435,
           0.05441374,
           -0.023763109,
           -0.0023723696,
           0.01847494,
           -0.14776428,
           -0.03641069,
           0.0076509323,
           0.05203741,
           0.023319023,
           -0.1101153,
           0.044975556,
           -0.018329747,
           -0.01329608,
           0.02996441,
           0.03959239,
           -0.035447393,
           0.013863256,
           -0.13218819,
           0.04503203,
           -0.06588495,
           -0.10094266,
           0.12066499,
           -0.031161882,
           0.03677124,
           -0.070251755,
           0.07209332,
           -0.15692149,
           0.028525498,
           -0.022675687,
           -0.07762078,
           -0.07710435,
           0.16157444,
           -0.079164036,
           -0.090499684,
           0.06782473,
           0.028756257,
           -0.1283275,
           0.019441957,
           -0.01716964,
           -0.11079297,
           -0.048822124,
           0.14922671,
           -0.045339357,
           0.11990257,
           -0.056253143,
           0.044501033,
           0.07574837,
           -0.028635243,
           -0.03243301,
           0.016851576,
           0.089989506,
           0.00231681,
           0.000985845,
           -0.048138797,
           0.006707264,
           -0.027967844,
           0.104649134,
           0.07678688,
           0.10152621,
           0.121460475,
           0.052456908,
           0.10037402,
           -0.052505102,
           0.106676236,
           -0.065731086,
           0.14898244,
           0.0035049764,
           0.07896413,
           -0.024994045,
           0.016990772,
           0.063432045,
           0.025509663,
           -0.0028346295,
           -0.13862102,
           0.109819375,
           -0.08507971,
           0.10879564,
           0.044950075,
           0.008732349,
           0.11844683,
           -0.07423171,
           -0.035062082,
           0.041544575,
           -0.09293427,
           -0.12997083,
           -0.008714419,
           -0.02150149,
           -0.054162018,
           0.027607135,
           0.039027,
           0.041567195,
           0.079954594,
           0.007607228,
           0.089477494,
           -0.06712287,
           -0.055127304,
           -0.028450925,
           -0.024235602,
           -0.031975012,
           -0.0075703645,
           0.03756522,
           0.04845084,
           0.16833343,
           0.052207973,
           -0.016074494,
           0.10373251,
           -0.020152839,
           -0.12799627,
           0.04128779,
           -0.024950031,
           0.17145805,
           0.01169866,
           -0.09583995,
           -0.06739663,
           -0.13798916,
           0.0014398495,
           0.0025379916,
           -0.20133583,
           0.0724651,
           -0.07163859
          ],
          [
           0.06284008,
           -0.08990473,
           -0.0358727,
           0.005673676,
           -0.022732843,
           0.02481464,
           -0.06963505,
           -0.013565784,
           -0.04809051,
           -0.04126873,
           -0.041143373,
           -0.06728891,
           -0.04283129,
           -0.023424756,
           -0.053471204,
           -0.027039446,
           0.06853786,
           -0.04185218,
           0.00890287,
           0.021296794,
           0.015801571,
           0.0994653,
           -0.040494613,
           -0.043373507,
           -0.1247948,
           -0.012609383,
           0.015900344,
           0.014034963,
           0.046062388,
           0.05936133,
           0.09204695,
           -0.10397159,
           0.05610666,
           0.05501094,
           0.095756575,
           -0.04749439,
           -0.06434173,
           0.06477398,
           0.15016586,
           0.06399857,
           0.116114505,
           0.09829085,
           0.03270785,
           -0.0042360006,
           -0.013343874,
           0.08153779,
           0.14829479,
           0.09347687,
           -0.05967215,
           -0.049124956,
           -0.014180634,
           -0.03845616,
           -0.031848103,
           0.0026196684,
           -0.036909536,
           0.0945118,
           0.008620803,
           0.020875204,
           0.069105096,
           -0.00032152902,
           -0.0039773607,
           0.13480967,
           0.1435018,
           0.14862978,
           0.00518759,
           -0.044228144,
           0.026220988,
           0.12729248,
           -0.029859887,
           0.039092217,
           -0.13252403,
           0.014705418,
           -0.049618818,
           0.03535442,
           -0.0662548,
           0.038008824,
           -0.05628688,
           0.08987264,
           0.05562689,
           -0.013260902,
           0.117662184,
           0.01110609,
           -0.08884815,
           0.09655801,
           0.036618475,
           -0.059935633,
           0.101246335,
           -0.14126334,
           -0.060913626,
           -0.096068464,
           -0.032398835,
           0.029999971,
           0.018036583,
           -0.018352706,
           -0.002202891,
           0.07030899,
           0.06970535,
           0.027205462,
           0.04788968,
           0.055474564,
           0.014121071,
           0.1358448,
           0.12052043,
           -0.1107144,
           0.020754667,
           -0.15023406,
           0.03565663,
           0.03175147,
           -0.103319876,
           -0.050788015,
           -0.028344687,
           -0.01904143,
           0.06127625,
           0.05063366,
           -0.006518644,
           0.065143056,
           -0.053196426,
           -0.022448761,
           -0.08637795,
           0.05610483,
           -0.149332,
           0.0058993422,
           -0.021234049,
           -0.042779654,
           -0.020665385,
           0.055356886,
           -0.030236691,
           0.13258496
          ],
          [
           0.018980427,
           0.013494543,
           -0.0041958494,
           -0.0042657168,
           -0.005603961,
           0.004374824,
           -0.03998407,
           -0.14080906,
           -0.0577268,
           -0.05272578,
           -0.003961361,
           0.021003006,
           -0.03481271,
           0.038814984,
           -0.039538126,
           -0.12971349,
           -0.13999616,
           -0.014149423,
           -0.049746517,
           -0.016924592,
           0.124585964,
           -0.08702749,
           -0.014215136,
           0.04837351,
           0.14670166,
           0.093589775,
           0.021441778,
           -0.08841296,
           -0.0695132,
           0.03547775,
           -0.043220602,
           0.08535154,
           -0.031253874,
           0.036842834,
           -0.021695303,
           0.01036625,
           0.105012394,
           0.050427865,
           0.04401514,
           0.031424444,
           -0.04170747,
           0.09153724,
           -0.10962833,
           0.030808624,
           -0.029933222,
           -0.047785573,
           -0.02797148,
           -0.13201876,
           0.06480264,
           0.08382075,
           -0.006173293,
           0.12643741,
           0.06090994,
           0.02390869,
           -0.028317,
           -0.118210934,
           -0.01861385,
           -0.046128314,
           0.045663647,
           -0.028583765,
           -0.014325008,
           -0.06403093,
           0.019237055,
           -0.05129627,
           -0.122059815,
           -0.10195356,
           -0.099016584,
           -0.04342971,
           0.13502401,
           0.016644336,
           0.026001457,
           0.10975676,
           -0.11930125,
           -0.072900675,
           -0.026830744,
           0.038774878,
           -0.15268773,
           -0.13427539,
           0.0605766,
           0.103421785,
           0.031058928,
           -0.037482798,
           -0.1863289,
           0.103743866,
           0.024437468,
           -0.072150506,
           -0.060938857,
           -0.116420396,
           0.06461505,
           -0.026312891,
           0.10219391,
           -0.02212684,
           0.055573348,
           0.065196685,
           -0.03453551,
           -0.05042968,
           0.039558675,
           0.012408273,
           -0.0522779,
           -0.113537535,
           0.07688614,
           0.14349806,
           -0.029147806,
           0.117355764,
           0.030899566,
           -0.06535815,
           -0.03324236,
           0.020433635,
           -0.059866257,
           0.013485812,
           0.11780646,
           0.14520264,
           -0.06575177,
           0.0291608,
           -0.056289274,
           -0.023288626,
           -0.04362368,
           0.11625679,
           0.03829759,
           0.06330262,
           0.0842669,
           0.034531265,
           0.014630076,
           -0.08972987,
           0.02730106,
           -0.086630024,
           -0.16082756,
           -0.017089887
          ],
          [
           -0.013436149,
           -0.02952841,
           -0.06490931,
           0.019489132,
           -0.009446315,
           0.02682588,
           0.04299098,
           -0.07535052,
           0.05738263,
           0.14875238,
           0.117997676,
           0.04897586,
           -0.03429248,
           -0.00055585033,
           0.075928286,
           -0.10145043,
           0.016132522,
           -0.08277456,
           -0.0141351605,
           -0.04408228,
           -0.018735576,
           0.17006297,
           0.05486723,
           0.009120529,
           -0.08832628,
           0.08962794,
           0.10187726,
           -0.12919468,
           -0.06736468,
           0.054034296,
           -0.03299259,
           -0.013907161,
           0.05231115,
           0.045512345,
           -0.015702892,
           0.07658645,
           -0.002430465,
           0.0060736667,
           -0.13964981,
           0.051467493,
           0.068966955,
           -0.04259839,
           -0.012280702,
           0.120756365,
           -0.0064680288,
           -0.0026704073,
           0.0031098728,
           -0.0418999,
           -0.014986801,
           -0.018687714,
           -0.014753387,
           0.039364498,
           0.0736457,
           0.050768867,
           0.02489615,
           -0.03792308,
           0.04262207,
           0.007965483,
           0.11413166,
           -0.08861759,
           0.07587171,
           -0.08146107,
           0.0038845788,
           -0.08220132,
           0.078520805,
           -0.029242931,
           -0.03545988,
           -0.00089221366,
           0.10664866,
           -0.08102898,
           -0.0012619428,
           0.111134514,
           0.01638875,
           0.0959447,
           -0.040322542,
           0.027389564,
           0.062702425,
           0.046261344,
           -0.027761687,
           -0.0052903895,
           -0.035721254,
           -0.093382105,
           0.024619834,
           -0.07428491,
           -0.06478799,
           -0.12461405,
           -0.049301982,
           0.047326326,
           0.017666778,
           0.07807306,
           -0.046576615,
           -0.011297683,
           -0.07164968,
           0.031875696,
           -0.052230522,
           -0.019477477,
           -0.021619568,
           -0.030039463,
           -0.090256356,
           -0.031247627,
           -0.14582916,
           0.061126173,
           0.08710825,
           -0.044535067,
           -0.12812236,
           0.1653286,
           -0.07420086,
           -0.03404485,
           0.023201985,
           0.1018142,
           -0.07692974,
           -0.0511967,
           0.008825519,
           0.07048762,
           0.1550041,
           0.041691575,
           -0.0038444395,
           -0.12387516,
           -0.071019374,
           0.14266221,
           0.018613728,
           0.028766716,
           -0.079315424,
           -0.011697763,
           -0.04509826,
           -0.019096399,
           0.003781944,
           0.023927107
          ],
          [
           -0.033232547,
           -0.08616395,
           -0.118189305,
           0.13055742,
           -0.046792068,
           0.07693008,
           -0.063001014,
           -0.032898083,
           0.022225395,
           -0.010151892,
           -0.054764356,
           0.04034168,
           -0.09643303,
           -0.07894419,
           -0.041024916,
           0.06274354,
           -0.009295137,
           -0.04051707,
           0.026819745,
           -0.008376111,
           -0.122121856,
           -0.12808146,
           -0.07933819,
           -0.065221995,
           -0.06250257,
           -0.053432923,
           -0.049342018,
           0.10219613,
           -0.009306032,
           0.0128397085,
           -0.022662496,
           0.048761863,
           -0.020935921,
           0.12717187,
           -0.00058367447,
           0.021797787,
           -0.009471733,
           0.029171051,
           -0.005843969,
           -0.12507619,
           -0.028334549,
           -0.014551051,
           -0.046654023,
           -0.056466505,
           -0.057919167,
           -0.02081407,
           0.029880106,
           0.025083581,
           -0.021221431,
           -0.026939658,
           0.035572506,
           -0.017978754,
           -0.044747308,
           0.03597246,
           0.07118323,
           0.04475769,
           0.019532725,
           0.010167537,
           0.019385522,
           -0.045770187,
           -0.11356277,
           -0.041162144,
           0.058347028,
           0.040550746,
           -0.052546795,
           -0.0030614429,
           -0.057395134,
           -0.1427567,
           -0.055728953,
           0.029639754,
           -0.067108,
           -0.108194396,
           0.044823885,
           0.070355676,
           0.019068876,
           0.016765233,
           0.010151848,
           -0.0863942,
           0.019706136,
           -0.07989625,
           -0.099234104,
           -0.053904295,
           0.11845537,
           -0.010361841,
           0.039105684,
           -0.15585005,
           -0.05413593,
           0.13952285,
           0.065542825,
           0.16418462,
           0.11195575,
           0.088929735,
           0.059017345,
           0.045122124,
           0.06609648,
           -0.054737516,
           -0.16094315,
           -0.049678873,
           -0.0110996915,
           0.16362236,
           -0.13648307,
           0.030956505,
           0.020987924,
           0.081177674,
           -0.00081357884,
           -0.04570456,
           0.05426527,
           0.09073887,
           0.070353895,
           -0.040058926,
           0.08367509,
           0.08317938,
           0.011506246,
           0.0038411866,
           0.05307717,
           0.02945422,
           -0.12707701,
           -0.0008081582,
           0.0276304,
           0.1500888,
           0.055192653,
           -0.039176416,
           -0.09781647,
           -0.06789487,
           0.005668636,
           0.002748626,
           0.11909096,
           0.109559536
=======
           0.018218702,
           -0.0029133651,
           -0.026235987,
           -0.062357914,
           0.046023812,
           0.000005817713,
           0.073289305,
           0.00342051,
           0.030424945,
           0.08781496,
           -0.09600659,
           -0.035167992,
           0.014907507,
           -0.01765515,
           -0.063399754,
           0.11453181,
           0.100098096,
           -0.005341869,
           0.020056972,
           0.070129186,
           -0.14739932,
           0.041133754,
           0.110694945,
           0.046161976,
           0.009085773,
           -0.11343164,
           -0.08436297,
           -0.02271985,
           0.03725123,
           -0.059418425,
           0.10346368,
           0.18101287,
           -0.05026429,
           -0.020652598,
           0.07240185,
           0.014010041,
           0.015837265,
           0.08336117,
           -0.081736706,
           -0.019584553,
           -0.030016623,
           -0.06361942,
           0.037047427,
           -0.108821675,
           -0.08487259,
           0.040245485,
           -0.04576267,
           -0.051821947,
           0.11390618,
           -0.05755931,
           0.094106026,
           -0.024417108,
           -0.11105447,
           0.14519233,
           0.20027594,
           -0.119405776,
           0.10599167,
           -0.11114229,
           0.060600467,
           -0.01397652,
           0.056775924,
           0.113384426,
           0.11626543,
           -0.026015393,
           -0.065091714,
           0.045554668,
           -0.00078237517,
           -0.009327886,
           -0.03736528,
           0.039126884,
           -0.015429133,
           -0.07494147,
           0.14667377,
           -0.0431225,
           0.020377284,
           0.053861793,
           -0.107089765,
           0.06325507,
           0.0149873905,
           0.019885527,
           0.18067318,
           -0.08492786,
           0.07533745,
           0.034242995,
           -0.113524966,
           -0.088770114,
           0.047919907,
           -0.009137917,
           0.023390438,
           -0.030201942,
           0.038120955,
           -0.04846142,
           -0.030802187,
           -0.032018136,
           -0.06880949,
           -0.035182483,
           -0.11946272,
           -0.10093825,
           -0.009943869,
           0.06403004,
           -0.0029435568,
           -0.049621195,
           -0.018152924,
           0.0018275678,
           -0.016326731,
           -0.0046908576,
           0.023516154,
           0.10390721,
           0.010009804,
           0.18520856,
           -0.049055494,
           -0.14465375,
           -0.01981233,
           0.004231954,
           0.06672916,
           -0.1395749,
           0.013143129,
           0.036164448,
           -0.13002202,
           0.041957818,
           0.12974215,
           0.018369522,
           0.018052792,
           -0.043823652,
           -0.048767783,
           0.023790857,
           -0.03942972,
           -0.10696218
          ],
          [
           -0.14860626,
           0.13423352,
           0.09372215,
           -0.034903735,
           0.093408264,
           0.12276347,
           -0.005412544,
           -0.12495707,
           0.0023181557,
           0.004487566,
           0.07961571,
           0.045935925,
           0.01953443,
           -0.047090776,
           0.05493208,
           0.059935484,
           0.16752778,
           0.07218521,
           -0.11089566,
           -0.023256628,
           -0.012113949,
           -0.021734433,
           -0.048470724,
           0.08183897,
           -0.06962804,
           0.0106316935,
           0.0809013,
           -0.012389246,
           -0.07720268,
           -0.05021448,
           0.11526897,
           -0.05378013,
           -0.06203039,
           0.0017939707,
           -0.0064766635,
           0.17127815,
           -0.19865349,
           0.04188578,
           -0.055635355,
           -0.015971217,
           0.0022527883,
           0.14199266,
           -0.014934391,
           -0.018781632,
           -0.09883435,
           -0.0084874015,
           -0.13589053,
           -0.102675624,
           -0.028367488,
           -0.07982953,
           0.010823597,
           0.015386556,
           0.050056115,
           0.06447556,
           -0.12369575,
           0.096397385,
           0.06618786,
           0.08072191,
           0.048338488,
           -0.09716916,
           -0.054023053,
           0.15234172,
           0.032304052,
           0.090442844,
           0.011304473,
           -0.021708978,
           0.13204128,
           0.102840975,
           0.082515106,
           -0.04793347,
           -0.03599411,
           0.041034084,
           0.006191037,
           -0.122980684,
           0.07961688,
           0.034307253,
           -0.092555724,
           -0.07012579,
           -0.00715457,
           0.0068484466,
           0.0265405,
           -0.045624997,
           -0.018579494,
           -0.032776214,
           0.044504803,
           0.039160818,
           0.08935409,
           0.05639965,
           0.036364753,
           0.059571676,
           -0.018381273,
           -0.04760301,
           -0.046165716,
           0.023307374,
           -0.038238198,
           -0.028820949,
           -0.044033796,
           -0.021590248,
           0.00008237196,
           -0.027975082,
           -0.0042941743,
           0.059056964,
           -0.0037874696,
           -0.029071564,
           0.05331788,
           -0.10406843,
           0.039706066,
           -0.13683115,
           -0.07486284,
           0.0002070666,
           -0.034140855,
           -0.032088157,
           0.109056376,
           -0.0034092388,
           -0.056188025,
           -0.086855456,
           0.028956244,
           -0.023005283,
           -0.0052484153,
           -0.059132192,
           -0.022781838,
           0.013145076,
           -0.06854571,
           -0.08789041,
           0.08400864,
           -0.14023274,
           -0.03950505,
           0.07370229
          ],
          [
           0.03687907,
           -0.08082782,
           -0.059410136,
           0.13509777,
           0.055320933,
           -0.008411703,
           0.10775573,
           0.024192188,
           -0.13581188,
           0.015511672,
           -0.08479913,
           -0.0039082845,
           -0.12852056,
           -0.0545377,
           -0.033629633,
           -0.09278279,
           -0.017250022,
           0.06608569,
           -0.057628937,
           0.010442104,
           0.05258448,
           -0.0049113827,
           -0.052538108,
           0.071351156,
           -0.053561226,
           -0.11249451,
           -0.19937341,
           -0.20581652,
           -0.017431088,
           0.0068153786,
           -0.04262943,
           -0.18711393,
           0.0010467566,
           0.07534424,
           -0.0860976,
           0.013505648,
           -0.046375804,
           -0.02644113,
           -0.0952699,
           -0.07831654,
           0.020701716,
           -0.059714366,
           0.05101822,
           0.03652761,
           0.05361616,
           -0.09478536,
           0.036528133,
           0.008700409,
           0.030019432,
           -0.115731165,
           -0.05943059,
           0.0038255607,
           0.07546309,
           -0.017616825,
           0.07341008,
           -0.14577273,
           -0.100890145,
           0.08963199,
           -0.079906255,
           0.037367932,
           -0.09735845,
           0.05752092,
           -0.08367544,
           0.09469112,
           0.16017362,
           -0.018341212,
           0.03675339,
           0.18505065,
           -0.033748914,
           -0.00910324,
           0.032397885,
           -0.019151539,
           -0.098633766,
           0.0024119876,
           -0.01609206,
           -0.11411243,
           -0.0017153312,
           0.00087035215,
           -0.040239636,
           -0.033121534,
           -0.01890101,
           -0.15265593,
           0.057783045,
           0.04998347,
           -0.08774313,
           0.04426788,
           -0.14911057,
           -0.030536603,
           -0.049454756,
           -0.054494653,
           0.022558006,
           -0.09268128,
           0.020635966,
           -0.04843533,
           0.08111274,
           -0.062237356,
           0.026640145,
           0.096157916,
           0.094221115,
           -0.02593094,
           -0.15124705,
           0.077983856,
           -0.07398626,
           0.06809363,
           -0.0041267844,
           0.08228358,
           0.012620397,
           0.035022657,
           0.122558735,
           0.04662535,
           -0.13491672,
           0.088490665,
           -0.022295961,
           -0.13364358,
           0.04143921,
           0.06264882,
           -0.05953867,
           0.036282267,
           -0.06524598,
           -0.05690651,
           0.009643667,
           0.037665725,
           0.0025551994,
           -0.066072024,
           0.10906221,
           0.033666823,
           -0.029857798,
           0.028621597
          ],
          [
           0.006158995,
           -0.005660154,
           0.061392583,
           -0.03559277,
           0.06839755,
           0.11594789,
           0.027383108,
           0.026273048,
           -0.03552933,
           -0.05335743,
           0.06798377,
           -0.06988127,
           0.09630136,
           -0.15480646,
           0.03957926,
           -0.010231941,
           0.011591895,
           0.01057208,
           -0.08309937,
           -0.076966345,
           -0.021837687,
           -0.052833915,
           0.009788011,
           -0.101083994,
           0.07198949,
           -0.05564282,
           -0.1232886,
           0.049858823,
           -0.017854793,
           0.02107897,
           0.01571474,
           0.03684133,
           0.025764935,
           0.084581986,
           -0.1527654,
           -0.075084105,
           0.07430274,
           0.23264132,
           -0.27189496,
           -0.04232654,
           0.04936536,
           -0.113080636,
           -0.042019136,
           -0.02103732,
           0.04509638,
           -0.08966145,
           0.06943145,
           0.052531693,
           -0.09489054,
           0.08970815,
           0.000120173194,
           -0.15630391,
           -0.07763448,
           0.1798263,
           0.11186231,
           -0.13141881,
           0.15115526,
           0.012431617,
           0.0052360306,
           -0.014972932,
           0.12188166,
           0.04788928,
           0.046332702,
           0.040436983,
           0.012367083,
           -0.019564148,
           0.051765062,
           -0.06349046,
           -0.117687486,
           -0.06606409,
           -0.10702792,
           0.016974045,
           -0.11988408,
           0.02714564,
           0.038315088,
           -0.0548497,
           -0.07708557,
           -0.0023459035,
           0.0005107769,
           0.0071633975,
           0.008662989,
           -0.109598786,
           -0.14566574,
           -0.086156815,
           0.0007608441,
           0.04343135,
           -0.033722058,
           -0.017711543,
           0.00044542763,
           0.00047639335,
           -0.0011209989,
           -0.09093649,
           0.08376033,
           -0.11601535,
           0.097367205,
           0.053513486,
           0.050748203,
           -0.023277562,
           -0.07277186,
           0.06585687,
           0.09270661,
           0.040116534,
           -0.03644516,
           -0.040305544,
           0.08859047,
           -0.048290882,
           -0.004801403,
           -0.08559756,
           0.037756085,
           0.027693918,
           -0.046225455,
           0.093791515,
           -0.05317891,
           0.028251845,
           0.012499936,
           -0.15678489,
           0.12365548,
           -0.00059967145,
           -0.008558672,
           0.07320816,
           -0.005375391,
           0.02042568,
           0.04092586,
           -0.060807735,
           0.13132752,
           0.010746929,
           -0.027263414,
           -0.032010768
          ],
          [
           -0.046118375,
           0.13328537,
           0.028395968,
           0.0048375265,
           0.1548604,
           -0.050420925,
           -0.1181016,
           -0.012092509,
           0.08451237,
           0.065487064,
           -0.16879448,
           -0.09502752,
           -0.07238997,
           -0.14680164,
           -0.0077760387,
           -0.057282932,
           0.061506335,
           -0.10981262,
           0.005562376,
           -0.122638814,
           0.1467955,
           -0.03468114,
           -0.00267102,
           -0.023561796,
           0.09046839,
           -0.020851152,
           -0.08647909,
           -0.05832286,
           -0.024401348,
           0.06772054,
           0.06426852,
           0.0150567135,
           -0.0138796205,
           -0.014619137,
           0.004822668,
           0.06644237,
           0.060282867,
           -0.0113662025,
           0.057833035,
           0.10595387,
           -0.034133036,
           -0.08282686,
           0.0211894,
           0.023795348,
           -0.10771712,
           -0.02502882,
           0.05609597,
           0.026691686,
           0.076563135,
           0.022209752,
           0.0035718416,
           -0.009908163,
           0.02614779,
           0.013723114,
           -0.09290122,
           0.12667526,
           0.067005746,
           0.013419687,
           0.033751167,
           0.019043747,
           -0.024223806,
           0.051460974,
           0.058201816,
           -0.037736155,
           -0.07358315,
           0.037970256,
           -0.061783608,
           0.03298734,
           0.017365113,
           -0.16373216,
           0.022891182,
           0.10942567,
           -0.07834216,
           -0.067336865,
           -0.049019307,
           0.028567381,
           0.026244203,
           -0.05805356,
           0.025359467,
           -0.047880743,
           0.002827143,
           -0.030698922,
           0.0045338036,
           0.12428743,
           -0.15134272,
           -0.1372084,
           -0.05656395,
           0.023231199,
           0.088402495,
           0.02355538,
           0.0020827514,
           0.06840812,
           -0.117504254,
           0.07738105,
           0.04048403,
           -0.03975443,
           0.092288464,
           -0.15590963,
           0.065361336,
           -0.11720684,
           0.01995171,
           -0.07105923,
           0.1764286,
           -0.053200897,
           0.18786854,
           0.07347263,
           -0.029421393,
           -0.009046552,
           0.0025629965,
           -0.0026363863,
           -0.16507179,
           0.0015769567,
           -0.0058072847,
           0.03411445,
           0.025907034,
           0.027494382,
           0.0029920575,
           0.18927412,
           -0.096554324,
           -0.02992692,
           -0.014875648,
           -0.09659726,
           -0.0064406986,
           -0.003111362,
           -0.07219069,
           0.042307336,
           0.013520515,
           0.04139998
          ],
          [
           -0.048200432,
           0.010492224,
           0.09454263,
           -0.05106451,
           -0.037540987,
           0.03314271,
           -0.16090845,
           0.01864095,
           0.01003031,
           -0.21787491,
           -0.09619361,
           -0.025772901,
           -0.048908185,
           -0.05254887,
           0.045285672,
           0.03767942,
           0.009548205,
           -0.13223542,
           0.09839792,
           0.12497874,
           0.038706824,
           -0.090474516,
           -0.085944355,
           0.052328955,
           0.00036307116,
           0.2576218,
           -0.009899018,
           -0.036848657,
           -0.10224088,
           0.007936585,
           -0.0753126,
           0.03526677,
           -0.052700765,
           -0.054099917,
           -0.016095499,
           0.055551358,
           -0.0011414035,
           -0.092959106,
           0.06708573,
           -0.092974976,
           -0.1535413,
           -0.14260773,
           0.05618619,
           -0.043247055,
           0.07698203,
           -0.025073351,
           -0.017103039,
           -0.13122132,
           0.0398539,
           0.010691785,
           -0.0032097711,
           -0.07737486,
           0.06039844,
           0.030835837,
           -0.146391,
           0.07526772,
           0.039054886,
           0.03930506,
           -0.03592547,
           -0.0026812833,
           0.017971719,
           -0.14522484,
           -0.080869064,
           -0.014237876,
           0.081803456,
           0.08527981,
           0.038695604,
           -0.05876123,
           0.028848138,
           -0.0018378869,
           0.05674898,
           0.12829272,
           0.10311763,
           -0.09778167,
           0.09294824,
           -0.022750767,
           0.029954765,
           -0.020041391,
           -0.14247955,
           -0.09835738,
           -0.0040387567,
           -0.09903574,
           -0.07135827,
           0.0986122,
           0.022755217,
           0.038906094,
           0.0675292,
           0.055638503,
           0.1677289,
           -0.11583104,
           -0.12972513,
           0.028464587,
           0.0058654426,
           0.03896474,
           0.0013391619,
           0.006894288,
           0.010937762,
           0.07955872,
           0.05262575,
           0.026235973,
           -0.062258072,
           -0.08943151,
           0.0070614484,
           0.0009912092,
           0.037481826,
           0.07950351,
           0.009472442,
           -0.0025981257,
           -0.03208857,
           -0.016004665,
           -0.1863842,
           -0.0067102606,
           -0.073370606,
           0.01160328,
           0.11625749,
           -0.0406627,
           -0.10590255,
           -0.018588983,
           -0.03326932,
           -0.059002116,
           0.00035033296,
           0.036643237,
           0.043969512,
           -0.10968509,
           -0.055052888,
           0.030332578,
           -0.06560162,
           0.03464978
          ],
          [
           0.0225358,
           0.07680648,
           0.028327556,
           -0.079337746,
           -0.0014519944,
           -0.086509444,
           -0.053796545,
           0.048215233,
           0.05441198,
           -0.022477657,
           -0.002647663,
           0.017861923,
           -0.14920712,
           -0.039559804,
           0.008822556,
           0.05233008,
           0.021693476,
           -0.10511238,
           0.046236012,
           -0.017797317,
           -0.01386726,
           0.0311873,
           0.039559744,
           -0.036077667,
           0.011115043,
           -0.13135889,
           0.045940686,
           -0.065837994,
           -0.10246444,
           0.118570186,
           -0.033891056,
           0.043168955,
           -0.07408435,
           0.06767826,
           -0.15484262,
           0.026833063,
           -0.02283367,
           -0.07617088,
           -0.07592601,
           0.16004542,
           -0.07901136,
           -0.088721,
           0.06987295,
           0.029512474,
           -0.12986599,
           0.020031752,
           -0.017306197,
           -0.10247244,
           -0.04891855,
           0.14846955,
           -0.047056835,
           0.11999707,
           -0.05542436,
           0.03793439,
           0.07573521,
           -0.031560954,
           -0.032635424,
           0.013898151,
           0.09353548,
           -0.0008857129,
           0.0040261485,
           -0.05411186,
           0.011216782,
           -0.023685277,
           0.10411487,
           0.072424285,
           0.10072665,
           0.117587246,
           0.051630806,
           0.10045766,
           -0.052430075,
           0.10776106,
           -0.06846367,
           0.15019521,
           0.0027582846,
           0.07933726,
           -0.022743797,
           0.016486162,
           0.056278132,
           0.02751668,
           -0.006698072,
           -0.14057541,
           0.11029427,
           -0.08657365,
           0.1110812,
           0.0459298,
           0.0077318815,
           0.12012535,
           -0.076155685,
           -0.03515692,
           0.043577548,
           -0.092949495,
           -0.13224742,
           -0.0039439215,
           -0.02202152,
           -0.054949816,
           0.028423894,
           0.03818162,
           0.04082928,
           0.07968367,
           0.0100423535,
           0.086713016,
           -0.066562295,
           -0.05495101,
           -0.03221716,
           -0.023556137,
           -0.029955313,
           -0.004855479,
           0.038915865,
           0.051920936,
           0.16550562,
           0.05351706,
           -0.01538033,
           0.104474835,
           -0.022544697,
           -0.12771542,
           0.038441144,
           -0.024423206,
           0.1722974,
           0.014210357,
           -0.09556845,
           -0.06721061,
           -0.1396081,
           0.0000030805322,
           0.00392503,
           -0.1991769,
           0.072432615,
           -0.0717334
          ],
          [
           0.063214265,
           -0.08904058,
           -0.03679807,
           0.008100977,
           -0.024919197,
           0.023406945,
           -0.066391096,
           -0.015289919,
           -0.046671834,
           -0.03869814,
           -0.040465325,
           -0.06664432,
           -0.045199405,
           -0.0271409,
           -0.055479042,
           -0.02896724,
           0.06495809,
           -0.041924473,
           0.0101323435,
           0.021990044,
           0.014120529,
           0.098839246,
           -0.039302785,
           -0.040295053,
           -0.12471071,
           -0.012046952,
           0.013077944,
           0.01248013,
           0.0472935,
           0.063341156,
           0.09095894,
           -0.102484815,
           0.056958716,
           0.054257445,
           0.09622735,
           -0.048498247,
           -0.06564052,
           0.06402577,
           0.14934668,
           0.06571287,
           0.11366261,
           0.099839725,
           0.033439405,
           -0.0047680377,
           -0.013248166,
           0.08253023,
           0.14660724,
           0.09308918,
           -0.063606866,
           -0.049346387,
           -0.015097296,
           -0.038278136,
           -0.03435648,
           0.004320473,
           -0.037940126,
           0.09831926,
           0.008977976,
           0.017525455,
           0.068355665,
           0.0024914842,
           -0.004960669,
           0.14098659,
           0.14644729,
           0.14881995,
           0.0058227824,
           -0.04857412,
           0.026824718,
           0.12786542,
           -0.030673604,
           0.037801065,
           -0.13422558,
           0.018278584,
           -0.049822748,
           0.03600306,
           -0.066562586,
           0.035883978,
           -0.05870498,
           0.09131162,
           0.05517132,
           -0.01427958,
           0.1176423,
           0.008991705,
           -0.09366672,
           0.097060464,
           0.03725243,
           -0.06035599,
           0.10092895,
           -0.14132999,
           -0.058069766,
           -0.09269754,
           -0.03201358,
           0.027526587,
           0.011389483,
           -0.018706664,
           0.0006792951,
           0.06678092,
           0.07028177,
           0.0225507,
           0.045719672,
           0.05632669,
           0.012699938,
           0.1326593,
           0.12265891,
           -0.11198104,
           0.027673269,
           -0.15139888,
           0.03806025,
           0.035708416,
           -0.10312214,
           -0.04936156,
           -0.02947323,
           -0.01797902,
           0.059822414,
           0.050279655,
           -0.0075889453,
           0.06655429,
           -0.05429646,
           -0.022516513,
           -0.087491445,
           0.05678213,
           -0.14951596,
           0.0068475637,
           -0.024498062,
           -0.042434644,
           -0.024605474,
           0.058316667,
           -0.032154832,
           0.13311824
          ],
          [
           0.019845773,
           0.01149193,
           -0.00455027,
           -0.008029414,
           -0.0052741943,
           0.0029217904,
           -0.04048363,
           -0.14181286,
           -0.05916001,
           -0.052488618,
           -0.0033927732,
           0.022433406,
           -0.034524236,
           0.03832591,
           -0.04050483,
           -0.12645559,
           -0.14055452,
           -0.013222529,
           -0.05308564,
           -0.01664468,
           0.12219017,
           -0.08848216,
           -0.015501156,
           0.047230892,
           0.14743245,
           0.09455305,
           0.021443525,
           -0.08678331,
           -0.068620145,
           0.03485701,
           -0.04603112,
           0.08625702,
           -0.030673746,
           0.036613666,
           -0.019227944,
           0.009378001,
           0.101628736,
           0.050536986,
           0.046298966,
           0.033211537,
           -0.04270256,
           0.08673522,
           -0.11102695,
           0.034372803,
           -0.030947613,
           -0.052128177,
           -0.026039384,
           -0.13712443,
           0.06028859,
           0.08285795,
           -0.0036119472,
           0.12633918,
           0.061248764,
           0.025583228,
           -0.030635744,
           -0.118670575,
           -0.01824375,
           -0.044698823,
           0.045596547,
           -0.027004942,
           -0.016420588,
           -0.0639434,
           0.018749006,
           -0.050669607,
           -0.122198395,
           -0.10102985,
           -0.09914911,
           -0.03820114,
           0.1370895,
           0.014977101,
           0.026070466,
           0.11029528,
           -0.121222384,
           -0.074784465,
           -0.027903052,
           0.035955433,
           -0.15224037,
           -0.13731785,
           0.058952294,
           0.10370406,
           0.025156379,
           -0.036365364,
           -0.18377571,
           0.10269706,
           0.025178378,
           -0.074786834,
           -0.059924345,
           -0.1158509,
           0.06499291,
           -0.02722389,
           0.10072884,
           -0.027221207,
           0.05792021,
           0.06565009,
           -0.032717843,
           -0.049837157,
           0.0371779,
           0.016961249,
           -0.055891566,
           -0.118398696,
           0.08193515,
           0.1475438,
           -0.02846062,
           0.11866337,
           0.030622397,
           -0.064023435,
           -0.036115646,
           0.018644718,
           -0.059360836,
           0.0075743534,
           0.11846953,
           0.1508673,
           -0.06332845,
           0.028896281,
           -0.052169126,
           -0.024963217,
           -0.04586531,
           0.12055031,
           0.041803762,
           0.061566036,
           0.084953316,
           0.034048196,
           0.015797991,
           -0.0902331,
           0.027229698,
           -0.0860228,
           -0.16634873,
           -0.015772833
          ],
          [
           -0.017715251,
           -0.027995955,
           -0.065110005,
           0.018022921,
           -0.0053365445,
           0.02943075,
           0.040577773,
           -0.07417327,
           0.055044714,
           0.14466815,
           0.117212206,
           0.046848703,
           -0.037201304,
           -0.0020487593,
           0.07403873,
           -0.10108589,
           0.016595554,
           -0.085091166,
           -0.013682732,
           -0.044720206,
           -0.014559337,
           0.16990456,
           0.055070743,
           0.009686557,
           -0.09124541,
           0.083673954,
           0.101334825,
           -0.12891898,
           -0.06323104,
           0.05221739,
           -0.032832544,
           -0.015311935,
           0.054513365,
           0.04424324,
           -0.01632229,
           0.076111995,
           -0.0033765167,
           0.008655646,
           -0.13883498,
           0.053779334,
           0.06821717,
           -0.044390157,
           -0.008720825,
           0.11957809,
           -0.0078798635,
           -0.0013277672,
           0.006291065,
           -0.04403852,
           -0.015887968,
           -0.017331615,
           -0.010807783,
           0.04325782,
           0.06722199,
           0.052628346,
           0.02554121,
           -0.037804283,
           0.043572273,
           0.009935792,
           0.11369903,
           -0.08661324,
           0.07671737,
           -0.08055982,
           0.0035525332,
           -0.079141974,
           0.07486382,
           -0.027017955,
           -0.03167025,
           0.0005843656,
           0.105265096,
           -0.07759705,
           -0.0026816595,
           0.107772775,
           0.014923229,
           0.09260465,
           -0.04559353,
           0.02520037,
           0.06354046,
           0.04496646,
           -0.029649656,
           -0.0025958354,
           -0.037733745,
           -0.09631204,
           0.023117775,
           -0.070746444,
           -0.06378921,
           -0.124209434,
           -0.0487953,
           0.04764282,
           0.017620396,
           0.07325018,
           -0.049906008,
           -0.010914817,
           -0.06825075,
           0.028719125,
           -0.0500436,
           -0.016450055,
           -0.019659713,
           -0.029041382,
           -0.090116665,
           -0.030254694,
           -0.14257725,
           0.059248235,
           0.082241006,
           -0.04417897,
           -0.12393487,
           0.16221143,
           -0.073942326,
           -0.035397347,
           0.021678012,
           0.10034246,
           -0.07331027,
           -0.049093142,
           0.0085434085,
           0.07130192,
           0.15488224,
           0.039773893,
           -0.0063304533,
           -0.12043617,
           -0.07111603,
           0.1420417,
           0.0199336,
           0.026924906,
           -0.079378694,
           -0.013008798,
           -0.039404552,
           -0.019778064,
           0.0048859776,
           0.020965522
          ],
          [
           -0.034120206,
           -0.08665548,
           -0.11855489,
           0.13031314,
           -0.04716133,
           0.076818556,
           -0.064308,
           -0.03282187,
           0.021200519,
           -0.010066757,
           -0.05506209,
           0.040824965,
           -0.09581359,
           -0.07878229,
           -0.041077204,
           0.06272204,
           -0.00967789,
           -0.039969984,
           0.026606442,
           -0.008397638,
           -0.12228345,
           -0.12788437,
           -0.079912744,
           -0.065497905,
           -0.06259471,
           -0.053227343,
           -0.04853832,
           0.10224529,
           -0.0096601285,
           0.012972651,
           -0.022289813,
           0.048890315,
           -0.021560343,
           0.1275523,
           -0.0006129926,
           0.022036515,
           -0.010614648,
           0.028922083,
           -0.0057758833,
           -0.12431924,
           -0.027199145,
           -0.014758179,
           -0.04671983,
           -0.05647078,
           -0.058168374,
           -0.02052418,
           0.029816888,
           0.025332648,
           -0.020907398,
           -0.027008004,
           0.036466915,
           -0.018295351,
           -0.044935565,
           0.03638737,
           0.07068573,
           0.044964373,
           0.01938387,
           0.009649012,
           0.018912597,
           -0.046202622,
           -0.114112034,
           -0.04113176,
           0.05878389,
           0.04027298,
           -0.052876055,
           -0.0033192139,
           -0.05663613,
           -0.14325045,
           -0.05562958,
           0.02827824,
           -0.067417756,
           -0.10919916,
           0.04459097,
           0.070495516,
           0.018820217,
           0.016633218,
           0.009917463,
           -0.086362466,
           0.019543113,
           -0.07962481,
           -0.09921143,
           -0.05344706,
           0.11712665,
           -0.00946852,
           0.039594244,
           -0.15563841,
           -0.05432734,
           0.13890602,
           0.06599044,
           0.16471033,
           0.11191438,
           0.08912124,
           0.059166584,
           0.044556227,
           0.06550957,
           -0.05441794,
           -0.16097353,
           -0.04978333,
           -0.011988375,
           0.16434152,
           -0.1361697,
           0.030283218,
           0.020356612,
           0.0815668,
           -0.0023867807,
           -0.046519075,
           0.053864732,
           0.09111646,
           0.07028751,
           -0.039984092,
           0.0840054,
           0.08373641,
           0.012011526,
           0.0035174573,
           0.051529825,
           0.029204644,
           -0.1276224,
           0.0013725035,
           0.027491506,
           0.14975011,
           0.055362493,
           -0.039076928,
           -0.09751178,
           -0.06773767,
           0.0049689705,
           0.002726791,
           0.12050903,
           0.11024309
>>>>>>> Stashed changes
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(model.embed.W_E)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 18,
=======
   "execution_count": 25,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding shape is torch.Size([11, 128]), so our vectors of length 128\n"
     ]
    }
   ],
   "source": [
    "# Take the dot product of all the embedding vectors\n",
    "emb = model.embed.W_E\n",
    "vec_count = emb.shape[0]\n",
    "vec_dim = emb.shape[1]\n",
    "print(f\"The embedding shape is {emb.shape}, so our vectors of length {emb.shape[1]}\")\n",
    "\n",
    "dot_products = einops.einsum(emb, emb, \"v2 embs, v1 emb -> v1 v2\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 19,
=======
   "execution_count": 26,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 11])\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
<<<<<<< Updated upstream
           0.031688277,
           -0.015521754,
           -0.29327112,
           -0.09646457,
           -0.0332596,
           -0.21164064,
           0.025786422,
           0.18120697,
           -0.12289112,
           0.035517912,
           -0.075020984
          ],
          [
           -0.015521754,
           0.0076029645,
           0.14365193,
           0.04725089,
           0.016291428,
           0.10366717,
           -0.01263087,
           -0.08875996,
           0.060195312,
           -0.01739761,
           0.03674726
          ],
          [
           -0.29327112,
           0.14365193,
           2.7141883,
           0.8927678,
           0.30781353,
           1.9587083,
           -0.23865019,
           -1.6770484,
           1.1373423,
           -0.32871395,
           0.69431007
          ],
          [
           -0.09646457,
           0.04725089,
           0.8927678,
           0.29365474,
           0.101247944,
           0.64427054,
           -0.078498304,
           -0.55162525,
           0.37410173,
           -0.10812264,
           0.22837679
          ],
          [
           -0.0332596,
           0.016291428,
           0.30781353,
           0.101247944,
           0.03490884,
           0.22213525,
           -0.02706509,
           -0.19019246,
           0.12898491,
           -0.037279136,
           0.078741044
          ],
          [
           -0.21164064,
           0.10366717,
           1.9587083,
           0.64427054,
           0.22213525,
           1.4135121,
           -0.17222315,
           -1.2102507,
           0.8207691,
           -0.23721814,
           0.5010525
          ],
          [
           0.025786422,
           -0.01263087,
           -0.23865019,
           -0.078498304,
           -0.02706509,
           -0.17222315,
           0.020983772,
           0.14745767,
           -0.10000299,
           0.028902799,
           -0.061048534
          ],
          [
           0.18120697,
           -0.08875996,
           -1.6770484,
           -0.55162525,
           -0.19019246,
           -1.2102507,
           0.14745767,
           1.0362182,
           -0.7027435,
           0.20310646,
           -0.42900175
          ],
          [
           -0.12289112,
           0.060195312,
           1.1373423,
           0.37410173,
           0.12898491,
           0.8207691,
           -0.10000299,
           -0.7027435,
           0.47658724,
           -0.13774294,
           0.29094082
          ],
          [
           0.035517912,
           -0.01739761,
           -0.32871395,
           -0.10812264,
           -0.037279136,
           -0.23721814,
           0.028902799,
           0.20310646,
           -0.13774294,
           0.039810374,
           -0.08408753
          ],
          [
           -0.075020984,
           0.03674726,
           0.69431007,
           0.22837679,
           0.078741044,
           0.5010525,
           -0.061048534,
           -0.42900175,
           0.29094082,
           -0.08408753,
           0.1776098
=======
           0.050585683,
           -0.018719796,
           -0.36611527,
           -0.12450469,
           -0.036944978,
           -0.2741793,
           0.032348163,
           0.22419687,
           -0.16125798,
           0.0424354,
           -0.09657122
          ],
          [
           -0.018719796,
           0.0069274693,
           0.13548504,
           0.04607435,
           0.0136719,
           0.10146311,
           -0.0119707985,
           -0.08296655,
           0.059675317,
           -0.015703693,
           0.035737257
          ],
          [
           -0.36611527,
           0.13548504,
           2.6497693,
           0.9011061,
           0.26739028,
           1.9843802,
           -0.23412071,
           -1.622631,
           1.1671091,
           -0.3071274,
           0.6989369
          ],
          [
           -0.12450469,
           0.04607435,
           0.9011061,
           0.30643886,
           0.09093132,
           0.6748275,
           -0.07961735,
           -0.5518075,
           0.3968984,
           -0.104444705,
           0.23768722
          ],
          [
           -0.036944978,
           0.0136719,
           0.26739028,
           0.09093132,
           0.02698256,
           0.20024535,
           -0.023625303,
           -0.16374095,
           0.11777389,
           -0.030992463,
           0.070530266
          ],
          [
           -0.2741793,
           0.10146311,
           1.9843802,
           0.6748275,
           0.20024535,
           1.4860784,
           -0.17533018,
           -1.2151687,
           0.8740339,
           -0.23000398,
           0.5234254
          ],
          [
           0.032348163,
           -0.0119707985,
           -0.23412071,
           -0.07961735,
           -0.023625303,
           -0.17533018,
           0.020685766,
           0.14336777,
           -0.10312008,
           0.02713628,
           -0.06175466
          ],
          [
           0.22419687,
           -0.08296655,
           -1.622631,
           -0.5518075,
           -0.16374095,
           -1.2151687,
           0.14336777,
           0.9936454,
           -0.714699,
           0.18807463,
           -0.42800578
          ],
          [
           -0.16125798,
           0.059675317,
           1.1671091,
           0.3968984,
           0.11777389,
           0.8740339,
           -0.10312008,
           -0.714699,
           0.5140612,
           -0.13527636,
           0.30785155
          ],
          [
           0.0424354,
           -0.015703693,
           -0.3071274,
           -0.104444705,
           -0.030992463,
           -0.23000398,
           0.02713628,
           0.18807463,
           -0.13527636,
           0.035598278,
           -0.081011824
          ],
          [
           -0.09657122,
           0.035737257,
           0.6989369,
           0.23768722,
           0.070530266,
           0.5234254,
           -0.06175466,
           -0.42800578,
           0.30785155,
           -0.081011824,
           0.18436047
>>>>>>> Stashed changes
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0,
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dot_products.shape)\n",
    "imshow_div(dot_products)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What would your hypothesis around the attention head activations be based on seeing this?\n",
    "+ Jack - My poorly informed guess is that tokens with low dot products and/or low norms won't have any strong attentional interaction\n",
    "+ Omar - I think that corner moves [0, 2, 6, 8] will have similar attention patterns\n",
    "+ Ari - I think same as Omar, plus center attends to everything, middle edges have attention symmetry too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformer_lens.ActivationCache.ActivationCache'>\n",
      "torch.Size([8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-0abd3acf-0642\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-0abd3acf-0642\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"10\", \"0\", \"2\"], \"attention\": [[[1.0, 0.0, 0.0], [0.5240195989608765, 0.47598040103912354, 0.0], [0.2810288667678833, 0.26403579115867615, 0.45493537187576294]], [[1.0, 0.0, 0.0], [0.4234985113143921, 0.5765015482902527, 0.0], [0.3256113529205322, 0.37678006291389465, 0.2976085841655731]], [[1.0, 0.0, 0.0], [0.4763963520526886, 0.5236036777496338, 0.0], [0.30136385560035706, 0.3840942680835724, 0.31454184651374817]], [[1.0, 0.0, 0.0], [0.5770627856254578, 0.422937273979187, 0.0], [0.4069257080554962, 0.32499608397483826, 0.2680782377719879]], [[1.0, 0.0, 0.0], [0.6146308779716492, 0.38536906242370605, 0.0], [0.20430782437324524, 0.191360741853714, 0.6043314933776855]], [[1.0, 0.0, 0.0], [0.4553534984588623, 0.5446465015411377, 0.0], [0.3150535225868225, 0.33740007877349854, 0.34754639863967896]], [[1.0, 0.0, 0.0], [0.46721452474594116, 0.5327854752540588, 0.0], [0.2579633295536041, 0.30932262539863586, 0.4327141046524048]], [[1.0, 0.0, 0.0], [0.5332695841789246, 0.46673038601875305, 0.0], [0.3559171259403229, 0.31818950176239014, 0.325893372297287]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fbcdca56c80>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [10,0,2]\n",
    "# tokens = ([10] * 5) + [1,2,5,8,7]\n",
    "str_tokens = [str(token) for token in tokens]\n",
    "logits, cache = model.run_with_cache(torch.tensor(tokens).to('cuda'), remove_batch_dim=True)\n",
    "\n",
    "print(type(cache))\n",
    "attention_pattern = cache[\"pattern\", 3, \"attn\"]\n",
    "print(attention_pattern.shape)\n",
    "cv.attention.attention_patterns(tokens=str_tokens, attention=attention_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
