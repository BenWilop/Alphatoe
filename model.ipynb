{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import tqdm\n",
    "#functional\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = HookedTransformerConfig(\n",
    "    n_layers = 1,\n",
    "    n_heads = 4,\n",
    "    d_model = 128,\n",
    "    d_head = 32,\n",
    "    d_mlp = 512,\n",
    "    act_fn = \"relu\",\n",
    "    normalization_type=None,\n",
    "    d_vocab=11,\n",
    "    d_vocab_out=10,\n",
    "    n_ctx=10,\n",
    "    init_weights=True,\n",
    "    device=\"cuda\",\n",
    "    seed = 999,\n",
    ")\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "test_train_split = 0.8\n",
    "epochs = 100\n",
    "batch_size = 4096\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np_data = np.load('data/moves.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46080, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46080\n",
      "46080\n",
      "[10  0  1  2  3  4  6  5  8  7]\n",
      "[0 1 2 3 4 6 5 8 7 9]\n"
     ]
    }
   ],
   "source": [
    "#load npy file\n",
    "np_data = np.load('data/moves.npy')\n",
    "data = np_data[:, :-1]\n",
    "labels = np_data[:, 1:]\n",
    "\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "print(data[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]]])\n",
      "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "encoded_labels = F.one_hot(t.tensor(labels))\n",
    "print(encoded_labels)\n",
    "print(t.sum(encoded_labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "encoded_data = F.one_hot(t.tensor(data))\n",
    "print(encoded_data[1238])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_labels[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data and labels as numpy arrays\n",
    "data = np.array(data)\n",
    "encoded_labels = np.array(encoded_labels)\n",
    "#data and encoded_labels as tensors\n",
    "data = t.from_numpy(data)\n",
    "encoded_labels = t.from_numpy(encoded_labels).to(t.float)\n",
    "total_data = list(zip(data, encoded_labels))\n",
    "split_data = list(t.utils.data.random_split(total_data, [.8, .2]))\n",
    "train_pairs = split_data[0]\n",
    "test_pairs= split_data[1]\n",
    "train_data, train_labels = zip(*train_pairs)\n",
    "test_data, test_labels = zip(*test_pairs)\n",
    "\n",
    "train_data = t.stack(train_data).to(cfg.device)\n",
    "train_labels = t.stack(train_labels).to(cfg.device)\n",
    "test_data = t.stack(test_data).to(cfg.device)\n",
    "test_labels = t.stack(test_labels).to(cfg.device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test train split\n",
    "train_data = data[:int(len(data)*test_train_split)]\n",
    "train_labels = encoded_labels[:int(len(data)*test_train_split)]\n",
    "test_data = data[int(len(data)*test_train_split):]\n",
    "test_labels = encoded_labels[int(len(data)*test_train_split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9216\n",
      "9216\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits, labels):\n",
    "    return t.nn.functional.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3133)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten = t.tensor([0,1]).to(t.float)\n",
    "loss_fn(ten, ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:00<00:23,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: 2.3084352016448975 | Test Loss: 2.2736759185791016\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 0 | Train Loss: 2.273963451385498 | Test Loss: 2.240736246109009\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 0 | Train Loss: 2.2392828464508057 | Test Loss: 2.2084593772888184\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 0 | Train Loss: 2.208704710006714 | Test Loss: 2.175663948059082\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 0 | Train Loss: 2.1750845909118652 | Test Loss: 2.1416101455688477\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 0 | Train Loss: 2.141380786895752 | Test Loss: 2.1062185764312744\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 0 | Train Loss: 2.105660915374756 | Test Loss: 2.0700032711029053\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 0 | Train Loss: 2.0699117183685303 | Test Loss: 2.0341427326202393\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 0 | Train Loss: 2.0336382389068604 | Test Loss: 2.000300884246826\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 1 | Train Loss: 1.9985243082046509 | Test Loss: 1.9699444770812988\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 1 | Train Loss: 1.9683483839035034 | Test Loss: 1.9435619115829468\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 1 | Train Loss: 1.9422340393066406 | Test Loss: 1.9204654693603516\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 1 | Train Loss: 1.919944167137146 | Test Loss: 1.899461269378662\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 1 | Train Loss: 1.8977537155151367 | Test Loss: 1.8796216249465942\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 1 | Train Loss: 1.8797876834869385 | Test Loss: 1.8607016801834106\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 1 | Train Loss: 1.8593473434448242 | Test Loss: 1.8429228067398071\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 1 | Train Loss: 1.8421989679336548 | Test Loss: 1.8262676000595093\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 1 | Train Loss: 1.8246986865997314 | Test Loss: 1.8103516101837158\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:00<00:17,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.8069508075714111 | Test Loss: 1.7944214344024658\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 2 | Train Loss: 1.7912724018096924 | Test Loss: 1.7777135372161865\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 2 | Train Loss: 1.7776060104370117 | Test Loss: 1.7598670721054077\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 2 | Train Loss: 1.7593739032745361 | Test Loss: 1.7408891916275024\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 2 | Train Loss: 1.7397760152816772 | Test Loss: 1.7208720445632935\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 2 | Train Loss: 1.7226158380508423 | Test Loss: 1.6999338865280151\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 2 | Train Loss: 1.700068712234497 | Test Loss: 1.678348183631897\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 2 | Train Loss: 1.6779263019561768 | Test Loss: 1.6563060283660889\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 2 | Train Loss: 1.6546392440795898 | Test Loss: 1.6338738203048706\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 3 | Train Loss: 1.6314586400985718 | Test Loss: 1.6104310750961304\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 3 | Train Loss: 1.6077280044555664 | Test Loss: 1.5857306718826294\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 3 | Train Loss: 1.5874406099319458 | Test Loss: 1.5598822832107544\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 3 | Train Loss: 1.5616399049758911 | Test Loss: 1.5324220657348633\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 3 | Train Loss: 1.5305695533752441 | Test Loss: 1.5027897357940674\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 3 | Train Loss: 1.5043131113052368 | Test Loss: 1.4720567464828491\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 3 | Train Loss: 1.471551775932312 | Test Loss: 1.4392772912979126\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 3 | Train Loss: 1.4403736591339111 | Test Loss: 1.4036228656768799\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 3 | Train Loss: 1.403818964958191 | Test Loss: 1.365966558456421\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 4 | Train Loss: 1.36447274684906 | Test Loss: 1.325711727142334\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:00<00:12,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 1.3245958089828491 | Test Loss: 1.2817693948745728\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 4 | Train Loss: 1.2843353748321533 | Test Loss: 1.2342296838760376\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 4 | Train Loss: 1.2352865934371948 | Test Loss: 1.183946967124939\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 4 | Train Loss: 1.1810743808746338 | Test Loss: 1.1307432651519775\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 4 | Train Loss: 1.1320003271102905 | Test Loss: 1.074152946472168\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 4 | Train Loss: 1.0730904340744019 | Test Loss: 1.0154024362564087\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 4 | Train Loss: 1.018262505531311 | Test Loss: 0.9551762342453003\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 4 | Train Loss: 0.9538663029670715 | Test Loss: 0.8927038908004761\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 5 | Train Loss: 0.8909425735473633 | Test Loss: 0.8292928338050842\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 5 | Train Loss: 0.8292223215103149 | Test Loss: 0.7668195366859436\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 5 | Train Loss: 0.7695200443267822 | Test Loss: 0.704833447933197\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 5 | Train Loss: 0.7044113874435425 | Test Loss: 0.6438491344451904\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 5 | Train Loss: 0.6432368159294128 | Test Loss: 0.5841413736343384\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 5 | Train Loss: 0.5847768187522888 | Test Loss: 0.5259396433830261\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 5 | Train Loss: 0.52294921875 | Test Loss: 0.47054147720336914\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 5 | Train Loss: 0.47340402007102966 | Test Loss: 0.4176543354988098\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 5 | Train Loss: 0.4161096513271332 | Test Loss: 0.36870911717414856\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 6 | Train Loss: 0.36751481890678406 | Test Loss: 0.32365313172340393\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 6 | Train Loss: 0.3240126669406891 | Test Loss: 0.28267934918403625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:01<00:11,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 6 | Train Loss: 0.28439071774482727 | Test Loss: 0.24554821848869324\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 6 | Train Loss: 0.24469926953315735 | Test Loss: 0.21203462779521942\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 6 | Train Loss: 0.21331261098384857 | Test Loss: 0.18206001818180084\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 6 | Train Loss: 0.183105930685997 | Test Loss: 0.15541744232177734\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 6 | Train Loss: 0.1545868217945099 | Test Loss: 0.13199186325073242\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 6 | Train Loss: 0.13250701129436493 | Test Loss: 0.11166907846927643\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 6 | Train Loss: 0.11106842011213303 | Test Loss: 0.0941723957657814\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 7 | Train Loss: 0.09355290979146957 | Test Loss: 0.0792088508605957\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 7 | Train Loss: 0.07924937456846237 | Test Loss: 0.06646102666854858\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 7 | Train Loss: 0.06624680012464523 | Test Loss: 0.05559037625789642\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 7 | Train Loss: 0.05512538552284241 | Test Loss: 0.046378862112760544\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 7 | Train Loss: 0.04632292315363884 | Test Loss: 0.03873471915721893\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 7 | Train Loss: 0.038672346621751785 | Test Loss: 0.03249663859605789\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 7 | Train Loss: 0.03220553323626518 | Test Loss: 0.027437973767518997\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 7 | Train Loss: 0.027563929557800293 | Test Loss: 0.02333899401128292\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 7 | Train Loss: 0.023257195949554443 | Test Loss: 0.02000599168241024\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 8 | Train Loss: 0.019921382889151573 | Test Loss: 0.017278600484132767\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 8 | Train Loss: 0.017322737723588943 | Test Loss: 0.015015830285847187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:01<00:10,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 8 | Train Loss: 0.01495665218681097 | Test Loss: 0.013112249784171581\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 8 | Train Loss: 0.013069182634353638 | Test Loss: 0.011510593816637993\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 8 | Train Loss: 0.011537162587046623 | Test Loss: 0.010174412280321121\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 8 | Train Loss: 0.01019543968141079 | Test Loss: 0.00906230229884386\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 8 | Train Loss: 0.00900044571608305 | Test Loss: 0.008131269365549088\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 8 | Train Loss: 0.008198382332921028 | Test Loss: 0.007344519719481468\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 8 | Train Loss: 0.007381947245448828 | Test Loss: 0.006669801194220781\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 9 | Train Loss: 0.006699488963931799 | Test Loss: 0.006087800022214651\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 9 | Train Loss: 0.006165312137454748 | Test Loss: 0.005580593831837177\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 9 | Train Loss: 0.005537285003811121 | Test Loss: 0.005137814208865166\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 9 | Train Loss: 0.00512426532804966 | Test Loss: 0.004750402178615332\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 9 | Train Loss: 0.004782806616276503 | Test Loss: 0.004410800989717245\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 9 | Train Loss: 0.0044592032209038734 | Test Loss: 0.0041115921922028065\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 9 | Train Loss: 0.004094273783266544 | Test Loss: 0.003846497740596533\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 9 | Train Loss: 0.003892547218129039 | Test Loss: 0.00360952434130013\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 9 | Train Loss: 0.003610992105677724 | Test Loss: 0.003397056134417653\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 10 | Train Loss: 0.0034344331361353397 | Test Loss: 0.00320589542388916\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 10 | Train Loss: 0.003253193339332938 | Test Loss: 0.0030336605850607157\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:01<00:09,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.0030006305314600468 | Test Loss: 0.0028788228519260883\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 10 | Train Loss: 0.0028704048600047827 | Test Loss: 0.0027390741743147373\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 10 | Train Loss: 0.002744479803368449 | Test Loss: 0.0026123085990548134\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 10 | Train Loss: 0.0026314964052289724 | Test Loss: 0.0024969237856566906\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 10 | Train Loss: 0.0024803050328046083 | Test Loss: 0.0023913532495498657\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 10 | Train Loss: 0.002416779287159443 | Test Loss: 0.0022943324875086546\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 10 | Train Loss: 0.0022892148699611425 | Test Loss: 0.002204922726377845\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 11 | Train Loss: 0.002231179503723979 | Test Loss: 0.002122384263202548\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 11 | Train Loss: 0.002147190272808075 | Test Loss: 0.002046284032985568\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 11 | Train Loss: 0.002023068955168128 | Test Loss: 0.001976410625502467\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 11 | Train Loss: 0.0019715004600584507 | Test Loss: 0.0019119293428957462\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 11 | Train Loss: 0.0019115392351523042 | Test Loss: 0.0018525263294577599\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 11 | Train Loss: 0.0018627578392624855 | Test Loss: 0.0017974658403545618\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 11 | Train Loss: 0.0017801908543333411 | Test Loss: 0.0017463469412177801\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 11 | Train Loss: 0.0017646715277805924 | Test Loss: 0.0016986876726150513\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 11 | Train Loss: 0.0016938867047429085 | Test Loss: 0.0016541867516934872\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 12 | Train Loss: 0.0016707767499610782 | Test Loss: 0.0016125318361446261\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 12 | Train Loss: 0.001629963400773704 | Test Loss: 0.0015734763583168387\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 12 | Train Loss: 0.0015582945197820663 | Test Loss: 0.0015367845771834254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:01<00:09,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 12 | Train Loss: 0.0015299328370019794 | Test Loss: 0.0015022450825199485\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 12 | Train Loss: 0.0015029434580355883 | Test Loss: 0.0014696783619001508\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 12 | Train Loss: 0.0014743052888661623 | Test Loss: 0.0014389054849743843\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 12 | Train Loss: 0.0014212819514796138 | Test Loss: 0.0014097988605499268\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 12 | Train Loss: 0.001421986031346023 | Test Loss: 0.0013821171596646309\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 12 | Train Loss: 0.0013768937205895782 | Test Loss: 0.0013556859921664\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 13 | Train Loss: 0.0013662626734003425 | Test Loss: 0.0013304516905918717\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 13 | Train Loss: 0.001344961696304381 | Test Loss: 0.001306217978708446\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 13 | Train Loss: 0.0012926673516631126 | Test Loss: 0.0012830274645239115\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 13 | Train Loss: 0.0012760859681293368 | Test Loss: 0.0012608130928128958\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 13 | Train Loss: 0.001261616707779467 | Test Loss: 0.0012395275989547372\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 13 | Train Loss: 0.0012428265763446689 | Test Loss: 0.0012191474670544267\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 13 | Train Loss: 0.001204154803417623 | Test Loss: 0.0011996168177574873\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 13 | Train Loss: 0.001208694651722908 | Test Loss: 0.0011808404233306646\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 13 | Train Loss: 0.0011751361889764667 | Test Loss: 0.0011627513449639082\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 14 | Train Loss: 0.0011716209119185805 | Test Loss: 0.0011453138431534171\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 14 | Train Loss: 0.0011571007780730724 | Test Loss: 0.001128444797359407\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 14 | Train Loss: 0.0011162266600877047 | Test Loss: 0.001112152705900371\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:01<00:08,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.0011059970129281282 | Test Loss: 0.0010963947279378772\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 14 | Train Loss: 0.0010968162678182125 | Test Loss: 0.0010811446700245142\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 14 | Train Loss: 0.0010844928910955787 | Test Loss: 0.0010663748253136873\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 14 | Train Loss: 0.0010539146605879068 | Test Loss: 0.0010520765790715814\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 14 | Train Loss: 0.0010592114413157105 | Test Loss: 0.0010382080217823386\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 14 | Train Loss: 0.0010321036679670215 | Test Loss: 0.0010247245663776994\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 15 | Train Loss: 0.0010318675776943564 | Test Loss: 0.0010116114281117916\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 15 | Train Loss: 0.001021192641928792 | Test Loss: 0.000998818431980908\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 15 | Train Loss: 0.0009872557129710913 | Test Loss: 0.0009863822488114238\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 15 | Train Loss: 0.0009805583395063877 | Test Loss: 0.0009742511319927871\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 15 | Train Loss: 0.0009740235400386155 | Test Loss: 0.0009624238009564579\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 15 | Train Loss: 0.0009651514701545238 | Test Loss: 0.0009508921066299081\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 15 | Train Loss: 0.000939772289711982 | Test Loss: 0.0009396477835252881\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 15 | Train Loss: 0.0009451880468986928 | Test Loss: 0.0009286631247960031\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 15 | Train Loss: 0.000922242586966604 | Test Loss: 0.0009179136250168085\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 16 | Train Loss: 0.0009234159369952977 | Test Loss: 0.0009073922992683947\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 16 | Train Loss: 0.0009152671555057168 | Test Loss: 0.0008970722556114197\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 16 | Train Loss: 0.0008866828866302967 | Test Loss: 0.0008869885932654142\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 16 | Train Loss: 0.0008814007160253823 | Test Loss: 0.0008771080174483359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:02<00:08,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 16 | Train Loss: 0.0008765258244238794 | Test Loss: 0.0008674345444887877\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 16 | Train Loss: 0.0008699538302607834 | Test Loss: 0.0008579607820138335\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 16 | Train Loss: 0.0008478660020045936 | Test Loss: 0.0008486898732371628\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 16 | Train Loss: 0.0008530504419468343 | Test Loss: 0.0008395991753786802\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 16 | Train Loss: 0.000833039463032037 | Test Loss: 0.000830679084174335\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 17 | Train Loss: 0.0008348426781594753 | Test Loss: 0.0008219202281907201\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 17 | Train Loss: 0.0008285019430331886 | Test Loss: 0.0008133039227686822\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 17 | Train Loss: 0.0008040143293328583 | Test Loss: 0.0008048487943597138\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 17 | Train Loss: 0.000799488858319819 | Test Loss: 0.0007965403492562473\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 17 | Train Loss: 0.0007957215420901775 | Test Loss: 0.0007883796351961792\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 17 | Train Loss: 0.0007905876263976097 | Test Loss: 0.0007803647313266993\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 17 | Train Loss: 0.0007710931240580976 | Test Loss: 0.0007724981405772269\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 17 | Train Loss: 0.0007758355350233614 | Test Loss: 0.0007647696766071022\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 17 | Train Loss: 0.0007582834805361927 | Test Loss: 0.0007571625174023211\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 18 | Train Loss: 0.0007602172554470599 | Test Loss: 0.0007496777689084411\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 18 | Train Loss: 0.0007553304894827306 | Test Loss: 0.000742296630050987\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 18 | Train Loss: 0.0007336583803407848 | Test Loss: 0.0007350377272814512\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 18 | Train Loss: 0.0007299624267034233 | Test Loss: 0.0007278901757672429\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:02<00:08,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.0007269373745657504 | Test Loss: 0.0007208569440990686\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 18 | Train Loss: 0.0007226932211779058 | Test Loss: 0.0007139347726479173\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 18 | Train Loss: 0.0007053997251205146 | Test Loss: 0.0007071328582242131\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 18 | Train Loss: 0.0007097379420883954 | Test Loss: 0.0007004409562796354\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 18 | Train Loss: 0.0006940902676433325 | Test Loss: 0.0006938449223525822\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 19 | Train Loss: 0.0006961089675314724 | Test Loss: 0.0006873475504107773\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 19 | Train Loss: 0.0006922621396370232 | Test Loss: 0.0006809307378716767\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 19 | Train Loss: 0.0006727981963194907 | Test Loss: 0.0006746126455254853\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 19 | Train Loss: 0.0006698374054394662 | Test Loss: 0.0006683838437311351\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 19 | Train Loss: 0.0006673514726571739 | Test Loss: 0.0006622452638112009\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 19 | Train Loss: 0.0006638322374783456 | Test Loss: 0.000656198535580188\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 19 | Train Loss: 0.0006483252509497106 | Test Loss: 0.0006502473843283951\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 19 | Train Loss: 0.0006523348274640739 | Test Loss: 0.0006443848833441734\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 19 | Train Loss: 0.0006381995044648647 | Test Loss: 0.0006386027671396732\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 20 | Train Loss: 0.0006403140141628683 | Test Loss: 0.000632899405900389\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 20 | Train Loss: 0.0006371845374815166 | Test Loss: 0.000627262401394546\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 20 | Train Loss: 0.0006196028552949429 | Test Loss: 0.0006217086920514703\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 20 | Train Loss: 0.0006172099383547902 | Test Loss: 0.0006162275094538927\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 20 | Train Loss: 0.000615137571003288 | Test Loss: 0.0006108207744546235\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:02<00:07,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.0006122149643488228 | Test Loss: 0.0006054897094145417\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 20 | Train Loss: 0.0005981785361655056 | Test Loss: 0.0006002396694384515\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 20 | Train Loss: 0.0006019125576131046 | Test Loss: 0.0005950640770606697\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 20 | Train Loss: 0.0005890667089261115 | Test Loss: 0.0005899541429243982\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 21 | Train Loss: 0.0005912298802286386 | Test Loss: 0.0005849101580679417\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 21 | Train Loss: 0.0005886591388843954 | Test Loss: 0.0005799201899208128\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 21 | Train Loss: 0.0005727158859372139 | Test Loss: 0.000574999488890171\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 21 | Train Loss: 0.0005707491072826087 | Test Loss: 0.0005701389745809138\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 21 | Train Loss: 0.0005690159159712493 | Test Loss: 0.0005653409752994776\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 21 | Train Loss: 0.0005665717180818319 | Test Loss: 0.0005606088670901954\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 21 | Train Loss: 0.0005537730176001787 | Test Loss: 0.0005559434066526592\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 21 | Train Loss: 0.0005572878872044384 | Test Loss: 0.0005513403448276222\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 21 | Train Loss: 0.0005455337814055383 | Test Loss: 0.0005467939772643149\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 22 | Train Loss: 0.0005477195954881608 | Test Loss: 0.0005423040129244328\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 22 | Train Loss: 0.0005456053768284619 | Test Loss: 0.0005378597998060286\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 22 | Train Loss: 0.0005310971173457801 | Test Loss: 0.000533475773409009\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 22 | Train Loss: 0.0005294586881063879 | Test Loss: 0.0005291423294693232\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 22 | Train Loss: 0.0005279974429868162 | Test Loss: 0.0005248631350696087\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 22 | Train Loss: 0.0005259705940261483 | Test Loss: 0.0005206360365264118\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:02<00:07,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.0005142183508723974 | Test Loss: 0.0005164692993275821\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 22 | Train Loss: 0.0005175494006834924 | Test Loss: 0.0005123558221384883\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 22 | Train Loss: 0.0005067494348622859 | Test Loss: 0.0005082899006083608\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 23 | Train Loss: 0.0005089270998723805 | Test Loss: 0.0005042724660597742\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 23 | Train Loss: 0.0005071978084743023 | Test Loss: 0.0005002944963052869\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 23 | Train Loss: 0.0004939380451105535 | Test Loss: 0.0004963678075000644\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 23 | Train Loss: 0.0004925690009258687 | Test Loss: 0.0004924843087792397\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 23 | Train Loss: 0.0004913230077363551 | Test Loss: 0.0004886460956186056\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 23 | Train Loss: 0.0004896493046544492 | Test Loss: 0.0004848547396250069\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 23 | Train Loss: 0.00047882497892715037 | Test Loss: 0.00048111265641637146\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 23 | Train Loss: 0.0004819716268684715 | Test Loss: 0.0004774181579705328\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 23 | Train Loss: 0.00047201942652463913 | Test Loss: 0.0004737648705486208\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 24 | Train Loss: 0.0004741684242617339 | Test Loss: 0.0004701522702816874\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 24 | Train Loss: 0.0004727619234472513 | Test Loss: 0.00046657375060021877\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 24 | Train Loss: 0.0004605833091773093 | Test Loss: 0.00046303862472996116\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 24 | Train Loss: 0.00045945323654450476 | Test Loss: 0.0004595417995005846\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 24 | Train Loss: 0.0004583829140756279 | Test Loss: 0.0004560826637316495\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 24 | Train Loss: 0.0004569954180624336 | Test Loss: 0.0004526645934674889\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 24 | Train Loss: 0.0004469985142350197 | Test Loss: 0.0004492898005992174\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [00:02<00:07,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.0004499717615544796 | Test Loss: 0.0004459555202629417\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 24 | Train Loss: 0.0004407646774780005 | Test Loss: 0.00044265625183470547\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 25 | Train Loss: 0.0004428655083756894 | Test Loss: 0.0004393937415443361\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 25 | Train Loss: 0.0004417352320160717 | Test Loss: 0.00043615998583845794\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 25 | Train Loss: 0.00043050586828030646 | Test Loss: 0.0004329652583692223\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 25 | Train Loss: 0.0004295862454455346 | Test Loss: 0.00042980347643606365\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 25 | Train Loss: 0.00042866237345151603 | Test Loss: 0.00042667464003898203\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 25 | Train Loss: 0.00042751329601742327 | Test Loss: 0.00042358183418400586\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 25 | Train Loss: 0.0004182510601822287 | Test Loss: 0.00042052665958181024\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 25 | Train Loss: 0.0004210633342154324 | Test Loss: 0.00041750766104087234\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 25 | Train Loss: 0.0004125235718674958 | Test Loss: 0.0004145197744946927\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 26 | Train Loss: 0.0004145648272242397 | Test Loss: 0.0004115645424462855\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 26 | Train Loss: 0.0004136749485041946 | Test Loss: 0.00040863361209630966\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 26 | Train Loss: 0.00040328968316316605 | Test Loss: 0.00040573603473603725\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 26 | Train Loss: 0.0004025503003504127 | Test Loss: 0.000402868288801983\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 26 | Train Loss: 0.000401749653974548 | Test Loss: 0.00040003046160563827\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 26 | Train Loss: 0.00040080954204313457 | Test Loss: 0.0003972233971580863\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 26 | Train Loss: 0.00039219894097186625 | Test Loss: 0.0003944485215470195\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 26 | Train Loss: 0.00039486493915319443 | Test Loss: 0.0003917055146303028\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:03<00:07, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.00038692637463100255 | Test Loss: 0.0003889914369210601\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 27 | Train Loss: 0.0003889006329700351 | Test Loss: 0.00038630329072475433\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 27 | Train Loss: 0.0003882085147779435 | Test Loss: 0.0003836383402813226\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 27 | Train Loss: 0.0003785824519582093 | Test Loss: 0.0003810024936683476\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 27 | Train Loss: 0.000377992371795699 | Test Loss: 0.00037839222932234406\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 27 | Train Loss: 0.00037729422911070287 | Test Loss: 0.00037580804200842977\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 27 | Train Loss: 0.00037653720937669277 | Test Loss: 0.00037325001903809607\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 27 | Train Loss: 0.0003685079573187977 | Test Loss: 0.00037072302075102925\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 27 | Train Loss: 0.0003710420278366655 | Test Loss: 0.00036822285619564354\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 27 | Train Loss: 0.0003636438923422247 | Test Loss: 0.00036574783734977245\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 28 | Train Loss: 0.0003655468754004687 | Test Loss: 0.00036329589784145355\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 28 | Train Loss: 0.000365022657206282 | Test Loss: 0.0003608663100749254\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 28 | Train Loss: 0.0003560792829375714 | Test Loss: 0.00035846096579916775\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 28 | Train Loss: 0.0003556146693881601 | Test Loss: 0.00035607750760391355\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 28 | Train Loss: 0.00035500150988809764 | Test Loss: 0.0003537186421453953\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 28 | Train Loss: 0.0003544036881066859 | Test Loss: 0.0003513834672048688\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 28 | Train Loss: 0.00034690689062699676 | Test Loss: 0.0003490745148155838\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 28 | Train Loss: 0.00034931066329590976 | Test Loss: 0.00034679073723964393\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 28 | Train Loss: 0.00034240135573782027 | Test Loss: 0.00034452779800631106\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:03<00:06, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.0003442371671553701 | Test Loss: 0.0003422873269300908\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 29 | Train Loss: 0.00034385817707516253 | Test Loss: 0.00034006417263299227\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 29 | Train Loss: 0.0003355253138579428 | Test Loss: 0.0003378644469194114\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 29 | Train Loss: 0.0003351683262735605 | Test Loss: 0.00033568390063010156\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 29 | Train Loss: 0.00033463072031736374 | Test Loss: 0.00033352544414810836\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 29 | Train Loss: 0.0003341730625834316 | Test Loss: 0.00033138709841296077\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 29 | Train Loss: 0.0003271529858466238 | Test Loss: 0.00032927191932685673\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 29 | Train Loss: 0.0003294381021987647 | Test Loss: 0.0003271801397204399\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 29 | Train Loss: 0.0003229687863495201 | Test Loss: 0.0003251073358114809\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 30 | Train Loss: 0.0003247443528380245 | Test Loss: 0.000323052576277405\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 30 | Train Loss: 0.00032448588171973825 | Test Loss: 0.0003210146969649941\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 30 | Train Loss: 0.0003167064278386533 | Test Loss: 0.00031899652094580233\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 30 | Train Loss: 0.0003164412046317011 | Test Loss: 0.000316995574394241\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 30 | Train Loss: 0.00031597065390087664 | Test Loss: 0.0003150151460431516\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 30 | Train Loss: 0.00031563034281134605 | Test Loss: 0.0003130514523945749\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 30 | Train Loss: 0.0003090424870606512 | Test Loss: 0.0003111094410996884\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 30 | Train Loss: 0.000311220355797559 | Test Loss: 0.0003091866965405643\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 30 | Train Loss: 0.000305145513266325 | Test Loss: 0.00030728126876056194\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 31 | Train Loss: 0.00030686138779856265 | Test Loss: 0.0003053938562516123\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:03<00:06, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.00030670789419673383 | Test Loss: 0.00030351951136253774\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 31 | Train Loss: 0.00029943097615614533 | Test Loss: 0.00030166475335136056\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 31 | Train Loss: 0.0002992421796079725 | Test Loss: 0.00029982480918988585\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 31 | Train Loss: 0.000298829487292096 | Test Loss: 0.0002980018325615674\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 31 | Train Loss: 0.00029859039932489395 | Test Loss: 0.00029619582346640527\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 31 | Train Loss: 0.0002923977153841406 | Test Loss: 0.0002944083244074136\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 31 | Train Loss: 0.0002944757870864123 | Test Loss: 0.0002926386659964919\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 31 | Train Loss: 0.0002887587761506438 | Test Loss: 0.000290883966954425\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 32 | Train Loss: 0.00029041283414699137 | Test Loss: 0.00028914629365317523\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 32 | Train Loss: 0.00029035491752438247 | Test Loss: 0.0002874191268347204\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 32 | Train Loss: 0.00028353440575301647 | Test Loss: 0.00028570982976816595\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 32 | Train Loss: 0.00028340937569737434 | Test Loss: 0.00028401403687894344\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 32 | Train Loss: 0.0002830481098499149 | Test Loss: 0.0002823328541126102\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 32 | Train Loss: 0.00028289802139624953 | Test Loss: 0.00028066642698831856\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 32 | Train Loss: 0.0002770627324935049 | Test Loss: 0.00027901766588911414\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 32 | Train Loss: 0.0002790465659927577 | Test Loss: 0.00027738482458516955\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 32 | Train Loss: 0.00027365973801352084 | Test Loss: 0.0002757648180704564\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 33 | Train Loss: 0.00027525005862116814 | Test Loss: 0.0002741602365858853\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 33 | Train Loss: 0.00027527319616638124 | Test Loss: 0.00027256537578068674\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:03<00:06, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 0.0002688684908207506 | Test Loss: 0.000270987133262679\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 33 | Train Loss: 0.0002687988744582981 | Test Loss: 0.0002694188733585179\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 33 | Train Loss: 0.000268481089733541 | Test Loss: 0.0002678654855117202\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 33 | Train Loss: 0.0002684095816221088 | Test Loss: 0.0002663250779733062\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 33 | Train Loss: 0.00026290235109627247 | Test Loss: 0.0002648004738148302\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 33 | Train Loss: 0.00026479471125639975 | Test Loss: 0.00026328852982260287\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 33 | Train Loss: 0.00025970974820666015 | Test Loss: 0.0002617909631226212\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 34 | Train Loss: 0.000261240842519328 | Test Loss: 0.0002603042230475694\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 34 | Train Loss: 0.0002613300457596779 | Test Loss: 0.0002588277857284993\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 34 | Train Loss: 0.00025530598941259086 | Test Loss: 0.0002573648816905916\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 34 | Train Loss: 0.0002552811929490417 | Test Loss: 0.00025591347366571426\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 34 | Train Loss: 0.0002550030767451972 | Test Loss: 0.00025447324151173234\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 34 | Train Loss: 0.0002550007193349302 | Test Loss: 0.0002530452038627118\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 34 | Train Loss: 0.0002497919776942581 | Test Loss: 0.00025163282407447696\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 34 | Train Loss: 0.00025159685174003243 | Test Loss: 0.0002502312418073416\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 34 | Train Loss: 0.00024679224588908255 | Test Loss: 0.00024884127196855843\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 35 | Train Loss: 0.00024826268781907856 | Test Loss: 0.0002474650682415813\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 35 | Train Loss: 0.00024841123376972973 | Test Loss: 0.0002460935793351382\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 35 | Train Loss: 0.00024273568124044687 | Test Loss: 0.00024473803932778537\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [00:04<00:06, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 0.00024275291070807725 | Test Loss: 0.00024338958610314876\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 35 | Train Loss: 0.00024250498972833157 | Test Loss: 0.0002420533710392192\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 35 | Train Loss: 0.00024256657343357801 | Test Loss: 0.0002407285792287439\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 35 | Train Loss: 0.00023763281933497638 | Test Loss: 0.00023941477411426604\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 35 | Train Loss: 0.00023935400531627238 | Test Loss: 0.00023811367282178253\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 35 | Train Loss: 0.00023480775416828692 | Test Loss: 0.0002368225104874\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 36 | Train Loss: 0.00023621977015864104 | Test Loss: 0.00023554236395284534\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 36 | Train Loss: 0.00023641959705855697 | Test Loss: 0.00023426931875292212\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 36 | Train Loss: 0.00023106318258214742 | Test Loss: 0.00023300855536945164\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 36 | Train Loss: 0.00023111623886507004 | Test Loss: 0.00023175671231001616\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 36 | Train Loss: 0.0002308971743332222 | Test Loss: 0.00023051285825204104\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 36 | Train Loss: 0.00023101444821804762 | Test Loss: 0.00022928106773179024\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 36 | Train Loss: 0.00022633225307799876 | Test Loss: 0.0002280604821862653\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 36 | Train Loss: 0.00022797822020947933 | Test Loss: 0.00022684969007968903\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 36 | Train Loss: 0.00022367066412698478 | Test Loss: 0.00022564874961972237\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 37 | Train Loss: 0.00022502860520035028 | Test Loss: 0.00022445744252763689\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 37 | Train Loss: 0.00022527326655108482 | Test Loss: 0.0002232729602837935\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 37 | Train Loss: 0.00022020938922651112 | Test Loss: 0.00022209860617294908\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 37 | Train Loss: 0.00022029569663573056 | Test Loss: 0.00022093240113463253\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [00:04<00:06, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 0.00022009899839758873 | Test Loss: 0.00021977593132760376\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 37 | Train Loss: 0.00022026659280527383 | Test Loss: 0.00021862761059310287\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 37 | Train Loss: 0.0002158187417080626 | Test Loss: 0.00021749065490439534\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 37 | Train Loss: 0.00021739206567872316 | Test Loss: 0.00021636209567077458\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 37 | Train Loss: 0.00021330500021576881 | Test Loss: 0.00021524283511098474\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 38 | Train Loss: 0.0002146103943232447 | Test Loss: 0.00021413248032331467\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 38 | Train Loss: 0.00021489379287231714 | Test Loss: 0.00021302791719790548\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 38 | Train Loss: 0.00021009845659136772 | Test Loss: 0.00021193396241869777\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 38 | Train Loss: 0.00021021664724685252 | Test Loss: 0.000210845930268988\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 38 | Train Loss: 0.00021003866277169436 | Test Loss: 0.00020976750238332897\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 38 | Train Loss: 0.00021024789020884782 | Test Loss: 0.00020869693253189325\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 38 | Train Loss: 0.00020601809956133366 | Test Loss: 0.00020763478823937476\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 38 | Train Loss: 0.00020752455748151988 | Test Loss: 0.00020658204448409379\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 38 | Train Loss: 0.00020364070951472968 | Test Loss: 0.00020553726062644273\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 39 | Train Loss: 0.00020489601592998952 | Test Loss: 0.00020450068404898047\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 39 | Train Loss: 0.00020521145779639482 | Test Loss: 0.0002034688659477979\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 39 | Train Loss: 0.00020066443539690226 | Test Loss: 0.00020244697225280106\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 39 | Train Loss: 0.00020080832473468035 | Test Loss: 0.00020143174333497882\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 39 | Train Loss: 0.0002006496797548607 | Test Loss: 0.0002004244306590408\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:04<00:05, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 0.0002008949959417805 | Test Loss: 0.00019942277867812663\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 39 | Train Loss: 0.00019686520681716502 | Test Loss: 0.00019843106565531343\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 39 | Train Loss: 0.0001983086549444124 | Test Loss: 0.0001974473852897063\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 39 | Train Loss: 0.00019461437477730215 | Test Loss: 0.00019647052977234125\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 40 | Train Loss: 0.0001958219363586977 | Test Loss: 0.00019550180877558887\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 40 | Train Loss: 0.00019616562349256128 | Test Loss: 0.0001945381663972512\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 40 | Train Loss: 0.0001918507769005373 | Test Loss: 0.0001935816544573754\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 40 | Train Loss: 0.00019201547547709197 | Test Loss: 0.00019263121066614985\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 40 | Train Loss: 0.00019187215366400778 | Test Loss: 0.00019168961443938315\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 40 | Train Loss: 0.0001921486691571772 | Test Loss: 0.00019075347518082708\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 40 | Train Loss: 0.0001883086224552244 | Test Loss: 0.00018982386973220855\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 40 | Train Loss: 0.00018969064694829285 | Test Loss: 0.00018890376668423414\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 40 | Train Loss: 0.00018617328896652907 | Test Loss: 0.00018799040117301047\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 41 | Train Loss: 0.00018733693286776543 | Test Loss: 0.00018708292918745428\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 41 | Train Loss: 0.00018770295719150454 | Test Loss: 0.00018618015747051686\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 41 | Train Loss: 0.00018360180547460914 | Test Loss: 0.00018528524378780276\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 41 | Train Loss: 0.00018378642562311143 | Test Loss: 0.00018439591804053634\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 41 | Train Loss: 0.00018365579308010638 | Test Loss: 0.00018351356266066432\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 41 | Train Loss: 0.00018396099039819092 | Test Loss: 0.00018263686797581613\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [00:04<00:05, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 0.00018029606144409627 | Test Loss: 0.00018176586308982223\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 41 | Train Loss: 0.00018162162450607866 | Test Loss: 0.00018090291996486485\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 41 | Train Loss: 0.00017826646217145026 | Test Loss: 0.00018004585581365973\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 42 | Train Loss: 0.00017938976816367358 | Test Loss: 0.00017919573292601854\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 42 | Train Loss: 0.00017977350216824561 | Test Loss: 0.00017834831669460982\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 42 | Train Loss: 0.00017587305046617985 | Test Loss: 0.000177509049535729\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 42 | Train Loss: 0.0001760722225299105 | Test Loss: 0.00017667388601694256\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 42 | Train Loss: 0.0001759524893714115 | Test Loss: 0.00017584509623702615\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 42 | Train Loss: 0.0001762843457981944 | Test Loss: 0.00017502329137641937\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 42 | Train Loss: 0.0001727798953652382 | Test Loss: 0.00017420636140741408\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 42 | Train Loss: 0.0001740520674502477 | Test Loss: 0.0001733957906253636\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 42 | Train Loss: 0.00017084724095184356 | Test Loss: 0.00017259165178984404\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 43 | Train Loss: 0.0001719354186207056 | Test Loss: 0.0001717921404633671\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 43 | Train Loss: 0.00017233243852388114 | Test Loss: 0.00017099747492466122\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 43 | Train Loss: 0.0001686196046648547 | Test Loss: 0.00017020785890053958\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 43 | Train Loss: 0.00016882902127690613 | Test Loss: 0.00016942362708505243\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 43 | Train Loss: 0.000168720303918235 | Test Loss: 0.00016864614735823125\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 43 | Train Loss: 0.00016907589451875538 | Test Loss: 0.00016787307686172426\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 43 | Train Loss: 0.0001657224929658696 | Test Loss: 0.00016710523050278425\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [00:04<00:05, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 0.0001669423800194636 | Test Loss: 0.00016634375788271427\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 43 | Train Loss: 0.000163881471962668 | Test Loss: 0.00016558780043851584\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 44 | Train Loss: 0.00016493267321493477 | Test Loss: 0.0001648362958803773\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 44 | Train Loss: 0.00016534065071027726 | Test Loss: 0.000164088822202757\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 44 | Train Loss: 0.00016180168313439935 | Test Loss: 0.00016334715473931283\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 44 | Train Loss: 0.00016202402184717357 | Test Loss: 0.0001626095181563869\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 44 | Train Loss: 0.00016192346811294556 | Test Loss: 0.00016187669825740159\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 44 | Train Loss: 0.00016229737957473844 | Test Loss: 0.00016114956815727055\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 44 | Train Loss: 0.000159086353960447 | Test Loss: 0.00016042686183936894\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 44 | Train Loss: 0.0001602573465788737 | Test Loss: 0.00015971118409652263\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 44 | Train Loss: 0.0001573297195136547 | Test Loss: 0.00015899993013590574\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 45 | Train Loss: 0.0001583471748745069 | Test Loss: 0.00015829163021408021\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 45 | Train Loss: 0.0001587630104040727 | Test Loss: 0.0001575882633915171\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 45 | Train Loss: 0.00015538760635536164 | Test Loss: 0.00015688886924181134\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 45 | Train Loss: 0.00015561787586193532 | Test Loss: 0.00015619532496202737\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 45 | Train Loss: 0.00015552574768662453 | Test Loss: 0.00015550597163382918\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 45 | Train Loss: 0.00015591768897138536 | Test Loss: 0.00015482123126275837\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 45 | Train Loss: 0.00015284045366570354 | Test Loss: 0.00015414036170113832\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 45 | Train Loss: 0.0001539662916911766 | Test Loss: 0.00015346455620601773\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [00:05<00:05, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train Loss: 0.0001511610025772825 | Test Loss: 0.00015279350918717682\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 46 | Train Loss: 0.00015214412997011095 | Test Loss: 0.0001521272788522765\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 46 | Train Loss: 0.0001525672123534605 | Test Loss: 0.00015146573423407972\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 46 | Train Loss: 0.0001493461022619158 | Test Loss: 0.00015080568846315145\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 46 | Train Loss: 0.00014958408428356051 | Test Loss: 0.00015015233657322824\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 46 | Train Loss: 0.00014949885371606797 | Test Loss: 0.00014950173499528319\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 46 | Train Loss: 0.00014990533236414194 | Test Loss: 0.00014885535347275436\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 46 | Train Loss: 0.00014695267600473017 | Test Loss: 0.0001482136285630986\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 46 | Train Loss: 0.00014803466910962015 | Test Loss: 0.00014757690951228142\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 46 | Train Loss: 0.00014534764341078699 | Test Loss: 0.00014694393030367792\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 47 | Train Loss: 0.00014629762154072523 | Test Loss: 0.0001463154039811343\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 47 | Train Loss: 0.00014672607358079404 | Test Loss: 0.0001456890458939597\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 47 | Train Loss: 0.00014364736853167415 | Test Loss: 0.00014506820298265666\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 47 | Train Loss: 0.00014389299030881375 | Test Loss: 0.0001444509980501607\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 47 | Train Loss: 0.0001438125764252618 | Test Loss: 0.00014383731468115002\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 47 | Train Loss: 0.000144233024911955 | Test Loss: 0.0001432274584658444\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 47 | Train Loss: 0.00014139992708805948 | Test Loss: 0.00014262158947531134\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 47 | Train Loss: 0.0001424379152012989 | Test Loss: 0.00014201932935975492\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 47 | Train Loss: 0.00013986139674670994 | Test Loss: 0.00014142210420686752\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [00:05<00:05, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train Loss: 0.00014078017557039857 | Test Loss: 0.0001408280077157542\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 48 | Train Loss: 0.0001412131096003577 | Test Loss: 0.00014023727271705866\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 48 | Train Loss: 0.00013826890790369362 | Test Loss: 0.00013965163088869303\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 48 | Train Loss: 0.00013851988478563726 | Test Loss: 0.00013906776439398527\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 48 | Train Loss: 0.00013844401109963655 | Test Loss: 0.00013848849630448967\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 48 | Train Loss: 0.00013887621753383428 | Test Loss: 0.0001379100576741621\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 48 | Train Loss: 0.00013615343777928501 | Test Loss: 0.00013733841478824615\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 48 | Train Loss: 0.0001371507823932916 | Test Loss: 0.00013676990056410432\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 48 | Train Loss: 0.00013468049291986972 | Test Loss: 0.0001362042676191777\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 49 | Train Loss: 0.00013556711201090366 | Test Loss: 0.0001356429565930739\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 49 | Train Loss: 0.00013600305828731507 | Test Loss: 0.00013508470146916807\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 49 | Train Loss: 0.00013318582205101848 | Test Loss: 0.0001345299679087475\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 49 | Train Loss: 0.00013344014587346464 | Test Loss: 0.00013397762086242437\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 49 | Train Loss: 0.00013336745905689895 | Test Loss: 0.0001334285334451124\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 49 | Train Loss: 0.00013380871678236872 | Test Loss: 0.00013288292393554002\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 49 | Train Loss: 0.00013119295181240886 | Test Loss: 0.0001323416508967057\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 49 | Train Loss: 0.0001321496965829283 | Test Loss: 0.00013180285168346018\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 49 | Train Loss: 0.00012977882579434663 | Test Loss: 0.0001312684762524441\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 50 | Train Loss: 0.0001306368358200416 | Test Loss: 0.00013073766604065895\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [00:05<00:04, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 0.00013107476115692407 | Test Loss: 0.00013020822370890528\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 50 | Train Loss: 0.00012837453687097877 | Test Loss: 0.0001296837581321597\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 50 | Train Loss: 0.0001286332553718239 | Test Loss: 0.00012916013656649739\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 50 | Train Loss: 0.00012856331886723638 | Test Loss: 0.0001286409969907254\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 50 | Train Loss: 0.00012901343870908022 | Test Loss: 0.0001281247823499143\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 50 | Train Loss: 0.00012649704876821488 | Test Loss: 0.00012761114339809865\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 50 | Train Loss: 0.00012741559476125985 | Test Loss: 0.00012710184091702104\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 50 | Train Loss: 0.00012513926776591688 | Test Loss: 0.00012659543426707387\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 51 | Train Loss: 0.00012597048771567643 | Test Loss: 0.00012609342229552567\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 51 | Train Loss: 0.00012640864588320255 | Test Loss: 0.00012559049355331808\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 51 | Train Loss: 0.00012381850683595985 | Test Loss: 0.00012509194493759423\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 51 | Train Loss: 0.00012407859321683645 | Test Loss: 0.00012459710706025362\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 51 | Train Loss: 0.00012401220737956464 | Test Loss: 0.00012410548515617847\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 51 | Train Loss: 0.0001244702289113775 | Test Loss: 0.00012361507106106728\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 51 | Train Loss: 0.00012204735685372725 | Test Loss: 0.00012312867329455912\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 51 | Train Loss: 0.00012292983592487872 | Test Loss: 0.00012264474935363978\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 51 | Train Loss: 0.00012074138794559985 | Test Loss: 0.0001221651182277128\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 52 | Train Loss: 0.00012154674914199859 | Test Loss: 0.00012168702232884243\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 52 | Train Loss: 0.00012198216427350417 | Test Loss: 0.00012121120380470529\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [00:05<00:04, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Train Loss: 0.00011949681356782094 | Test Loss: 0.0001207390014315024\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 52 | Train Loss: 0.00011976076348219067 | Test Loss: 0.00012026978220092133\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 52 | Train Loss: 0.00011969770275754854 | Test Loss: 0.00011980222188867629\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 52 | Train Loss: 0.00012015898391837254 | Test Loss: 0.0001193382777273655\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 52 | Train Loss: 0.00011782727960962802 | Test Loss: 0.0001188764872495085\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 52 | Train Loss: 0.00011867550347233191 | Test Loss: 0.00011841714149340987\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 52 | Train Loss: 0.0001165701323770918 | Test Loss: 0.00011796138278441504\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 53 | Train Loss: 0.00011735122097888961 | Test Loss: 0.0001175073703052476\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 53 | Train Loss: 0.00011778403859352693 | Test Loss: 0.00011705717042787\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 53 | Train Loss: 0.00011539848492247984 | Test Loss: 0.0001166087095043622\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 53 | Train Loss: 0.00011566306056920439 | Test Loss: 0.00011616432311711833\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 53 | Train Loss: 0.00011560266284504905 | Test Loss: 0.00011571971117518842\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 53 | Train Loss: 0.00011606952466536313 | Test Loss: 0.00011527792958077043\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 53 | Train Loss: 0.0001138204024755396 | Test Loss: 0.00011483828711789101\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 53 | Train Loss: 0.00011463424016255885 | Test Loss: 0.00011440338130341843\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 53 | Train Loss: 0.00011260937753831968 | Test Loss: 0.0001139709129347466\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 54 | Train Loss: 0.00011336793977534398 | Test Loss: 0.00011354045273037627\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 54 | Train Loss: 0.00011379923671483994 | Test Loss: 0.00011311109847156331\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 54 | Train Loss: 0.00011150562204420567 | Test Loss: 0.00011268517118878663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:05<00:04, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 54 | Train Loss: 0.00011177094711456448 | Test Loss: 0.00011226056813029572\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 54 | Train Loss: 0.00011171018559252843 | Test Loss: 0.00011183899187017232\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 54 | Train Loss: 0.00011218040162930265 | Test Loss: 0.00011142040602862835\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 54 | Train Loss: 0.00011001319217029959 | Test Loss: 0.00011100315896328539\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 54 | Train Loss: 0.00011079587420681491 | Test Loss: 0.00011058854579459876\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 54 | Train Loss: 0.00010884607036132365 | Test Loss: 0.00011017635551979765\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 55 | Train Loss: 0.00010958052007481456 | Test Loss: 0.00010976599878631532\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 55 | Train Loss: 0.00011000865924870595 | Test Loss: 0.00010935879981843755\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 55 | Train Loss: 0.0001078032873920165 | Test Loss: 0.00010895412560785189\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 55 | Train Loss: 0.00010806975478772074 | Test Loss: 0.00010855080472538248\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 55 | Train Loss: 0.00010801017197081819 | Test Loss: 0.00010814861889230087\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 55 | Train Loss: 0.00010848297097254544 | Test Loss: 0.0001077490160241723\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 55 | Train Loss: 0.00010639042739057913 | Test Loss: 0.00010735450632637367\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 55 | Train Loss: 0.00010714545351220295 | Test Loss: 0.00010695827222662047\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 55 | Train Loss: 0.00010526589903747663 | Test Loss: 0.0001065671895048581\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 56 | Train Loss: 0.00010597871005302295 | Test Loss: 0.00010617774387355894\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 56 | Train Loss: 0.00010640519758453593 | Test Loss: 0.00010578914225334302\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 56 | Train Loss: 0.00010428114183014259 | Test Loss: 0.00010540352377574891\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [00:06<00:04, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Train Loss: 0.00010454712173668668 | Test Loss: 0.00010501987708266824\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 56 | Train Loss: 0.00010449074761709198 | Test Loss: 0.0001046370089170523\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 56 | Train Loss: 0.00010496371396584436 | Test Loss: 0.0001042578587657772\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 56 | Train Loss: 0.00010294358799001202 | Test Loss: 0.00010387966176494956\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 56 | Train Loss: 0.00010366924107074738 | Test Loss: 0.00010350429511163384\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 56 | Train Loss: 0.00010185949940932915 | Test Loss: 0.00010313134407624602\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 57 | Train Loss: 0.00010255106462864205 | Test Loss: 0.0001027609032462351\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 57 | Train Loss: 0.00010297405970050022 | Test Loss: 0.00010238960385322571\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 57 | Train Loss: 0.00010092707816511393 | Test Loss: 0.00010202314297202975\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 57 | Train Loss: 0.00010119389480678365 | Test Loss: 0.00010165713320020586\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 57 | Train Loss: 0.00010113774624187499 | Test Loss: 0.00010129393922397867\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 57 | Train Loss: 0.0001016131354845129 | Test Loss: 0.00010093124001286924\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 57 | Train Loss: 9.965888602891937e-05 | Test Loss: 0.00010057116742245853\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 57 | Train Loss: 0.00010035929881269112 | Test Loss: 0.00010021292109740898\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 57 | Train Loss: 9.861327998805791e-05 | Test Loss: 9.985810902435333e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 58 | Train Loss: 9.928557847160846e-05 | Test Loss: 9.950474486686289e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 58 | Train Loss: 9.97041497612372e-05 | Test Loss: 9.915226837620139e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 58 | Train Loss: 9.77324671112001e-05 | Test Loss: 9.880182187771425e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 58 | Train Loss: 9.799783583730459e-05 | Test Loss: 9.845314343692735e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [00:06<00:04, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Train Loss: 9.794311336008832e-05 | Test Loss: 9.810639312490821e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 58 | Train Loss: 9.84185971901752e-05 | Test Loss: 9.775973012438044e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 58 | Train Loss: 9.65272993198596e-05 | Test Loss: 9.741661051521078e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 58 | Train Loss: 9.72038324107416e-05 | Test Loss: 9.707664139568806e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 58 | Train Loss: 9.552111441735178e-05 | Test Loss: 9.673625754658133e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 59 | Train Loss: 9.617167233955115e-05 | Test Loss: 9.639894415158778e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 59 | Train Loss: 9.658635099185631e-05 | Test Loss: 9.606270032236353e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 59 | Train Loss: 9.468490316066891e-05 | Test Loss: 9.572874841978773e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 59 | Train Loss: 9.494902042206377e-05 | Test Loss: 9.539588791085407e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 59 | Train Loss: 9.489540389040485e-05 | Test Loss: 9.50647154240869e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 59 | Train Loss: 9.537004370940849e-05 | Test Loss: 9.47349180933088e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 59 | Train Loss: 9.354147914564237e-05 | Test Loss: 9.440754365641624e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 59 | Train Loss: 9.41943289944902e-05 | Test Loss: 9.408144978806376e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 59 | Train Loss: 9.256733028450981e-05 | Test Loss: 9.375709487358108e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 60 | Train Loss: 9.320085518993437e-05 | Test Loss: 9.343502460978925e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 60 | Train Loss: 9.361100819660351e-05 | Test Loss: 9.311352914664894e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 60 | Train Loss: 9.177577885566279e-05 | Test Loss: 9.279538789996877e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 60 | Train Loss: 9.203977242577821e-05 | Test Loss: 9.247741400031373e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 60 | Train Loss: 9.198764018947259e-05 | Test Loss: 9.216058242600411e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [00:06<00:03, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | Train Loss: 9.245986439054832e-05 | Test Loss: 9.184756345348433e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 60 | Train Loss: 9.069030784303322e-05 | Test Loss: 9.153322025667876e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 60 | Train Loss: 9.132017294177786e-05 | Test Loss: 9.122195478994399e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 60 | Train Loss: 8.974876254796982e-05 | Test Loss: 9.091227548196912e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 61 | Train Loss: 9.036436676979065e-05 | Test Loss: 9.060483716893941e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 61 | Train Loss: 9.076962305698544e-05 | Test Loss: 9.029701323015615e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 61 | Train Loss: 8.899829117581248e-05 | Test Loss: 8.999321289593354e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 61 | Train Loss: 8.926062582759187e-05 | Test Loss: 8.968866313807666e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 61 | Train Loss: 8.920804248191416e-05 | Test Loss: 8.938649989431724e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 61 | Train Loss: 8.967983012553304e-05 | Test Loss: 8.90854571480304e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 61 | Train Loss: 8.796241309028119e-05 | Test Loss: 8.87869464349933e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 61 | Train Loss: 8.857469219947234e-05 | Test Loss: 8.848898869473487e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 61 | Train Loss: 8.705449727131054e-05 | Test Loss: 8.819242066238075e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 62 | Train Loss: 8.765370876062661e-05 | Test Loss: 8.789893763605505e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 62 | Train Loss: 8.805411926005036e-05 | Test Loss: 8.76045087352395e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 62 | Train Loss: 8.634268306195736e-05 | Test Loss: 8.731401612749323e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 62 | Train Loss: 8.660402818350121e-05 | Test Loss: 8.702321792952716e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 62 | Train Loss: 8.65519032231532e-05 | Test Loss: 8.673435513628647e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 62 | Train Loss: 8.70218500494957e-05 | Test Loss: 8.644536137580872e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [00:06<00:03, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 | Train Loss: 8.535628148820251e-05 | Test Loss: 8.616088598500937e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 62 | Train Loss: 8.594925020588562e-05 | Test Loss: 8.587499178247526e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 62 | Train Loss: 8.447880099993199e-05 | Test Loss: 8.559299749322236e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 63 | Train Loss: 8.506275480613112e-05 | Test Loss: 8.531211642548442e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 63 | Train Loss: 8.545804303139448e-05 | Test Loss: 8.50291908136569e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 63 | Train Loss: 8.380337385460734e-05 | Test Loss: 8.475040522171184e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 63 | Train Loss: 8.406180859310552e-05 | Test Loss: 8.44734167912975e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 63 | Train Loss: 8.401068043895066e-05 | Test Loss: 8.419805089943111e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 63 | Train Loss: 8.44791138661094e-05 | Test Loss: 8.392165182158351e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 63 | Train Loss: 8.28636038932018e-05 | Test Loss: 8.364690438611433e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 63 | Train Loss: 8.343625086126849e-05 | Test Loss: 8.337524923263118e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 63 | Train Loss: 8.201554010156542e-05 | Test Loss: 8.310431439895183e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 64 | Train Loss: 8.258216985268518e-05 | Test Loss: 8.283412171294913e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 64 | Train Loss: 8.297128806589171e-05 | Test Loss: 8.25665847514756e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 64 | Train Loss: 8.137462282320485e-05 | Test Loss: 8.229891682276502e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 64 | Train Loss: 8.16307365312241e-05 | Test Loss: 8.203227480407804e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 64 | Train Loss: 8.157904085237533e-05 | Test Loss: 8.176748815458268e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 64 | Train Loss: 8.204334153560922e-05 | Test Loss: 8.15046951174736e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 64 | Train Loss: 8.047706796787679e-05 | Test Loss: 8.124277519527823e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [00:06<00:03, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 | Train Loss: 8.10323326732032e-05 | Test Loss: 8.098110993159935e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 64 | Train Loss: 7.965685654198751e-05 | Test Loss: 8.072124182945117e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 65 | Train Loss: 8.020785026019439e-05 | Test Loss: 8.04624505690299e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 65 | Train Loss: 8.059113315539435e-05 | Test Loss: 8.020576933631673e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 65 | Train Loss: 7.904643280198798e-05 | Test Loss: 7.995001215022057e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 65 | Train Loss: 7.930154970381409e-05 | Test Loss: 7.96951717347838e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 65 | Train Loss: 7.925018144305795e-05 | Test Loss: 7.944135722937062e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 65 | Train Loss: 7.971204468049109e-05 | Test Loss: 7.918826304376125e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 65 | Train Loss: 7.81892886152491e-05 | Test Loss: 7.893695874372497e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 65 | Train Loss: 7.872739661252126e-05 | Test Loss: 7.868619286455214e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 65 | Train Loss: 7.739543070783839e-05 | Test Loss: 7.843787898309529e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 66 | Train Loss: 7.793278200551867e-05 | Test Loss: 7.819172606104985e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 66 | Train Loss: 7.831196853658184e-05 | Test Loss: 7.794411794748157e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 66 | Train Loss: 7.681623537791893e-05 | Test Loss: 7.769787771394476e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 66 | Train Loss: 7.706783071625978e-05 | Test Loss: 7.745409675408155e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 66 | Train Loss: 7.701681897742674e-05 | Test Loss: 7.721022120676935e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 66 | Train Loss: 7.747564086457714e-05 | Test Loss: 7.69695034250617e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 66 | Train Loss: 7.599775562994182e-05 | Test Loss: 7.672733772778884e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 66 | Train Loss: 7.651809573872015e-05 | Test Loss: 7.648774771951139e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [00:07<00:03, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 | Train Loss: 7.522982195951045e-05 | Test Loss: 7.624862337252125e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 67 | Train Loss: 7.57514062570408e-05 | Test Loss: 7.601218385389075e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 67 | Train Loss: 7.612512854393572e-05 | Test Loss: 7.577399810543284e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 67 | Train Loss: 7.467647083103657e-05 | Test Loss: 7.553978502983227e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 67 | Train Loss: 7.492781151086092e-05 | Test Loss: 7.530547009082511e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 67 | Train Loss: 7.487511174986139e-05 | Test Loss: 7.507199188694358e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 67 | Train Loss: 7.533202733611688e-05 | Test Loss: 7.483931403839961e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 67 | Train Loss: 7.389402890112251e-05 | Test Loss: 7.460825145244598e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 67 | Train Loss: 7.440015906468034e-05 | Test Loss: 7.437773456331342e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 67 | Train Loss: 7.315027323784307e-05 | Test Loss: 7.414929132210091e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 68 | Train Loss: 7.365975761786103e-05 | Test Loss: 7.392148836515844e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 68 | Train Loss: 7.402720075333491e-05 | Test Loss: 7.369476952590048e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 68 | Train Loss: 7.26259604562074e-05 | Test Loss: 7.346871279878542e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 68 | Train Loss: 7.287362677743658e-05 | Test Loss: 7.324269972741604e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 68 | Train Loss: 7.281936996150762e-05 | Test Loss: 7.30192186892964e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 68 | Train Loss: 7.327377534238622e-05 | Test Loss: 7.279523561010137e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 68 | Train Loss: 7.187588926171884e-05 | Test Loss: 7.257344987010583e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 68 | Train Loss: 7.23671109881252e-05 | Test Loss: 7.235180964926258e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 68 | Train Loss: 7.115423795767128e-05 | Test Loss: 7.21326214261353e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [00:07<00:02, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 69 | Train Loss: 7.165128772612661e-05 | Test Loss: 7.191453914856538e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 69 | Train Loss: 7.201399421319366e-05 | Test Loss: 7.169664604589343e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 69 | Train Loss: 7.065588579280302e-05 | Test Loss: 7.14795824023895e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 69 | Train Loss: 7.090043072821572e-05 | Test Loss: 7.126451237127185e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 69 | Train Loss: 7.084823300829157e-05 | Test Loss: 7.104883115971461e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 69 | Train Loss: 7.12990658939816e-05 | Test Loss: 7.083451782818884e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 69 | Train Loss: 6.993934221100062e-05 | Test Loss: 7.062134682200849e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 69 | Train Loss: 7.041516801109537e-05 | Test Loss: 7.040854688966647e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 69 | Train Loss: 6.92400717525743e-05 | Test Loss: 7.019764598226175e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 70 | Train Loss: 6.972355913603678e-05 | Test Loss: 6.998753087827936e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 70 | Train Loss: 7.008133979979903e-05 | Test Loss: 6.977861630730331e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 70 | Train Loss: 6.876454426674172e-05 | Test Loss: 6.956927973078564e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 70 | Train Loss: 6.900561129441485e-05 | Test Loss: 6.936253339517862e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 70 | Train Loss: 6.895304977660999e-05 | Test Loss: 6.915619451319799e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 70 | Train Loss: 6.940087041584775e-05 | Test Loss: 6.895017577335238e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 70 | Train Loss: 6.80789744365029e-05 | Test Loss: 6.874525570310652e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 70 | Train Loss: 6.854021921753883e-05 | Test Loss: 6.854043749626726e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 70 | Train Loss: 6.739985110471025e-05 | Test Loss: 6.833797669969499e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [00:07<00:02, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 | Train Loss: 6.787175516365096e-05 | Test Loss: 6.813597428845242e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 71 | Train Loss: 6.822341674705967e-05 | Test Loss: 6.793499778723344e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 71 | Train Loss: 6.694667536066845e-05 | Test Loss: 6.773505447199568e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 71 | Train Loss: 6.718628719681874e-05 | Test Loss: 6.753420893801376e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 71 | Train Loss: 6.713121547363698e-05 | Test Loss: 6.733697227900848e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 71 | Train Loss: 6.757728260708973e-05 | Test Loss: 6.713773473165929e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 71 | Train Loss: 6.628972914768383e-05 | Test Loss: 6.694155308650807e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 71 | Train Loss: 6.673765165032819e-05 | Test Loss: 6.674457108601928e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 71 | Train Loss: 6.563084752997383e-05 | Test Loss: 6.654961907770485e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 72 | Train Loss: 6.609147385461256e-05 | Test Loss: 6.635578029090539e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 72 | Train Loss: 6.643831147812307e-05 | Test Loss: 6.61616722936742e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 72 | Train Loss: 6.51977097732015e-05 | Test Loss: 6.596857565455139e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 72 | Train Loss: 6.54344548820518e-05 | Test Loss: 6.577693420695141e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 72 | Train Loss: 6.53809547657147e-05 | Test Loss: 6.558564928127453e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 72 | Train Loss: 6.582139030797407e-05 | Test Loss: 6.539509195135906e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 72 | Train Loss: 6.456937262555584e-05 | Test Loss: 6.520596070913598e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 72 | Train Loss: 6.500389281427488e-05 | Test Loss: 6.501696771010756e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 72 | Train Loss: 6.392969953594729e-05 | Test Loss: 6.482905882876366e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 73 | Train Loss: 6.437873526010662e-05 | Test Loss: 6.464229227276519e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [00:07<00:02, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 | Train Loss: 6.471962115028873e-05 | Test Loss: 6.44552128505893e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 73 | Train Loss: 6.351558113237843e-05 | Test Loss: 6.427011976484209e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 73 | Train Loss: 6.374970689648762e-05 | Test Loss: 6.408632907550782e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 73 | Train Loss: 6.369736365741119e-05 | Test Loss: 6.390133057720959e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 73 | Train Loss: 6.41331571387127e-05 | Test Loss: 6.371883500833064e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 73 | Train Loss: 6.291370664257556e-05 | Test Loss: 6.353630305966362e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 73 | Train Loss: 6.333531200652942e-05 | Test Loss: 6.335553189273924e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 73 | Train Loss: 6.229335122043267e-05 | Test Loss: 6.317380029940978e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 74 | Train Loss: 6.273106555454433e-05 | Test Loss: 6.299440428847447e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 74 | Train Loss: 6.306738941930234e-05 | Test Loss: 6.281568494159728e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 74 | Train Loss: 6.189884879859164e-05 | Test Loss: 6.263594696065411e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 74 | Train Loss: 6.212927837623283e-05 | Test Loss: 6.245699478313327e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 74 | Train Loss: 6.207481783349067e-05 | Test Loss: 6.228096754057333e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 74 | Train Loss: 6.250860315049067e-05 | Test Loss: 6.210377614479512e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 74 | Train Loss: 6.13191441516392e-05 | Test Loss: 6.192892760736868e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 74 | Train Loss: 6.172955181682482e-05 | Test Loss: 6.175404269015417e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 74 | Train Loss: 6.0716422012774274e-05 | Test Loss: 6.158054020488635e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 75 | Train Loss: 6.114477582741529e-05 | Test Loss: 6.1406048189383e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 75 | Train Loss: 6.147410022094846e-05 | Test Loss: 6.1234095483087e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [00:08<00:02, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 | Train Loss: 6.033946920069866e-05 | Test Loss: 6.106190994614735e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 75 | Train Loss: 6.056810525478795e-05 | Test Loss: 6.089076123316772e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 75 | Train Loss: 6.0515827499330044e-05 | Test Loss: 6.071975440136157e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 75 | Train Loss: 6.0944010328967124e-05 | Test Loss: 6.0549999034265056e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 75 | Train Loss: 5.9785437770187855e-05 | Test Loss: 6.038108404027298e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 75 | Train Loss: 6.018378189764917e-05 | Test Loss: 6.021296576363966e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 75 | Train Loss: 5.919915929553099e-05 | Test Loss: 6.0045047575840726e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 76 | Train Loss: 5.961600618320517e-05 | Test Loss: 5.987726399325766e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 76 | Train Loss: 5.994194725644775e-05 | Test Loss: 5.9710710047511384e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 76 | Train Loss: 5.883841004106216e-05 | Test Loss: 5.954485459369607e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 76 | Train Loss: 5.9063106164103374e-05 | Test Loss: 5.9380734455771744e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 76 | Train Loss: 5.9011694247601554e-05 | Test Loss: 5.921516640228219e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 76 | Train Loss: 5.9435122238937765e-05 | Test Loss: 5.905112993787043e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 76 | Train Loss: 5.830641748616472e-05 | Test Loss: 5.888845771551132e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 76 | Train Loss: 5.869291999260895e-05 | Test Loss: 5.872590190847404e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 76 | Train Loss: 5.7734974689083174e-05 | Test Loss: 5.8564844948705286e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 77 | Train Loss: 5.814391261083074e-05 | Test Loss: 5.840333324158564e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 77 | Train Loss: 5.846398926223628e-05 | Test Loss: 5.8242887462256476e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 77 | Train Loss: 5.739126572734676e-05 | Test Loss: 5.8082787290913984e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [00:08<00:02,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 77 | Train Loss: 5.761332795373164e-05 | Test Loss: 5.7924771681427956e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 77 | Train Loss: 5.756224345532246e-05 | Test Loss: 5.776527541456744e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 77 | Train Loss: 5.798183337901719e-05 | Test Loss: 5.760765270679258e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 77 | Train Loss: 5.6881046475609764e-05 | Test Loss: 5.745040834881365e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 77 | Train Loss: 5.725637311115861e-05 | Test Loss: 5.729328404413536e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 77 | Train Loss: 5.632433021673933e-05 | Test Loss: 5.713718928745948e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 78 | Train Loss: 5.6723783927736804e-05 | Test Loss: 5.698164750356227e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 78 | Train Loss: 5.7039083912968636e-05 | Test Loss: 5.682736082235351e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 78 | Train Loss: 5.599583892035298e-05 | Test Loss: 5.6673485232749954e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 78 | Train Loss: 5.6216053053503856e-05 | Test Loss: 5.651862738886848e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 78 | Train Loss: 5.6163116823881865e-05 | Test Loss: 5.636625792249106e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 78 | Train Loss: 5.657966903527267e-05 | Test Loss: 5.6214292271761224e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 78 | Train Loss: 5.550587229663506e-05 | Test Loss: 5.606135164271109e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 78 | Train Loss: 5.586941188084893e-05 | Test Loss: 5.59113068447914e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 78 | Train Loss: 5.4964340961305425e-05 | Test Loss: 5.5760989198461175e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 79 | Train Loss: 5.5354845244437456e-05 | Test Loss: 5.560937643167563e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 79 | Train Loss: 5.5663393141003326e-05 | Test Loss: 5.5460186558775604e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 79 | Train Loss: 5.464865898829885e-05 | Test Loss: 5.531094211619347e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [00:08<00:01,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 79 | Train Loss: 5.486532609211281e-05 | Test Loss: 5.516274904948659e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 79 | Train Loss: 5.481355037773028e-05 | Test Loss: 5.5015803809510544e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 79 | Train Loss: 5.5225140386028215e-05 | Test Loss: 5.486899317475036e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 79 | Train Loss: 5.417732973000966e-05 | Test Loss: 5.4722178902011365e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 79 | Train Loss: 5.4532280046259984e-05 | Test Loss: 5.457635779748671e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 79 | Train Loss: 5.365012475522235e-05 | Test Loss: 5.443028931040317e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 80 | Train Loss: 5.4031355830375105e-05 | Test Loss: 5.4286363592837006e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 80 | Train Loss: 5.43376081623137e-05 | Test Loss: 5.4142437875270844e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 80 | Train Loss: 5.334944216883741e-05 | Test Loss: 5.399892688728869e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 80 | Train Loss: 5.356419205782004e-05 | Test Loss: 5.385515760281123e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 80 | Train Loss: 5.351187428459525e-05 | Test Loss: 5.371175575419329e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 80 | Train Loss: 5.391822196543217e-05 | Test Loss: 5.357100963010453e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 80 | Train Loss: 5.2896037232130766e-05 | Test Loss: 5.34285391040612e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 80 | Train Loss: 5.323918230715208e-05 | Test Loss: 5.3288535127649084e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 80 | Train Loss: 5.238246012595482e-05 | Test Loss: 5.314815280144103e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 81 | Train Loss: 5.275575676932931e-05 | Test Loss: 5.300791599438526e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 81 | Train Loss: 5.305543527356349e-05 | Test Loss: 5.28685086464975e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 81 | Train Loss: 5.209377923165448e-05 | Test Loss: 5.2730007155332714e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [00:08<00:01,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 81 | Train Loss: 5.230588067206554e-05 | Test Loss: 5.259177851257846e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 81 | Train Loss: 5.225520726526156e-05 | Test Loss: 5.245467400527559e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 81 | Train Loss: 5.2658015192719176e-05 | Test Loss: 5.231748218648136e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 81 | Train Loss: 5.165863694855943e-05 | Test Loss: 5.218022488406859e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 81 | Train Loss: 5.1993236411362886e-05 | Test Loss: 5.204329136176966e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 81 | Train Loss: 5.115713065606542e-05 | Test Loss: 5.190878073335625e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 82 | Train Loss: 5.152295489097014e-05 | Test Loss: 5.177389903110452e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 82 | Train Loss: 5.181890446692705e-05 | Test Loss: 5.163894093129784e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 82 | Train Loss: 5.088156467536464e-05 | Test Loss: 5.150614379090257e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 82 | Train Loss: 5.1091989007545635e-05 | Test Loss: 5.137245898367837e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 82 | Train Loss: 5.104087176732719e-05 | Test Loss: 5.123834853293374e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 82 | Train Loss: 5.143837915966287e-05 | Test Loss: 5.110570782562718e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 82 | Train Loss: 5.046199294156395e-05 | Test Loss: 5.097397661302239e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 82 | Train Loss: 5.0788319640560076e-05 | Test Loss: 5.084246731712483e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 82 | Train Loss: 4.9974809371633455e-05 | Test Loss: 5.071216946817003e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 83 | Train Loss: 5.033195702708326e-05 | Test Loss: 5.0582959374878556e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 83 | Train Loss: 5.062509444542229e-05 | Test Loss: 5.0451213610358536e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 83 | Train Loss: 4.971073940396309e-05 | Test Loss: 5.032197805121541e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [00:08<00:01,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 83 | Train Loss: 4.991807145415805e-05 | Test Loss: 5.019283344154246e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 83 | Train Loss: 4.9866619519889355e-05 | Test Loss: 5.0064136303262785e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 83 | Train Loss: 5.026013241149485e-05 | Test Loss: 4.99361522088293e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 83 | Train Loss: 4.9306789151160046e-05 | Test Loss: 4.980856101610698e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 83 | Train Loss: 4.962452294421382e-05 | Test Loss: 4.9680624215397984e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 83 | Train Loss: 4.883174187853001e-05 | Test Loss: 4.9554444558452815e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 84 | Train Loss: 4.918095874018036e-05 | Test Loss: 4.942843224853277e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 84 | Train Loss: 4.946796252625063e-05 | Test Loss: 4.930237264488824e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 84 | Train Loss: 4.8578614951111376e-05 | Test Loss: 4.9178350309375674e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 84 | Train Loss: 4.878389518125914e-05 | Test Loss: 4.905207970296033e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 84 | Train Loss: 4.873120997217484e-05 | Test Loss: 4.892825381830335e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 84 | Train Loss: 4.912125950795598e-05 | Test Loss: 4.8804678954184055e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 84 | Train Loss: 4.8190362576860934e-05 | Test Loss: 4.868040923611261e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 84 | Train Loss: 4.849776087212376e-05 | Test Loss: 4.8558013077126816e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 84 | Train Loss: 4.772678221343085e-05 | Test Loss: 4.843572241952643e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 85 | Train Loss: 4.806877041119151e-05 | Test Loss: 4.831354090129025e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 85 | Train Loss: 4.835083382204175e-05 | Test Loss: 4.819125751964748e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 85 | Train Loss: 4.748382343677804e-05 | Test Loss: 4.8070851335069165e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [00:09<00:01, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 | Train Loss: 4.768542930833064e-05 | Test Loss: 4.794933556695469e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 85 | Train Loss: 4.7633537178626284e-05 | Test Loss: 4.782967516803183e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 85 | Train Loss: 4.801922113983892e-05 | Test Loss: 4.77101857541129e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 85 | Train Loss: 4.7109195293160155e-05 | Test Loss: 4.7590492613380775e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 85 | Train Loss: 4.740929580293596e-05 | Test Loss: 4.747193452203646e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 85 | Train Loss: 4.665716551244259e-05 | Test Loss: 4.7353696572827175e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 86 | Train Loss: 4.69920014438685e-05 | Test Loss: 4.723579331766814e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 86 | Train Loss: 4.7270150389522314e-05 | Test Loss: 4.711825749836862e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 86 | Train Loss: 4.6425815526163206e-05 | Test Loss: 4.700153294834308e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 86 | Train Loss: 4.662492574425414e-05 | Test Loss: 4.688429908128455e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 86 | Train Loss: 4.657383760786615e-05 | Test Loss: 4.676795651903376e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 86 | Train Loss: 4.695465031545609e-05 | Test Loss: 4.6652141463709995e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 86 | Train Loss: 4.6064331399975345e-05 | Test Loss: 4.653663927456364e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 86 | Train Loss: 4.635752702597529e-05 | Test Loss: 4.6420438593486324e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 86 | Train Loss: 4.5622273319168016e-05 | Test Loss: 4.6306853619171306e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 87 | Train Loss: 4.59512957604602e-05 | Test Loss: 4.619325773091987e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 87 | Train Loss: 4.6225457481341437e-05 | Test Loss: 4.607891241903417e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 87 | Train Loss: 4.540160807664506e-05 | Test Loss: 4.596613143803552e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 87 | Train Loss: 4.5598233555210754e-05 | Test Loss: 4.5852117182221264e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [00:09<00:01,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 | Train Loss: 4.554705446935259e-05 | Test Loss: 4.573999103740789e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 87 | Train Loss: 4.592363984556869e-05 | Test Loss: 4.562679896480404e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 87 | Train Loss: 4.505196920945309e-05 | Test Loss: 4.551580423139967e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 87 | Train Loss: 4.533855462796055e-05 | Test Loss: 4.540474037639797e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 87 | Train Loss: 4.4622891437029466e-05 | Test Loss: 4.529335274128243e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 88 | Train Loss: 4.494359382078983e-05 | Test Loss: 4.518189962254837e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 88 | Train Loss: 4.521220762399025e-05 | Test Loss: 4.507153425947763e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 88 | Train Loss: 4.4408687244867906e-05 | Test Loss: 4.4962362153455615e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 88 | Train Loss: 4.460266063688323e-05 | Test Loss: 4.485373938223347e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 88 | Train Loss: 4.45532459707465e-05 | Test Loss: 4.474322122405283e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 88 | Train Loss: 4.492420703172684e-05 | Test Loss: 4.463428558665328e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 88 | Train Loss: 4.407192318467423e-05 | Test Loss: 4.452651410247199e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 88 | Train Loss: 4.435068694874644e-05 | Test Loss: 4.441833516466431e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 88 | Train Loss: 4.365233689895831e-05 | Test Loss: 4.431043635122478e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 89 | Train Loss: 4.3967007513856515e-05 | Test Loss: 4.420460754772648e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 89 | Train Loss: 4.423281643539667e-05 | Test Loss: 4.409749453770928e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 89 | Train Loss: 4.3449723307276145e-05 | Test Loss: 4.399169483804144e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 89 | Train Loss: 4.364033884485252e-05 | Test Loss: 4.388404340716079e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 89 | Train Loss: 4.358909427537583e-05 | Test Loss: 4.377864388516173e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [00:09<00:00, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 89 | Train Loss: 4.3957337766187266e-05 | Test Loss: 4.367363726487383e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 89 | Train Loss: 4.3123949581058696e-05 | Test Loss: 4.356864155852236e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 89 | Train Loss: 4.339436054578982e-05 | Test Loss: 4.346307832747698e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 89 | Train Loss: 4.271252691978589e-05 | Test Loss: 4.336029815021902e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 90 | Train Loss: 4.3022566387662664e-05 | Test Loss: 4.3256921344436705e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 90 | Train Loss: 4.3282951082801446e-05 | Test Loss: 4.315365004003979e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 90 | Train Loss: 4.2518891859799623e-05 | Test Loss: 4.305000038584694e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 90 | Train Loss: 4.270678255124949e-05 | Test Loss: 4.294637983548455e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 90 | Train Loss: 4.2656025470932946e-05 | Test Loss: 4.284462193027139e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 90 | Train Loss: 4.3020099838031456e-05 | Test Loss: 4.274260572856292e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 90 | Train Loss: 4.2204290366498753e-05 | Test Loss: 4.2641153413569555e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 90 | Train Loss: 4.24681966251228e-05 | Test Loss: 4.2539330024737865e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 90 | Train Loss: 4.180343239568174e-05 | Test Loss: 4.243867806508206e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 91 | Train Loss: 4.210621045785956e-05 | Test Loss: 4.233907020534389e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 91 | Train Loss: 4.236296808812767e-05 | Test Loss: 4.2237876186845824e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 91 | Train Loss: 4.161628748988733e-05 | Test Loss: 4.2137889977311715e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 91 | Train Loss: 4.180204268777743e-05 | Test Loss: 4.203883872833103e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 91 | Train Loss: 4.175300637143664e-05 | Test Loss: 4.193990753265098e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [00:09<00:00, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 | Train Loss: 4.2112758819712326e-05 | Test Loss: 4.183995406492613e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 91 | Train Loss: 4.13132511312142e-05 | Test Loss: 4.174161222181283e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 91 | Train Loss: 4.1570619941921905e-05 | Test Loss: 4.164247729931958e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 91 | Train Loss: 4.0920866013038903e-05 | Test Loss: 4.154511771048419e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 92 | Train Loss: 4.121848178328946e-05 | Test Loss: 4.144692502450198e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 92 | Train Loss: 4.1468960262136534e-05 | Test Loss: 4.1350598621647805e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 92 | Train Loss: 4.0742361306911334e-05 | Test Loss: 4.1253028030041605e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 92 | Train Loss: 4.0924329368863255e-05 | Test Loss: 4.115644333069213e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 92 | Train Loss: 4.087491106474772e-05 | Test Loss: 4.1060575313167647e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 92 | Train Loss: 4.12313274864573e-05 | Test Loss: 4.096468546777032e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 92 | Train Loss: 4.044967863592319e-05 | Test Loss: 4.086900662514381e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 92 | Train Loss: 4.070042268722318e-05 | Test Loss: 4.077289122506045e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 92 | Train Loss: 4.006589369964786e-05 | Test Loss: 4.067984991706908e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 93 | Train Loss: 4.035842721350491e-05 | Test Loss: 4.058457489009015e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 93 | Train Loss: 4.0604823880130425e-05 | Test Loss: 4.048975097248331e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 93 | Train Loss: 3.989376637036912e-05 | Test Loss: 4.03953563363757e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 93 | Train Loss: 4.0073042328003794e-05 | Test Loss: 4.0302656998392195e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 93 | Train Loss: 4.0025242924457416e-05 | Test Loss: 4.020987034891732e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 93 | Train Loss: 4.037735561723821e-05 | Test Loss: 4.0116061427397653e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [00:09<00:00, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 | Train Loss: 3.961151378462091e-05 | Test Loss: 4.002282730652951e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 93 | Train Loss: 3.9856084185885265e-05 | Test Loss: 3.9931463106768206e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 93 | Train Loss: 3.923761687474325e-05 | Test Loss: 3.98387637687847e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 94 | Train Loss: 3.9522117731394246e-05 | Test Loss: 3.974667197326198e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 94 | Train Loss: 3.976504012825899e-05 | Test Loss: 3.965617361245677e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 94 | Train Loss: 3.9072121580829844e-05 | Test Loss: 3.9564500184496865e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 94 | Train Loss: 3.924981501768343e-05 | Test Loss: 3.947306686313823e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 94 | Train Loss: 3.920039307558909e-05 | Test Loss: 3.938287409255281e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 94 | Train Loss: 3.954807834816165e-05 | Test Loss: 3.929282684111968e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 94 | Train Loss: 3.879854193655774e-05 | Test Loss: 3.9203463529702276e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 94 | Train Loss: 3.903782271663658e-05 | Test Loss: 3.911489693564363e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 94 | Train Loss: 3.843390732072294e-05 | Test Loss: 3.902472599293105e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 95 | Train Loss: 3.871271837851964e-05 | Test Loss: 3.893543180311099e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 95 | Train Loss: 3.895206828019582e-05 | Test Loss: 3.8846083043608814e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 95 | Train Loss: 3.8273970858426765e-05 | Test Loss: 3.875683614751324e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 95 | Train Loss: 3.844859384116717e-05 | Test Loss: 3.866902261506766e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 95 | Train Loss: 3.8400474295485765e-05 | Test Loss: 3.8581292756134644e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 95 | Train Loss: 3.8744135963497683e-05 | Test Loss: 3.849368658848107e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 95 | Train Loss: 3.8010006392141804e-05 | Test Loss: 3.840698627755046e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [00:10<00:00, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 | Train Loss: 3.824297527899034e-05 | Test Loss: 3.8320027670124546e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 95 | Train Loss: 3.7652160244761035e-05 | Test Loss: 3.823361112154089e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 96 | Train Loss: 3.792657298617996e-05 | Test Loss: 3.814730007434264e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 96 | Train Loss: 3.816204844042659e-05 | Test Loss: 3.80603814846836e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 96 | Train Loss: 3.749923416762613e-05 | Test Loss: 3.7974616134306416e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 96 | Train Loss: 3.767267116927542e-05 | Test Loss: 3.7888807128183544e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 96 | Train Loss: 3.762315463973209e-05 | Test Loss: 3.780412953346968e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 96 | Train Loss: 3.796391683863476e-05 | Test Loss: 3.771860428969376e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 96 | Train Loss: 3.72451868315693e-05 | Test Loss: 3.763365384656936e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 96 | Train Loss: 3.7471316318260506e-05 | Test Loss: 3.754982753889635e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 96 | Train Loss: 3.6895227822242305e-05 | Test Loss: 3.7465713830897585e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 97 | Train Loss: 3.716323772096075e-05 | Test Loss: 3.7381654692580923e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 97 | Train Loss: 3.7394926039269194e-05 | Test Loss: 3.729844684130512e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 97 | Train Loss: 3.67482534784358e-05 | Test Loss: 3.7214682379271835e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 97 | Train Loss: 3.691876190714538e-05 | Test Loss: 3.713168189278804e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 97 | Train Loss: 3.6870271287625656e-05 | Test Loss: 3.704861956066452e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 97 | Train Loss: 3.7206566048553213e-05 | Test Loss: 3.696526982821524e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 97 | Train Loss: 3.650150028988719e-05 | Test Loss: 3.688308424898423e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 97 | Train Loss: 3.672274397104047e-05 | Test Loss: 3.680136796901934e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:10<00:00, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 97 | Train Loss: 3.615845344029367e-05 | Test Loss: 3.671991726150736e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 98 | Train Loss: 3.64228144462686e-05 | Test Loss: 3.663892493932508e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 98 | Train Loss: 3.6650373658631e-05 | Test Loss: 3.6557936255121604e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 98 | Train Loss: 3.601832577260211e-05 | Test Loss: 3.6477315006777644e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 98 | Train Loss: 3.618772097979672e-05 | Test Loss: 3.6395205825101584e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 98 | Train Loss: 3.61374368367251e-05 | Test Loss: 3.631533036241308e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 98 | Train Loss: 3.647048652055673e-05 | Test Loss: 3.623483280534856e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 98 | Train Loss: 3.5779936297331005e-05 | Test Loss: 3.6154608096694574e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 98 | Train Loss: 3.599559931899421e-05 | Test Loss: 3.60743397322949e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 98 | Train Loss: 3.544325227267109e-05 | Test Loss: 3.599548654165119e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 99 | Train Loss: 3.5702407330973074e-05 | Test Loss: 3.5917284549213946e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 99 | Train Loss: 3.592722350731492e-05 | Test Loss: 3.583821307984181e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 99 | Train Loss: 3.530893809511326e-05 | Test Loss: 3.5758985177380964e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 99 | Train Loss: 3.547486994648352e-05 | Test Loss: 3.5680452128872275e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 99 | Train Loss: 3.542651757015847e-05 | Test Loss: 3.56026430381462e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 99 | Train Loss: 3.5755379940383136e-05 | Test Loss: 3.552458292688243e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 99 | Train Loss: 3.507866131258197e-05 | Test Loss: 3.544676292221993e-05\n",
      "torch.float32\n",
      "torch.float32\n",
      "Epoch 99 | Train Loss: 3.528915112838149e-05 | Test Loss: 3.536952135618776e-05\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Train Loss: 3.474972254480235e-05 | Test Loss: 3.529262539814226e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "model = HookedTransformer(cfg).to(cfg.device)\n",
    "optimizer = t.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "    for batch in range(0, len(train_data), batch_size):\n",
    "        train_logits = model(train_data[batch:batch+batch_size])\n",
    "        print(train_logits.dtype)\n",
    "        print(train_labels.dtype)\n",
    "        train_loss = loss_fn(train_logits, train_labels[batch:batch+batch_size])\n",
    "\n",
    "        train_loss.backward()\n",
    "\n",
    "        train_losses.append(train_loss.item())\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with t.inference_mode():\n",
    "            test_logits = model(test_data)\n",
    "            test_loss = loss_fn(test_logits, test_labels)\n",
    "            test_losses.append(test_loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch} | Train Loss: {train_loss.item()} | Test Loss: {test_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = t.tensor([10] * 10).to(cfg.device)\n",
    "out = model(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0359, -0.3514, -0.1337, -0.3044, -0.7261, -0.2734, -0.5421, -0.9072,\n",
       "         -0.8235,  2.8281]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Must provide a tokenizer if passing a string to the model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model([\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:259\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Input is either a batch of tokens ([batch, pos]) or a text string, a string is automatically tokenized to a batch of a single element. The prepend_bos flag only applies when inputting a text string.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[1;32m    249\u001b[0m \u001b[39mreturn_type Optional[str]: The type of output to return. Can be one of: None (return nothing, don't calculate logits), 'logits' (return logits), 'loss' (return cross-entropy loss), 'both' (return logits and loss)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mNote that loss is the standard \"predict the next token\" cross-entropy loss for GPT-2 style language models - if you want a custom loss function, the recommended behaviour is returning the logits and then applying your custom loss function.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39minput\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39minput\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m    257\u001b[0m     \u001b[39m# If text, convert to tokens (batch_size=1)\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[39massert\u001b[39;00m (\n\u001b[0;32m--> 259\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mMust provide a tokenizer if passing a string to the model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m     \u001b[39m# This is only intended to support passing in a single string\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_tokens(\u001b[39minput\u001b[39m, prepend_bos\u001b[39m=\u001b[39mprepend_bos)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Must provide a tokenizer if passing a string to the model"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f759933a9e0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(test_losses)\n",
    "# plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7590bb3f10>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.semilogy(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75a00730d0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGdCAYAAAAfTAk2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8OUlEQVR4nO3dfXhU9Z3//9fcJJMEklFMk5AaJVoWUFoXsYRQFbatlCqLLf1VkTYtbTfFdRHRa0ultF9jt4XCtV/K9kpv+bmuewlrr62ya/fnZolt5atfEu5s5KY0VkWh4hCUMIkQkszM+f0xOSczmclkJsxMJjPPx3XN1eTMOWfOcOx1Xnl/3p9zbIZhGAIAAMgi9rE+AAAAgGQj4AAAgKxDwAEAAFmHgAMAALIOAQcAAGQdAg4AAMg6BBwAAJB1CDgAACDrOMf6AMZCIBDQqVOnVFxcLJvNNtaHAwAA4mAYhrq7u1VZWSm7PXaNJicDzqlTp1RVVTXWhwEAAEbh5MmTuvLKK2Ouk5MBp7i4WFLwH6ikpGSMjwYAAMSjq6tLVVVV1nU8lpwMOOawVElJCQEHAIBxJp72EpqMAQBA1iHgAACArEPAAQAAWYeAAwAAsg4BBwAAZB0CDgAAyDoEHAAAkHUIOAAAIOsQcAAAQNZJS8D5yU9+ourqahUUFGj27Nl68cUXY66/e/duzZ49WwUFBbrmmmv0s5/9LGKdp59+Wtddd51cLpeuu+467dy5M1WHDwAAxpmUB5xf/vKXWrNmjdavX6/f//73uuWWW/TpT39aJ06ciLr+8ePHdfvtt+uWW27R73//e33rW9/S6tWr9fTTT1vrtLS06O6771ZdXZ1eeeUV1dXV6a677tLevXtT/XUAAMA4YDMMw0jlB9TU1OjGG2/UT3/6U2vZjBkz9JnPfEYbN26MWP+b3/ymnn32WR07dsxadu+99+qVV15RS0uLJOnuu+9WV1eX/vu//9taZ9GiRbr88sv1b//2byMeU1dXl9xut7xeL8+iAgBgnEjk+p3Sh2329fXp4MGDevjhh8OWL1y4UHv27Im6TUtLixYuXBi27FOf+pQee+wx9ff3Ky8vTy0tLXrwwQcj1tm6dWvUffb29qq3t9f6vauraxTfJjcYhqFeX0C9voCOvu2VJHl7+uU3DPkDhs5d6JfdJvX6AnI57eq66JPDblOfLyCH3SaH3abzvT7lOezyBQw57Tb1+vxy2GzyG4ZsssnpsOlCn195Dpucdrv8AUMOu029voDyHTbZ7TYZhmRICgSM4LpOm/LsdvX5A7LbbHLYJYctuI0hWcsMQ+r3B2S322S32WS3Sf1+Q4ZhWMsMQ/KFrGOzBX/XwH7Mh7hFZP+BZ7v5/Yb8hmHtP/ShbzEf/2Yz/42j7DvsHAS/+9B9mh8Tenz+gGQMrG2TeTxDPnbIgkDAUMAY3KctZN9DPzvK4YfsN/pxh34165iHrJ/aP6tCPifOz4v23L7hzuVI+wzd10j7GEms/55C9xHvv2es5xOO/OjC8S1N/8khxBUT83Xfgg+N2eenNOC8++678vv9Ki8vD1teXl4uj8cTdRuPxxN1fZ/Pp3fffVeTJ08edp3h9rlx40Y9+uijl/BNslMgYKj1jff0+pn39UL7GR1626vzvT5d6POP9aEBAMa5az4wIXsDjmnoX5CGYcR81Hm09YcuT2Sf69at00MPPWT93tXVpaqqqvgOPgv19Pm17cU39EJ7h14+cW7Y9YpdTpWVuOQPGJrgcspht6mipEC+QLAi4rDb5cqzq8DpkD8QkM1mU78/oMuK8tTnC1ZEbLLJ4bDJabcpMHAefX5DE11O+QKG+v0BOe02+QKGCvIc8vkD8gWMgcpCsCJR5HKqzxeQzx+QK88hf8CwXi6nXTab5A/I2r/LGawKBYzgsjxHsFLjD6lc5DmDlZzgMkN5juB+zOqGYUgOuyKqOYYhORyDlaDQSszgX/aR/y2Gbm+322L+ZW9+d5tt8C9zQ4OlFWNgf2a1yW4brJwYQ/9OjfKrWbVS6DaGrD/hzc8OP/6h+4my45DjtoX9e4SsP+RzIr9/lL+zR9hmOIYMa/1YlQtr/RH+xA/d30j7jLavRLaPdTxD9xPPvkaSroqa9XlRvgOyzxUT8sf081MacEpLS+VwOCIqKx0dHREVGFNFRUXU9Z1Op6644oqY6wy3T5fLJZfLNdqvkVUu9vv1lX/Zp9Y3zlrLil1O3TrtA1p0fYWuvqJIpRNdKsp3aKLLKaeDOwkAAMaflAac/Px8zZ49W83NzfrsZz9rLW9ubtadd94ZdZva2lr9+te/Dlu2a9cu3XTTTcrLy7PWaW5uDuvD2bVrl+bNm5eCb5E9+v0BrXh8MNysmDdFd3+0SjMm02gNAMguKR+ieuihh1RXV6ebbrpJtbW1+sUvfqETJ07o3nvvlRQcPnr77bf1r//6r5KCM6YaGxv10EMPqb6+Xi0tLXrsscfCZkc98MADuvXWW7Vp0ybdeeed+s///E89//zzeumll1L9dcYtnz+gRVv/j14/c16FeQ59/7MztfTGK8f6sAAASImUB5y7775b7733nr773e/qnXfe0cyZM/Xcc8/p6quvliS98847YffEqa6u1nPPPacHH3xQP/7xj1VZWakf/ehH+tznPmetM2/ePD311FP69re/re985zu69tpr9ctf/lI1NTWp/jrj1v99/T29fua8JOl/33WDbv/w5DE+IgAAUifl98HJRLl4H5y/eeKAnj92Wl+qvVrfvXPmWB8OAAAJS+T6TQdpDnj9zPt6/thpSdKX500Z24MBACANCDg5YHtrcAjwkzPKdO0HJo7x0QAAkHoEnCwXCBj6/w6fkiQt++hVY3w0AACkBwEny7353nmd7uqVy2nXLX9ROtaHAwBAWhBwstyhPwefJ3V9ZYlcTscYHw0AAOlBwMly+98M3tTvhqrLxvZAAABIIwJOFjMMQy+0n5Ek3TKV4SkAQO4g4GSxM929evtcj+w2ae41V4z14QAAkDYEnCz2Wsf7kqSrJhWpKD8tD44HACAjEHCy2OtnggGHe98AAHINASeLHX/3giTpmg9MGOMjAQAgvQg4Wex090VJUnlJwRgfCQAA6UXAyWJnunolEXAAALmHgJPFOgYqOGXFrjE+EgAA0ouAk6UMw9BpKjgAgBxFwMlS5y70q6ffL0kqK6GCAwDILQScLPVHT7ck6crLC7kHDgAg5xBwslS7p0uSNL2iZIyPBACA9CPgZKm3zgbvgXNtGffAAQDkHgJOlvJe6JckTSrKH+MjAQAg/Qg4WcrbEww47sK8MT4SAADSj4CTpc4NBJzLigg4AIDcQ8DJUmYFp4QKDgAgBxFwstS5gR6cywrpwQEA5B4CThYyDENdZg8OQ1QAgBxEwMlCPf1+9fkDkmgyBgDkJgJOFuocGJ7Kd9g1Id8xxkcDAED6EXCyUOf5PknBGVQ2m22MjwYAgPQj4GShzgvBgHM5N/kDAOQoAk4WMoeouAcOACBXEXCy0LmBCs6kCVRwAAC5iYCThTrPmxUcAg4AIDcRcLLQYA8OQ1QAgNxEwMlCnQxRAQByHAEnCw02GRNwAAC5iYCThc4xRAUAyHEEnCx01rrRHxUcAEBuIuBkIfNJ4vTgAAByFQEny/T7A3q/1yeJISoAQO4i4GSZ7os+6+fiAgIOACA3EXCyzPmB6k1Bnl0OOw/aBADkppQGnM7OTtXV1cntdsvtdquurk7nzp2LuY1hGGpoaFBlZaUKCwu1YMECHT16NGydX/ziF1qwYIFKSkpks9lG3GcuudDnlyRNyHeO8ZEAADB2Uhpwli9frra2NjU1NampqUltbW2qq6uLuc3mzZu1ZcsWNTY2av/+/aqoqNBtt92m7u5ua50LFy5o0aJF+ta3vpXKwx+XzvcFKzhFLscYHwkAAGMnZX/mHzt2TE1NTWptbVVNTY0kadu2baqtrVV7e7umTZsWsY1hGNq6davWr1+vpUuXSpKeeOIJlZeXa8eOHVq5cqUkac2aNZKkF154IVWHP25d6KWCAwBAyio4LS0tcrvdVriRpLlz58rtdmvPnj1Rtzl+/Lg8Ho8WLlxoLXO5XJo/f/6w28Sjt7dXXV1dYa9sZc6gmuAi4AAAclfKAo7H41FZWVnE8rKyMnk8nmG3kaTy8vKw5eXl5cNuE4+NGzdafUBut1tVVVWj3lemu2AOUeUzRAUAyF0JB5yGhgbZbLaYrwMHDkiSbLbIWTyGYURdHmro+/FsE8u6devk9Xqt18mTJ0e9r0x3niZjAAAS78FZtWqVli1bFnOdKVOm6NChQzp9+nTEe2fOnImo0JgqKiokBSs5kydPtpZ3dHQMu008XC6XXC7XqLcfTy4wRAUAQOIBp7S0VKWlpSOuV1tbK6/Xq3379mnOnDmSpL1798rr9WrevHlRt6murlZFRYWam5s1a9YsSVJfX592796tTZs2JXqoOem8FXAYogIA5K6U9eDMmDFDixYtUn19vVpbW9Xa2qr6+notXrw4bAbV9OnTtXPnTknBoak1a9Zow4YN2rlzp44cOaIVK1aoqKhIy5cvt7bxeDxqa2vTa6+9Jkk6fPiw2tradPbs2VR9nXHDHKIqYogKAJDDUnoV3L59u1avXm3NilqyZIkaGxvD1mlvb5fX67V+X7t2rXp6enTfffeps7NTNTU12rVrl4qLi611fvazn+nRRx+1fr/11lslSY8//rhWrFiRwm+U+cwm4wk0GQMAcpjNMAxjrA8i3bq6uuR2u+X1elVSUjLWh5NUq//t93r2lVP6X4uv01dvrh7rwwEAIGkSuX7zLKosQw8OAAAEnKxjPaqBHhwAQA4j4GQZ62GbVHAAADmMgJNlrCEqKjgAgBxGwMky582HbXKjPwBADiPgjIHftXeo7eS5lOz7PM+iAgAgtffBQaS3z/XoK4/vlyQd33j7JT1jayjDMEJ6cDi1AIDcRQUnzU53XbR+Nu86nCy9voD8geBtjajgAAByGQEnzcwAIkkdIWEnGbovBoenbDaajAEAuY2Ak2bvD4QQSTrT3ZvUfXdd7JckFbucstuTN/QFAMB4Q8BJMzOESNKZ95MccHoGAk5BXlL3CwDAeEPASbP3ewcrOB1dya7gBPddUkjAAQDkNgJOmnWHDFH19Ce3ydis4JQU0H8DAMhtBJw0C+3B6fMFkrpvc/iLCg4AINcRcNKsO6QHp9+f5IDTMzBERQ8OACDHEXDSLHSIKtkBp9uq4DBEBQDIbQScNOvuDQ04Row1E8eDNgEACCLgpFnoEFVfkis4ZtNyIXcxBgDkOAJOmoVOE+9PcpPxxf7g/gryCDgAgNxGwEmzVPbgWBUcAg4AIMcRcNLs/Yup68G5OBBwCvI4rQCA3MaVMM1SWcG5SAUHAABJBJy06vX5wxqLUzVEVUCTMQAgxxFw0ii0eiMlf4iqp28g4DgJOACA3EbASSOP92LY78meJm7OomKaOAAg1xFw0ujI296w3+nBAQAgNQg4afSHd7okSdPKiyWlLuAwiwoAkOu4EqbR2fN9kqSqSYWSpH5f8npwDMPgPjgAAAwg4KSR2SNjPu07mRWcPn9AgYG8xCwqAECuI+CkUa8vWGEpLgg+DDOZTca9IY99cDk5rQCA3MaVMI3MHpniVFRwQgJOvoPTCgDIbVwJ06inP7yC40vifXDMsJTnsMlmsyVtvwAAjEcEnDSyenAKgxWcZA5RmQ3LVG8AACDgpJU5RGU2Gff2B2QYyanimGEpj/4bAAAIOOlyvtenP3f2SJKuvLxQNlswlLw3MHX8Upk9OHlUcAAAIOCkywNPtVk/lxTmqby4QJJ04uyFpOzf7MFhiAoAAAJO2jx/7LT1c2Gew7rZ38lkBxyGqAAAIOCMhYI8u66aNEGS9MaZ80nZZ1/ILCoAAHIdAWcMFOQ5dEOVW5L08onOpOyTHhwAAAZxNRwDLqddN151uSTplZPnkrLP/oF76jBEBQAAAWdM2Gw2lRW7JEnv9/qSss/BG/1xSgEASOnVsLOzU3V1dXK73XK73aqrq9O5c+dibmMYhhoaGlRZWanCwkItWLBAR48etd4/e/as7r//fk2bNk1FRUW66qqrtHr1anm93lR+lUt25eXBpuIV86ZIGgwiAUPyJeGGf8yiAgBgUEqvhsuXL1dbW5uamprU1NSktrY21dXVxdxm8+bN2rJlixobG7V//35VVFTotttuU3d3tyTp1KlTOnXqlP7xH/9Rhw8f1r/8y7+oqalJX/va11L5VS5ZT1/wJn/L5lRJCh9K6k/CIxvMh20yRAUAgORM1Y6PHTumpqYmtba2qqamRpK0bds21dbWqr29XdOmTYvYxjAMbd26VevXr9fSpUslSU888YTKy8u1Y8cOrVy5UjNnztTTTz9tbXPttdfq+9//vr74xS/K5/PJ6UzZV7ok5nOoivKCxxc6lNTnC6gw33FJ++9nFhUAAJaU/bnf0tIit9tthRtJmjt3rtxut/bs2RN1m+PHj8vj8WjhwoXWMpfLpfnz5w+7jSR5vV6VlJQMG256e3vV1dUV9konwzCsgFOQH/wnDw0iyXgmVT+zqAAAsKTsaujxeFRWVhaxvKysTB6PZ9htJKm8vDxseXl5+bDbvPfee/qHf/gHrVy5cthj2bhxo9UH5Ha7VVVVFe/XSIpeX0DmI6eK8oMhzGazWcNJSQk4fh62CQCAKeGrYUNDg2w2W8zXgQMHJAUv4kMZhhF1eaih7w+3TVdXl+644w5dd911euSRR4bd37p16+T1eq3XyZMn4/mqSXNhoP9GCt7F2GSGEbP6cin6uJMxAACWhBtWVq1apWXLlsVcZ8qUKTp06JBOnz4d8d6ZM2ciKjSmiooKScFKzuTJk63lHR0dEdt0d3dr0aJFmjhxonbu3Km8vLxhj8flcsnlcsU85lS60BecCp7vsMthHwxq+U671JucCg43+gMAYFDCAae0tFSlpaUjrldbWyuv16t9+/Zpzpw5kqS9e/fK6/Vq3rx5Ubeprq5WRUWFmpubNWvWLElSX1+fdu/erU2bNlnrdXV16VOf+pRcLpeeffZZFRQUJPo10qqrJxhwSgrD/7nNPpyf/O41zftQqe66afRDZ9wHBwCAQSm7Gs6YMUOLFi1SfX29Wltb1draqvr6ei1evDhsBtX06dO1c+dOScGhqTVr1mjDhg3auXOnjhw5ohUrVqioqEjLly+XFKzcLFy4UOfPn9djjz2mrq4ueTweeTwe+f3+qMcy1s5d6JMkXVaUH7bcHE76j7ZTWvurQzp1rmfUn2FVcJzMogIAIKVzqrdv367Vq1dbs6KWLFmixsbGsHXa29vDbtK3du1a9fT06L777lNnZ6dqamq0a9cuFRcXS5IOHjyovXv3SpI+9KEPhe3r+PHjmjJlSgq/0eh0XuiXJE0aEnCGVluajnj01ZurR/UZ5wf6fCbmZ+Y0eQAA0imlV8NJkybpySefjLmOYYTf5M5ms6mhoUENDQ1R11+wYEHENpmu06rghPcJDZ3xdLLzwqg/w3zkw8QCAg4AADRspEHn+WDAuXyYISpTR3fvqD/j/YvBKtFEFwEHAAACThqYQ1SXTxgScIZUcM50XULAGajgFFPBAQCAgJMO3p5gwBk6RHW6+2LM3xPRfXFgiMo1/HR5AAByBQEnDS6az6Ea8ryp997vC/v9zCUMUVkBhwoOAAAEnHTo9QUDjmtIz03oHY6lwSA0GlaTMT04AAAQcNKhd+AeNS5n7CeGBwwpEEh8hphhGPTgAAAQgoCTBr39ZsAZ+Z/bN4qAc7E/IP/AdhOo4AAAQMBJh4vmEFVe+D/3khsqJUl/E3JzP18g8edSmUNgklTAwzYBAEjtjf4QZFZwCoYMUW3+fz6i5TVX6SNXuvX/vnRc0ugqOP3+wW1CH+YJAECuIuCkQe8wFZyCPIfmXnNFWN+Nz594wDGrPnkOm2w2Ag4AAIxnpMFITcZ2u01mLhnNEJUZipx2TicAABIBJy3M6d+xmozzBsLJaCo4/f5gKHIyPAUAgCQCTlrEM03c7J3xj6IHx9zG6SDgAAAgEXDSwgo4ecP/c5vhxKzGJMJsMnY6OJ0AAEgEnJTz+QfvUTN0FlUo5yVUcKwmY4aoAACQRMBJObN6I41UwRnowbmEaeJUcAAACOKKmGKhz5fKjxFAzArOqKaJm03G9OAAACCJgJNyZgUn32GXPcYQktlkPKpp4maTMUNUAABIIuCkXJ8ZcEZ4hELeJQxRDQYcTicAABIBJ+XMWVEjBRxHEoao8hiiAgBAEgEn5frivAmf8xKGqGgyBgAgHFfEFDPDR94I4cNsEB7dEBV3MgYAIBQBJ8V8cQ5ROS/hUQ2+OEMUAAC5gitiivXF2R8zeKO/0QxRBbdxUMEBAEASASfl+uN80vfgoxpG/ywqmowBAAgi4KRY/8A08bw4h6hG86iGfqaJAwAQhitiilnTxEcaorqEh21yJ2MAAMIRcFKsPxDnLKpLedgmTcYAAIThiphi1hDViAHnEh62yTRxAADCEHBSrD/OWVQO8z44oxqi4kZ/AACE4oqYYoMBZ4RnUdkv5UZ/PGwTAIBQBJwU64uzP8ZxCUNUNBkDABCOgJNivngrOAPh5Ng7XTKMxEKOL85GZgAAcgVXxBQbfJp47OpKUb5TkvSfbaf0+P99M6HP6PPRZAwAQCgCTor1xXkn4+ICp/Xz1udfTegz+uN83hUAALmCK2KKxdtkHBpwzGpOvMwKDgEHAIAgrogpZvXgjDBEVVKQZ/1c5HIk9Bl91t2SOZ0AAEgEnJQzH545UvgIreBMGGUFx0UFBwAASQSclDOrKyP14EwMG6JKsILDEBUAAGG4IqbY4NPEYw9RTXRdQsChyRgAgDBcEVOsP87+GLttMAAVuRIbouo1KziOxIIRAADZKqUBp7OzU3V1dXK73XK73aqrq9O5c+dibmMYhhoaGlRZWanCwkItWLBAR48eDVtn5cqVuvbaa1VYWKgPfOADuvPOO/XHP/4xhd9k9OJ9mviUKyZYPztsid3PhiEqAADCpfSKuHz5crW1tampqUlNTU1qa2tTXV1dzG02b96sLVu2qLGxUfv371dFRYVuu+02dXd3W+vMnj1bjz/+uI4dO6b/+Z//kWEYWrhwofx+fyq/zqjE+zRxd1Gevn7rNcFtEnzgJgEHAIBwiY2FJODYsWNqampSa2urampqJEnbtm1TbW2t2tvbNW3atIhtDMPQ1q1btX79ei1dulSS9MQTT6i8vFw7duzQypUrJUlf//rXrW2mTJmi733ve7rhhhv05ptv6tprr03VVxqV/gSeE1VdOmFgm8Qe1cA0cQAAwqXsitjS0iK3222FG0maO3eu3G639uzZE3Wb48ePy+PxaOHChdYyl8ul+fPnD7vN+fPn9fjjj6u6ulpVVVVR1+nt7VVXV1fYK13inSYuDVZ5qOAAAHBpUnZF9Hg8Kisri1heVlYmj8cz7DaSVF5eHra8vLw8Ypuf/OQnmjhxoiZOnKimpiY1NzcrPz8/6n43btxo9QG53e5hg1Aq9MV5J+PgOsEqjy8wuoDDfXAAAAhK+IrY0NAgm80W83XgwAFJki1Ks6xhGFGXhxr6frRtvvCFL+j3v/+9du/eralTp+quu+7SxYsXo+5v3bp18nq91uvkyZOJfOVLMvg08ZGHqKwKjm+UQ1QEHAAAJI2iB2fVqlVatmxZzHWmTJmiQ4cO6fTp0xHvnTlzJqJCY6qoqJAUrORMnjzZWt7R0RGxjVmNmTp1qubOnavLL79cO3fu1D333BOxX5fLJZfLNeJ3SwVziCovjvBhPg28f5QVHHpwAAAISjjglJaWqrS0dMT1amtr5fV6tW/fPs2ZM0eStHfvXnm9Xs2bNy/qNtXV1aqoqFBzc7NmzZolSerr69Pu3bu1adOmmJ9nGIZ6e3sT/Dap8X9ePaMrJubr+kr34MM2R7iTsTQYgujBAQDg0qTsijhjxgwtWrRI9fX1am1tVWtrq+rr67V48eKwGVTTp0/Xzp07JQWHptasWaMNGzZo586dOnLkiFasWKGioiItX75ckvTGG29o48aNOnjwoE6cOKGWlhbdddddKiws1O23356qrxO34++e15f+eZ/u+NFLkkJ7cOIYohoIQb4EZlEZhsEQFQAAQ6Rsmrgkbd++XatXr7ZmRS1ZskSNjY1h67S3t8vr9Vq/r127Vj09PbrvvvvU2dmpmpoa7dq1S8XFxZKkgoICvfjii9q6das6OztVXl6uW2+9VXv27Ina1Jxux999P+x3q4ITR/gwQ1BfAhWc0HUJOAAABKU04EyaNElPPvlkzHUMI7xaYbPZ1NDQoIaGhqjrV1ZW6rnnnkvWISadTYOVmj5fwKrGxNMf43QkXsExh6fi/QwAAHIBV8QU6unzJ3Sjv/xR3Aen+6IvuH+7jWniAAAM4IqYZL7AYPXlQr/PqrDEdR+cgSeOJ3InY29PvyTpsqK8EaffAwCQKwg4SdbTP/g8rAt9/oTuZOy0J17BMQNOSWFeIocJAEBWI+AkWU+fL+Rnv3VX4ngqOPlWD078AefchYEKDgEHAAALASfJevoGKzjne32DN/qLowfH7NM53+fXoT+fi+vzugYqOG4CDgAAFgJOkvX0D1Zfui4OVnOccVRwPlA8eLfl3/3xTFyfd66nT5J0WVH053ABAJCLCDhJFtqDc+5Cn/VzvE8TX15zlaT4H7jppYIDAEAEAk6ShfbghFZw4hmikqSiPIek+G/2d743GKgmuBzxHiIAAFmPgJNkoRUcs7pis0kOe3wBx3oeVZxPFPcPTEt3xvGsKwAAcgVXxSTr6RusvLzeEXxsQ57DHvc9avIGglC8Q1Q+K+BwDxwAAEwEnCQ73zs4LLX3+HuSBkNLPPISvJuxfyAIOeIcAgMAIBcQcJKs62K/9fO77webjAvz4++PcVoBJ74hKio4AABEIuAkmdl3E6ogL/6AYzYjx1/BCQYcBz04AABYuComWWgFx1SYQMDJdyb2RHEqOAAARCLgJFlXjy9iWUJDVAOVmHinifv9ZgWHgAMAgImAk0SBgKHuKBWc0QxRxfs8Kio4AABEIuAk0fk+nwbyhia7C6zliQxR5SXYZGzNoiLgAABgIeAkkXnn4nynXaUTB58rNZqAE+8QlVXBYZo4AAAWAk4SmU/2LinIU3GB01pelNA08cSGqJhFBQBAJK6KSTS9olhHHv2Unlt9sya6BgNOQQIBJ5/74AAAcMmcI6+CeNlsNk10OTXR5VRZyeiGqJyjvg8OAQcAABMVnBS5vtJt/Ty6JmNmUQEAMFoEnBSZGRJwEske1jTxALOoAAAYLQJOilxfWaK/KJ8oSZpaXhz3dlYFxxdnBcdvVnA4lQAAmOjBSRG73ab/uv8WHT3l1Q1XXhb3doN3Mo63gkMPDgAAQxFwUijfadesqy5PcBtziCqxJmPugwMAwCDGNTJMwkNUVHAAAIhAwMkwTjPgxN1kzCwqAACGIuBkmALnQA+OLxDX3Yx9zKICACACASfDXFaUb00rf+9834jrD1ZwOJUAAJi4KmYYh91mPajzTHfviOsP9uCk9LAAABhXuCxmIPMxDx3dF0dc17wPDg/bBABgEFfFDPSBhCo4wR4cmowBABhEwMlAZcUFkqSOrpEDDjf6AwAgEgEnA32geKCC8378PThUcAAAGETAyUBWD84IFZxAwJAxcLscKjgAAAwi4GSgsjgrOKFPHGeaOAAAg7gqZiBziGqkWVT+kIDj4FlUAABYCDgZyGwyHmkWVegDOenBAQBgEAEnA01wBR/yfrE/oECMZ1L1+0OHqAg4AACYCDgZKC9kuKk/MPzzqC72+yVJ+Q679ZBOAACQ4oDT2dmpuro6ud1uud1u1dXV6dy5czG3MQxDDQ0NqqysVGFhoRYsWKCjR48Ou+6nP/1p2Ww2/cd//Efyv8AYyQsJK6FVmqF6BgKOK49wAwBAqJReGZcvX662tjY1NTWpqalJbW1tqquri7nN5s2btWXLFjU2Nmr//v2qqKjQbbfdpu7u7oh1t27dKpst+4Zm8kMDjm/4Ck5PXzDgFOY5Un5MAACMJ85U7fjYsWNqampSa2urampqJEnbtm1TbW2t2tvbNW3atIhtDMPQ1q1btX79ei1dulSS9MQTT6i8vFw7duzQypUrrXVfeeUVbdmyRfv379fkyZNT9TXGhN1uk9Nuky9gqN8/8hBVYT4BBwCAUCmr4LS0tMjtdlvhRpLmzp0rt9utPXv2RN3m+PHj8ng8WrhwobXM5XJp/vz5YdtcuHBB99xzjxobG1VRUTHisfT29qqrqyvslenMYareWBWcfio4AABEk7KA4/F4VFZWFrG8rKxMHo9n2G0kqby8PGx5eXl52DYPPvig5s2bpzvvvDOuY9m4caPVB+R2u1VVVRXv1xgzZqNx7ApO8L0CAg4AAGESDjgNDQ2y2WwxXwcOHJCkqP0xhmGM2Dcz9P3QbZ599ln99re/1datW+M+5nXr1snr9VqvkydPxr3tWMl3Bk9NPE3GVHAAAAiXcA/OqlWrtGzZspjrTJkyRYcOHdLp06cj3jtz5kxEhcZkDjd5PJ6wvpqOjg5rm9/+9rd6/fXXddlll4Vt+7nPfU633HKLXnjhhYj9ulwuuVyumMecacwhqpgVnD56cAAAiCbhgFNaWqrS0tIR16utrZXX69W+ffs0Z84cSdLevXvl9Xo1b968qNtUV1eroqJCzc3NmjVrliSpr69Pu3fv1qZNmyRJDz/8sP7mb/4mbLsPf/jD+uEPf6i//uu/TvTrZCwz4PTFCDhmBaeAaeIAAIRJ2SyqGTNmaNGiRaqvr9fPf/5zSdLXv/51LV68OGwG1fTp07Vx40Z99rOflc1m05o1a7RhwwZNnTpVU6dO1YYNG1RUVKTly5dLClZ5ojUWX3XVVaqurk7V10k7qwcnjiZjenAAAAiXsoAjSdu3b9fq1autWVFLlixRY2Nj2Drt7e3yer3W72vXrlVPT4/uu+8+dXZ2qqamRrt27VJxcXEqDzXjDA5RDd+Dc5EeHAAAokppwJk0aZKefPLJmOsYRvgF3GazqaGhQQ0NDXF/ztB9ZIPBJmOmiQMAkCiaNzJUPD04NBkDABAdASdDxXMfHHpwAACIjoCToawKTswm4+B7DFEBABCOgJOh8uO4D475sE0qOAAAhCPgZKjBHpzhG6h7fWYPDqcRAIBQXBkzlDWLKtYQVR+zqAAAiIaAk6HieVQDTcYAAERHwMlQ+c7gLKrYTcZUcAAAiIaAk6Ec9mDA8QVi3MmY++AAABAVASdDOWzBgBOIcZfmiz6miQMAEA0BJ0M57MFTE6uCwzRxAACiI+BkqIEeYwWGCTiGYdBkDADAMAg4Gcqs4PiHCTi9Ic3H9OAAABCOgJOhzArOcENUFweqN5JU4OQ0AgAQiitjhhqpydis4NhtktPBaQQAIBRXxgw1UpOxeX+cfKo3AABE4OqYoUZqMjYrOPlUbwAAiMDVMUPZB270N1yT8WAFhwZjAACGIuBkKOdIAWfgGVUuhqgAAIjA1TFD2QeajP3DNBnTgwMAwPC4OmaoESs49OAAADAsro4ZyjHiEFXwPjhUcAAAiMTVMUPF32TMKQQAYCiujhlqpCEqpokDADA8ro4ZiiZjAABGj6tjhnI64psmTsABACASV8cMZVVw6MEBACBhXB0z1IizqAYCjoseHAAAInB1zFBx3weHCg4AABG4OmaoEZuM6cEBAGBYXB0zlDlENdzTxK0hKgIOAAARuDpmKDPg+EaYRZVHDw4AABG4OmaokZqMzeVmrw4AABhEwMlQ1hDVMD04ZsCxE3AAAIhAwMlQDlvsISoz+JjrAQCAQQScDDVSkzEVHAAAhkfAyVAjNRkP9Bhb6wEAgEEEnAw1UgWHISoAAIZHwMlQ1iwqmowBAEgYASdDjThN3KrgpO2QAAAYNwg4GcoxwtPEzaErenAAAIiU0oDT2dmpuro6ud1uud1u1dXV6dy5czG3MQxDDQ0NqqysVGFhoRYsWKCjR4+GrbNgwQLZbLaw17Jly1L4TdJv5CZjhqgAABhOSgPO8uXL1dbWpqamJjU1NamtrU11dXUxt9m8ebO2bNmixsZG7d+/XxUVFbrtttvU3d0dtl59fb3eeecd6/Xzn/88lV8l7WgyBgBg9Jyp2vGxY8fU1NSk1tZW1dTUSJK2bdum2tpatbe3a9q0aRHbGIahrVu3av369Vq6dKkk6YknnlB5ebl27NihlStXWusWFRWpoqIiVYc/5kZ6mjgVHAAAhpeyCk5LS4vcbrcVbiRp7ty5crvd2rNnT9Rtjh8/Lo/Ho4ULF1rLXC6X5s+fH7HN9u3bVVpaquuvv15///d/H1HhCdXb26uurq6wV6ZzOkZqMg7+LxUcAAAipayC4/F4VFZWFrG8rKxMHo9n2G0kqby8PGx5eXm53nrrLev3L3zhC6qurlZFRYWOHDmidevW6ZVXXlFzc3PU/W7cuFGPPvroaL/KmDCHqPr9hvr9gYinhtNkDADA8BKu4DQ0NEQ0+A59HThwQJJki1JdMAwj6vJQQ98fuk19fb0++clPaubMmVq2bJl+9atf6fnnn9fLL78cdX/r1q2T1+u1XidPnkz0a6ddsSvP+vkT/3t3xPsMUQEAMLyEKzirVq0accbSlClTdOjQIZ0+fTrivTNnzkRUaExmT43H49HkyZOt5R0dHcNuI0k33nij8vLy9Kc//Uk33nhjxPsul0sulyvmMWeawnyH9fOJsxciQp6fJmMAAIaVcMApLS1VaWnpiOvV1tbK6/Vq3759mjNnjiRp79698nq9mjdvXtRtzGGn5uZmzZo1S5LU19en3bt3a9OmTcN+1tGjR9Xf3x8WirKNP2BYfTlS6BDVWB0RAACZK2WXxxkzZmjRokWqr69Xa2urWltbVV9fr8WLF4fNoJo+fbp27twpKTg0tWbNGm3YsEE7d+7UkSNHtGLFChUVFWn58uWSpNdff13f/e53deDAAb355pt67rnn9PnPf16zZs3Sxz72sVR9nTE3dDaV+budCg4AABFS1mQsBWc6rV692poVtWTJEjU2Noat097eLq/Xa/2+du1a9fT06L777lNnZ6dqamq0a9cuFRcXS5Ly8/P1m9/8Rv/0T/+k999/X1VVVbrjjjv0yCOPyOFwKFsNnU1lVnAIOAAAREppwJk0aZKefPLJmOsYQyoTNptNDQ0NamhoiLp+VVWVdu+ObLrNdhEBx5wmTpMxAAAR6ODIYA9+8i+snwOB8PeYRQUAwPAIOBns/o9/yPrZNyTh8KgGAACGR8DJYHa7TWZ+iWgytio46T4qAAAyH5fHDGdWaCKGqKjgAAAwLAJOhjObiEOHqHp9fr1x5nzY+wAAYBABJ8OZASa0grPumcPWzzQZAwAQiYCT4cwhqNAenGdefjvifQAAMIiAk+HMCs3Q++CYGKICACASASfDOUcIONzJGACASAScDEcFBwCAxBFwMpw1TdwYLuCk82gAABgfuDxmuMFp4gxRAQAQLwJOhnMwRAUAQMIIOBnOug/OMENUVHAAAIhEwMlwZoHG56eCAwBAvAg4Gc458DTN4ZuMCTgAAAxFwMlwI00TZ4gKAIBIBJwMZ04DDw04oUUbKjgAAEQi4GQ461lUIQHHFlK14VlUAABEIuBkOGuaeEgPTmiksXEGAQCIwOUxw1nTxMMqOCHvU8EBACACASfDmU3EoXcytoXUcOjBAQAgEgEnwzkdsW/0RwEHAIBIBJwMZ4/SZFx5WYH1cz5P2wQAIAJXxwwX62Gbv/z63LAZVQAAIIiAk+HMJuLQJmNzRlW+k9MHAEA0XCEzXLRp4v6B51KZj3EAAADhuEJmOEeURzWYw1XMoAIAIDoCToaL9iwqPwEHAICYCDgZLtqjGqjgAAAQGwEnwzntkffBMRuOnQQcAACiIuBkOHuUaeJUcAAAiI2Ak+HMoanNTe0Ry8y7HAMAgHAEnAz3R0+39bM5NOULBCRRwQEAYDgEnAxXf0u19bMvYCgQMGSOVnEfHAAAouMKmeEWzaywfvYFAmE3/HPwmAYAAKJyjvUBILbQKo0vYMhuCwk49OAAABAVASfDhU4F9/kNOUICDtPEAQCIjiGqDGe322TmGF8gIJ8/pIJDwAEAICoCzjhgDlP5/IYOvHVWklQ6MZ8KDgAAwyDgjAPm/W58fkMv/uldSdLtH54sG03GAABEldKA09nZqbq6OrndbrndbtXV1encuXMxtzEMQw0NDaqsrFRhYaEWLFigo0ePRqzX0tKij3/845owYYIuu+wyLViwQD09PSn6JmPLYd3NOKCz5/skSVdNKhrLQwIAIKOlNOAsX75cbW1tampqUlNTk9ra2lRXVxdzm82bN2vLli1qbGzU/v37VVFRodtuu03d3YM3vGtpadGiRYu0cOFC7du3T/v379eqVatkz9L7wuQ5BoaoAoa8Pf2SpJLCvLE8JAAAMlrKZlEdO3ZMTU1Nam1tVU1NjSRp27Ztqq2tVXt7u6ZNmxaxjWEY2rp1q9avX6+lS5dKkp544gmVl5drx44dWrlypSTpwQcf1OrVq/Xwww9b206dOjVVX2XMWRUc/2DAcRNwAAAYVspKHi0tLXK73Va4kaS5c+fK7XZrz549Ubc5fvy4PB6PFi5caC1zuVyaP3++tU1HR4f27t2rsrIyzZs3T+Xl5Zo/f75eeumlYY+lt7dXXV1dYa/xJC9kiKqLgAMAwIhSFnA8Ho/KysoilpeVlcnj8Qy7jSSVl5eHLS8vL7fee+ONNyRJDQ0Nqq+vV1NTk2688UZ94hOf0J/+9Keo+924caPVB+R2u1VVVTXq7zUWnFGGqAg4AAAML+GA09DQIJvNFvN14MABSYo6y8cwjBFn/wx9P3SbwMCDJleuXKmvfOUrmjVrln74wx9q2rRp+ud//ueo+1u3bp28Xq/1OnnyZKJfe0w5Q4aoui4ScAAAGEnCPTirVq3SsmXLYq4zZcoUHTp0SKdPn45478yZMxEVGlNFRfC5Sx6PR5MnT7aWd3R0WNuYy6+77rqwbWfMmKETJ05E3a/L5ZLL5Yp5zJnMnCbefbFf/QM3+iPgAAAwvIQDTmlpqUpLS0dcr7a2Vl6vV/v27dOcOXMkSXv37pXX69W8efOiblNdXa2Kigo1Nzdr1qxZkqS+vj7t3r1bmzZtkhQMT5WVlWpvbw/b9tVXX9WnP/3pRL/OuOAYmB1mVm8kqSjfMVaHAwBAxktZD86MGTO0aNEi1dfXq7W1Va2traqvr9fixYvDZlBNnz5dO3fulBQcmlqzZo02bNignTt36siRI1qxYoWKioq0fPlya51vfOMb+tGPfqRf/epXeu211/Sd73xHf/zjH/W1r30tVV9nTOUNVHAu9PklSfkOOzf5AwAghpQ+bHP79u1avXq1NStqyZIlamxsDFunvb1dXq/X+n3t2rXq6enRfffdp87OTtXU1GjXrl0qLi621lmzZo0uXryoBx98UGfPntUNN9yg5uZmXXvttan8OmPGnCa+fucRSYOBBwAARGczDMMYebXs0tXVJbfbLa/Xq5KSkrE+nBHduvl3OnH2gvX7ZUV5avtfC2NsAQBA9knk+p2dt/7NMn2+QNjv5p2NAQBAdFwpx4Fenz/s93wCDgAAMXGlHAcu9g+t4NCDAwBALASccWBoBYchKgAAYuNKOQ4EhrSBE3AAAIiNK+U45GSICgCAmAg445B/aEkHAACEIeCMQz4/AQcAgFgIOONQfyAw8koAAOQwAs44sPoTU8N+p4IDAEBsBJxx4MFPTlXruk9Yv/v8VHAAAIiFgDMO2Gw2VbgLrN/7aTIGACAmAs44xCwqAABiI+CMQ/0MUQEAEBMBZxyiyRgAgNgIOOOQj2niAADERMAZh/qp4AAAEBMBZxy54Uq3JGnR9RVjfCQAAGQ251gfAOL32IqP6rnD7+jOv/zgWB8KAAAZjYAzjpROdOlLtVPG+jAAAMh4DFEBAICsQ8ABAABZh4ADAACyDgEHAABkHQIOAADIOgQcAACQdQg4AAAg6xBwAABA1iHgAACArEPAAQAAWYeAAwAAsg4BBwAAZB0CDgAAyDo5+TRxwzAkSV1dXWN8JAAAIF7mddu8jseSkwGnu7tbklRVVTXGRwIAABLV3d0tt9sdcx2bEU8MyjKBQECnTp1ScXGxbDZbUvfd1dWlqqoqnTx5UiUlJUndNxLH+cg8nJPMwvnILJyP2AzDUHd3tyorK2W3x+6yyckKjt1u15VXXpnSzygpKeE/zgzC+cg8nJPMwvnILJyP4Y1UuTHRZAwAALIOAQcAAGQdAk6SuVwuPfLII3K5XGN9KBDnIxNxTjIL5yOzcD6SJyebjAEAQHajggMAALIOAQcAAGQdAg4AAMg6BBwAAJB1CDhJ9JOf/ETV1dUqKCjQ7Nmz9eKLL471IWWljRs36qMf/aiKi4tVVlamz3zmM2pvbw9bxzAMNTQ0qLKyUoWFhVqwYIGOHj0atk5vb6/uv/9+lZaWasKECVqyZIn+/Oc/p/OrZKWNGzfKZrNpzZo11jLOR/q9/fbb+uIXv6grrrhCRUVF+su//EsdPHjQep9zkj4+n0/f/va3VV1drcLCQl1zzTX67ne/q0AgYK3D+UgBA0nx1FNPGXl5eca2bduMP/zhD8YDDzxgTJgwwXjrrbfG+tCyzqc+9Snj8ccfN44cOWK0tbUZd9xxh3HVVVcZ77//vrXOD37wA6O4uNh4+umnjcOHDxt33323MXnyZKOrq8ta59577zU++MEPGs3NzcbLL79s/NVf/ZVxww03GD6fbyy+VlbYt2+fMWXKFOMjH/mI8cADD1jLOR/pdfbsWePqq682VqxYYezdu9c4fvy48fzzzxuvvfaatQ7nJH2+973vGVdccYXxX//1X8bx48eNf//3fzcmTpxobN261VqH85F8BJwkmTNnjnHvvfeGLZs+fbrx8MMPj9ER5Y6Ojg5DkrF7927DMAwjEAgYFRUVxg9+8ANrnYsXLxput9v42c9+ZhiGYZw7d87Iy8sznnrqKWudt99+27Db7UZTU1N6v0CW6O7uNqZOnWo0Nzcb8+fPtwIO5yP9vvnNbxo333zzsO9zTtLrjjvuML761a+GLVu6dKnxxS9+0TAMzkeqMESVBH19fTp48KAWLlwYtnzhwoXas2fPGB1V7vB6vZKkSZMmSZKOHz8uj8cTdj5cLpfmz59vnY+DBw+qv78/bJ3KykrNnDmTczZKf/d3f6c77rhDn/zkJ8OWcz7S79lnn9VNN92kz3/+8yorK9OsWbO0bds2633OSXrdfPPN+s1vfqNXX31VkvTKK6/opZde0u233y6J85EqOfmwzWR799135ff7VV5eHra8vLxcHo9njI4qNxiGoYceekg333yzZs6cKUnWv3m08/HWW29Z6+Tn5+vyyy+PWIdzlrinnnpKL7/8svbv3x/xHucj/d544w399Kc/1UMPPaRvfetb2rdvn1avXi2Xy6UvfelLnJM0++Y3vymv16vp06fL4XDI7/fr+9//vu655x5J/H8kVQg4SWSz2cJ+NwwjYhmSa9WqVTp06JBeeumliPdGcz44Z4k7efKkHnjgAe3atUsFBQXDrsf5SJ9AIKCbbrpJGzZskCTNmjVLR48e1U9/+lN96UtfstbjnKTHL3/5Sz355JPasWOHrr/+erW1tWnNmjWqrKzUl7/8ZWs9zkdyMUSVBKWlpXI4HBEpuqOjIyKRI3nuv/9+Pfvss/rd736nK6+80lpeUVEhSTHPR0VFhfr6+tTZ2TnsOojPwYMH1dHRodmzZ8vpdMrpdGr37t360Y9+JKfTaf17cj7SZ/LkybruuuvCls2YMUMnTpyQxP9H0u0b3/iGHn74YS1btkwf/vCHVVdXpwcffFAbN26UxPlIFQJOEuTn52v27Nlqbm4OW97c3Kx58+aN0VFlL8MwtGrVKj3zzDP67W9/q+rq6rD3q6urVVFREXY++vr6tHv3but8zJ49W3l5eWHrvPPOOzpy5AjnLEGf+MQndPjwYbW1tVmvm266SV/4whfU1tama665hvORZh/72Mcibp3w6quv6uqrr5bE/0fS7cKFC7Lbwy+3DofDmibO+UiRMWpuzjrmNPHHHnvM+MMf/mCsWbPGmDBhgvHmm2+O9aFlnb/927813G638cILLxjvvPOO9bpw4YK1zg9+8APD7XYbzzzzjHH48GHjnnvuiTrl8sorrzSef/554+WXXzY+/vGPM+UySUJnURkG5yPd9u3bZzidTuP73/++8ac//cnYvn27UVRUZDz55JPWOpyT9Pnyl79sfPCDH7SmiT/zzDNGaWmpsXbtWmsdzkfyEXCS6Mc//rFx9dVXG/n5+caNN95oTVtGckmK+nr88cetdQKBgPHII48YFRUVhsvlMm699Vbj8OHDYfvp6ekxVq1aZUyaNMkoLCw0Fi9ebJw4cSLN3yY7DQ04nI/0+/Wvf23MnDnTcLlcxvTp041f/OIXYe9zTtKnq6vLeOCBB4yrrrrKKCgoMK655hpj/fr1Rm9vr7UO5yP5bIZhGGNZQQIAAEg2enAAAEDWIeAAAICsQ8ABAABZh4ADAACyDgEHAABkHQIOAADIOgQcAACQdQg4AAAg6xBwAABA1iHgAACArEPAAQAAWYeAAwAAss7/D6X/VH+LSHZsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(t.tensor(test_losses)-t.tensor(train_losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
