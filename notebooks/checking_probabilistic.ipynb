{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphatoe import game, data, train, evals\n",
    "import torch\n",
    "from torch.nn.functional import cross_entropy\n",
    "from tqdm import tqdm\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating all possible games...\n",
      "Generated 255168 games\n",
      "Generated array of moves\n",
      "torch.Size([255168, 10])\n",
      "Generated data and labels\n",
      "One hot encoded labels\n"
     ]
    }
   ],
   "source": [
    "# Combine all data to get loss across all games\n",
    "train_data, train_labels, test_data, test_labels = data.gen_data(\"all\")\n",
    "all_data = torch.cat([train_data, test_data])\n",
    "all_labels = torch.cat([train_labels, test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255168/255168 [01:53<00:00, 2246.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Drop the dummy dimension here\n",
    "logits = einops.rearrange(torch.stack([game.autoregressive_guess(seq)[0] for seq in tqdm(all_data) ]), 'batch seq tokens -> (batch seq) tokens')\n",
    "arranged_labels = train.rearrange(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss \u001b[39m=\u001b[39m cross_entropy(torch\u001b[39m.\u001b[39;49msoftmax(logits[\u001b[39m0\u001b[39;49m], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), arranged_labels[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "loss = cross_entropy(torch.softmax(logits, dim=1), arranged_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "          -inf])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(logits[0])\n",
    "print(arranged_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:20<00:00, 496.45it/s]\n"
     ]
    }
   ],
   "source": [
    "sampled_games = evals.sample_games(game.autoregressive_guess, temp=1, num_games = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4404\n"
     ]
    }
   ],
   "source": [
    "error_rate = evals.error_rate(sampled_games)\n",
    "print(error_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
